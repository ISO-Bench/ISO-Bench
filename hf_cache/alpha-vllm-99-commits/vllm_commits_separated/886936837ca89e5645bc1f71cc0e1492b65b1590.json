{
  "commit_hash": "886936837ca89e5645bc1f71cc0e1492b65b1590",
  "pr_url": "https://github.com/vllm-project/vllm/pull/7209",
  "pr_date": "2024-12-14",
  "timeline_text": "Copy link Contributor llsj14 commented Aug 6, 2024 ‚Ä¢ edited Loading Uh oh! There was an error while loading. Please reload this page . FIX #6923 Summary I discovered that the eviction logic with the OrderedDict free_table in Evictor V1 and V2 slows down overall performance (especially TTFT ) when using prefix caching mode. In some scenarios, utilizing prefix caching mode makes the system slower compared to when prefix caching is not used. The evict function is frequently called when allocating a new block, as no block is evicted until the block space is full in prefix caching mode. The eviction logic was slow because free_table is declared as an OrderedDict, which is a linked list, and it tries to find a block with content hash (Evictor V1) or block ID (Evictor V2) in this free_table. Utilizing a priority queue and lazy deletion helps find the block faster. Result Verification As shown in the following output, the block ID and content hash had the same value between the as-is and to-be states (which is expected). With this change, I could make the duration of the evict function much faster. ===============================\nevicted_block_id compare:  12010   12010\ncontent_hash_compare:  -7334740008364413937   -7334740008364413937\nas-is evict duration:  7.0807114243507385 ms\nto-be evict duration:  0.012848526239395142 ms\n===============================\nevicted_block_id compare:  12038   12038\ncontent_hash_compare:  -7008894356950570757   -7008894356950570757\nas-is evict duration:  7.1028973907232285 ms\nto-be evict duration:  0.008581206202507019 ms\n=============================== Performance I checked the TTFT performance using llmperf and the Llama3-8B model with an A100 GPU. I benchmarked with 1536 input token length (512 same prefix + 1024 random input) and 512 output token length. By applying this commit, I can make the system faster while utilizing prefix caching. The speed-up metric is calculated based on the performance without prefix caching mode. as-is Model Num Clients Block Manager Prefix Caching TTFT (mean) Speed Up Llama3-8B 16 v2 X 841 ms Llama3-8B 32 v2 X 1441 ms Llama3-8B 64 v2 X 2619 ms Llama3-8B 128 v2 X 4729 ms Llama3-8B 16 v2 O 1962 ms 0.43 (slowed down) Llama3-8B 32 v2 O 8382 ms 0.17 (slowed down) Llama3-8B 64 v2 O 12665 ms 0.21 (slowed down) Llama3-8B 128 v2 O 22439 ms 0.21 (slowed down) to-be Model Num Clients Block Manager Prefix Caching TTFT (mean) Speed Up Llama3-8B 16 v2 O 541 ms 1.55 Llama3-8B 32 v2 O 901 ms 1.60 Llama3-8B 64 v2 O 1563 ms 1.68 Llama3-8B 128 v2 O 2947 ms 1.60 Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 4 robertgshaw2-redhat, appleeji, jeongin601, and MonadKai reacted with thumbs up emoji üéâ 2 jeongin601 and nickandbro reacted with hooray emoji All reactions üëç 4 reactions üéâ 2 reactions Copy link github-actions bot commented Aug 6, 2024 üëã Hi! Thank you for contributing to the vLLM project. Just a reminder: PRs would not trigger full CI run by default. Instead, it would only run fastcheck CI which consists a small and essential subset of CI tests to quickly catch errors. You can run other CI tests on top of default ones by unblocking the steps in your fast-check build on Buildkite UI. Once the PR is approved and ready to go, please make sure to run full CI as it is required to merge (or just use auto-merge). To run full CI, you can do one of these: Comment /ready on the PR Add ready label to the PR Enable auto-merge. üöÄ All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Member youkaichao commented Aug 6, 2024 thanks for the contribution! cc @alexm-neuralmagic @cadedaniel for block manager related optimization. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Yard1 reviewed Aug 6, 2024 View reviewed changes vllm/core/evictor_v2.py Outdated def update(self, block_id: int, last_accessed: float): self.free_table[block_id].last_accessed = last_accessed def _cleanup_if_necessary(self): if len(self.priority_queue) > 50 * len(self.free_table): Copy link Collaborator Yard1 Aug 6, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment that 50 constant should be a defined global. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 llsj14 reacted with thumbs up emoji All reactions üëç 1 reaction Copy link Contributor Author llsj14 Aug 7, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment @Yard1 , thank you for your comments. I have fixed the issue and rebased my code. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Copy link Collaborator Yard1 commented Aug 6, 2024 FYI this PR seems to be optimizing the same path #7193 All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Collaborator cadedaniel commented Aug 6, 2024 At high level these fixes look great, will need evictor folks to review with more detail (sorry for second ping @robertgshaw2-neuralmagic ) ‚ù§Ô∏è 1 llsj14 reacted with heart emoji All reactions ‚ù§Ô∏è 1 reaction Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Collaborator robertgshaw2-redhat commented Aug 7, 2024 At high level these fixes look great, will need evictor folks to review with more detail (sorry for second ping @robertgshaw2-neuralmagic ) Thanks, Alex is going to take a look from out side, since he most recently has been in this codepath optimizing BMv2 ‚ù§Ô∏è 2 cadedaniel and llsj14 reacted with heart emoji All reactions ‚ù§Ô∏è 2 reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . llsj14 force-pushed the feat/optimize-evict branch\n    from 8071838 to 95495a7 Compare August 7, 2024 00:05 alexm-redhat reviewed Aug 7, 2024 View reviewed changes Copy link Collaborator alexm-redhat left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Thanks for revealing this bottleneck and fixing it! It is a good idea to use a heap + dict to quickly access an LRU item. Left some minor comments. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 llsj14 reacted with thumbs up emoji All reactions üëç 1 reaction vllm/core/evictor_v2.py Outdated def add(self, block_id: int, content_hash: int, num_hashed_tokens: int, last_accessed: float): self.free_table[block_id] = BlockMetaData(content_hash, num_hashed_tokens, last_accessed) heapq.heappush( self.priority_queue, (last_accessed, -num_hashed_tokens, content_hash, block_id)) Copy link Collaborator alexm-redhat Aug 7, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Nice trick with the -num_hashed_tokens to provide heap sorting. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/core/evictor_v2.py Outdated heapq.heappush( self.priority_queue, (last_accessed, -num_hashed_tokens, content_hash, block_id)) self._cleanup_if_necessary() Copy link Collaborator alexm-redhat Aug 7, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Why it was necessary to delay the cleanup? Did you find it to be too slow? Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 llsj14 reacted with thumbs up emoji All reactions üëç 1 reaction Copy link Contributor Author llsj14 Aug 7, 2024 ‚Ä¢ edited Loading Uh oh! There was an error while loading. Please reload this page . There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment The reason I applied lazy deletion and event triggered cleanup is that searching specific block and deleting outdated blocks from the heap is O(log n) . Thus, I skip and pop outdated blocks by checking the free_table in eviction operation, and only clean up the priority queue when it consumes too much memory with outdated blocks. Since cleanup itself is O(n log n) , calling the cleanup function every time would make the system too slow. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Copy link Contributor Author llsj14 Aug 7, 2024 ‚Ä¢ edited Loading Uh oh! There was an error while loading. Please reload this page . There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment The ideal scenario is when the cleanup function is not needed, as outdated blocks are naturally popped out during the eviction operation. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Copy link Contributor Author llsj14 Aug 7, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment @alexm-neuralmagic, thanks to your comment, I fixed the data type mistake and optimized the performance of the cleanup operation. I used only the free_table and heapify to create a new priority queue, achieving O(n) complexity. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/core/evictor_v2.py Outdated @@ -76,7 +79,8 @@ class LRUEvictor(Evictor): \"\"\" def __init__(self): self.free_table: OrderedDict [int, BlockMetaData] = OrderedDict() self.free_table: Dict [int, BlockMetaData] = {} Copy link Collaborator alexm-redhat Aug 7, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Dict is definitely faster here Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/core/evictor_v2.py Outdated from typing import OrderedDict, Tuple from typing import Dict, List, Tuple CLEANUP_THRESHOLD = 50 Copy link Collaborator alexm-redhat Aug 7, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment I would make this a static class member, since it is used only inside the scope of the class below. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 llsj14 reacted with thumbs up emoji All reactions üëç 1 reaction Copy link Contributor Author llsj14 Aug 7, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Thank you, I fixed this Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Copy link Collaborator alexm-redhat commented Aug 7, 2024 btw, I would rename the topic of the PR to \"[Performance] ....\", since it is not a bugfix All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . llsj14 changed the title [Bugfix][Core] Optimize the performance of evictor v1 and v2 by applying a priority queue and lazy deletion [Performance][Core] Optimize the performance of evictor v1 and v2 by applying a priority queue and lazy deletion Aug 7, 2024 Copy link Contributor Author llsj14 commented Aug 9, 2024 /ready All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . github-actions bot added\n  the ready ONLY add when PR is ready to merge/full CI is needed label Aug 9, 2024 llsj14 force-pushed the feat/optimize-evict branch\n    from fd520b2 to 273da1d Compare August 26, 2024 02:41 Copy link Contributor Author llsj14 commented Aug 26, 2024 I rebased codes to resolve the conflict All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . simon-mo requested review from zhuohan123 , youkaichao , comaniac and njhill as code owners November 26, 2024 05:49 Copy link mergify bot commented Nov 26, 2024 This pull request has merge conflicts that must be resolved before it can be merged. Please rebase the PR, @llsj14 . https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/syncing-a-fork All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . mergify bot added\n  the needs-rebase label Nov 26, 2024 llsj14 force-pushed the feat/optimize-evict branch\n    from 273da1d to 5d2bbcc Compare November 29, 2024 03:55 mergify bot removed\n  the needs-rebase label Nov 29, 2024 llsj14 force-pushed the feat/optimize-evict branch\n    from 5d2bbcc to a7ee9c4 Compare November 29, 2024 04:24 Copy link Contributor Author llsj14 commented Nov 29, 2024 @alexm-neuralmagic @Yard1 I rebased and tested my code again. I would appreciate your reviews. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . llsj14 force-pushed the feat/optimize-evict branch\n    from e5eb212 to 7e6b71c Compare December 11, 2024 14:56 Copy link Contributor Author llsj14 commented Dec 11, 2024 ‚Ä¢ edited Loading Uh oh! There was an error while loading. Please reload this page . In my local test, the test_eviction_alloc_mixed sometimes passes and sometimes fails. tests/core/block/test_prefix_caching_block.py ................. [  6%]\n............................................................... [ 29%]\n............................................................... [ 53%]\n............................................................... [ 76%]\n............................................................... [100%]\n=================== 269 passed, 2 warnings in 6.49s =================== I believe the assertion in this part is not strictly necessary, because all blocks can be candidates for eviction if they have same last accessed time. The key difference is that the previous code search blocks from the beginning of the free table, while my implementation does not. @leiwen83 @cadedaniel @comaniac Could you check whether it would be fine to remove the assertion mentioned above and review my PR please? -> I just changed my code to make the test pass. I prioritized the block_id to select the earlier one under the same conditions. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . llsj14 commented Dec 13, 2024 View reviewed changes vllm/core/evictor.py Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . llsj14 force-pushed the feat/optimize-evict branch\n    from e82e821 to 0038286 Compare December 13, 2024 09:13 Copy link Contributor Author llsj14 commented Dec 13, 2024 @comaniac Could you review this PR, please? This PR was previously reviewed, and I have been testing its stability by running it locally for several months. It has also successfully passed unit tests and CI checks. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . comaniac reviewed Dec 13, 2024 View reviewed changes vllm/core/evictor.py Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/core/evictor.py Outdated Comment on lines 92 to 106 while self.priority_queue: # Lazy deletion algorithm is applied. last_accessed, _, block_id, content_hash = heapq.heappop( self.priority_queue) if (block_id in self.free_table and self.free_table[block_id].last_accessed == last_accessed): self.free_table.pop(block_id) return block_id, content_hash Copy link Collaborator comaniac Dec 13, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment I'm a bit worry about this lazy deletion algorithm as it is pretty hard to understand for others and easy to introduce bugs in corner cases. Here are some possible questions people may ask by reading this code: How a block in the heap not in the free table? A related question is why we need to cleanup the heap. How a block in the heap and the free table could have different last access time? Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 llsj14 reacted with thumbs up emoji All reactions üëç 1 reaction Copy link Contributor Author llsj14 Dec 14, 2024 ‚Ä¢ edited Loading Uh oh! There was an error while loading. Please reload this page . There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment @comaniac Thank you for the valuable feedback. I've added comments regarding the lazy deletion process. I understand your concerns about the lazy deletion algorithm, as it shows O(n log n) time complexity when triggered. However, since outdated entries are also removed through heap pops, I believe cleanup is not an operation that happens frequently. In fact, I also considered using doubly linked list and dictionary for this optimization. While these structures are generally O(1), I think that if the key value changes(like num_hashed_tokens in this code) from being solely based on the last accessed time (which always increases), adding entries could then take O(n) time (to make doubly linked list sorted). That‚Äôs why I opted for a priority queue... Nevertheless, I acknowledge the concerns about lazy deletion holding outdated entries. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Copy link Collaborator comaniac Dec 14, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Yes I used doubly linked list in v1 prefix caching and it works well, but it would be tedious for v0. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 llsj14 reacted with thumbs up emoji All reactions üëç 1 reaction Copy link Contributor Author llsj14 Dec 14, 2024 There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Oh I see. I'll check the v1 implementation later as well. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions comaniac approved these changes Dec 14, 2024 View reviewed changes Copy link Collaborator comaniac left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Otherwise LGTM Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/core/evictor.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . llsj14 and others added 14 commits December 14, 2024 01:59 feat: optimize evictor v2 performance using priority queue and lazy d‚Ä¶ ‚Ä¶ 6a28606 ‚Ä¶eletion\n\nSigned-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> refactor: make format ‚Ä¶ 461c8fd Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> refactor: use global defined variable for cleanup threshold ‚Ä¶ ad9bf4a Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> refactor: make CLEAN_THRESHOLD as a static class member ‚Ä¶ a1ef9ec Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> refactor: make format ‚Ä¶ c505a93 Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> fix: optimize priority queue cleanup operation ‚Ä¶ 02e92f7 Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> trigger test ‚Ä¶ 76e4665 Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> prioritize block_id in priority queue ‚Ä¶ 840612a Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> make format ‚Ä¶ add810e Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> retrigger test ‚Ä¶ 1c8c2b8 Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> add comment ‚Ä¶ e1d7d7a Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> make format ‚Ä¶ 0d554e4 Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> update comments ‚Ä¶ b923060 Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>\nSigned-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> make format ‚Ä¶ 46798ad Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com> llsj14 force-pushed the feat/optimize-evict branch\n    from dd3165c to 46798ad Compare December 14, 2024 01:59 Hide details View details comaniac merged commit 8869368 into vllm-project : main Dec 14, 2024 51 checks passed Uh oh! There was an error while loading. Please reload this page . xiangyuT mentioned this pull request Dec 24, 2024 Refine evictor based on #7209 analytics-zoo/vllm#70 Merged PeaBrane mentioned this pull request May 11, 2025 feat: vllm mock workers, Rusty skeleton ai-dynamo/dynamo#1033 Merged Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-07 17:47:28",
  "has_lm_eval": false,
  "has_performance": true,
  "has_serving": false,
  "has_general_test": true,
  "test_details": "PERF: TTFT, TTFT, TTFT | TEST: test, test, test",
  "analysis_extracted_at": "2025-09-07 17:47:28",
  "models": [
    "N/A"
  ],
  "lm_eval_commands": null,
  "perf_command": null,
  "commit_subject": "[Performance][Core] Optimize the performance of evictor v1 and v2 by applying a priority queue and lazy deletion (#7209)",
  "commit_message": "[Performance][Core] Optimize the performance of evictor v1 and v2 by applying a priority queue and lazy deletion (#7209)",
  "commit_date": "2024-12-14T11:38:10-08:00",
  "files_changed": [
    "vllm/core/evictor.py"
  ],
  "functions_changed": [],
  "stats": {
    "num_test_files": 0,
    "num_non_test_files": 1,
    "only_test_files": 0,
    "only_non_test_files": 1,
    "num_files": 1,
    "num_hunks": 3,
    "num_edited_lines": 63,
    "num_non_test_edited_lines": 63,
    "commit_year": 2024
  },
  "diff_text": "diff --git a/vllm/core/evictor.py b/vllm/core/evictor.py\nindex ed7e06cab..44adc4158 100644\n--- a/vllm/core/evictor.py\n+++ b/vllm/core/evictor.py\n@@ -1,6 +1,7 @@\n import enum\n+import heapq\n from abc import ABC, abstractmethod\n-from typing import OrderedDict, Tuple\n+from typing import Dict, List, Tuple\n \n \n class EvictionPolicy(enum.Enum):\n@@ -75,8 +76,14 @@ class LRUEvictor(Evictor):\n     highest num_hashed_tokens value, then one will be chose arbitrarily\n     \"\"\"\n \n+    # CLEANUP_THRESHOLD determines the maximum allowable size of the priority\n+    # queue relative to the free table size. When this threshold is exceeded,\n+    # a cleanup operation is triggered to reduce memory usage.\n+    CLEANUP_THRESHOLD = 50\n+\n     def __init__(self):\n-        self.free_table: OrderedDict[int, BlockMetaData] = OrderedDict()\n+        self.free_table: Dict[int, BlockMetaData] = {}\n+        self.priority_queue = []\n \n     def __contains__(self, block_id: int) -> bool:\n         return block_id in self.free_table\n@@ -85,34 +92,50 @@ class LRUEvictor(Evictor):\n         if len(self.free_table) == 0:\n             raise ValueError(\"No usable cache memory left\")\n \n-        evicted_block, evicted_block_id = None, None\n-        # The blocks with the lowest timestamps should be placed consecutively\n-        # at the start of OrderedDict. Loop through all these blocks to\n-        # find the one with maximum number of hashed tokens.\n-        for _id, block in self.free_table.items():\n-            if evicted_block is None:\n-                evicted_block, evicted_block_id = block, _id\n-                continue\n-            if evicted_block.last_accessed < block.last_accessed:\n-                break\n-            if evicted_block.num_hashed_tokens < block.num_hashed_tokens:\n-                evicted_block, evicted_block_id = block, _id\n-\n-        assert evicted_block is not None\n-        assert evicted_block_id is not None\n-        self.free_table.pop(evicted_block_id)\n-\n-        return evicted_block_id, evicted_block.content_hash\n+        while self.priority_queue:\n+            # We do not remove outdated entries from the priority queue at the\n+            # time of updating the last_accessed timestamp. Instead, outdated\n+            # entries are filtered out here during eviction. Outdated entries\n+            # would either not in the free table, or have older last accessed\n+            # time.\n+            last_accessed, _, block_id, content_hash = heapq.heappop(\n+                self.priority_queue)\n+            if (block_id in self.free_table and\n+                    self.free_table[block_id].last_accessed == last_accessed):\n+                self.free_table.pop(block_id)\n+                return block_id, content_hash\n+\n+        raise ValueError(\"No usable cache memory left\")\n \n     def add(self, block_id: int, content_hash: int, num_hashed_tokens: int,\n             last_accessed: float):\n         self.free_table[block_id] = BlockMetaData(content_hash,\n                                                   num_hashed_tokens,\n                                                   last_accessed)\n+        heapq.heappush(\n+            self.priority_queue,\n+            (last_accessed, -num_hashed_tokens, block_id, content_hash))\n+        self._cleanup_if_necessary()\n \n     def update(self, block_id: int, last_accessed: float):\n         self.free_table[block_id].last_accessed = last_accessed\n \n+    def _cleanup_if_necessary(self):\n+        if len(self.priority_queue) > LRUEvictor.CLEANUP_THRESHOLD * len(\n+                self.free_table):\n+            self._cleanup()\n+\n+    def _cleanup(self):\n+        new_priority_queue: List[Tuple[float, int, int, int]] = []\n+\n+        for block_id, block in self.free_table.items():\n+            new_priority_queue.append(\n+                (block.last_accessed, -block.num_hashed_tokens, block_id,\n+                 block.content_hash))\n+        heapq.heapify(new_priority_queue)\n+\n+        self.priority_queue = new_priority_queue\n+\n     def remove(self, block_id: int):\n         if block_id not in self.free_table:\n             raise ValueError(",
  "apis": [
    "vllm.core.evictor.LRUEvictor.__init__",
    "vllm.core.evictor.LRUEvictor.evict",
    "vllm.core.evictor.LRUEvictor.add"
  ],
  "affected_paths": [
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/core/evictor.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/core/block_manager.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/engine/llm_engine.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/v1/engine/llm_engine.py"
  ],
  "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm",
  "llm_reason": "The commit modifies a non-test source file (vllm/core/evictor.py) and significantly changes the eviction logic by introducing a heap-based priority queue and lazy deletion mechanism. These changes replace the previous Linear search using OrderedDict with a more efficient algorithm for evicting cache blocks. The modifications are non-trivial as they affect core performance by improving the eviction strategy, reducing overhead, and include a cleanup process to maintain efficiency. This commit clearly serves as a performance optimization on CPU, not merely a refactoring or bug fix.",
  "llm_api_reason": "The commit refactors the LRUEvictor class to improve eviction performance by switching from an iterative search inside an ordered dictionary to a heap-based (priority queue) approach with lazy deletion. Changes were made in the constructor (__init__) to initialize a new priority queue, in the evict method to pop outdated entries from the heap until a valid candidate is found, and in the add method to push new entries onto the heap along with triggering periodic cleanup. These modifications optimize eviction operations and reduce memory usage overhead."
}