{
  "commit_hash": "ac45c44d98e77f30e47b8fb69134f4635183070d",
  "pr_url": "https://github.com/vllm-project/vllm/pull/21837",
  "pr_date": null,
  "timeline_text": "Copy link Contributor varun-sundar-rabindranath commented Jul 29, 2025 ‚Ä¢ edited by github-actions bot Loading Uh oh! There was an error while loading. Please reload this page . Purpose DeepEPHighThroughput All2All kernel when used with DeepSeek models dispatches the tokens in 16bit datatype and quantizes after dispatch. This is inefficient for 2 reasons, More data in communication More data to quantize after dispatch This PR introduces a fix to quantize to fp8 first and then dispatch the fp8 tensor. Test Plan canhazgpu  run -g2 -- pytest -s tests/kernels/moe/test_modular_kernel_combinations.py canhazgpu run -g2 -- pytest tests/kernels/moe/test_deepep_deepgemm_moe.py VLLM_ALL2ALL_BACKEND=\"deepep_high_throughput\" VLLM_USE_DEEP_GEMM=1  canhazgpu run -g 2 --  vllm serve Qwen/Qwen3-30B-A3B-FP8  --trust-remote-code --enable-expert-parallel --data-parallel-size 2 --port 9010 --no-enable-prefix-caching Test Result All tests pass for canhazgpu  run -g2 -- pytest -s tests/kernels/moe/test_modular_kernel_combinations.py All tests pass for canhazgpu run -g2 -- pytest tests/kernels/moe/test_deepep_deepgemm_moe.py |Tasks|Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n|-----|------:|----------------|-----:|-----------|---|----:|---|-----:|\n|gsm8k|      3|flexible-extract|     5|exact_match|‚Üë  | 0.86|¬±  |0.0349|\n|     |       |strict-match    |     5|exact_match|‚Üë  | 0.94|¬±  |0.0239| Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Copy link github-actions bot commented Jul 29, 2025 üëã Hi! Thank you for contributing to the vLLM project. üí¨ Join our developer Slack at https://slack.vllm.ai to discuss your PR in #pr-reviews, coordinate on features in #feat- channels, or join special interest groups in #sig- channels. Just a reminder: PRs would not trigger full CI run by default. Instead, it would only run fastcheck CI which starts running only a small and essential subset of CI tests to quickly catch errors. You can run other CI tests on top of those by going to your fastcheck build on Buildkite UI (linked in the PR checks section) and unblock them. If you do not have permission to unblock, ping simon-mo or khluu to add you in our Buildkite org. Once the PR is approved and ready to go, your PR reviewer(s) can run CI to test the changes comprehensively before merging. To run CI, PR reviewers can either: Add ready label to the PR or enable auto-merge. üöÄ All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . mergify bot added\n  the deepseek Related to DeepSeek models label Jul 29, 2025 gemini-code-assist bot reviewed Jul 29, 2025 View reviewed changes Copy link Contributor gemini-code-assist bot left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Code Review This pull request introduces a performance optimization for MoE layers using DeepEPHighThroughput with block quantization (e.g., for DeepSeek models). The change correctly modifies the logic to quantize the activations before dispatching them, which reduces communication overhead and is more efficient. The implementation is clean and effective. The condition for pre-quantization is correctly expanded to include block-quantized cases, and the call to the quantization kernel is updated to pass the correct parameters, which also fixes a potential bug that the logical change would have otherwise introduced. Overall, the changes look solid and align well with the stated purpose. I couldn't find any issues of high or critical severity. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Copy link Contributor Author varun-sundar-rabindranath commented Jul 29, 2025 @tlrmchlsmth @bnellnm PTAL ! Thanks üôå All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Contributor bnellnm commented Jul 29, 2025 So we still go down the \"quantize after\" codepath if the quantization is per-tensor?  Is there some reason that quantization can't happen beforehand in that case also?  Or does DeepEP not support that? All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Contributor Author varun-sundar-rabindranath commented Jul 29, 2025 So we still go down the \"quantize after\" codepath if the quantization is per-tensor? Is there some reason that quantization can't happen beforehand in that case also? Or does DeepEP not support that? It is a DeepEP limitation. DeepEP doesn't support that. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Contributor bnellnm commented Jul 29, 2025 So we still go down the \"quantize after\" codepath if the quantization is per-tensor? Is there some reason that quantization can't happen beforehand in that case also? Or does DeepEP not support that? It is a DeepEP limitation. DeepEP doesn't support that. Would it make sense to fake it out by replicating the scale and then resizing/truncating them after the dispatch? All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Contributor Author varun-sundar-rabindranath commented Jul 30, 2025 ‚Ä¢ edited Loading Uh oh! There was an error while loading. Please reload this page . So we still go down the \"quantize after\" codepath if the quantization is per-tensor? Is there some reason that quantization can't happen beforehand in that case also? Or does DeepEP not support that? It is a DeepEP limitation. DeepEP doesn't support that. Would it make sense to fake it out by replicating the scale and then resizing/truncating them after the dispatch? I went back and looked at the DeepEP documentation here The documentation suggests that only block-quantization is supported. But the function seemingly also supports per-token quantization (We have unit test that have been passing - look here ). However, it looks like we are an assert away in the DeepEP repo from crashing. To be safe, I have updated the code to support only block-quantization for the \"Quant-then-Dispatch\" block. For any other quantization we will \"Dispatch-then-Quant\" cc @tlrmchlsmth üëç 1 bnellnm reacted with thumbs up emoji All reactions üëç 1 reaction Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . tlrmchlsmth approved these changes Jul 31, 2025 View reviewed changes Copy link Collaborator tlrmchlsmth left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Thanks! Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions tlrmchlsmth added\n  the ready ONLY add when PR is ready to merge/full CI is needed label Jul 31, 2025 tlrmchlsmth enabled auto-merge (squash) July 31, 2025 14:33 Varun Sundar Rabindranath added 2 commits August 1, 2025 06:32 quant then dispatch ‚Ä¶ ed5a03f Signed-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com> Remove per-act-token-quant ‚Ä¶ fcf2fe9 Signed-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com> auto-merge was automatically disabled August 1, 2025 06:33 Head branch was pushed to by a user without write access varun-sundar-rabindranath force-pushed the varun/ht-quant-dispatch-ordering branch\n    from 80cb125 to fcf2fe9 Compare August 1, 2025 06:33 varun-sundar-rabindranath changed the title [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant and then Dispatch [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before Dispatch Aug 1, 2025 Hide details View details vllm-bot merged commit ac45c44 into vllm-project : main Aug 1, 2025 41 of 44 checks passed Uh oh! There was an error while loading. Please reload this page . wenscarl pushed a commit\n        to wenscarl/vllm\n      that referenced\n      this pull request Aug 4, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ b787b9a ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: shuw <shuw@nvidia.com> juuice-lee pushed a commit\n        to juuice-lee/vllm-moe.code\n      that referenced\n      this pull request Aug 5, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ a171dbf ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ e53887f ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ fc8f4fa ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: x22x22 <wadeking@qq.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 6058cc5 ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: x22x22 <wadeking@qq.com> npanpaliya pushed a commit\n        to odh-on-pz/vllm-upstream\n      that referenced\n      this pull request Aug 6, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 7f0c9e2 ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com> jingyu-ml pushed a commit\n        to jingyu-ml/vllm\n      that referenced\n      this pull request Aug 8, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 506a08a ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: jingyu <jingyu@omniml.ai> jinzhen-lin pushed a commit\n        to jinzhen-lin/vllm\n      that referenced\n      this pull request Aug 9, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 024bae4 ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: Jinzhen Lin <linjinzhen@hotmail.com> noamgat pushed a commit\n        to noamgat/vllm\n      that referenced\n      this pull request Aug 9, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ e62f88f ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: Noam Gat <noamgat@gmail.com> paulpak58 pushed a commit\n        to paulpak58/vllm\n      that referenced\n      this pull request Aug 13, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 02137be ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: Paul Pak <paulpak58@gmail.com> taneem-ibrahim pushed a commit\n        to taneem-ibrahim/vllm\n      that referenced\n      this pull request Aug 14, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ d35b39e ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com> BoyuanFeng pushed a commit\n        to BoyuanFeng/vllm\n      that referenced\n      this pull request Aug 14, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 0c4f6b9 ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: Boyuan Feng <boyuan@meta.com> diegocastanibm pushed a commit\n        to diegocastanibm/vllm\n      that referenced\n      this pull request Aug 15, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 998c08f ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nSigned-off-by: Diego-Castan <diego.castan@ibm.com> epwalsh pushed a commit\n        to epwalsh/vllm\n      that referenced\n      this pull request Aug 28, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 4a6adca ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com> zhewenl pushed a commit\n        to zhewenl/vllm\n      that referenced\n      this pull request Aug 28, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 4c75149 ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com> googlercolin pushed a commit\n        to googlercolin/vllm\n      that referenced\n      this pull request Aug 29, 2025 [Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before‚Ä¶ ‚Ä¶ 445bac5 ‚Ä¶ Dispatch ( vllm-project#21837 )\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com> Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-07 17:49:52",
  "has_lm_eval": true,
  "has_performance": true,
  "has_serving": true,
  "has_general_test": true,
  "test_details": "LM_EVAL: gsm8k | PERF: optimization | SERVING: vllm serve, serve | TEST: Test, Test, test",
  "analysis_extracted_at": "2025-09-07 17:49:52",
  "models": [
    "deepseek-ai/DeepSeek-V2",
    "deepseek-ai/DeepSeek-V3"
  ],
  "lm_eval_commands": [
    "lm_eval --model vllm --model_args pretrained=deepseek-ai/DeepSeek-V2 --tasks gsm8k"
  ],
  "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V2",
  "commit_subject": "[Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before Dispatch (#21837)",
  "commit_message": "[Bugfix] [Performance] DeepEPHighThroughput + DeepSeek : Quant before Dispatch (#21837)\n\nSigned-off-by: Varun Sundar Rabindranath <vsundarr@redhat.com>\nCo-authored-by: Varun Sundar Rabindranath <vsundarr@redhat.com>",
  "commit_date": "2025-08-01T10:14:38-07:00",
  "files_changed": [
    "vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py"
  ],
  "functions_changed": [],
  "stats": {
    "num_test_files": 0,
    "num_non_test_files": 1,
    "only_test_files": 0,
    "only_non_test_files": 1,
    "num_files": 1,
    "num_hunks": 3,
    "num_edited_lines": 13,
    "num_non_test_edited_lines": 13,
    "commit_year": 2025
  },
  "diff_text": "diff --git a/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py b/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py\nindex 7016ff34c..f6b62254e 100644\n--- a/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py\n+++ b/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py\n@@ -144,12 +144,13 @@ class DeepEPHTPrepareAndFinalize(mk.FusedMoEPrepareAndFinalize):\n                 \"apply_router_weight_on_input is only implemented for topk=1\")\n             a1 = a1 * topk_weights.to(a1.dtype)\n \n-        if quant_config.per_act_token_quant:\n+        if quant_config.is_block_quantized:\n+            # Quant and Dispatch\n             a1q, a1q_scale = moe_kernel_quantize_input(\n                 a1,\n                 a1_scale,\n                 quant_dtype=quant_config.quant_dtype,\n-                per_act_token_quant=True,\n+                per_act_token_quant=quant_config.per_act_token_quant,\n                 block_shape=quant_config.block_shape,\n             )\n             if a1q_scale is not None and a1q_scale.numel() == 1:\n@@ -162,8 +163,10 @@ class DeepEPHTPrepareAndFinalize(mk.FusedMoEPrepareAndFinalize):\n                  rank_topk_weights=topk_weights,\n                  num_experts=num_experts)\n         else:\n-            # DeepEP kernels only support dispatching per-token-quant\n-            # quantization. dispatch in bfloat16.\n+            # Dispatch and Quant\n+            # DeepEP kernels only support dispatching block-quantized\n+            # activation scales.\n+            # Dispatch in bfloat16\n             (expert_x, _, expert_tokens_meta, expert_topk_ids,\n              expert_topk_weights) = self._do_dispatch(\n                  tokens=a1,\n@@ -171,7 +174,7 @@ class DeepEPHTPrepareAndFinalize(mk.FusedMoEPrepareAndFinalize):\n                  rank_topk_ids=topk_ids,\n                  rank_topk_weights=topk_weights,\n                  num_experts=num_experts)\n-            # quantize now\n+            # Quantize after dispatch.\n             expert_x_scale = None\n             if expert_x.numel() != 0:\n                 expert_x, expert_x_scale = moe_kernel_quantize_input(",
  "apis": [
    "DeepEPHTPrepareAndFinalize.prepare"
  ],
  "affected_paths": [
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/model_executor/models/deepseek.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/model_executor/models/deepseek_v2.py"
  ],
  "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm",
  "llm_reason": "The diff updates the logic in a critical numeric computation file (a non-test source file) by changing the conditions and order in which quantization is applied relative to dispatch. The commit changes key internal quantization calls (e.g., switching from per-activation to block quantization under certain conditions and thus altering the computational path), which can have a direct performance impact on the high-throughput MoE process. Despite the commit message containing a bugfix label, the changes are performance sensitive since correcting the quantization order can boost throughput on CPU and improve runtime performance. The commit satisfies conditions for modifying non-test source code and affecting performance of top-level APIs without being tied to specific hardware.",
  "llm_api_reason": "This commit changes the conditional logic in the prepare method of the DeepEPHTPrepareAndFinalize class so that quantization is performed before dispatch when block quantization is enabled. This adjustment alters the behavior of the public prepare API in the fused MoE layer that is used during inference."
}