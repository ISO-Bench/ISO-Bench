{
  "commit_hash": "2f1928354903ae0c6edfe76cc90081eb513ead2c",
  "pr_url": "https://github.com/vllm-project/vllm/pull/3890",
  "pr_date": "2024-04-07",
  "timeline_text": "Copy link Member youkaichao commented Apr 7, 2024 Some code is inefficient. Find some equivalent but more efficient code. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . ðŸš€ 3 ywang96, zhuohan123, and anttttti reacted with rocket emoji All reactions ðŸš€ 3 reactions avoid get_token_ids by len b8cadb3 youkaichao marked this pull request as draft April 7, 2024 01:25 cadedaniel approved these changes Apr 7, 2024 View reviewed changes youkaichao marked this pull request as ready for review April 7, 2024 02:13 youkaichao merged commit 2f19283 into vllm-project : main Apr 7, 2024 youkaichao deleted the latency_optimize branch April 7, 2024 02:14 z103cb pushed a commit\n        to z103cb/opendatahub_vllm\n      that referenced\n      this pull request Apr 22, 2024 [Core] latency optimization ( vllm-project#3890 ) 9d9b6c4 dtrifiro mentioned this pull request May 15, 2024 bump ubi base image tag opendatahub-io/vllm#24 Merged Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-07 17:49:09",
  "has_lm_eval": false,
  "has_performance": true,
  "has_serving": false,
  "has_general_test": false,
  "test_details": "PERF: latency, optimization",
  "analysis_extracted_at": "2025-09-07 17:49:09",
  "models": [
    "N/A"
  ],
  "lm_eval_commands": null,
  "perf_command": null,
  "commit_subject": "[Core] latency optimization (#3890)",
  "commit_message": "[Core] latency optimization (#3890)",
  "commit_date": "2024-04-06T19:14:06-07:00",
  "files_changed": [
    "vllm/core/block_manager_v1.py"
  ],
  "functions_changed": [],
  "stats": {
    "num_test_files": 0,
    "num_non_test_files": 1,
    "only_test_files": 0,
    "only_non_test_files": 1,
    "num_files": 1,
    "num_hunks": 1,
    "num_edited_lines": 2,
    "num_non_test_edited_lines": 2,
    "commit_year": 2024
  },
  "diff_text": "diff --git a/vllm/core/block_manager_v1.py b/vllm/core/block_manager_v1.py\nindex b2aaeb33c..e7e3b4dc1 100644\n--- a/vllm/core/block_manager_v1.py\n+++ b/vllm/core/block_manager_v1.py\n@@ -328,7 +328,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         self,\n         seq: Sequence,\n     ) -> bool:\n-        token_ids_len = len(seq.data.get_token_ids())\n+        token_ids_len = seq.data.get_len()\n         return token_ids_len > 0 and token_ids_len % seq.block_size == 0\n \n     def _maybe_promote_last_block(",
  "apis": [
    "vllm.core.block_manager"
  ],
  "affected_paths": [
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/engine/llm_engine.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/v1/engine/llm_engine.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/entrypoints/api_server.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/entrypoints/openai/api_server.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/entrypoints/openai/serving_completion.py"
  ],
  "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm",
  "llm_reason": "The commit modifies a non-test source file in a non-trivial way. Instead of calling len() on the full token_ids list, it now directly calls get_len(), likely avoiding the cost of list construction and thereby improving latency. The commit message specifically mentions \"latency optimization\", and the change affects the core functionality, likely improving performance for high-level APIs. Overall, it meets the criteria as a performance-related optimization change that is testable on CPU.",
  "llm_api_reason": "The commit replaces a call to get the length of token IDs via seq.data.get_token_ids() with a new, likely more efficient, method seq.data.get_len() within the BlockSpaceManagerV1 class. This change directly affects the code responsible for managing the physical block allocation (KV cache management) in the vLLM core. Since the block manager is exposed as part of the memory management APIs (vllm.core.block_manager), this change affects that API's functionality and latency characteristics."
}