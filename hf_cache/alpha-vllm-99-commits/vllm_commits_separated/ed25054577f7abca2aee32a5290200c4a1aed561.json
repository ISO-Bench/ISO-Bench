{
  "commit_hash": "ed25054577f7abca2aee32a5290200c4a1aed561",
  "pr_url": "https://github.com/vllm-project/vllm/pull/21222",
  "pr_date": "2025-07-19",
  "timeline_text": "Copy link Contributor Jialin commented Jul 19, 2025 ‚Ä¢ edited by github-actions bot Loading Uh oh! There was an error while loading. Please reload this page . Essential Elements of an Effective PR Description Checklist The purpose of the PR, such as \"Fix some issue (link existing issues this PR will resolve)\". The test plan, such as providing test command. The test results, such as pasting the results comparison before and after, or e2e results (Optional) The necessary documentation update, such as updating supported_models.md and examples for a new model. Purpose Most of the block_pool operators are on critical path forward path is hard blocked by kv block allocation decode cycle end is hard blocked by kv block free In this PR, we're focusing on further optimization these 2 operators. Bulk popleft instead of popleft n times Originally, in block_pool.get_new_blocks, we popped blocks one at a time, which would triggered the second block to fake head connections (which are unnecessary operations as the second block might be popped right after this). As we knew total number of blocks to pop ahead, we could simply introduce popleft_n for buck popleft. Overall, the number link list operations to linked list of popleft_n would only be half of n popleft. Bulk append instead of append n times Similar, in block_pool.free_blocks, we invoke append one at a time. Introducing bulk append would also cut link list operations by half. Test Plan Evaluate with benchmark scripts Evaluate with benchmark_blockpoll New Unit Test for append_n and popleft_n are added Test Result benchmark scripts Get new blocks improved from 0.15ms to 0.008ms Free new blocks improved from 33us to 9us After Before benchmark_blockpool As expected, get_blocks and free_blocks times are cut in half. After Before (Optional) Documentation Update Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Jialin requested review from WoosukKwon , robertgshaw2-redhat , njhill , ywang96 , comaniac and alexm-redhat as code owners July 19, 2025 09:39 Copy link github-actions bot commented Jul 19, 2025 üëã Hi! Thank you for contributing to the vLLM project. üí¨ Join our developer Slack at https://slack.vllm.ai to discuss your PR in #pr-reviews, coordinate on features in #feat- channels, or join special interest groups in #sig- channels. Just a reminder: PRs would not trigger full CI run by default. Instead, it would only run fastcheck CI which starts running only a small and essential subset of CI tests to quickly catch errors. You can run other CI tests on top of those by going to your fastcheck build on Buildkite UI (linked in the PR checks section) and unblock them. If you do not have permission to unblock, ping simon-mo or khluu to add you in our Buildkite org. Once the PR is approved and ready to go, your PR reviewer(s) can run CI to test the changes comprehensively before merging. To run CI, PR reviewers can either: Add ready label to the PR or enable auto-merge. üöÄ All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Contributor Author Jialin commented Jul 19, 2025 resolve #21141 All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . mergify bot added\n  the v1 label Jul 19, 2025 gemini-code-assist bot reviewed Jul 19, 2025 View reviewed changes Copy link Contributor gemini-code-assist bot left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Code Review This pull request introduces popleft_n and append_n methods to FreeKVCacheBlockQueue for bulk operations, optimizing get_new_blocks and free_blocks in BlockPool . Benchmark results show significant improvements. To enhance robustness, I've suggested materializing the ordered_blocks iterable to a list in free_blocks to prevent potential OOM errors. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/v1/core/block_pool.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . Jialin mentioned this pull request Jul 18, 2025 [Performance]: Opportunities to speed up BlockPool processing #21141 Open 5 tasks DarkLight1337 requested a review\n  from heheda12345 July 19, 2025 12:19 Jialin force-pushed the blockpool branch\n    from a3253a5 to a3042bd Compare July 20, 2025 10:12 njhill reviewed Jul 20, 2025 View reviewed changes vllm/v1/core/kv_cache_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/core/kv_cache_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/core/block_pool.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/core/block_pool.py Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . Jialin mentioned this pull request Jul 21, 2025 [Core] Minimize number of dict lookup in _maybe_evict_cached_block #21281 Merged 4 tasks njhill reviewed Jul 21, 2025 View reviewed changes vllm/v1/core/kv_cache_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/core/block_pool.py Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/core/block_pool.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . Jialin force-pushed the blockpool branch\n    from 073075f to ca9fca3 Compare July 21, 2025 22:14 houseroad added performance Performance-related issues ready ONLY add when PR is ready to merge/full CI is needed labels Jul 21, 2025 houseroad reviewed Jul 22, 2025 View reviewed changes vllm/v1/core/kv_cache_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . houseroad reviewed Jul 22, 2025 View reviewed changes vllm/v1/core/kv_cache_utils.py Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . houseroad approved these changes Jul 22, 2025 View reviewed changes Copy link Collaborator houseroad left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Looks good to me. Impressive results, and two nits to consider to address. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . ‚ù§Ô∏è 1 Jialin reacted with heart emoji All reactions ‚ù§Ô∏è 1 reaction Jialin added 7 commits July 21, 2025 22:20 Introduce popleft_n and append_n in FreeKVCacheBlockQueue ‚Ä¶ 9353288 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Fix free_blocks to correctly iterate ordered_blocks twice ‚Ä¶ 7dd32ff Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Materialize iterable instead of using itertools.tee ‚Ä¶ d62f3e8 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Address comments ‚Ä¶ a7b16ba Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Address comments (further simplify implementation and avoid list iter‚Ä¶ ‚Ä¶ 429e723 ‚Ä¶ations)\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Added a TODO to clean up incr_ref and decr_ref ‚Ä¶ 3655119 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Address comments ‚Ä¶ ad59a94 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Jialin force-pushed the blockpool branch\n    from ca9fca3 to ad59a94 Compare July 22, 2025 05:23 houseroad enabled auto-merge (squash) July 22, 2025 05:23 njhill approved these changes Jul 22, 2025 View reviewed changes Copy link Member njhill left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Thanks @Jialin ! Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Hide details View details vllm-bot merged commit ed25054 into vllm-project : main Jul 22, 2025 64 of 66 checks passed Uh oh! There was an error while loading. Please reload this page . yeqcharlotte pushed a commit\n        to yeqcharlotte/vllm\n      that referenced\n      this pull request Jul 23, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 4420ad5 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> zixi-qi pushed a commit\n        to zixi-qi/vllm\n      that referenced\n      this pull request Jul 23, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 40ab4c4 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: qizixi <qizixi@meta.com> LyrisZhong pushed a commit\n        to LyrisZhong/vllm\n      that referenced\n      this pull request Jul 23, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ cf5038f ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> avigny pushed a commit\n        to avigny/vllm\n      that referenced\n      this pull request Jul 31, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 40dcc2e ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: avigny <47987522+avigny@users.noreply.github.com> wenscarl pushed a commit\n        to wenscarl/vllm\n      that referenced\n      this pull request Aug 4, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ e28b77c ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: shuw <shuw@nvidia.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ a1cdc67 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: x22x22 <wadeking@qq.com> Pradyun92 pushed a commit\n        to Pradyun92/vllm\n      that referenced\n      this pull request Aug 6, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ a7521ad ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> npanpaliya pushed a commit\n        to odh-on-pz/vllm-upstream\n      that referenced\n      this pull request Aug 6, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 22a3904 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> jinzhen-lin pushed a commit\n        to jinzhen-lin/vllm\n      that referenced\n      this pull request Aug 9, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ aedd951 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: Jinzhen Lin <linjinzhen@hotmail.com> paulpak58 pushed a commit\n        to paulpak58/vllm\n      that referenced\n      this pull request Aug 13, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 231c183 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: Paul Pak <paulpak58@gmail.com> taneem-ibrahim pushed a commit\n        to taneem-ibrahim/vllm\n      that referenced\n      this pull request Aug 14, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 5081f27 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> diegocastanibm pushed a commit\n        to diegocastanibm/vllm\n      that referenced\n      this pull request Aug 15, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 7ad8303 ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: Diego-Castan <diego.castan@ibm.com> epwalsh pushed a commit\n        to epwalsh/vllm\n      that referenced\n      this pull request Aug 28, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ 01377bf ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> googlercolin pushed a commit\n        to googlercolin/vllm\n      that referenced\n      this pull request Aug 29, 2025 [Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to f‚Ä¶ ‚Ä¶ b8e251c ‚Ä¶urther optimize block_pool ( vllm-project#21222 )\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-07 17:50:11",
  "has_lm_eval": false,
  "has_performance": true,
  "has_serving": false,
  "has_general_test": true,
  "test_details": "PERF: optimization | TEST: test, test, test",
  "analysis_extracted_at": "2025-09-07 17:50:11",
  "models": [
    "N/A"
  ],
  "lm_eval_commands": null,
  "perf_command": null,
  "commit_subject": "[Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to further optimize block_pool (#21222)",
  "commit_message": "[Core] Introduce popleft_n and append_n in FreeKVCacheBlockQueue to further optimize block_pool (#21222)\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>",
  "commit_date": "2025-07-22T06:17:47-07:00",
  "files_changed": [
    "tests/v1/core/test_kv_cache_utils.py",
    "vllm/v1/core/block_pool.py",
    "vllm/v1/core/kv_cache_utils.py"
  ],
  "functions_changed": [],
  "stats": {
    "num_test_files": 1,
    "num_non_test_files": 2,
    "only_test_files": 0,
    "only_non_test_files": 0,
    "num_files": 3,
    "num_hunks": 6,
    "num_edited_lines": 203,
    "num_non_test_edited_lines": 98,
    "commit_year": 2025
  },
  "diff_text": "diff --git a/tests/v1/core/test_kv_cache_utils.py b/tests/v1/core/test_kv_cache_utils.py\nindex 68b060156..ccdbe79df 100644\n--- a/tests/v1/core/test_kv_cache_utils.py\n+++ b/tests/v1/core/test_kv_cache_utils.py\n@@ -184,6 +184,111 @@ def test_free_kv_cache_block_queue_operations():\n     assert str(e.value) == \"No free blocks available\"\n \n \n+def test_free_kv_cache_block_queue_append_n():\n+    # Create an empty FreeKVCacheBlockQueue with these blocks\n+    queue = FreeKVCacheBlockQueue([])\n+    blocks = [KVCacheBlock(block_id=i) for i in range(6)]\n+    # Append 0 block\n+    # fake_head->fake_tail\n+    queue.append_n([])\n+    assert queue.num_free_blocks == 0\n+    assert (queue.fake_free_list_head.next_free_block\n+            is queue.fake_free_list_tail)\n+    assert (queue.fake_free_list_tail.prev_free_block\n+            is queue.fake_free_list_head)\n+    # Append 1 block\n+    # fake_head->b0->fake_tail\n+    queue.append_n(blocks[0:1])\n+    assert queue.num_free_blocks == 1\n+    assert queue.fake_free_list_head.next_free_block is blocks[0]\n+    assert blocks[0].prev_free_block is queue.fake_free_list_head\n+    assert blocks[0].next_free_block is queue.fake_free_list_tail\n+    assert queue.fake_free_list_tail.prev_free_block is blocks[0]\n+    # Append 2 blocks\n+    # fake_head->b0->b4->b5->fake_tail\n+    queue.append_n(blocks[4:6])\n+    assert queue.num_free_blocks == 3\n+    assert queue.fake_free_list_head.next_free_block is blocks[0]\n+    assert blocks[0].prev_free_block is queue.fake_free_list_head\n+    assert blocks[0].next_free_block is blocks[4]\n+    assert blocks[4].prev_free_block is blocks[0]\n+    assert blocks[4].next_free_block is blocks[5]\n+    assert blocks[5].prev_free_block is blocks[4]\n+    assert blocks[5].next_free_block is queue.fake_free_list_tail\n+    assert queue.fake_free_list_tail.prev_free_block is blocks[5]\n+    # Append 3 blocks\n+    # fake_head->b0->b4->b5->b1->b2->b3->fake_tail\n+    queue.append_n(blocks[1:4])\n+    assert queue.num_free_blocks == 6\n+    assert queue.fake_free_list_head.next_free_block is blocks[0]\n+    assert blocks[0].prev_free_block is queue.fake_free_list_head\n+    assert blocks[0].next_free_block is blocks[4]\n+    assert blocks[4].prev_free_block is blocks[0]\n+    assert blocks[4].next_free_block is blocks[5]\n+    assert blocks[5].prev_free_block is blocks[4]\n+    assert blocks[5].next_free_block is blocks[1]\n+    assert blocks[1].prev_free_block is blocks[5]\n+    assert blocks[1].next_free_block is blocks[2]\n+    assert blocks[2].prev_free_block is blocks[1]\n+    assert blocks[2].next_free_block is blocks[3]\n+    assert blocks[3].prev_free_block is blocks[2]\n+    assert blocks[3].next_free_block is queue.fake_free_list_tail\n+    assert queue.fake_free_list_tail.prev_free_block is blocks[3]\n+\n+\n+def test_free_kv_cache_block_queue_popleft_n():\n+    blocks = [KVCacheBlock(block_id=i) for i in range(6)]\n+    # Create a empty FreeKVCacheBlockQueue with these blocks\n+    queue = FreeKVCacheBlockQueue(\n+        [blocks[1], blocks[3], blocks[5], blocks[4], blocks[0], blocks[2]])\n+    assert queue.num_free_blocks == 6\n+    assert queue.fake_free_list_head.next_free_block is blocks[1]\n+    assert blocks[1].prev_free_block is queue.fake_free_list_head\n+    assert blocks[1].next_free_block is blocks[3]\n+    assert blocks[3].prev_free_block is blocks[1]\n+    assert blocks[3].next_free_block is blocks[5]\n+    assert blocks[5].prev_free_block is blocks[3]\n+    assert blocks[5].next_free_block is blocks[4]\n+    assert blocks[4].prev_free_block is blocks[5]\n+    assert blocks[4].next_free_block is blocks[0]\n+    assert blocks[0].prev_free_block is blocks[4]\n+    assert blocks[0].next_free_block is blocks[2]\n+    assert blocks[2].prev_free_block is blocks[0]\n+    assert blocks[2].next_free_block is queue.fake_free_list_tail\n+    assert queue.fake_free_list_tail.prev_free_block is blocks[2]\n+\n+    # Pop 0 block\n+    # fake_head->b1->b3->b5->b4->b0->b2->fake_tail\n+    assert len(queue.popleft_n(0)) == 0\n+    # Pop 1 block\n+    # fake_head->b3->b5->b4->b0->b2->fake_tail\n+    result_blocks = queue.popleft_n(1)\n+    assert len(result_blocks) == 1\n+    assert result_blocks[0] is blocks[1]\n+    for block in result_blocks:\n+        assert block.prev_free_block is None\n+        assert block.next_free_block is None\n+    # Pop 2 blocks\n+    # fake_head->b4->b0->b2->fake_tail\n+    result_blocks = queue.popleft_n(2)\n+    assert len(result_blocks) == 2\n+    assert result_blocks[0] is blocks[3]\n+    assert result_blocks[1] is blocks[5]\n+    for block in result_blocks:\n+        assert block.prev_free_block is None\n+        assert block.next_free_block is None\n+    # Pop 3 blocks\n+    # fake_head->fake_tail\n+    result_blocks = queue.popleft_n(3)\n+    assert len(result_blocks) == 3\n+    assert result_blocks[0] is blocks[4]\n+    assert result_blocks[1] is blocks[0]\n+    assert result_blocks[2] is blocks[2]\n+    for block in result_blocks:\n+        assert block.prev_free_block is None\n+        assert block.next_free_block is None\n+\n+\n def test_free_kv_cache_block_queue_get_all_free_blocks():\n     # Create a list of KVCacheBlock objects\n     blocks = [KVCacheBlock(block_id=i) for i in range(5)]\ndiff --git a/vllm/v1/core/block_pool.py b/vllm/v1/core/block_pool.py\nindex cbb6bb268..5bf4d3a2a 100644\n--- a/vllm/v1/core/block_pool.py\n+++ b/vllm/v1/core/block_pool.py\n@@ -214,21 +214,18 @@ class BlockPool:\n             raise ValueError(\n                 f\"Cannot get {num_blocks} free blocks from the pool\")\n \n-        ret: list[KVCacheBlock] = []\n-        idx = 0\n-        while idx < num_blocks:\n-            # First allocate blocks.\n-            curr_block = self.free_block_queue.popleft()\n-            assert curr_block.ref_cnt == 0\n-\n-            # If the block is cached, evict it.\n-            if self.enable_caching:\n-                self._maybe_evict_cached_block(curr_block)\n-\n-            curr_block.incr_ref()\n-            ret.append(curr_block)\n-            idx += 1\n-\n+        ret: list[KVCacheBlock] = self.free_block_queue.popleft_n(num_blocks)\n+\n+        # In order to only iterate the list once, we duplicated code a bit\n+        if self.enable_caching:\n+            for block in ret:\n+                self._maybe_evict_cached_block(block)\n+                assert block.ref_cnt == 0\n+                block.ref_cnt += 1\n+        else:\n+            for block in ret:\n+                assert block.ref_cnt == 0\n+                block.ref_cnt += 1\n         return ret\n \n     def _maybe_evict_cached_block(self, block: KVCacheBlock) -> bool:\n@@ -289,11 +286,14 @@ class BlockPool:\n             ordered_blocks: A list of blocks to free ordered by their eviction\n                 priority.\n         \"\"\"\n-        for block in ordered_blocks:\n-            block.decr_ref()\n-            # null_block should not be added to the free list.\n-            if block.ref_cnt == 0 and not block.is_null:\n-                self.free_block_queue.append(block)\n+        # Materialize the iterable to allow multiple passes.\n+        blocks_list = list(ordered_blocks)\n+        for block in blocks_list:\n+            block.ref_cnt -= 1\n+        self.free_block_queue.append_n([\n+            block for block in blocks_list\n+            if block.ref_cnt == 0 and not block.is_null\n+        ])\n \n     def reset_prefix_cache(self) -> bool:\n         \"\"\"Reset prefix cache. This function may be used in RLHF\ndiff --git a/vllm/v1/core/kv_cache_utils.py b/vllm/v1/core/kv_cache_utils.py\nindex 457d95cc7..198d79cfb 100644\n--- a/vllm/v1/core/kv_cache_utils.py\n+++ b/vllm/v1/core/kv_cache_utils.py\n@@ -154,6 +154,8 @@ class KVCacheBlock:\n     # Whether the block is a null block that should never be cached.\n     is_null: bool = False\n \n+    # TODO(Jialin): For performance, let callers handle ref_cnt bumps to\n+    # avoid function calls.\n     def incr_ref(self):\n         self.ref_cnt += 1\n \n@@ -273,6 +275,39 @@ class FreeKVCacheBlockQueue:\n         self.num_free_blocks -= 1\n         return first_block\n \n+    def popleft_n(self, n: int) -> list[KVCacheBlock]:\n+        \"\"\"Pop the first n free blocks and reduce num_free_blocks by n.\n+\n+        Args:\n+            n: The number of blocks to pop.\n+\n+        Returns:\n+            A list of n free blocks.\n+        \"\"\"\n+        if n == 0:\n+            return []\n+        assert self.num_free_blocks >= n\n+        self.num_free_blocks -= n\n+\n+        curr_block = self.fake_free_list_head.next_free_block\n+        # Pop n blocks from the head of the list\n+        ret = []\n+        for _ in range(n):\n+            assert curr_block is not None\n+            ret.append(curr_block)\n+            last_block = curr_block\n+            curr_block = curr_block.next_free_block\n+            # Reset prev_free_block and next_free_block of all popped blocks\n+            last_block.prev_free_block = None\n+            last_block.next_free_block = None\n+\n+        if curr_block is not None:\n+            # The queue is not empty, connect the fake head to\n+            # the new first block.\n+            self.fake_free_list_head.next_free_block = curr_block\n+            curr_block.prev_free_block = self.fake_free_list_head\n+        return ret\n+\n     def remove(self, block: KVCacheBlock) -> None:\n         \"\"\"Remove a block in the free list and reduce num_free_blocks by 1.\n \n@@ -315,6 +350,29 @@ class FreeKVCacheBlockQueue:\n \n         self.num_free_blocks += 1\n \n+    def append_n(self, blocks: list[KVCacheBlock]) -> None:\n+        \"\"\"Put a list of blocks back into the free list\n+\n+        Args:\n+            blocks: The blocks to append.\n+        \"\"\"\n+        if len(blocks) == 0:\n+            return\n+        self.num_free_blocks += len(blocks)\n+\n+        last_block = self.fake_free_list_tail.prev_free_block\n+        assert last_block is not None, (\n+            \"prev_free_block of fake_free_list_tail should always exist\")\n+        # Add inter-connections between consecutive blocks\n+        for block in blocks:\n+            block.prev_free_block = last_block\n+            last_block.next_free_block = block\n+            last_block = block\n+\n+        # Connect the last block of <blocks> to the fake tail\n+        last_block.next_free_block = self.fake_free_list_tail\n+        self.fake_free_list_tail.prev_free_block = last_block\n+\n     def get_all_free_blocks(self) -> list[KVCacheBlock]:\n         \"\"\"Get all free blocks in the free list. Mainly used for testing.",
  "apis": [
    "FreeKVCacheBlockQueue.popleft_n",
    "FreeKVCacheBlockQueue.append_n",
    "BlockPool.get_new_blocks",
    "BlockPool.free_blocks"
  ],
  "affected_paths": [
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/v1/core/kv_cache_utils.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/v1/core/block_pool.py"
  ],
  "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm",
  "llm_reason": "The changes modify core files (block_pool.py and kv_cache_utils.py), not just test files, and introduce new methods (popleft_n and append_n) that batch process blocks. These are non-trivial modifications aimed at reducing iteration overhead and improving the efficiency of block management in the cache, indicating a performance optimization. The commit message and the nature of changes confirm this is a performance-related change.",
  "llm_api_reason": "The commit adds tests for the newly introduced popleft_n and append_n methods in the FreeKVCacheBlockQueue class and updates the BlockPool methods to use these new APIs for bulk block allocation and free operations. Additionally, the implementation of get_new_blocks and free_blocks in BlockPool now leverages these optimized methods. Overall, the changes aim at better performance by reducing per-block Python function call overhead."
}