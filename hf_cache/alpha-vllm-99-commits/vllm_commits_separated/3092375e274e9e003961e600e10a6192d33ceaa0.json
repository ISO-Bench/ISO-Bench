{
  "commit_hash": "3092375e274e9e003961e600e10a6192d33ceaa0",
  "pr_url": "https://github.com/vllm-project/vllm/pull/16432",
  "pr_date": "2025-04-10",
  "timeline_text": "Copy link Contributor p88h commented Apr 10, 2025 ‚Ä¢ edited by github-actions bot Loading Uh oh! There was an error while loading. Please reload this page . FIX #16185 ( link existing issues this PR will resolve ) This is a rebase of #16279 which had too entangled commits. Implements additional handling of MultimodalKwargs on top of #13790 Further improves memory usage on top of improvements in #16273 by another 50% Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 2 ywang96 and DarkLight1337 reacted with thumbs up emoji All reactions üëç 2 reactions p88h requested review from WoosukKwon , robertgshaw2-redhat , njhill , ywang96 , comaniac and alexm-redhat as code owners April 10, 2025 21:02 Copy link github-actions bot commented Apr 10, 2025 üëã Hi! Thank you for contributing to the vLLM project. üí¨ Join our developer Slack at https://slack.vllm.ai to discuss your PR in #pr-reviews, coordinate on features in #feat- channels, or join special interest groups in #sig- channels. Just a reminder: PRs would not trigger full CI run by default. Instead, it would only run fastcheck CI which starts running only a small and essential subset of CI tests to quickly catch errors. You can run other CI tests on top of those by going to your fastcheck build on Buildkite UI (linked in the PR checks section) and unblock them. If you do not have permission to unblock, ping simon-mo or khluu to add you in our Buildkite org. Once the PR is approved and ready to go, your PR reviewer(s) can run CI to test the changes comprehensively before merging. To run CI, PR reviewers can either: Add ready label to the PR or enable auto-merge. üöÄ All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . mergify bot added\n  the v1 label Apr 10, 2025 p88h force-pushed the serialize-multimodal-kwargs branch\n    from 3268c77 to 43d87ec Compare April 10, 2025 21:15 p88h mentioned this pull request Apr 10, 2025 [V1][Performance] Implement custom serializaton for MultiModalKwargs #16279 Closed p88h force-pushed the serialize-multimodal-kwargs branch\n    from 43d87ec to f4832a7 Compare April 10, 2025 21:41 Copy link Member ywang96 commented Apr 10, 2025 @p88h This is amazing! Have you tried running some benchmarks to see the throughput performance impact of this PR? All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Contributor Author p88h commented Apr 10, 2025 @ywang96 I've added a benchmark table to the linked bug #16185 My benchmark focused on memory performance rather than throughput, and only used a single model.  It should not really change throughput that much other than in cases that do run into memory issues, though. I'll try running some throughput checks tomorrow All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . njhill reviewed Apr 10, 2025 View reviewed changes Copy link Member njhill left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Thanks @p88h ! I think this looks good. The main thing I think is to add custom serialization for the field . And we'll probably want to add a few more comments since it's tightly coupled with the custom tensor encoding format. Also, I haven't looked closely at the entire flow, but in the case of MMKs created from items, it might make sense to defer the population of their data (via the \"reduce\" operations). Since that will be repeated in the receiving process and causes extra cpu and mem overhead since tensors may get stacked etc. It would be nice if there was a way for this to happen lazily but I guess that depends on how the data is later accessed. cc @ywang96 @DarkLight1337 Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . tests/v1/test_serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . Copy link Member njhill commented Apr 11, 2025 Also, I haven't looked closely at the entire flow, but in the case of MMKs created from items, it might make sense to defer the population of their data (via the \"reduce\" operations). Since that will be repeated in the receiving process and causes extra cpu and mem overhead since tensors may get stacked etc. It would be nice if there was a way for this to happen lazily but I guess that depends on how the data is later accessed. FYI I've opened another PR to help with this: #16440 . It should in theory help all of the cases not just the multi-proc case. It would still be additionally beneficial to postpone doing this reduce operation until after being transferred to the engine though. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . DarkLight1337 reviewed Apr 11, 2025 View reviewed changes tests/v1/test_serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . xtknight mentioned this pull request Apr 11, 2025 [Performance]: MultiModalKwargs serialization has significant impact on E2E latency (w/ proof-of-concept patch) #16461 Closed 1 task Copy link Contributor Author p88h commented Apr 11, 2025 I have some experimental data with this PR in place. Interestingly it performs much better with zero-copy disabled In this new benchmark,` I am feeding gradually increasing document sets to the engine. Turns out custom serialization helps less than expected - I think previously it was augmented by the cache, but now all files are unique so results are a bit different. The 'mix' performance case measures running all prompts together (15 total, with 128 images total) after they have been initially processed one-by-one, so it's expected that it's performing much better / cached. config / benchmark case       | 4 images | 8 images | 16 images | 32 images | t.max | t.mix\n------------------------------+----------+----------+-----------+-----------+-------+-------\nbaseline (zero-copy disabled) | 3.55 GB  | 5.11 GB  | 9.96 GB   | 22.54 GB  | 90.4s | 44.1s\nbaseline (zero-copy enabled)  | 3.50 GB  | 5.01 GB  | 9.87 GB   | 22.56 GB  | 75.3s | 39.4s\n#16432 (zero-copy enabled)    | 3.40 GB  | 4.75 GB  | 8.53 GB   | 22.02 GB  | 13.8s | 36.1s\n#16432 (zero-copy disabled)   | 3.28 GB  | 3.95 GB  | 4.76 GB   | 5.85 GB   | 14.4s | 36.3s All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . p88h force-pushed the serialize-multimodal-kwargs branch\n    from d56435a to 408f36b Compare April 11, 2025 12:03 mergify bot added documentation Improvements or additions to documentation ci/build tpu Related to Google TPUs labels Apr 11, 2025 p88h and others added 4 commits April 11, 2025 14:04 Implement efficient serialization of MultiModalKwargs ‚Ä¶ 7b6b7ba In addition to serializing base Tensors, this now allows to pass\nTensors embedded in MultiModalKwargs correctly.\n\nHandles both V0 and V1 style args.\n\nImproves memory usage with large multimodal payloads by a further\n50% (but still not on par with single-threaded behavior).\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com> Apply suggestions from code review ‚Ä¶ 4bdd16e Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com>\nSigned-off-by: Staszek Pasko <staszek@gmail.com> Additional fixes after code review ‚Ä¶ e5931af Signed-off-by: Staszek Pasko <staszek@gmail.com> Fix some broken bits & reformat ‚Ä¶ 6641584 Signed-off-by: Staszek Pasko <staszek@gmail.com> p88h force-pushed the serialize-multimodal-kwargs branch\n    from 408f36b to 6641584 Compare April 11, 2025 12:05 mergify bot removed\n  the tpu Related to Google TPUs label Apr 11, 2025 Add custom support for MultiModalFieldConfig, less pickle ‚Ä¶ a94df99 Signed-off-by: Staszek Pasko <staszek@gmail.com> mergify bot added\n  the multi-modality Related to multi-modality (#4194) label Apr 11, 2025 45 hidden items Load more‚Ä¶ p88h added 2 commits April 16, 2025 07:33 Merge branch 'vllm-project:main' into serialize-multimodal-kwargs d7cb694 style ‚Ä¶ 7511262 Signed-off-by: Staszek Pasko <staszek@gmail.com> p88h requested a review\n  from njhill April 16, 2025 09:39 Merge branch 'vllm-project:main' into serialize-multimodal-kwargs 97188e6 njhill reviewed Apr 16, 2025 View reviewed changes vllm/v1/serial_utils.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . remove unnecessary comment ‚Ä¶ 48ab2d9 Signed-off-by: Staszek Pasko <staszek@gmail.com> p88h requested a review\n  from njhill April 16, 2025 15:00 njhill approved these changes Apr 16, 2025 View reviewed changes Copy link Member njhill left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Thanks for the great work @p88h ! Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üéâ 1 p88h reacted with hooray emoji All reactions üéâ 1 reaction njhill added ready ONLY add when PR is ready to merge/full CI is needed performance Performance-related issues labels Apr 16, 2025 p88h force-pushed the serialize-multimodal-kwargs branch\n    from 1f2779a to 48ab2d9 Compare April 16, 2025 19:35 Merge branch 'vllm-project:main' into serialize-multimodal-kwargs a60333e Copy link Member njhill commented Apr 16, 2025 Looks like a CI test is failing - but unfortunately the root cause is obscured (the OOM failure of the subsequent test is a result of improper cleanup after the original failure). This should hopefully be addressed by #11737 . In the meantime I can try running this test locally. p.s. there's no need to keep rebasing on latest main, this just causes all the tests to start over. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Accommodate floats in NestedTensors ‚Ä¶ 281f0f1 Signed-off-by: Nick Hill <nhill@redhat.com> Copy link Member njhill commented Apr 16, 2025 It turns out it was because sometimes MMKwargs can contain non-tensor data (specifically \"second_per_grid_ts\": [1.0] in this case). So I pushed an update to allow floats and ints too. All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Hide details View details njhill merged commit 3092375 into vllm-project : main Apr 17, 2025 42 checks passed Uh oh! There was an error while loading. Please reload this page . Copy link Contributor Author p88h commented Apr 17, 2025 Thank you ! I was about to go back to debugging this morning ;) üëç 1 njhill reacted with thumbs up emoji All reactions üëç 1 reaction Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . lionelvillard pushed a commit\n        to lionelvillard/vllm\n      that referenced\n      this pull request Apr 17, 2025 [V1][Performance] Implement custom serializaton for MultiModalKwargs ‚Ä¶ ‚Ä¶ c2df8d3 ‚Ä¶[Rebased] ( vllm-project#16432 )\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com>\nSigned-off-by: Nick Hill <nhill@redhat.com>\nCo-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com> DarkLight1337 mentioned this pull request Apr 17, 2025 [Bug]: Unable to deploy Qwen2.5-VL-3B-Instruct  after updating vLLM to latest version #16791 Closed 1 task p88h mentioned this pull request Apr 17, 2025 [Bug]: Mistral 3.1 Small Image inference is broken on 0.8.4 #16675 Closed 1 task njhill mentioned this pull request Apr 18, 2025 [BugFix] Support bf16 in zero-copy tensor serialization #16860 Closed p88h deleted the serialize-multimodal-kwargs branch April 18, 2025 20:22 yangw-dev pushed a commit\n        to yangw-dev/vllm\n      that referenced\n      this pull request Apr 21, 2025 [V1][Performance] Implement custom serializaton for MultiModalKwargs ‚Ä¶ ‚Ä¶ 2f35558 ‚Ä¶[Rebased] ( vllm-project#16432 )\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com>\nSigned-off-by: Nick Hill <nhill@redhat.com>\nCo-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com>\nSigned-off-by: Yang Wang <elainewy@meta.com> DarkLight1337 mentioned this pull request Apr 28, 2025 [Feature]: Performance issue, when using Qwen2.5-VL-32B-Instruct model for multi graph inference #17297 Closed 1 task jikunshang pushed a commit\n        to jikunshang/vllm\n      that referenced\n      this pull request Apr 29, 2025 [V1][Performance] Implement custom serializaton for MultiModalKwargs ‚Ä¶ ‚Ä¶ 6fcc767 ‚Ä¶[Rebased] ( vllm-project#16432 )\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com>\nSigned-off-by: Nick Hill <nhill@redhat.com>\nCo-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com> lk-chen pushed a commit\n        to lk-chen/vllm\n      that referenced\n      this pull request Apr 29, 2025 [V1][Performance] Implement custom serializaton for MultiModalKwargs ‚Ä¶ ‚Ä¶ 365538f ‚Ä¶[Rebased] ( vllm-project#16432 )\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com>\nSigned-off-by: Nick Hill <nhill@redhat.com>\nCo-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com> adobrzyn pushed a commit\n        to HabanaAI/vllm-fork\n      that referenced\n      this pull request Apr 30, 2025 [V1][Performance] Implement custom serializaton for MultiModalKwargs ‚Ä¶ ‚Ä¶ 0c1294a ‚Ä¶[Rebased] ( vllm-project#16432 )\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com>\nSigned-off-by: Nick Hill <nhill@redhat.com>\nCo-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com>\nSigned-off-by: Agata Dobrzyniewicz <adobrzyniewicz@habana.ai> RichardoMrMu pushed a commit\n        to RichardoMrMu/vllm\n      that referenced\n      this pull request May 12, 2025 [V1][Performance] Implement custom serializaton for MultiModalKwargs ‚Ä¶ ‚Ä¶ f09c519 ‚Ä¶[Rebased] ( vllm-project#16432 )\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com>\nSigned-off-by: Nick Hill <nhill@redhat.com>\nCo-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com>\nSigned-off-by: Mu Huai <tianbowen.tbw@antgroup.com> ckhordiasma mentioned this pull request May 14, 2025 nm vllm ent 0.8.5 sync red-hat-data-services/vllm#139 Merged Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-07 17:51:22",
  "has_lm_eval": false,
  "has_performance": true,
  "has_serving": false,
  "has_general_test": true,
  "test_details": "PERF: throughput, throughput, throughput | TEST: test, test, test",
  "analysis_extracted_at": "2025-09-07 17:51:22",
  "models": [
    "N/A"
  ],
  "lm_eval_commands": null,
  "perf_command": null,
  "commit_subject": "[V1][Performance] Implement custom serializaton for MultiModalKwargs [Rebased] (#16432)",
  "commit_message": "[V1][Performance] Implement custom serializaton for MultiModalKwargs [Rebased] (#16432)\n\nSigned-off-by: Staszek Pasko <staszek@gmail.com>\nSigned-off-by: Nick Hill <nhill@redhat.com>\nCo-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>\nCo-authored-by: Nick Hill <nhill@redhat.com>",
  "commit_date": "2025-04-16T19:28:32-07:00",
  "files_changed": [
    "tests/v1/test_serial_utils.py",
    "vllm/envs.py",
    "vllm/v1/serial_utils.py"
  ],
  "functions_changed": [],
  "stats": {
    "num_test_files": 1,
    "num_non_test_files": 2,
    "only_test_files": 0,
    "only_non_test_files": 0,
    "num_files": 3,
    "num_hunks": 12,
    "num_edited_lines": 218,
    "num_non_test_edited_lines": 119,
    "commit_year": 2025
  },
  "diff_text": "diff --git a/tests/v1/test_serial_utils.py b/tests/v1/test_serial_utils.py\nindex bc0e0cbd8..e58d3c403 100644\n--- a/tests/v1/test_serial_utils.py\n+++ b/tests/v1/test_serial_utils.py\n@@ -1,10 +1,16 @@\n # SPDX-License-Identifier: Apache-2.0\n from collections import UserDict\n from dataclasses import dataclass\n+from typing import Optional\n \n+import msgspec\n import numpy as np\n import torch\n \n+from vllm.multimodal.inputs import (MultiModalBatchedField,\n+                                    MultiModalFieldElem, MultiModalKwargs,\n+                                    MultiModalKwargsItem,\n+                                    MultiModalSharedField, NestedTensors)\n from vllm.v1.serial_utils import MsgpackDecoder, MsgpackEncoder\n \n \n@@ -50,7 +56,7 @@ def test_encode_decode():\n         large_non_contig_tensor=torch.rand(1024, 512)[:, 10:20],\n     )\n \n-    encoder = MsgpackEncoder()\n+    encoder = MsgpackEncoder(size_threshold=256)\n     decoder = MsgpackDecoder(MyType)\n \n     encoded = encoder.encode(obj)\n@@ -78,6 +84,97 @@ def test_encode_decode():\n     assert_equal(decoded2, obj)\n \n \n+class MyRequest(msgspec.Struct):\n+    mm: Optional[list[MultiModalKwargs]]\n+\n+\n+def test_multimodal_kwargs():\n+    d = {\n+        \"foo\":\n+        torch.zeros(20000, dtype=torch.float16),\n+        \"bar\": [torch.zeros(i * 1000, dtype=torch.int8) for i in range(3)],\n+        \"baz\": [\n+            torch.rand((256), dtype=torch.float16),\n+            [\n+                torch.rand((1, 12), dtype=torch.float32),\n+                torch.rand((3, 5, 7), dtype=torch.float64),\n+            ], [torch.rand((4, 4), dtype=torch.float16)]\n+        ],\n+    }\n+\n+    # pack mm kwargs into a mock request so that it can be decoded properly\n+    req = MyRequest(mm=[MultiModalKwargs(d)])\n+\n+    encoder = MsgpackEncoder()\n+    decoder = MsgpackDecoder(MyRequest)\n+\n+    encoded = encoder.encode(req)\n+\n+    assert len(encoded) == 6\n+\n+    total_len = sum(memoryview(x).cast(\"B\").nbytes for x in encoded)\n+\n+    # expected total encoding length, should be 44536, +-20 for minor changes\n+    assert total_len >= 44516 and total_len <= 44556\n+    decoded: MultiModalKwargs = decoder.decode(encoded).mm[0]\n+    assert all(nested_equal(d[k], decoded[k]) for k in d)\n+\n+\n+def test_multimodal_items_by_modality():\n+    e1 = MultiModalFieldElem(\"audio\", \"a0\", torch.zeros(1000,\n+                                                        dtype=torch.int16),\n+                             MultiModalBatchedField())\n+    e2 = MultiModalFieldElem(\n+        \"video\",\n+        \"v0\",\n+        [torch.zeros(1000, dtype=torch.int8) for _ in range(4)],\n+        MultiModalBatchedField(),\n+    )\n+    e3 = MultiModalFieldElem(\"image\", \"i0\", torch.zeros(1000,\n+                                                        dtype=torch.int32),\n+                             MultiModalSharedField(4))\n+    e4 = MultiModalFieldElem(\"image\", \"i1\", torch.zeros(1000,\n+                                                        dtype=torch.int32),\n+                             MultiModalBatchedField())\n+    audio = MultiModalKwargsItem.from_elems([e1])\n+    video = MultiModalKwargsItem.from_elems([e2])\n+    image = MultiModalKwargsItem.from_elems([e3, e4])\n+    mm = MultiModalKwargs.from_items([audio, video, image])\n+\n+    # pack mm kwargs into a mock request so that it can be decoded properly\n+    req = MyRequest([mm])\n+\n+    encoder = MsgpackEncoder()\n+    decoder = MsgpackDecoder(MyRequest)\n+\n+    encoded = encoder.encode(req)\n+\n+    assert len(encoded) == 8\n+\n+    total_len = sum(memoryview(x).cast(\"B\").nbytes for x in encoded)\n+\n+    # expected total encoding length, should be 14255, +-20 for minor changes\n+    assert total_len >= 14235 and total_len <= 14275\n+    decoded: MultiModalKwargs = decoder.decode(encoded).mm[0]\n+\n+    # check all modalities were recovered and do some basic sanity checks\n+    assert len(decoded.modalities) == 3\n+    images = decoded.get_items(\"image\")\n+    assert len(images) == 1\n+    assert len(images[0].items()) == 2\n+    assert list(images[0].keys()) == [\"i0\", \"i1\"]\n+\n+    # check the tensor contents and layout in the main dict\n+    assert all(nested_equal(mm[k], decoded[k]) for k in mm)\n+\n+\n+def nested_equal(a: NestedTensors, b: NestedTensors):\n+    if isinstance(a, torch.Tensor):\n+        return torch.equal(a, b)\n+    else:\n+        return all(nested_equal(x, y) for x, y in zip(a, b))\n+\n+\n def assert_equal(obj1: MyType, obj2: MyType):\n     assert torch.equal(obj1.tensor1, obj2.tensor1)\n     assert obj1.a_string == obj2.a_string\ndiff --git a/vllm/envs.py b/vllm/envs.py\nindex f80bf878f..d32968c3d 100644\n--- a/vllm/envs.py\n+++ b/vllm/envs.py\n@@ -107,6 +107,7 @@ if TYPE_CHECKING:\n     VLLM_TPU_BUCKET_PADDING_GAP: int = 0\n     VLLM_USE_DEEP_GEMM: bool = False\n     VLLM_XGRAMMAR_CACHE_MB: int = 0\n+    VLLM_MSGPACK_ZERO_COPY_THRESHOLD: int = 256\n \n \n def get_default_cache_root():\n@@ -704,6 +705,16 @@ environment_variables: dict[str, Callable[[], Any]] = {\n     # It can be changed with this variable if needed for some reason.\n     \"VLLM_XGRAMMAR_CACHE_MB\":\n     lambda: int(os.getenv(\"VLLM_XGRAMMAR_CACHE_MB\", \"512\")),\n+\n+    # Control the threshold for msgspec to use 'zero copy' for\n+    # serialization/deserialization of tensors. Tensors below\n+    # this limit will be encoded into the msgpack buffer, and\n+    # tensors above will instead be sent via a separate message.\n+    # While the sending side still actually copies the tensor\n+    # in all cases, on the receiving side, tensors above this\n+    # limit will actually be zero-copy decoded.\n+    \"VLLM_MSGPACK_ZERO_COPY_THRESHOLD\":\n+    lambda: int(os.getenv(\"VLLM_MSGPACK_ZERO_COPY_THRESHOLD\", \"256\")),\n }\n \n # end-env-vars-definition\ndiff --git a/vllm/v1/serial_utils.py b/vllm/v1/serial_utils.py\nindex 3af6793fd..4f7987ee4 100644\n--- a/vllm/v1/serial_utils.py\n+++ b/vllm/v1/serial_utils.py\n@@ -1,5 +1,6 @@\n # SPDX-License-Identifier: Apache-2.0\n \n+import dataclasses\n import pickle\n from collections.abc import Sequence\n from inspect import isclass\n@@ -12,12 +13,26 @@ import torch\n import zmq\n from msgspec import msgpack\n \n+from vllm import envs\n+from vllm.multimodal.inputs import (BaseMultiModalField,\n+                                    MultiModalBatchedField,\n+                                    MultiModalFieldConfig, MultiModalFieldElem,\n+                                    MultiModalFlatField, MultiModalKwargs,\n+                                    MultiModalKwargsItem,\n+                                    MultiModalSharedField, NestedTensors)\n+\n CUSTOM_TYPE_PICKLE = 1\n CUSTOM_TYPE_CLOUDPICKLE = 2\n CUSTOM_TYPE_RAW_VIEW = 3\n \n-# TODO calibrate this size\n-MIN_NOCOPY_BUF_SIZE = 512\n+# MultiModalField class serialization type map.\n+# These need to list all possible field types and match them\n+# to factory methods in `MultiModalFieldConfig`.\n+MMF_CLASS_TO_FACTORY: dict[type[BaseMultiModalField], str] = {\n+    MultiModalFlatField: \"flat\",\n+    MultiModalSharedField: \"shared\",\n+    MultiModalBatchedField: \"batched\",\n+}\n \n bytestr = Union[bytes, bytearray, memoryview, zmq.Frame]\n \n@@ -27,14 +42,20 @@ class MsgpackEncoder:\n \n     Note that unlike vanilla `msgspec` Encoders, this interface is generally\n     not thread-safe when encoding tensors / numpy arrays.\n+\n+    By default, arrays below 256B are serialized inline Larger will get sent \n+    via dedicated messages. Note that this is a per-tensor limit.\n     \"\"\"\n \n-    def __init__(self):\n+    def __init__(self, size_threshold: Optional[int] = None):\n+        if size_threshold is None:\n+            size_threshold = envs.VLLM_MSGPACK_ZERO_COPY_THRESHOLD\n         self.encoder = msgpack.Encoder(enc_hook=self.enc_hook)\n         # This is used as a local stash of buffers that we can then access from\n         # our custom `msgspec` hook, `enc_hook`. We don't have a way to\n         # pass custom data to the hook otherwise.\n         self.aux_buffers: Optional[list[bytestr]] = None\n+        self.size_threshold = size_threshold\n \n     def encode(self, obj: Any) -> Sequence[bytestr]:\n         try:\n@@ -65,6 +86,25 @@ class MsgpackEncoder:\n         if isinstance(obj, np.ndarray) and obj.dtype.kind not in ('O', 'V'):\n             return self._encode_ndarray(obj)\n \n+        if isinstance(obj, MultiModalKwargs):\n+            mm: MultiModalKwargs = obj\n+            if not mm.modalities:\n+                # just return the main dict if there are no modalities.\n+                return dict(mm)\n+\n+            # ignore the main dict, it will be re-indexed.\n+            # Encode a list of MultiModalKwargsItems as plain dicts\n+            # + special handling for .field.\n+            # Any tensors *not* indexed by modality will be ignored.\n+            return [[{\n+                \"modality\": elem.modality,\n+                \"key\": elem.key,\n+                \"data\": self._encode_nested_tensors(elem.data),\n+                \"field\": self._encode_mm_field(elem.field),\n+            } for elem in item.values()]\n+                    for itemlist in mm._items_by_modality.values()\n+                    for item in itemlist]\n+\n         if isinstance(obj, FunctionType):\n             # `pickle` is generally faster than cloudpickle, but can have\n             # problems serializing methods.\n@@ -77,8 +117,9 @@ class MsgpackEncoder:\n         self, obj: np.ndarray\n     ) -> tuple[str, tuple[int, ...], Union[int, memoryview]]:\n         assert self.aux_buffers is not None\n+        # If the array is non-contiguous, we need to copy it first\n         arr_data = obj.data if obj.data.c_contiguous else obj.tobytes()\n-        if not obj.shape or obj.nbytes < MIN_NOCOPY_BUF_SIZE:\n+        if not obj.shape or obj.nbytes < self.size_threshold:\n             # Encode small arrays and scalars inline. Using this extension type\n             # ensures we can avoid copying when decoding.\n             data = msgpack.Ext(CUSTOM_TYPE_RAW_VIEW, arr_data)\n@@ -92,6 +133,26 @@ class MsgpackEncoder:\n         # backing buffers that we've stashed in `aux_buffers`.\n         return obj.dtype.str, obj.shape, data\n \n+    def _encode_nested_tensors(self, nt: NestedTensors) -> Any:\n+        if isinstance(nt, torch.Tensor):\n+            return self._encode_ndarray(nt.numpy())\n+        if isinstance(nt, (int, float)):\n+            # Although it violates NestedTensors type, MultiModalKwargs\n+            # values are sometimes floats.\n+            return nt\n+        return [self._encode_nested_tensors(x) for x in nt]\n+\n+    def _encode_mm_field(self, field: BaseMultiModalField):\n+        # Figure out the factory name for the field type.\n+        name = MMF_CLASS_TO_FACTORY.get(field.__class__)\n+        if not name:\n+            raise TypeError(f\"Unsupported field type: {field.__class__}\")\n+        # We just need to copy all of the field values in order\n+        # which will be then used to reconstruct the field.\n+        field_values = (getattr(field, f.name)\n+                        for f in dataclasses.fields(field))\n+        return name, *field_values\n+\n \n class MsgpackDecoder:\n     \"\"\"Decoder with custom torch tensor and numpy array serialization.\n@@ -126,13 +187,50 @@ class MsgpackDecoder:\n                 return self._decode_ndarray(obj)\n             if issubclass(t, torch.Tensor):\n                 return torch.from_numpy(self._decode_ndarray(obj))\n+            if issubclass(t, MultiModalKwargs):\n+                if isinstance(obj, list):\n+                    return MultiModalKwargs.from_items(\n+                        self._decode_mm_items(obj))\n+                return MultiModalKwargs({\n+                    k: self._decode_nested_tensors(v)\n+                    for k, v in obj.items()\n+                })\n         return obj\n \n     def _decode_ndarray(self, arr: Any) -> np.ndarray:\n         dtype, shape, data = arr\n-        buffer = self.aux_buffers[data] if isinstance(data, int) else data\n+        # Copy from inline representation, otherwise Torch is unhappy since\n+        # the returned memory is non-writeable.\n+        buffer = self.aux_buffers[data] if isinstance(data, int) \\\n+            else bytearray(data)\n         return np.ndarray(buffer=buffer, dtype=np.dtype(dtype), shape=shape)\n \n+    def _decode_mm_items(self, obj: list) -> list[MultiModalKwargsItem]:\n+        decoded_items = []\n+        for item in obj:\n+            elems = []\n+            for v in item:\n+                v[\"data\"] = self._decode_nested_tensors(v[\"data\"])\n+                # Reconstruct the field processor using MultiModalFieldConfig\n+                factory_meth_name, *field_args = v[\"field\"]\n+                factory_meth = getattr(MultiModalFieldConfig,\n+                                       factory_meth_name)\n+                v[\"field\"] = factory_meth(None, *field_args).field\n+                elems.append(MultiModalFieldElem(**v))\n+            decoded_items.append(MultiModalKwargsItem.from_elems(elems))\n+        return decoded_items\n+\n+    def _decode_nested_tensors(self, obj: Any) -> NestedTensors:\n+        if isinstance(obj, (int, float)):\n+            # Although it violates NestedTensors type, MultiModalKwargs\n+            # values are sometimes floats.\n+            return obj\n+        if not isinstance(obj, list):\n+            raise TypeError(f\"Unexpected NestedTensors contents: {type(obj)}\")\n+        if obj and isinstance(obj[0], str):\n+            return torch.from_numpy(self._decode_ndarray(obj))\n+        return [self._decode_nested_tensors(x) for x in obj]\n+\n     def ext_hook(self, code: int, data: memoryview) -> Any:\n         if code == CUSTOM_TYPE_RAW_VIEW:\n             return data",
  "apis": [
    "MsgpackEncoder.__init__",
    "MsgpackEncoder.encode",
    "MsgpackDecoder.decode"
  ],
  "affected_paths": [
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/v1/serial_utils.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/envs.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/multimodal/inputs.py"
  ],
  "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm",
  "llm_reason": "The commit modifies both test files and source code in vllm/envs.py and vllm/v1/serial_utils.py. It adds a new environment variable VLLM_MSGPACK_ZERO_COPY_THRESHOLD and uses it in the MsgpackEncoder to decide whether to inline or use zero-copy deserialization for tensors. This change alters the serialization strategy to improve performance by reducing unnecessary copies on the receiving side. The modifications are non-trivial, affect a high-level API (serialization/deserialization), and are designed for CPU performance improvements. Hence, the commit meets the criteria for being performance/optimization related.",
  "llm_api_reason": "The commit updates the serialization utilities in vllm/v1/serial_utils.py and adds tests for multimodal kwargs in tests/v1/test_serial_utils.py. In MsgpackEncoder, the constructor is modified to accept a size_threshold parameter (defaulting from the environment variable), and the encode() method now handles instances of MultiModalKwargs specially (i.e. it encodes its items into a list of plain dicts with extra field metadata). In MsgpackDecoder, new logic is introduced to decode MultiModalKwargs objects (using a helper method _decode_mm_items) as well as adjustments for zero-copy decoding. These changes affect the public APIs for serializing and deserializing model requests using MsgpackEncoder and MsgpackDecoder."
}