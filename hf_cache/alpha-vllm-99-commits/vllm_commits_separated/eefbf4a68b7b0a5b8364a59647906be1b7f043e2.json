{
  "commit_hash": "eefbf4a68b7b0a5b8364a59647906be1b7f043e2",
  "pr_url": "https://github.com/vllm-project/vllm/pull/22036",
  "pr_date": "2025-08-01",
  "timeline_text": "Copy link Collaborator yewentao256 commented Jul 31, 2025 ‚Ä¢ edited by github-actions bot Loading Uh oh! There was an error while loading. Please reload this page . Purpose Using vectorization utils to reshape_and_cache_flash and get performance improvement Test Acc lm_eval   --model vllm   --model_args \" pretrained=Qwen/Qwen3-30B-A3B-FP8,max_model_len=32768,enforce_eager=True \" --trust_remote_code   --tasks gsm8k   --num_fewshot 5   --batch_size auto | Tasks | Version | Filter | n-shot | Metric | | Value | | Stderr | | ----- | ------: | ---------------- | -----: | ----------- | --- | -----: | --- | -----: | | gsm8k | 3 | flexible-extract | 5 | exact_match | ‚Üë | 0.8173 | ¬± | 0.0106 | | | | strict-match | 5 | exact_match | ‚Üë | 0.8870 | ¬± | 0.0087 | # main | Tasks | Version | Filter | n-shot | Metric | | Value | | Stderr | | ----- | ------: | ---------------- | -----: | ----------- | --- | -----: | --- | -----: | | gsm8k | 3 | flexible-extract | 5 | exact_match | ‚Üë | 0.8173 | ¬± | 0.0106 | | | | strict-match | 5 | exact_match | ‚Üë | 0.8870 | ¬± | 0.0087 | pytest test_cache.py -x\n==================== test session starts ====================\nplatform linux -- Python 3.12.3, pytest-8.4.0, pluggy-1.6.0\nrootdir: /home/wentao/vllm-source\nconfigfile: pyproject.toml\nplugins: asyncio-1.0.0, anyio-4.9.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollected 1102 items                                        \n\ntest_cache.py ....................................... [  3%]\n...................................s...s...s...s...s. [  8%]\n..s...s...s...s...s...s...s...s...s...s...s...s...s.. [ 13%]\n..................................................... [ 17%]\n....................s...s...s...s...s...s...s...s...s [ 22%]\n...s...s...s...s...s...s...s...s...s................. [ 27%]\n..................................................... [ 32%]\n..................................................... [ 37%]\n..................................................... [ 42%]\n..................................................... [ 46%]\n..................................................... [ 51%]\n..................................................... [ 56%]\n..................................................... [ 61%]\n..................................................... [ 66%]\n..................................................... [ 70%]\n...........s.ss.sssss.ss.ss.sssss.ss.ss.sssss.ss.ss.s [ 75%]\nssss.ss.ss.sssss.ss.ss.sssss.ss.ss.sssss.ss.ss.sssss. [ 80%]\nss.ss.sssss.ss.ss.sssss.ss.ss.sssss.ss.ss.sssss.ss.ss [ 85%]\n.sssss.ss.ss.sssss.ss.ss.sssss.ss.ss.sssss.ss.ss.ssss [ 90%]\ns.ss.ss.sssss.s...................................... [ 94%]\n..................................................... [ 99%]\nsss                                                   [100%]\n\n======= 901 passed, 201 skipped in 349.21s (0:05:49) ======== Performance python benchmark_reshape_and_cache_flash.py num_tokens layout Old Run (¬µs) New Run (¬µs) Change (%) 2 HND 10.326 8.323 -19.4% üöÄ 4 HND 10.440 8.355 -20.0% üöÄ 8 HND 10.356 8.344 -19.4% üöÄ 16 HND 10.330 8.372 -19.0% üöÄ 32 HND 10.345 8.348 -19.3% üöÄ 64 HND 10.454 8.354 -20.1% üöÄ 128 HND 10.397 8.370 -19.5% üöÄ 256 HND 14.431 10.375 -28.1% üöÄ 512 HND 24.809 20.137 -18.8% üöÄ 1024 HND 51.389 45.196 -12.1% üöÄ 2048 HND 96.466 77.908 -19.2% üöÄ 4096 HND 175.695 147.068 -16.3% üöÄ 8192 HND 336.814 279.106 -17.1% üöÄ 16384 HND 668.001 547.169 -18.1% üöÄ 32768 HND 1320.570 1082.070 -18.1% üöÄ 65536 HND 2605.930 2149.950 -17.5% üöÄ 2 NHD 10.371 6.649 -35.9% üöÄ 4 NHD 10.337 6.407 -38.0% üöÄ 8 NHD 10.346 6.338 -38.7% üöÄ 16 NHD 10.352 6.394 -38.2% üöÄ 32 NHD 10.350 7.416 -28.3% üöÄ 64 NHD 10.341 7.305 -29.4% üöÄ 128 NHD 10.349 7.614 -26.4% üöÄ 256 NHD 14.401 10.363 -28.0% üöÄ 512 NHD 25.955 15.084 -41.9% üöÄ 1024 NHD 49.264 30.690 -37.7% üöÄ 2048 NHD 93.674 53.726 -42.6% üöÄ 4096 NHD 172.364 101.030 -41.4% üöÄ 8192 NHD 333.329 195.911 -41.2% üöÄ 16384 NHD 665.351 385.012 -42.1% üöÄ 32768 NHD 1308.720 762.607 -41.7% üöÄ 65536 NHD 2587.800 1519.310 -41.3% üöÄ Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üéâ 3 mgoin, ProExpertProg, and minosfuture reacted with hooray emoji All reactions üéâ 3 reactions yewentao256 added 2 commits July 31, 2025 17:15 optimize reshape and cache flash kernel ‚Ä¶ ec2e746 Signed-off-by: yewentao256 <zhyanwentao@126.com> add benchmark script ‚Ä¶ 1d25423 Signed-off-by: yewentao256 <zhyanwentao@126.com> mergify bot added\n  the performance Performance-related issues label Jul 31, 2025 gemini-code-assist bot reviewed Jul 31, 2025 View reviewed changes Copy link Contributor gemini-code-assist bot left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Code Review This pull request optimizes the reshape_and_cache_flash CUDA kernel by using vectorization, which results in significant performance improvements. The changes look good, but there is a critical correctness issue. The new implementation assumes a contiguous memory layout for the (num_heads, head_size) dimensions in the KV cache, which is only true for the NHD layout. This breaks support for the HND layout, which is also a supported configuration. I've provided a detailed comment with a suggested fix to address this. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions csrc/cache_kernels.cu Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . Copy link github-actions bot commented Jul 31, 2025 üëã Hi! Thank you for contributing to the vLLM project. üí¨ Join our developer Slack at https://slack.vllm.ai to discuss your PR in #pr-reviews, coordinate on features in #feat- channels, or join special interest groups in #sig- channels. Just a reminder: PRs would not trigger full CI run by default. Instead, it would only run fastcheck CI which starts running only a small and essential subset of CI tests to quickly catch errors. You can run other CI tests on top of those by going to your fastcheck build on Buildkite UI (linked in the PR checks section) and unblock them. If you do not have permission to unblock, ping simon-mo or khluu to add you in our Buildkite org. Once the PR is approved and ready to go, your PR reviewer(s) can run CI to test the changes comprehensively before merging. To run CI, PR reviewers can either: Add ready label to the PR or enable auto-merge. üöÄ All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . yewentao256 added 4 commits July 31, 2025 17:45 Fallback HND ‚Ä¶ 8c4484e Signed-off-by: yewentao256 <zhyanwentao@126.com> HND optimize ‚Ä¶ 27546f6 Signed-off-by: yewentao256 <zhyanwentao@126.com> optimize HND and update benchmark script ‚Ä¶ 8896ba3 Signed-off-by: yewentao256 <zhyanwentao@126.com> update comments ‚Ä¶ f850fb5 Signed-off-by: yewentao256 <zhyanwentao@126.com> Copy link Collaborator robertgshaw2-redhat commented Aug 1, 2025 wow, nice work üöÄ 1 yewentao256 reacted with rocket emoji All reactions üöÄ 1 reaction Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . mgoin added\n  the ready ONLY add when PR is ready to merge/full CI is needed label Aug 1, 2025 mgoin approved these changes Aug 1, 2025 View reviewed changes Copy link Member mgoin left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment LGTM, vectorize_with_alignment should deal with uneven shapes and existing CI should cover this. I'll make sure to unblock a full run just in case Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 yewentao256 reacted with thumbs up emoji All reactions üëç 1 reaction Hide details View details mgoin merged commit eefbf4a into vllm-project : main Aug 1, 2025 106 of 108 checks passed Uh oh! There was an error while loading. Please reload this page . wenscarl pushed a commit\n        to wenscarl/vllm\n      that referenced\n      this pull request Aug 4, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 2d1176c ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: shuw <shuw@nvidia.com> mgoin mentioned this pull request Aug 5, 2025 Update rms_norm_kernel by removing redundant global memory loads #22134 Closed juuice-lee pushed a commit\n        to juuice-lee/vllm-moe.code\n      that referenced\n      this pull request Aug 5, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 77fb21a ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ af2e1b0 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 243072a ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: x22x22 <wadeking@qq.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 70a4ebc ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: x22x22 <wadeking@qq.com> npanpaliya pushed a commit\n        to odh-on-pz/vllm-upstream\n      that referenced\n      this pull request Aug 6, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 0776d55 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com> jingyu-ml pushed a commit\n        to jingyu-ml/vllm\n      that referenced\n      this pull request Aug 8, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 4a21190 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: jingyu <jingyu@omniml.ai> jinzhen-lin pushed a commit\n        to jinzhen-lin/vllm\n      that referenced\n      this pull request Aug 9, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 8854ac4 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: Jinzhen Lin <linjinzhen@hotmail.com> noamgat pushed a commit\n        to noamgat/vllm\n      that referenced\n      this pull request Aug 9, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 417c8f8 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: Noam Gat <noamgat@gmail.com> yyihuang pushed a commit\n        to yyihuang/vllm\n      that referenced\n      this pull request Aug 11, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 677f751 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: Avery Yingyi Huang <yingyihuang2000@outlook.com> paulpak58 pushed a commit\n        to paulpak58/vllm\n      that referenced\n      this pull request Aug 13, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 8883b90 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: Paul Pak <paulpak58@gmail.com> taneem-ibrahim pushed a commit\n        to taneem-ibrahim/vllm\n      that referenced\n      this pull request Aug 14, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 4d7adb0 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com> BoyuanFeng pushed a commit\n        to BoyuanFeng/vllm\n      that referenced\n      this pull request Aug 14, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 9f6eea7 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: Boyuan Feng <boyuan@meta.com> diegocastanibm pushed a commit\n        to diegocastanibm/vllm\n      that referenced\n      this pull request Aug 15, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 59b5f69 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>\nSigned-off-by: Diego-Castan <diego.castan@ibm.com> yewentao256 mentioned this pull request Aug 24, 2025 Vectorize RMSNorm CUDA kernel #22602 Open epwalsh pushed a commit\n        to epwalsh/vllm\n      that referenced\n      this pull request Aug 28, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 018781e ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com> zhewenl pushed a commit\n        to zhewenl/vllm\n      that referenced\n      this pull request Aug 28, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 64db329 ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com> googlercolin pushed a commit\n        to googlercolin/vllm\n      that referenced\n      this pull request Aug 29, 2025 [Perf] Optimize reshape_and_cache_flash CUDA Kernel ( vllm-project#2‚Ä¶ ‚Ä¶ 27c54dd ‚Ä¶2036 )\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com> Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-07 17:49:48",
  "has_lm_eval": true,
  "has_performance": true,
  "has_serving": false,
  "has_general_test": true,
  "test_details": "LM_EVAL: lm_eval, gsm8k, gsm8k | PERF: improvement | TEST: Test, test, test",
  "analysis_extracted_at": "2025-09-07 17:49:48",
  "models": [
    "Qwen/Qwen3-30B-A3B-FP8"
  ],
  "lm_eval_commands": [
    "lm_eval --model vllm --model_args pretrained=Qwen/Qwen3-30B-A3B-FP8,dtype=float16 --tasks gsm8k --batch_size auto --limit 100"
  ],
  "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-30B-A3B-FP8 --dtype float16 --num-prompts 300 --seed 0",
  "commit_subject": "[Perf] Optimize `reshape_and_cache_flash` CUDA Kernel (#22036)",
  "commit_message": "[Perf] Optimize `reshape_and_cache_flash` CUDA Kernel (#22036)\n\nSigned-off-by: yewentao256 <zhyanwentao@126.com>",
  "commit_date": "2025-08-01T19:18:51-04:00",
  "files_changed": [
    "benchmarks/kernels/benchmark_reshape_and_cache_flash.py",
    "csrc/cache_kernels.cu"
  ],
  "functions_changed": [],
  "stats": {
    "num_test_files": 0,
    "num_non_test_files": 2,
    "only_test_files": 0,
    "only_non_test_files": 1,
    "num_files": 2,
    "num_hunks": 4,
    "num_edited_lines": 248,
    "num_non_test_edited_lines": 248,
    "commit_year": 2025
  },
  "diff_text": "diff --git a/benchmarks/kernels/benchmark_reshape_and_cache_flash.py b/benchmarks/kernels/benchmark_reshape_and_cache_flash.py\nnew file mode 100644\nindex 000000000..d4648c18f\n--- /dev/null\n+++ b/benchmarks/kernels/benchmark_reshape_and_cache_flash.py\n@@ -0,0 +1,156 @@\n+# SPDX-License-Identifier: Apache-2.0\n+# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\n+from __future__ import annotations\n+\n+import random\n+import time\n+\n+import torch\n+from tabulate import tabulate\n+\n+from vllm import _custom_ops as ops\n+from vllm.logger import init_logger\n+from vllm.platforms import current_platform\n+from vllm.utils import (\n+    STR_DTYPE_TO_TORCH_DTYPE,\n+    FlexibleArgumentParser,\n+    create_kv_caches_with_random_flash,\n+)\n+\n+logger = init_logger(__name__)\n+\n+\n+@torch.inference_mode()\n+def run_benchmark(\n+    num_tokens: int,\n+    num_heads: int,\n+    head_size: int,\n+    block_size: int,\n+    num_blocks: int,\n+    dtype: torch.dtype,\n+    kv_cache_dtype: str,\n+    kv_cache_layout: str,\n+    num_iters: int,\n+    device: str = \"cuda\",\n+) -> float:\n+    \"\"\"Return latency (seconds) for given num_tokens.\"\"\"\n+\n+    if kv_cache_dtype == \"fp8\" and head_size % 16:\n+        raise ValueError(\"fp8 kv-cache requires head_size to be a multiple of 16.\")\n+\n+    current_platform.seed_everything(42)\n+    torch.set_default_device(device)\n+\n+    # create random key / value tensors [T, H, D].\n+    key = torch.randn(num_tokens, num_heads, head_size, dtype=dtype, device=device)\n+    value = torch.randn_like(key)\n+\n+    # prepare the slot mapping.\n+    # each token is assigned a unique slot in the KV-cache.\n+    num_slots = block_size * num_blocks\n+    if num_tokens > num_slots:\n+        raise ValueError(\"num_tokens cannot exceed the total number of cache slots\")\n+    slot_mapping_lst = random.sample(range(num_slots), num_tokens)\n+    slot_mapping = torch.tensor(slot_mapping_lst, dtype=torch.long, device=device)\n+\n+    key_caches, value_caches = create_kv_caches_with_random_flash(\n+        num_blocks,\n+        block_size,\n+        1,  # num_layers\n+        num_heads,\n+        head_size,\n+        kv_cache_dtype,\n+        dtype,\n+        device=device,\n+        cache_layout=kv_cache_layout,\n+    )\n+    key_cache, value_cache = key_caches[0], value_caches[0]\n+\n+    # compute per-kernel scaling factors for fp8 conversion (if used).\n+    k_scale = (key.amax() / 64.0).to(torch.float32)\n+    v_scale = (value.amax() / 64.0).to(torch.float32)\n+\n+    def run_cuda_benchmark(n_iters: int) -> float:\n+        nonlocal key, value, key_cache, value_cache, slot_mapping\n+        torch.cuda.synchronize()\n+        start = time.perf_counter()\n+        for _ in range(n_iters):\n+            ops.reshape_and_cache_flash(\n+                key,\n+                value,\n+                key_cache,\n+                value_cache,\n+                slot_mapping,\n+                kv_cache_dtype,\n+                k_scale,\n+                v_scale,\n+            )\n+        torch.cuda.synchronize()\n+        end = time.perf_counter()\n+        return (end - start) / n_iters\n+\n+    # warm-up\n+    run_cuda_benchmark(3)\n+\n+    lat = run_cuda_benchmark(num_iters)\n+\n+    # free tensors to mitigate OOM when sweeping\n+    del key, value, key_cache, value_cache, slot_mapping\n+    torch.cuda.empty_cache()\n+\n+    return lat\n+\n+\n+def main(args):\n+    rows = []\n+    for layout in [\"NHD\", \"HND\"]:\n+        for exp in range(1, 17):\n+            n_tok = 2**exp\n+            lat = run_benchmark(\n+                num_tokens=n_tok,\n+                num_heads=args.num_heads,\n+                head_size=args.head_size,\n+                block_size=args.block_size,\n+                num_blocks=args.num_blocks,\n+                dtype=STR_DTYPE_TO_TORCH_DTYPE[args.dtype],\n+                kv_cache_dtype=args.kv_cache_dtype,\n+                kv_cache_layout=layout,\n+                num_iters=args.iters,\n+                device=\"cuda\",\n+            )\n+            rows.append([n_tok, layout, f\"{lat * 1e6:.3f}\"])\n+\n+    print(tabulate(rows, headers=[\"num_tokens\", \"layout\", \"latency (¬µs)\"]))\n+\n+\n+if __name__ == \"__main__\":\n+    parser = FlexibleArgumentParser()\n+\n+    parser.add_argument(\"--num-heads\", type=int, default=128)\n+    parser.add_argument(\n+        \"--head-size\",\n+        type=int,\n+        choices=[64, 80, 96, 112, 120, 128, 192, 256],\n+        default=128,\n+    )\n+    parser.add_argument(\"--block-size\", type=int, choices=[16, 32], default=16)\n+    parser.add_argument(\"--num-blocks\", type=int, default=128 * 512)\n+\n+    parser.add_argument(\n+        \"--dtype\",\n+        type=str,\n+        choices=[\"half\", \"bfloat16\", \"float\"],\n+        default=\"bfloat16\",\n+    )\n+\n+    parser.add_argument(\n+        \"--kv-cache-dtype\",\n+        type=str,\n+        choices=[\"auto\", \"fp8\"],\n+        default=\"auto\",\n+    )\n+\n+    parser.add_argument(\"--iters\", type=int, default=100)\n+    args = parser.parse_args()\n+\n+    main(args)\ndiff --git a/csrc/cache_kernels.cu b/csrc/cache_kernels.cu\nindex 88559c8fe..131dcb15c 100644\n--- a/csrc/cache_kernels.cu\n+++ b/csrc/cache_kernels.cu\n@@ -5,6 +5,7 @@\n #include \"cuda_utils.h\"\n #include \"cuda_compat.h\"\n #include \"dispatch_utils.h\"\n+#include \"quantization/vectorization_utils.cuh\"\n \n #ifdef USE_ROCM\n   #include \"quantization/fp8/amd/quant_utils.cuh\"\n@@ -261,14 +262,26 @@ __global__ void reshape_and_cache_kernel(\n   }\n }\n \n+// Used by vectorization_utils to copy/convert one element\n+template <typename OutT, typename InT, Fp8KVCacheDataType kv_dt>\n+struct CopyWithScaleOp {\n+  float scale;\n+\n+  __device__ __forceinline__ void operator()(OutT& dst, const InT src) const {\n+    if constexpr (kv_dt == Fp8KVCacheDataType::kAuto) {\n+      dst = static_cast<OutT>(src);\n+    } else {\n+      dst = fp8::scaled_convert<OutT, InT, kv_dt>(src, scale);\n+    }\n+  }\n+};\n+\n template <typename scalar_t, typename cache_t, Fp8KVCacheDataType kv_dt>\n __global__ void reshape_and_cache_flash_kernel(\n     const scalar_t* __restrict__ key,    // [num_tokens, num_heads, head_size]\n     const scalar_t* __restrict__ value,  // [num_tokens, num_heads, head_size]\n-    cache_t* __restrict__ key_cache,     // [num_blocks, block_size, num_heads,\n-                                         // head_size]\n-    cache_t* __restrict__ value_cache,   // [num_blocks, block_size, num_heads,\n-                                         // head_size]\n+    cache_t* __restrict__ key_cache,     // NHD or HND, shape see comments below\n+    cache_t* __restrict__ value_cache,   // same above\n     const int64_t* __restrict__ slot_mapping,  // [num_tokens]\n     const int64_t block_stride, const int64_t page_stride,\n     const int64_t head_stride, const int64_t key_stride,\n@@ -282,25 +295,58 @@ __global__ void reshape_and_cache_flash_kernel(\n   }\n   const int64_t block_idx = slot_idx / block_size;\n   const int64_t block_offset = slot_idx % block_size;\n-  const int n = num_heads * head_size;\n-  for (int i = threadIdx.x; i < n; i += blockDim.x) {\n-    const int64_t src_key_idx = token_idx * key_stride + i;\n-    const int64_t src_value_idx = token_idx * value_stride + i;\n-    const int head_idx = i / head_size;\n-    const int head_offset = i % head_size;\n-    const int64_t tgt_key_value_idx = block_idx * block_stride +\n-                                      block_offset * page_stride +\n-                                      head_idx * head_stride + head_offset;\n-    scalar_t tgt_key = key[src_key_idx];\n-    scalar_t tgt_value = value[src_value_idx];\n-    if constexpr (kv_dt == Fp8KVCacheDataType::kAuto) {\n-      key_cache[tgt_key_value_idx] = tgt_key;\n-      value_cache[tgt_key_value_idx] = tgt_value;\n-    } else {\n-      key_cache[tgt_key_value_idx] =\n-          fp8::scaled_convert<cache_t, scalar_t, kv_dt>(tgt_key, *k_scale);\n-      value_cache[tgt_key_value_idx] =\n-          fp8::scaled_convert<cache_t, scalar_t, kv_dt>(tgt_value, *v_scale);\n+  const int n_elems = num_heads * head_size;\n+\n+  // pointers to the beginning of the source row for this token.\n+  const scalar_t* __restrict__ key_src = key + token_idx * key_stride;\n+  const scalar_t* __restrict__ value_src = value + token_idx * value_stride;\n+\n+  // find the start position inside the kv-cache for this token.\n+  cache_t* __restrict__ key_dst =\n+      key_cache + block_idx * block_stride + block_offset * page_stride;\n+  cache_t* __restrict__ value_dst =\n+      value_cache + block_idx * block_stride + block_offset * page_stride;\n+\n+  // this is true for the NHD layout where `head_stride == head_size`\n+  const bool is_contiguous_heads = (head_stride == head_size);\n+\n+  float k_scale_val = (kv_dt == Fp8KVCacheDataType::kAuto) ? 0.f : *k_scale;\n+  float v_scale_val = (kv_dt == Fp8KVCacheDataType::kAuto) ? 0.f : *v_scale;\n+  constexpr int VEC_SIZE = (sizeof(scalar_t) == 2) ? 8 : 4;\n+  CopyWithScaleOp<cache_t, scalar_t, kv_dt> k_op{k_scale_val};\n+  CopyWithScaleOp<cache_t, scalar_t, kv_dt> v_op{v_scale_val};\n+  if (is_contiguous_heads) {\n+    // NHD layout\n+    // kv cache: [num_blocks, block_size, num_heads, head_size]\n+    vectorize_with_alignment<VEC_SIZE>(key_src, key_dst, n_elems, threadIdx.x,\n+                                       blockDim.x, k_op);\n+\n+    vectorize_with_alignment<VEC_SIZE>(value_src, value_dst, n_elems,\n+                                       threadIdx.x, blockDim.x, v_op);\n+\n+  } else {\n+    // HND layout: heads are strided, but each head_size segment is contiguous\n+    // kv cache: [num_blocks, num_heads, block_size, head_size]\n+    const int lane = threadIdx.x & 31;     // 0..31 within warp\n+    const int warp_id = threadIdx.x >> 5;  // warp index within block\n+    const int warps_per_block = blockDim.x >> 5;\n+\n+    for (int head = warp_id; head < num_heads; head += warps_per_block) {\n+      const scalar_t* __restrict__ k_src_h = key_src + head * head_size;\n+      const scalar_t* __restrict__ v_src_h = value_src + head * head_size;\n+\n+      cache_t* __restrict__ k_dst_h =\n+          key_dst + static_cast<int64_t>(head) * head_stride;\n+      cache_t* __restrict__ v_dst_h =\n+          value_dst + static_cast<int64_t>(head) * head_stride;\n+\n+      // within each head, let the 32 threads of the warp perform the vector\n+      // copy\n+      vectorize_with_alignment<VEC_SIZE>(k_src_h, k_dst_h, head_size, lane, 32,\n+                                         k_op);\n+\n+      vectorize_with_alignment<VEC_SIZE>(v_src_h, v_dst_h, head_size, lane, 32,\n+                                         v_op);\n     }\n   }\n }",
  "apis": [
    "vllm._custom_ops.reshape_and_cache_flash"
  ],
  "affected_paths": [
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/_custom_ops.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/benchmarks/kernels/benchmark_reshape_and_cache_flash.py"
  ],
  "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm",
  "llm_reason": "The commit makes modifications to a core CUDA kernel in a production source file (csrc/cache_kernels.cu) where it introduces vectorization and scaling operations, indicating a performance optimization. Additionally, it adds a benchmark file in the benchmarks/kernels directory to measure the latency of the modified kernel. The changes are non-trivial, modify key computation paths (memory copy and scaling in the CUDA kernel), and target performance improvement on the CPU/GPU interface. Therefore, the commit meets the criteria for a performance/optimization related change.",
  "llm_api_reason": "This commit introduces performance optimizations to the CUDA kernel used by the \"reshape_and_cache_flash\" operation by incorporating vectorized copying with scaling. Additionally, the benchmark file \"benchmark_reshape_and_cache_flash.py\" is added to measure the latency of this operation. The affected high-level Python API is the one that wraps this CUDA kernel, namely vllm._custom_ops.reshape_and_cache_flash."
}