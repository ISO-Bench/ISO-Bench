{
  "commit_hash": "a32237665df876fcb51196dc209e8aff9fd89d29",
  "pr_url": "https://github.com/vllm-project/vllm/pull/21245",
  "pr_date": "2025-07-20",
  "timeline_text": "Copy link Contributor Jialin commented Jul 20, 2025 ‚Ä¢ edited by github-actions bot Loading Uh oh! There was an error while loading. Please reload this page . Essential Elements of an Effective PR Description Checklist The purpose of the PR, such as \"Fix some issue (link existing issues this PR will resolve)\". The test plan, such as providing test command. The test results, such as pasting the results comparison before and after, or e2e results (Optional) The necessary documentation update, such as updating supported_models.md and examples for a new model. Purpose Fix update checks in MinTokensLogitsProcessor and LogitBiasLogitsProcessor. For a benchmark run without override min length or logit bias, we still see noticeable cost coming from MinTokensLogitsProcessor and LogitBiasLogitsProcessor. We found that it's due to inefficient needs_update tagging which would be tagged to True whenever there're new requests added to the batch. In this diff, we would tag needs_update to True, if new added request had customized min_token config a request with min_token config got popped Test Plan Rerun the benchmark. # vLLM Serving\nexport VLLM_USE_MODELSCOPE=False;\nexport VLLM_TORCH_PROFILER_DIR=~/vllm_profile; # for profiling\nvllm serve facebook/opt-125m \\\n    --swap-space 16 \\\n    --disable-log-requests \\\n    --host :: \\\n    --dtype float16\n\n# Capture traces\nvllm bench serve \\\n    --dataset-name random \\\n    --model facebook/opt-125m \\\n    --served-model-name facebook/opt-125m \\\n    --random-input-len 700 \\\n    --random-output-len 1 \\\n    --endpoint /v1/completions \\\n    --ignore-eos \\\n    --host localhost \\\n    --port 8000 \\\n    --request-rate 200 \\\n    --num-prompts 100 Test Result Confirmed the cost from MinTokensLogitsProcessor and LogitBiasLogitsProcessor is mostly gone. After Before (Optional) Documentation Update Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . üëç 1 yeqcharlotte reacted with thumbs up emoji All reactions üëç 1 reaction Jialin requested review from WoosukKwon , robertgshaw2-redhat , njhill , ywang96 , comaniac and alexm-redhat as code owners July 20, 2025 09:15 Copy link github-actions bot commented Jul 20, 2025 üëã Hi! Thank you for contributing to the vLLM project. üí¨ Join our developer Slack at https://slack.vllm.ai to discuss your PR in #pr-reviews, coordinate on features in #feat- channels, or join special interest groups in #sig- channels. Just a reminder: PRs would not trigger full CI run by default. Instead, it would only run fastcheck CI which starts running only a small and essential subset of CI tests to quickly catch errors. You can run other CI tests on top of those by going to your fastcheck build on Buildkite UI (linked in the PR checks section) and unblock them. If you do not have permission to unblock, ping simon-mo or khluu to add you in our Buildkite org. Once the PR is approved and ready to go, your PR reviewer(s) can run CI to test the changes comprehensively before merging. To run CI, PR reviewers can either: Add ready label to the PR or enable auto-merge. üöÄ All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . mergify bot added\n  the v1 label Jul 20, 2025 gemini-code-assist bot reviewed Jul 20, 2025 View reviewed changes Copy link Contributor gemini-code-assist bot left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Code Review This pull request optimizes update checks in MinTokensLogitsProcessor . I've added a suggestion to improve the maintainability of the new logic by making it more explicit and avoiding a side effect in a conditional statement. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/v1/sample/logits_processor.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . Jialin changed the title [Core] Optimize update checks in MinTokensLogitsProcessor [Core] Optimize update checks in LogitsProcessor Jul 20, 2025 Jialin force-pushed the min_token branch\n    from 9f1d4fd to b300005 Compare July 20, 2025 10:18 Copy link Member njhill commented Jul 20, 2025 Thanks @Jialin . I think I had similar logic in the my original impl of these LPs here https://github.com/vllm-project/vllm/pull/13360/files#diff-d01f143e1af472f24af24842cb879907ce624e6e5c977935e944545240723529R51 and hadn't realized that had been changed. cc @afeldman-nm ‚ù§Ô∏è 1 Jialin reacted with heart emoji All reactions ‚ù§Ô∏è 1 reaction Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . houseroad approved these changes Jul 21, 2025 View reviewed changes Copy link Collaborator houseroad left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Looks good to me. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions vllm/v1/sample/logits_processor.py Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . houseroad added\n  the ready ONLY add when PR is ready to merge/full CI is needed label Jul 21, 2025 Jialin force-pushed the min_token branch\n    from b300005 to 5142da8 Compare July 21, 2025 22:03 houseroad added\n  the performance Performance-related issues label Jul 21, 2025 houseroad enabled auto-merge (squash) July 21, 2025 22:08 Jialin added 2 commits July 21, 2025 22:24 Optimize update checks in MinTokensLogitsProcessor ‚Ä¶ d0baa38 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Apply updates to LogitBiasLogitsProcessor as well ‚Ä¶ b3026ed Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> auto-merge was automatically disabled July 22, 2025 05:25 Head branch was pushed to by a user without write access Jialin force-pushed the min_token branch\n    from 5142da8 to b3026ed Compare July 22, 2025 05:25 Hide details View details vllm-bot merged commit a322376 into vllm-project : main Jul 22, 2025 63 of 65 checks passed Uh oh! There was an error while loading. Please reload this page . Copy link Contributor afeldman-nm commented Jul 22, 2025 Thanks @Jialin ! I think this was probably my bad so thanks for the fix ‚ù§Ô∏è 1 Jialin reacted with heart emoji All reactions ‚ù§Ô∏è 1 reaction Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . Copy link Contributor Author Jialin commented Jul 22, 2025 Thanks @Jialin ! I think this was probably my bad so thanks for the fix No worry :) All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . yeqcharlotte pushed a commit\n        to yeqcharlotte/vllm\n      that referenced\n      this pull request Jul 23, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ f96ca50 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> zixi-qi pushed a commit\n        to zixi-qi/vllm\n      that referenced\n      this pull request Jul 23, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 25d0c72 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: qizixi <qizixi@meta.com> LyrisZhong pushed a commit\n        to LyrisZhong/vllm\n      that referenced\n      this pull request Jul 23, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ f9839e4 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> avigny pushed a commit\n        to avigny/vllm\n      that referenced\n      this pull request Jul 31, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ b5ee4f7 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: avigny <47987522+avigny@users.noreply.github.com> wenscarl pushed a commit\n        to wenscarl/vllm\n      that referenced\n      this pull request Aug 4, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 1e52328 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: shuw <shuw@nvidia.com> x22x22 pushed a commit\n        to x22x22/vllm\n      that referenced\n      this pull request Aug 5, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ daab1aa Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: x22x22 <wadeking@qq.com> Pradyun92 pushed a commit\n        to Pradyun92/vllm\n      that referenced\n      this pull request Aug 6, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ b6c32b5 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> npanpaliya pushed a commit\n        to odh-on-pz/vllm-upstream\n      that referenced\n      this pull request Aug 6, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 87908a8 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> jinzhen-lin pushed a commit\n        to jinzhen-lin/vllm\n      that referenced\n      this pull request Aug 9, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ fad4dd9 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: Jinzhen Lin <linjinzhen@hotmail.com> paulpak58 pushed a commit\n        to paulpak58/vllm\n      that referenced\n      this pull request Aug 13, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 97ee62f Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: Paul Pak <paulpak58@gmail.com> taneem-ibrahim pushed a commit\n        to taneem-ibrahim/vllm\n      that referenced\n      this pull request Aug 14, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 0ca234a Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> diegocastanibm pushed a commit\n        to diegocastanibm/vllm\n      that referenced\n      this pull request Aug 15, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 2ffbc24 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>\nSigned-off-by: Diego-Castan <diego.castan@ibm.com> epwalsh pushed a commit\n        to epwalsh/vllm\n      that referenced\n      this pull request Aug 28, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 34bfe4b Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> googlercolin pushed a commit\n        to googlercolin/vllm\n      that referenced\n      this pull request Aug 29, 2025 [Core] Optimize update checks in LogitsProcessor ( vllm-project#21245 ) ‚Ä¶ 9405819 Signed-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com> Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-07 17:50:16",
  "has_lm_eval": false,
  "has_performance": true,
  "has_serving": true,
  "has_general_test": true,
  "test_details": "PERF: benchmark run without override min length or logit bias, we still see noticeable cost coming from MinTokensLogitsProcessor and LogitBiasLogitsProcessor. We found that it's due to inefficient needs_update tagging which would be tagged to True whenever there're new requests added to the batch. In this diff, we would tag needs_update to True, if new added request had customized min_token config a request with min_token config got popped Test Plan Rerun the benchmark. # vLLM Serving, profiling | SERVING: vllm serve, Serving, serve | TEST: test, test, test",
  "analysis_extracted_at": "2025-09-07 17:50:16",
  "models": [
    "N/A"
  ],
  "lm_eval_commands": null,
  "perf_command": "vllm bench serve --dataset-name random --model facebook/opt-125m --served-model-name facebook/opt-125m --random-input-len 700 --random-output-len 1 --endpoint /v1/completions --ignore-eos --host localhost --port 8000 --request-rate 200 --num-prompts 100",
  "commit_subject": "[Core] Optimize update checks in LogitsProcessor (#21245)",
  "commit_message": "[Core] Optimize update checks in LogitsProcessor (#21245)\n\nSigned-off-by: Jialin Ouyang <Jialin.Ouyang@gmail.com>",
  "commit_date": "2025-07-22T05:27:18-07:00",
  "files_changed": [
    "vllm/v1/sample/logits_processor.py"
  ],
  "functions_changed": [],
  "stats": {
    "num_test_files": 0,
    "num_non_test_files": 1,
    "only_test_files": 0,
    "only_non_test_files": 1,
    "num_files": 1,
    "num_hunks": 3,
    "num_edited_lines": 18,
    "num_non_test_edited_lines": 18,
    "commit_year": 2025
  },
  "diff_text": "diff --git a/vllm/v1/sample/logits_processor.py b/vllm/v1/sample/logits_processor.py\nindex 3a4c25964..3a06e7105 100644\n--- a/vllm/v1/sample/logits_processor.py\n+++ b/vllm/v1/sample/logits_processor.py\n@@ -335,14 +335,19 @@ class LogitBiasLogitsProcessor(LogitsProcessor):\n         if not batch_update:\n             return\n \n+        needs_update: bool = False\n         # Process added requests.\n-        needs_update = bool(batch_update.added)\n         for index, params, _ in batch_update.added:\n             if isinstance(params, SamplingParams) and (lb :=\n                                                        params.logit_bias):\n                 self.biases[index] = lb\n+                needs_update = True\n             else:\n-                self.biases.pop(index, None)\n+                # Drop biases metadata at batch index\n+                if self.biases.pop(index, None) is not None:\n+                    # If a new request replaces an old request which\n+                    # specified biases, we should update processor tensors\n+                    needs_update = True\n \n         if self.biases:\n             # Process removed requests.\n@@ -419,7 +424,6 @@ class MinTokensLogitsProcessor(LogitsProcessor):\n \n         if batch_update:\n             # Process added requests.\n-            needs_update |= bool(batch_update.added)\n             for index, params, output_tok_ids in batch_update.added:\n                 if (isinstance(params, SamplingParams)\n                         and (min_tokens := params.min_tokens)\n@@ -427,9 +431,13 @@ class MinTokensLogitsProcessor(LogitsProcessor):\n                     # Replace request metadata at batch index\n                     self.min_toks[index] = (min_tokens, output_tok_ids,\n                                             params.all_stop_token_ids)\n+                    needs_update = True\n                 else:\n-                    # Drop request metadata at batch index\n-                    self.min_toks.pop(index, None)\n+                    # Drop min_toks metadata at batch index\n+                    if self.min_toks.pop(index, None) is not None:\n+                        # If a new request replaces an old request which\n+                        # specified min_toks, we should update processor tensors\n+                        needs_update = True\n \n             if self.min_toks:\n                 # Process removed requests.",
  "apis": [
    "LogitBiasLogitsProcessor.update_state",
    "MinTokensLogitsProcessor.update_state"
  ],
  "affected_paths": [
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/v1/sample/logits_processor.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/model_executor/layers/logits_processor.py",
    "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/entrypoints/openai/logits_processors.py"
  ],
  "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm",
  "llm_reason": "The commit modifies a non-test source file in core components (LogitsProcessor and MinTokensLogitsProcessor) and changes the update-check logic. Instead of simply checking the truthiness of batch updates, it introduces a more precise tracking variable (\"needs_update\") to only update processor tensors when necessary. This is intended to optimize performance by avoiding unnecessary updates. The changes are non-trivial, affect internal API performance, and are focused on CPU execution. Thus, it meets the conditions for being performance/optimization related. [ANSWER] YES [/ANSWER]",
  "llm_api_reason": "The commit optimizes the update checks within the update_state method implementations of two logits processor classes. In LogitBiasLogitsProcessor, the update_state method is modified to set a flag (needs_update) when biases are added or when an existing bias is dropped and replaced. Similarly, in MinTokensLogitsProcessor, the update_state method is changed to update the processor's state only when necessary by conditionally setting the update flag when min-token metadata is added or dropped. Both changes affect the behavior of the update_state APIs for these two classes, which are used to manage logits processing during model inference."
}