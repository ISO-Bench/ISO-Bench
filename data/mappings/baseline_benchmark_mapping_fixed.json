[
  {
    "human_commit_short": "015069b0",
    "human_commit_full": "015069b01741e9ecb9e604c7fe87fbdfc306ebe5",
    "parent_commit": "fbefc8a78d22b20eac042c586805c7dcbfc66b1c",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-1.7B --dataset-name sharegpt --request-rate 1",
    "model": "Qwen/Qwen3-1.7B",
    "benchmark_type": "serving",
    "docker_throughput": 1428.29
  },
  {
    "human_commit_short": "0ec82edd",
    "human_commit_full": "0ec82edda59aaf5cf3b07aadf4ecce1aa1131add",
    "parent_commit": "005ae9be6c22dfa2c2c5580b50b41e67faee4a87",
    "perf_command": "vllm bench throughput --model Qwen/Qwen3-30B-A3B --load-format dummy --input-len 1000 --output-len 100",
    "model": "Qwen/Qwen3-30B-A3B",
    "benchmark_type": "throughput",
    "docker_throughput": 6368.6
  },
  {
    "human_commit_short": "21d93c14",
    "human_commit_full": "21d93c140d0a97af5f0c59e660cf04bd417fd424",
    "parent_commit": "f1c8520146031a650404a6ab120ee11e91c10bed",
    "perf_command": "python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1 --tensor-parallel-size 8",
    "model": "mistralai/Mixtral-8x7B-v0.1",
    "benchmark_type": "unknown",
    "docker_throughput": 3058.0
  },
  {
    "human_commit_short": "22d33bac",
    "human_commit_full": "22d33baca2c0c639cfd45c48e99803e56c3efa74",
    "parent_commit": "b0e96aaebbfbe8e70478e4192a5a13864ffdefa6",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 3025.62,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "22dd9c27",
    "human_commit_full": "22dd9c2730dc1124b9d0ac15fff223d0b8d9020b",
    "parent_commit": "a6d795d593046abd490b16349bcd9b40feedd334",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "latency",
    "docker_throughput": null,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "296f927f",
    "human_commit_full": "296f927f2493908984707354e3cc5d7b2e41650b",
    "parent_commit": "0032903a5bb7c7c655f52f4efdfcc221947e9ca8",
    "perf_command": "python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B --dtype float16 --num-prompts 300 --seed 0",
    "model": "ibm-ai-platform/Bamba-9B",
    "benchmark_type": "serving",
    "docker_throughput": 813.28
  },
  {
    "human_commit_short": "2a052011",
    "human_commit_full": "2a052011ca473a9dc8160f3daa1f5f63a2ad1fe3",
    "parent_commit": "36fb68f94792a8cec8df5b58bab7ab4d4d6158b4",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-7B-Instruct --quantization fp8",
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6623.3
  },
  {
    "human_commit_short": "3092375e",
    "human_commit_full": "3092375e274e9e003961e600e10a6192d33ceaa0",
    "parent_commit": "3cd91dc9555e6f10e55f23d37782c65b0366f7cf",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 4449.6,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "3476ed08",
    "human_commit_full": "3476ed0809ec91a3457da0cb90543133a4f4b519",
    "parent_commit": "54600709b6d419fb243ce718a48ab7d40f5c3eb7",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6224.8,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "35fad35a",
    "human_commit_full": "35fad35a485eac9195c510731ba4a9d297dfd963",
    "parent_commit": "733e7c9e95f5b066ac420b00701eef7ea164a79e",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 2301.7,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "379da6dc",
    "human_commit_full": "379da6dcb5f5d062d0452b2fc23291e5113dcf04",
    "parent_commit": "ebce310b7433e050086f52ca48571807df467f50",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-70B --input-len 1000 --output-len 50 --tensor-parallel-size 4 --quantization fp8",
    "model": "meta-llama/Meta-Llama-3-70B",
    "benchmark_type": "unknown",
    "docker_throughput": 7099.3
  },
  {
    "human_commit_short": "3a243095",
    "human_commit_full": "3a243095e5e7b655b63ab08fbd5936cb40850415",
    "parent_commit": "64172a976c8d975b3aec946f1675716d2532d94f",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7125.0,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "660470e5",
    "human_commit_full": "660470e5a36b8e52083615ad7c85e9b4fd4c72ce",
    "parent_commit": "8d59dbb00044a588cab96bcdc028006ed922eb06",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --tensor-parallel-size 1 --enable-prefix-caching --use-v2-block-manager",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7150.3,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "67da5720",
    "human_commit_full": "67da5720d4ed2aa1f615ec812031f4f3753b3f62",
    "parent_commit": "5c04bb8b863bfdef8122b193631479315cc764f5",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-7B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 6421.13
  },
  {
    "human_commit_short": "6ce01f30",
    "human_commit_full": "6ce01f30667bbae33f112152e07a3b66b841078f",
    "parent_commit": "6a11fdfbb8d6701c7ad38648aead23d8cbe6aac5",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "unknown",
    "docker_throughput": 7062.1
  },
  {
    "human_commit_short": "6d646d08",
    "human_commit_full": "6d646d08a2e0e73e83e313a5ae470c1f9e4f200e",
    "parent_commit": "95a178f86120f42d183b3af5ee1ce58ee05c8889",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dataset ShareGPT_V3_unfiltered_cleaned_split.json",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "unknown",
    "docker_throughput": 8039.8
  },
  {
    "human_commit_short": "6e36f4fa",
    "human_commit_full": "6e36f4fa6ce64619b9ea94c88a157f5783a63a65",
    "parent_commit": "dd2a6a82e3f41b4673b1dbb24b2e99230ea96981",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7855.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "7c01f706",
    "human_commit_full": "7c01f706418d593b3cf23d2ec9110dca7151c539",
    "parent_commit": "51e971d39e1272f1c5b070a5da6b38ccfa92fc14",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6213.9,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "80aa7e91",
    "human_commit_full": "80aa7e91fcd547a7a1396f71b9bdce18e5c92245",
    "parent_commit": "bd43973522ea17be50e10fbb222a22f673c8067e",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6369.9,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "83450458",
    "human_commit_full": "83450458339b07765b0e72a822e5fe93eeaf5258",
    "parent_commit": "5b8a1fde84224e24ec121e0dc149d775330d911b",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Meta-Llama-3-8B --speculative-model '[ngram]' --num-speculative-tokens 5 --input-len 550 --output-len 150",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7443.9,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "89a84b0b",
    "human_commit_full": "89a84b0bb7b30706a02836234a94493ea8f780bf",
    "parent_commit": "084a01fd3544557990f8af8af6fd3c1185bae848",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen1.5-0.5B --backend vllm --num-prompts 2048 --input-len 1024",
    "model": "Qwen/Qwen1.5-0.5B",
    "benchmark_type": "unknown",
    "docker_throughput": 6003.6
  },
  {
    "human_commit_short": "8bc68e19",
    "human_commit_full": "8bc68e198c4c90ddc2e54fa76eb81c2c714bb1cd",
    "parent_commit": "0fca3cdcf265cd375bca684d951702b6b7adf65a",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6874.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "8d75fe48",
    "human_commit_full": "8d75fe48ca5f46b7af0f5201d8500b9604eed769",
    "parent_commit": "388596c91437a51d428a447594e9faec340c29b2",
    "perf_command": "python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --dataset-name sharegpt --dataset-path ./ShareGPT_V3_unfiltered_cleaned_split.json",
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "benchmark_type": "unknown",
    "docker_throughput": 6174.1
  },
  {
    "human_commit_short": "93e5f3c5",
    "human_commit_full": "93e5f3c5fb4a4bbd49610efb96aad30df95fca66",
    "parent_commit": "70363bccfac1a6a0818ea577ad9cf8123a0ec3ae",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 4912.1,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "9474e89b",
    "human_commit_full": "9474e89ba4ecae253b585eb6b3e1d85f4e108f01",
    "parent_commit": "20478c4d3abcd0aa8a1d9ace9c76ea3a2e04cb5e",
    "perf_command": "python benchmark_throughput_cache.py --backend vllm --model huggyllama/llama-7b --dataset ../data/ShareGPT_V3_unfiltered_cleaned_split.json --num-prompts 2000",
    "model": "huggyllama/llama-7b",
    "benchmark_type": "unknown",
    "docker_throughput": 7183.6
  },
  {
    "human_commit_short": "99abb8b6",
    "human_commit_full": "99abb8b650c66664cdc84d815b7f306f33bd9881",
    "parent_commit": "3a1e6481586ed7f079275b5d5072a6e246af691e",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dataset-name sharegpt --num-prompts 1000",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 2408.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "9badee53",
    "human_commit_full": "9badee53decb3d432dc805336abfb0eb81dfb48f",
    "parent_commit": "beebf4742af80296d3c3a657c66d512615c550c1",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dataset-path ShareGPT_V3_unfiltered_cleaned_split.json",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 8057.6,
    "original_model": "meta-llama/Llama-3.2-1B-Instruct"
  },
  {
    "human_commit_short": "9d72daf4",
    "human_commit_full": "9d72daf4ced05a5fec1ad8ea2914a39296f402da",
    "parent_commit": "6dd55af6c9dde9174e0616739d783133f5e45d42",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 2343.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "9ed82e70",
    "human_commit_full": "9ed82e7074a18e25680ab106fc846364ad97bc00",
    "parent_commit": "51f8aa90ad409cc77bfab208be7f5907bf7d5330",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 5615.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "ad8d696a",
    "human_commit_full": "ad8d696a99ca1eee19f1404e16e8e82df592ff85",
    "parent_commit": "3d925165f2b18379640a63fbb42de95440d63b64",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 6573.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "aea94362",
    "human_commit_full": "aea94362c9bdd08ed2b346701bdc09d278e85f66",
    "parent_commit": "7206ce4ce112ed117796a59045c968a6d353f691",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 3628.7,
    "original_model": "meta-llama/Llama-3.2-1B-Instruct"
  },
  {
    "human_commit_short": "b10e5198",
    "human_commit_full": "b10e51989551cd80dd74079429ccf91f0807bd92",
    "parent_commit": "9bde5ba12709ea0fe9e1a1eeee1e8d7b4c7ea668",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 4799.8,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "b6d10354",
    "human_commit_full": "b6d103542c654fb63013a1e45a586d654ae36a2a",
    "parent_commit": "51c31bc10ca7c48b580cd58fcd741ba4d6db4447",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Llama-2-70b-hf --dtype float16 --tensor-parallel-size 1",
    "model": "meta-llama/Llama-2-70b-hf",
    "benchmark_type": "unknown",
    "docker_throughput": 5212.5
  },
  {
    "human_commit_short": "c0569dbc",
    "human_commit_full": "c0569dbc82b5e945a77878190114d1b68027828b",
    "parent_commit": "8bb43b9c9ee878e07038d3f36aaf279ffb2fabab",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-30B-A3B-FP8 --dtype float16 --num-prompts 300 --seed 0",
    "model": "Qwen/Qwen3-30B-A3B-FP8",
    "benchmark_type": "throughput",
    "docker_throughput": 6561.6
  },
  {
    "human_commit_short": "ca7a2d5f",
    "human_commit_full": "ca7a2d5f28eac9621474563cdda0e08596222755",
    "parent_commit": "333681408feabb97193880303b23f6571ba39045",
    "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 8307.8
  },
  {
    "human_commit_short": "ccf02fcb",
    "human_commit_full": "ccf02fcbaebb1a5b59dfc6c7cb64aa7cc489f04c",
    "parent_commit": "acaea3bb07883c80b71643ebee1cd08d555797bc",
    "perf_command": "python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B --dtype float16 --num-prompts 300 --seed 0",
    "model": "ibm-ai-platform/Bamba-9B",
    "benchmark_type": "throughput",
    "docker_throughput": 5085.4
  },
  {
    "human_commit_short": "cf2f084d",
    "human_commit_full": "cf2f084d56a1293cb08da2393984cdc7685ac019",
    "parent_commit": "f721096d48a7e3b98dffcb9b400bf58989cef64d",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7080.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "d55e446d",
    "human_commit_full": "d55e446d1320d0f5f22bc3584f81f18d7924f166",
    "parent_commit": "ec82c3e388b962a30a02fa376c222cef787b3c14",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-8B --batch-size 2",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 6934.8
  },
  {
    "human_commit_short": "d7740ea4",
    "human_commit_full": "d7740ea4dcee4ab75d7d6eef723f33cae957b288",
    "parent_commit": "cc466a32903d53d0ceca459b766d74ad668c8f87",
    "perf_command": "python benchmarks/benchmark_throughput.py --model meta-llama/Meta-Llama-3-8B-Instruct --input-len 256 --output-len 256",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6946.3,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "dcc6cfb9",
    "human_commit_full": "dcc6cfb991cd76369aad96e04424f29c8fecdbd8",
    "parent_commit": "dd572c0ab3effa539b74f9a1288bb61ce83ada76",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-30B-A3B-FP8 --dtype float16 --num-prompts 300 --seed 0",
    "model": "Qwen/Qwen3-30B-A3B-FP8",
    "benchmark_type": "throughput",
    "docker_throughput": 6428.6
  },
  {
    "human_commit_short": "e206b543",
    "human_commit_full": "e206b5433109d298e53451015465b2bf8f03ef0a",
    "parent_commit": "1d35662e6dc199431bfe4004cc84d66fd9b297b1",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100 --guided-decoding-backend xgrammar",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 8148.0,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "e3580537",
    "human_commit_full": "e3580537a41a46b0f3cd750b86b633c1857a8c90",
    "parent_commit": "f508e03e7f2d8aed897d8843e1ed1668e5c4ad7a",
    "perf_command": "python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --enable-prefix-caching --enable-chunked-prefill --max-num-batched-tokens 2048",
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "benchmark_type": "unknown",
    "docker_throughput": 7440.7
  },
  {
    "human_commit_short": "e493e485",
    "human_commit_full": "e493e48524e9e78ab33eafec6461b3940e361189",
    "parent_commit": "4ce64e2df48649c4873f828b8bf71790aa1e56ee",
    "perf_command": "python benchmarks/benchmark_serving.py --model microsoft/phi-1_5 --backend vllm --num-prompts 100",
    "model": "microsoft/phi-1_5",
    "benchmark_type": "throughput",
    "docker_throughput": 6981.4
  },
  {
    "human_commit_short": "e7b20426",
    "human_commit_full": "e7b204268132cb775c139574c1ff4ad7e15c8f66",
    "parent_commit": "90f1e55421f1b61394ba25abe34bf5abd82a71af",
    "perf_command": "python benchmarks/benchmark_serving.py --model 01-ai/Yi-1.5-9B-Chat --dtype float16 --num-prompts 300 --seed 0",
    "model": "01-ai/Yi-1.5-9B-Chat",
    "benchmark_type": "throughput",
    "docker_throughput": 6582.5
  },
  {
    "human_commit_short": "fc7b8d1e",
    "human_commit_full": "fc7b8d1eefcbe837a56b7c080509417fe5167e6c",
    "parent_commit": "67abdbb42fdbb59c274130368981c0d0ac3539e3",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7174.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  }
]