[
  {
    "human_commit_short": "015069b0",
    "human_commit_full": "015069b01741e9ecb9e604c7fe87fbdfc306ebe5",
    "parent_commit": "fbefc8a78d22b20eac042c586805c7dcbfc66b1c",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-1.7B --dataset-name sharegpt --request-rate 1",
    "model": "Qwen/Qwen3-1.7B",
    "benchmark_type": "serving",
    "docker_throughput": 1428.29
  },
  {
    "human_commit_short": "0ec82edd",
    "human_commit_full": "0ec82edda59aaf5cf3b07aadf4ecce1aa1131add",
    "parent_commit": "005ae9be6c22dfa2c2c5580b50b41e67faee4a87",
    "perf_command": "vllm bench throughput --model Qwen/Qwen3-30B-A3B --load-format dummy --input-len 1000 --output-len 100",
    "model": "Qwen/Qwen3-30B-A3B",
    "benchmark_type": "throughput",
    "docker_throughput": 6368.6
  },
  {
    "human_commit_short": "21d93c14",
    "human_commit_full": "21d93c140d0a97af5f0c59e660cf04bd417fd424",
    "parent_commit": "f1c8520146031a650404a6ab120ee11e91c10bed",
    "perf_command": "python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1 --tensor-parallel-size 8",
    "model": "mistralai/Mixtral-8x7B-v0.1",
    "benchmark_type": "unknown",
    "docker_throughput": 3058.0
  },
  {
    "human_commit_short": "22d33bac",
    "human_commit_full": "22d33baca2c0c639cfd45c48e99803e56c3efa74",
    "parent_commit": "b0e96aaebbfbe8e70478e4192a5a13864ffdefa6",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 3025.62,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "22dd9c27",
    "human_commit_full": "22dd9c2730dc1124b9d0ac15fff223d0b8d9020b",
    "parent_commit": "a6d795d593046abd490b16349bcd9b40feedd334",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "latency",
    "docker_throughput": null,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "296f927f",
    "human_commit_full": "296f927f2493908984707354e3cc5d7b2e41650b",
    "parent_commit": "0032903a5bb7c7c655f52f4efdfcc221947e9ca8",
    "perf_command": "python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B --dtype float16 --num-prompts 300 --seed 0",
    "model": "ibm-ai-platform/Bamba-9B",
    "benchmark_type": "serving",
    "docker_throughput": 813.28
  },
  {
    "human_commit_short": "2a052011",
    "human_commit_full": "2a052011ca473a9dc8160f3daa1f5f63a2ad1fe3",
    "parent_commit": "36fb68f94792a8cec8df5b58bab7ab4d4d6158b4",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-7B-Instruct --quantization fp8",
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6623.3
  },
  {
    "human_commit_short": "3092375e",
    "human_commit_full": "3092375e274e9e003961e600e10a6192d33ceaa0",
    "parent_commit": "3cd91dc9555e6f10e55f23d37782c65b0366f7cf",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 4449.6,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "3476ed08",
    "human_commit_full": "3476ed0809ec91a3457da0cb90543133a4f4b519",
    "parent_commit": "54600709b6d419fb243ce718a48ab7d40f5c3eb7",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6224.8,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "35fad35a",
    "human_commit_full": "35fad35a485eac9195c510731ba4a9d297dfd963",
    "parent_commit": "733e7c9e95f5b066ac420b00701eef7ea164a79e",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 2301.7,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "379da6dc",
    "human_commit_full": "379da6dcb5f5d062d0452b2fc23291e5113dcf04",
    "parent_commit": "ebce310b7433e050086f52ca48571807df467f50",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-70B --input-len 1000 --output-len 50 --tensor-parallel-size 4 --quantization fp8",
    "model": "meta-llama/Meta-Llama-3-70B",
    "benchmark_type": "unknown",
    "docker_throughput": 7099.3
  },
  {
    "human_commit_short": "3a243095",
    "human_commit_full": "3a243095e5e7b655b63ab08fbd5936cb40850415",
    "parent_commit": "64172a976c8d975b3aec946f1675716d2532d94f",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7125.0,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "660470e5",
    "human_commit_full": "660470e5a36b8e52083615ad7c85e9b4fd4c72ce",
    "parent_commit": "8d59dbb00044a588cab96bcdc028006ed922eb06",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --tensor-parallel-size 1 --enable-prefix-caching --use-v2-block-manager",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7150.3,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "67da5720",
    "human_commit_full": "67da5720d4ed2aa1f615ec812031f4f3753b3f62",
    "parent_commit": "5c04bb8b863bfdef8122b193631479315cc764f5",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-7B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 6421.13
  },
  {
    "human_commit_short": "6ce01f30",
    "human_commit_full": "6ce01f30667bbae33f112152e07a3b66b841078f",
    "parent_commit": "6a11fdfbb8d6701c7ad38648aead23d8cbe6aac5",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "unknown",
    "docker_throughput": 7062.1
  },
  {
    "human_commit_short": "6d646d08",
    "human_commit_full": "6d646d08a2e0e73e83e313a5ae470c1f9e4f200e",
    "parent_commit": "95a178f86120f42d183b3af5ee1ce58ee05c8889",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dataset ShareGPT_V3_unfiltered_cleaned_split.json",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "unknown",
    "docker_throughput": 8039.8
  },
  {
    "human_commit_short": "6e36f4fa",
    "human_commit_full": "6e36f4fa6ce64619b9ea94c88a157f5783a63a65",
    "parent_commit": "dd2a6a82e3f41b4673b1dbb24b2e99230ea96981",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7855.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "7c01f706",
    "human_commit_full": "7c01f706418d593b3cf23d2ec9110dca7151c539",
    "parent_commit": "51e971d39e1272f1c5b070a5da6b38ccfa92fc14",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6213.9,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "80aa7e91",
    "human_commit_full": "80aa7e91fcd547a7a1396f71b9bdce18e5c92245",
    "parent_commit": "bd43973522ea17be50e10fbb222a22f673c8067e",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6369.9,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "83450458",
    "human_commit_full": "83450458339b07765b0e72a822e5fe93eeaf5258",
    "parent_commit": "5b8a1fde84224e24ec121e0dc149d775330d911b",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Meta-Llama-3-8B --speculative-model '[ngram]' --num-speculative-tokens 5 --input-len 550 --output-len 150",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7443.9,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "89a84b0b",
    "human_commit_full": "89a84b0bb7b30706a02836234a94493ea8f780bf",
    "parent_commit": "084a01fd3544557990f8af8af6fd3c1185bae848",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen1.5-0.5B --backend vllm --num-prompts 2048 --input-len 1024",
    "model": "Qwen/Qwen1.5-0.5B",
    "benchmark_type": "unknown",
    "docker_throughput": 6003.6
  },
  {
    "human_commit_short": "8bc68e19",
    "human_commit_full": "8bc68e198c4c90ddc2e54fa76eb81c2c714bb1cd",
    "parent_commit": "0fca3cdcf265cd375bca684d951702b6b7adf65a",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6874.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "8d75fe48",
    "human_commit_full": "8d75fe48ca5f46b7af0f5201d8500b9604eed769",
    "parent_commit": "388596c91437a51d428a447594e9faec340c29b2",
    "perf_command": "python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --dataset-name sharegpt --dataset-path ./ShareGPT_V3_unfiltered_cleaned_split.json",
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "benchmark_type": "unknown",
    "docker_throughput": 6174.1
  },
  {
    "human_commit_short": "93e5f3c5",
    "human_commit_full": "93e5f3c5fb4a4bbd49610efb96aad30df95fca66",
    "parent_commit": "70363bccfac1a6a0818ea577ad9cf8123a0ec3ae",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 4912.1,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "9474e89b",
    "human_commit_full": "9474e89ba4ecae253b585eb6b3e1d85f4e108f01",
    "parent_commit": "20478c4d3abcd0aa8a1d9ace9c76ea3a2e04cb5e",
    "perf_command": "python benchmark_throughput_cache.py --backend vllm --model huggyllama/llama-7b --dataset ../data/ShareGPT_V3_unfiltered_cleaned_split.json --num-prompts 2000",
    "model": "huggyllama/llama-7b",
    "benchmark_type": "unknown",
    "docker_throughput": 7183.6
  },
  {
    "human_commit_short": "99abb8b6",
    "human_commit_full": "99abb8b650c66664cdc84d815b7f306f33bd9881",
    "parent_commit": "3a1e6481586ed7f079275b5d5072a6e246af691e",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dataset-name sharegpt --num-prompts 1000",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 2408.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "9badee53",
    "human_commit_full": "9badee53decb3d432dc805336abfb0eb81dfb48f",
    "parent_commit": "beebf4742af80296d3c3a657c66d512615c550c1",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dataset-path ShareGPT_V3_unfiltered_cleaned_split.json",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 8057.6,
    "original_model": "meta-llama/Llama-3.2-1B-Instruct"
  },
  {
    "human_commit_short": "9d72daf4",
    "human_commit_full": "9d72daf4ced05a5fec1ad8ea2914a39296f402da",
    "parent_commit": "6dd55af6c9dde9174e0616739d783133f5e45d42",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 2343.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "9ed82e70",
    "human_commit_full": "9ed82e7074a18e25680ab106fc846364ad97bc00",
    "parent_commit": "51f8aa90ad409cc77bfab208be7f5907bf7d5330",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 5615.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "ad8d696a",
    "human_commit_full": "ad8d696a99ca1eee19f1404e16e8e82df592ff85",
    "parent_commit": "3d925165f2b18379640a63fbb42de95440d63b64",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 6573.2,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "aea94362",
    "human_commit_full": "aea94362c9bdd08ed2b346701bdc09d278e85f66",
    "parent_commit": "7206ce4ce112ed117796a59045c968a6d353f691",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 3628.7,
    "original_model": "meta-llama/Llama-3.2-1B-Instruct"
  },
  {
    "human_commit_short": "b10e5198",
    "human_commit_full": "b10e51989551cd80dd74079429ccf91f0807bd92",
    "parent_commit": "9bde5ba12709ea0fe9e1a1eeee1e8d7b4c7ea668",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 4799.8,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "b6d10354",
    "human_commit_full": "b6d103542c654fb63013a1e45a586d654ae36a2a",
    "parent_commit": "51c31bc10ca7c48b580cd58fcd741ba4d6db4447",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Llama-2-70b-hf --dtype float16 --tensor-parallel-size 1",
    "model": "meta-llama/Llama-2-70b-hf",
    "benchmark_type": "unknown",
    "docker_throughput": 5212.5
  },
  {
    "human_commit_short": "c0569dbc",
    "human_commit_full": "c0569dbc82b5e945a77878190114d1b68027828b",
    "parent_commit": "8bb43b9c9ee878e07038d3f36aaf279ffb2fabab",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-30B-A3B-FP8 --dtype float16 --num-prompts 300 --seed 0",
    "model": "Qwen/Qwen3-30B-A3B-FP8",
    "benchmark_type": "throughput",
    "docker_throughput": 6561.6
  },
  {
    "human_commit_short": "ca7a2d5f",
    "human_commit_full": "ca7a2d5f28eac9621474563cdda0e08596222755",
    "parent_commit": "333681408feabb97193880303b23f6571ba39045",
    "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 8307.8
  },
  {
    "human_commit_short": "ccf02fcb",
    "human_commit_full": "ccf02fcbaebb1a5b59dfc6c7cb64aa7cc489f04c",
    "parent_commit": "acaea3bb07883c80b71643ebee1cd08d555797bc",
    "perf_command": "python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B --dtype float16 --num-prompts 300 --seed 0",
    "model": "ibm-ai-platform/Bamba-9B",
    "benchmark_type": "throughput",
    "docker_throughput": 5085.4
  },
  {
    "human_commit_short": "cf2f084d",
    "human_commit_full": "cf2f084d56a1293cb08da2393984cdc7685ac019",
    "parent_commit": "f721096d48a7e3b98dffcb9b400bf58989cef64d",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7080.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "d55e446d",
    "human_commit_full": "d55e446d1320d0f5f22bc3584f81f18d7924f166",
    "parent_commit": "ec82c3e388b962a30a02fa376c222cef787b3c14",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-8B --batch-size 2",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "throughput",
    "docker_throughput": 6934.8
  },
  {
    "human_commit_short": "d7740ea4",
    "human_commit_full": "d7740ea4dcee4ab75d7d6eef723f33cae957b288",
    "parent_commit": "cc466a32903d53d0ceca459b766d74ad668c8f87",
    "perf_command": "python benchmarks/benchmark_throughput.py --model meta-llama/Meta-Llama-3-8B-Instruct --input-len 256 --output-len 256",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 6946.3,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "dcc6cfb9",
    "human_commit_full": "dcc6cfb991cd76369aad96e04424f29c8fecdbd8",
    "parent_commit": "dd572c0ab3effa539b74f9a1288bb61ce83ada76",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-30B-A3B-FP8 --dtype float16 --num-prompts 300 --seed 0",
    "model": "Qwen/Qwen3-30B-A3B-FP8",
    "benchmark_type": "throughput",
    "docker_throughput": 6428.6
  },
  {
    "human_commit_short": "e206b543",
    "human_commit_full": "e206b5433109d298e53451015465b2bf8f03ef0a",
    "parent_commit": "1d35662e6dc199431bfe4004cc84d66fd9b297b1",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B-Instruct --backend vllm --num-prompts 100 --guided-decoding-backend xgrammar",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 8148.0,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "e3580537",
    "human_commit_full": "e3580537a41a46b0f3cd750b86b633c1857a8c90",
    "parent_commit": "f508e03e7f2d8aed897d8843e1ed1668e5c4ad7a",
    "perf_command": "python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --enable-prefix-caching --enable-chunked-prefill --max-num-batched-tokens 2048",
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "benchmark_type": "unknown",
    "docker_throughput": 7440.7
  },
  {
    "human_commit_short": "e493e485",
    "human_commit_full": "e493e48524e9e78ab33eafec6461b3940e361189",
    "parent_commit": "4ce64e2df48649c4873f828b8bf71790aa1e56ee",
    "perf_command": "python benchmarks/benchmark_serving.py --model microsoft/phi-1_5 --backend vllm --num-prompts 100",
    "model": "microsoft/phi-1_5",
    "benchmark_type": "throughput",
    "docker_throughput": 6981.4
  },
  {
    "human_commit_short": "e7b20426",
    "human_commit_full": "e7b204268132cb775c139574c1ff4ad7e15c8f66",
    "parent_commit": "90f1e55421f1b61394ba25abe34bf5abd82a71af",
    "perf_command": "python benchmarks/benchmark_serving.py --model 01-ai/Yi-1.5-9B-Chat --dtype float16 --num-prompts 300 --seed 0",
    "model": "01-ai/Yi-1.5-9B-Chat",
    "benchmark_type": "throughput",
    "docker_throughput": 6582.5
  },
  {
    "human_commit_short": "fc7b8d1e",
    "human_commit_full": "fc7b8d1eefcbe837a56b7c080509417fe5167e6c",
    "parent_commit": "67abdbb42fdbb59c274130368981c0d0ac3539e3",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "benchmark_type": "unknown",
    "docker_throughput": 7174.5,
    "original_model": "meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "human_commit_short": "0d243f2a",
    "human_commit_full": "0d243f2a54fbd1c56da8a571f0899c30b6aba5d9",
    "parent_commit": "88f6ba3281f727d5641d362476ae68562b666081",
    "perf_command": "python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1",
    "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "25ebed2f",
    "human_commit_full": "25ebed2f8ca6d747d63f2be9ede023c561851ac8",
    "parent_commit": "d263bd9df7b2f5586910e5d006a11ff11ba7c310",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "299ebb62",
    "human_commit_full": "299ebb62b269ce167eb1c71b5e39a1dc1f65ce1c",
    "parent_commit": "f728ab8e3578c22b42ed53e51b5e8ec35328d8b9",
    "perf_command": "vllm bench serve --model Qwen/Qwen2.5-1.5B-Instruct --request-rate 1 --num-prompts 100 --random-input-len 1000 --random-output-len 100 --tokenizer Qwen/Qwen2.5-1.5B-Instruct --ignore-eos",
    "model": "Qwen/Qwen2.5-1.5B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "2deb029d",
    "human_commit_full": "2deb029d115dadd012ce5ea70487a207cb025493",
    "parent_commit": "029c71de11bc3bcf84a1b3cf9d91e79ab6949799",
    "perf_command": "python3 benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --output-len 200 --enable-prefix-caching [--use-v2-block-manager]",
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "benchmark_type": "serving",
    "docker_throughput": 0,
    "notes": "Model recovered from PR #7822 perf_command"
  },
  {
    "human_commit_short": "2f192835",
    "human_commit_full": "2f1928354903ae0c6edfe76cc90081eb513ead2c",
    "parent_commit": "95baec828f3ee046074dace1d88202a920b7dc15",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "30172b49",
    "human_commit_full": "30172b4947c52890b808c6da3a6c7580f55cbb74",
    "parent_commit": "a4d577b37944cbfa1bc62e4869667d1e2739d62a",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "310aca88",
    "human_commit_full": "310aca88c984983189a57f1b72e3b1dde89fb92f",
    "parent_commit": "a732900efc4eb0d4393e3885d5df8ef3516d4834",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Meta-Llama-3-70B --load-format dummy --enforce-eager -tp 4",
    "model": "meta-llama/Meta-Llama-3-70B",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "3127e975",
    "human_commit_full": "3127e975fb9417d10513e25b80820870f594c627",
    "parent_commit": "4001ea126692d9c4e6872936a791a1999c826156",
    "perf_command": "",
    "model": "",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "3b61cb45",
    "human_commit_full": "3b61cb450d899dc423feb264c297d4d18d701678",
    "parent_commit": "edc4fa31888b4a41060acb7b16250540f051ad59",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Llama-3.1-8B-Instruct --batch-size 32 --input-len 512 --output-len 128",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "4c822298",
    "human_commit_full": "4c822298981a8f7521492075ff72659985fc4c3f",
    "parent_commit": "c8d70e2437feecdb3762ce17298df33439ae1bd1",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Llama-3.1-8B-Instruct --speculative-model meta-llama/Llama-3.2-1B-Instruct --num-speculative-tokens 5",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "4fb56914",
    "human_commit_full": "4fb56914c5f27ef062e10d44a0f79c6ceab382f9",
    "parent_commit": "0df4d9b06b15fa39eeb2d440e7742da93afd5e6c",
    "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V3-0324 --dataset-name sharegpt --dataset-path ShareGPT_V3_unfiltered_cleaned_split.json",
    "model": "",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "526de822",
    "human_commit_full": "526de822d501c792b051c864ba873a836d78d5bf",
    "parent_commit": "56fe4c297c7d9d872eccc19e3edbf1d75e1a30e2",
    "perf_command": "python benchmarks/benchmark_latency.py --dtype bfloat16 --enable-chunked-prefill False --load-format dummy --batch-size BS --num-iters-warmup 2 --num-iters 5 --input-len INPUT_LEN --output-len OUTPUT_LEN --model MODEL",
    "model": "",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "58eee5f2",
    "human_commit_full": "58eee5f2e05b74eb2cb1a3bbda9c04df4805e4cc",
    "parent_commit": "067c34a1559400e956311f067ddd185f54207a2b",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "61b8cea3",
    "human_commit_full": "61b8cea3b42feab021d506e9143551de18f9165c",
    "parent_commit": "526078a96c52af678a1ddbdc3ecf78265e358f2b",
    "perf_command": "python benchmarks/benchmark_throughput.py --model meta-llama/Llama-3.2-3B-Instruct --dataset-name random --input-len 256 --output-len 128 --num-prompts 100",
    "model": "meta-llama/Llama-3.2-3B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "6a417b86",
    "human_commit_full": "6a417b8600d4d1e57698a91b71a38446e8fc5c45",
    "parent_commit": "d3ea50113c08bdd3c5cfda42ec6ecbc72328d7d1",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "6d0734c5",
    "human_commit_full": "6d0734c562e759fdb7076d762222b3881e62ab1f",
    "parent_commit": "7d94577138e3d4c7bcfd781337ee1e5a2befa685",
    "perf_command": "python benchmarks/benchmark_serving.py --model mistralai/Mistral-7B-Instruct-v0.3 --dtype float16 --num-prompts 300 --seed 0",
    "model": "mistralai/Mistral-7B-Instruct-v0.3",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "6dd94dbe",
    "human_commit_full": "6dd94dbe94c1820a1e224cba65efcf0befa97995",
    "parent_commit": "0e74d797ce8618fdb685126e0ff8576fb966e6ad",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Meta-Llama-3-8B --load-format dummy",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "70b808fe",
    "human_commit_full": "70b808fe1a63322bc6bf5f46a91981a8f6b8af00",
    "parent_commit": "63d635d17962377df089cdc9d4a2684f0b007208",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen2-VL-7B --dataset-name random --request-rate 1",
    "model": "Qwen/Qwen2-VL-7B",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "7661e92e",
    "human_commit_full": "7661e92ef85e552936195ae4b803e292b9a96776",
    "parent_commit": "f168b85725202915b5719c62b46d310a608b13dd",
    "perf_command": "python benchmarks/benchmark_serving.py --model nvidia/Nemotron-4-340B-Instruct --dataset-name sharegpt --request-rate 1",
    "model": "nvidia/Nemotron-4-340B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "88693683",
    "human_commit_full": "886936837ca89e5645bc1f71cc0e1492b65b1590",
    "parent_commit": "6d917d0eebd03990edf2443780a5f2506026ea78",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --enable-prefix-caching",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "8a4e5c5f",
    "human_commit_full": "8a4e5c5f3c1d39e924e48a87c9cc6cf382aa3532",
    "parent_commit": "76b494444fd864ffc53a623420668d1865c804b9",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "8aa1485f",
    "human_commit_full": "8aa1485fcff7be3e42300c0615ee0f3f3cbce9a8",
    "parent_commit": "89ac266b262f08d25ebf25fc66122d1b2367ae64",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 4 --max-model-len 16384",
    "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "8c1e77fb",
    "human_commit_full": "8c1e77fb585c4f42783a3d88c1efc7c9e15fd89f",
    "parent_commit": "5fc5ce0fe45f974fc8840175e8321652238400f0",
    "perf_command": "python benchmarks/benchmark_latency.py --model meta-llama/Llama-3.1-8B-Instruct --batch-size 32 --input-len 512 --output-len 128",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "9323a315",
    "human_commit_full": "9323a3153b20d4a2ca7ac04a2784609d6ce656e0",
    "parent_commit": "3257d449fa0fd3e05aa20cc8c5fff79ad101984f",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.2-3B-Instruct --guided-decoding-backend xgrammar",
    "model": "meta-llama/Llama-3.2-3B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "98f47f2a",
    "human_commit_full": "98f47f2a4032f8c395268de80858c64ffcfc60fa",
    "parent_commit": "8c1e77fb585c4f42783a3d88c1efc7c9e15fd89f",
    "perf_command": "python benchmarks/benchmark_latency.py",
    "model": "unknown",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "9a3b8832",
    "human_commit_full": "9a3b88328f7e434cac35b90ee463de6689f9a833",
    "parent_commit": "3014c920dae5a2360b9b4141395522cc52b59193",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-VL-3B-Instruct",
    "model": "Qwen/Qwen2.5-VL-3B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "a3223766",
    "human_commit_full": "a32237665df876fcb51196dc209e8aff9fd89d29",
    "parent_commit": "bc8a8ce5ec374dd18e86f59be7cb0057a4b21992",
    "perf_command": "vllm bench serve --dataset-name random --model facebook/opt-125m --served-model-name facebook/opt-125m --random-input-len 700 --random-output-len 1 --endpoint /v1/completions --ignore-eos --host localhost --port 8000 --request-rate 200 --num-prompts 100",
    "model": "facebook/opt-125m",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "ac45c44d",
    "human_commit_full": "ac45c44d98e77f30e47b8fb69134f4635183070d",
    "parent_commit": "d6664664b442cb236f8541a126e4076a5e12c56d",
    "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V2",
    "model": "",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "b2e0ad3b",
    "human_commit_full": "b2e0ad3b598ed0e022cdbd678a20821d411873c2",
    "parent_commit": "4a18fd14ba4a349291c798a16bf62fa8a9af0b6b",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dataset-name sharegpt --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "b55ed6ef",
    "human_commit_full": "b55ed6ef8ab0dce7fb0f79ff292dafdb4d22610c",
    "parent_commit": "2f385183f35497e030ef22c9820d83b83bc4f6db",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "b690e348",
    "human_commit_full": "b690e34824fd5a5c4054a0c0468ebfb6aa1dd215",
    "parent_commit": "25373b6c6cc2068e3914fa906d3240088f7af157",
    "perf_command": "python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dtype float16 --num-prompts 300 --seed 0",
    "model": "ibm-ai-platform/Bamba-9B-v2",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "baeded25",
    "human_commit_full": "baeded25699f9f4851843306f27f685c4d4ee7c5",
    "parent_commit": "3e1c76cf3a87854396d9e86a56a335e7d750c85f",
    "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V3 --dtype float16",
    "model": "",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "bc7c4d20",
    "human_commit_full": "bc7c4d206bbfb56b06d218b6c2971e8ca191db36",
    "parent_commit": "f67e9e9f221e9791733b827585d6eb6dbc23133c",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --num-prompts 300 --seed 0",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "bd6028d6",
    "human_commit_full": "bd6028d6b0bbc0c569ece0535067081c5e8bdc14",
    "parent_commit": "802329dee9e5b70c0c73df93c9db1ecdc4632664",
    "perf_command": "python benchmarks/benchmark_latency.py --model RedHatAI/Llama-4-Scout-17B-16E-Instruct-FP8-dynamic --max-model-len 8000 --tensor-parallel-size 2 --input-len 1000 --output-len 1000",
    "model": "RedHatAI/Llama-4-Scout-17B-16E-Instruct-FP8-dynamic",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "bfdb1ba5",
    "human_commit_full": "bfdb1ba5c3fb14387c69acb1f5067102d8028e56",
    "parent_commit": "cf2f084d56a1293cb08da2393984cdc7685ac019",
    "perf_command": "python /home/ray/default/vllm_public/benchmarks/benchmark_latency.py --model meta-llama/Llama-2-7b-chat-hf  --batch-size 1 --output-len 2 --input-len 1000 --num-iters 1",
    "model": "meta-llama/Llama-2-7b-chat-hf",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "c45f3c3a",
    "human_commit_full": "c45f3c3ab60f4bf4eaab791a76028b8b07ffe9bd",
    "parent_commit": "7a7929abe8e2fd6a4688487c471a1ee1fde0edd2",
    "perf_command": "python benchmark/benchmark_latency.py --model facebook/opt-13b",
    "model": "facebook/opt-13b",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "ce6bf3a2",
    "human_commit_full": "ce6bf3a2cff4860c5661cac2280e0a28bedb6440",
    "parent_commit": "3cdfe1f38b2c07a10a1681cd2d60c3bea1bae2f0",
    "perf_command": "python benchmarks/benchmark_throughput.py  --input-len 256 --output-len 256 --model google/gemma-2b",
    "model": "google/gemma-2b",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "d4bc1a4d",
    "human_commit_full": "d4bc1a4d248a5d23e1f731ecb53511a9a54f5dfc",
    "parent_commit": "b56b6ca0d650c653c80ec113e27d6a8e640a4b2f",
    "perf_command": "python benchmarks/benchmark_serving.py --model facebook/opt-125m --num-prompts 100",
    "model": "facebook/opt-125m",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "dae68969",
    "human_commit_full": "dae68969774e41b93b01cd31171ca033a92b574a",
    "parent_commit": "c34eeec58d3a94437c5311e256f8ba21d1912a39",
    "perf_command": "VLLM_USE_V1=1 VLLM_ATTENTION_BACKEND=FLASHMLA python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --tensor-parallel-size 8",
    "model": "deepseek-ai/DeepSeek-R1",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "e7523c2e",
    "human_commit_full": "e7523c2e031bc96740723ab63833d1cf94229ab4",
    "parent_commit": "a869baca73eb90ae7bd18402915dc4bfc36cf06b",
    "perf_command": "python benchmarks/benchmark_serving.py --backend openai-chat --model google/gemma-3-12b-it --endpoint /v1/chat/completions --dataset-name hf --dataset-path lmarena-ai/VisionArena-Chat --hf-split train --num-prompts 1000",
    "model": "google/gemma-3-12b-it",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "ec3b5ce9",
    "human_commit_full": "ec3b5ce9ccb4262194a16a8b1c31ffd6b3b824b9",
    "parent_commit": "6368e777a8ead7fb62054d3779c6237361ec0d86",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "ed250545",
    "human_commit_full": "ed25054577f7abca2aee32a5290200c4a1aed561",
    "parent_commit": "10904e6d755051260a7c3ce98659d8907c74caa9",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "eefbf4a6",
    "human_commit_full": "eefbf4a68b7b0a5b8364a59647906be1b7f043e2",
    "parent_commit": "88faa466d788e25082c02dc9688931d7976361f9",
    "perf_command": "python benchmarks/benchmark_latency.py --model Qwen/Qwen3-30B-A3B-FP8 --batch-size 32 --input-len 512 --output-len 128",
    "model": "Qwen/Qwen3-30B-A3B-FP8",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "f092153f",
    "human_commit_full": "f092153fbe349a9a1742940e3703bfcff6aa0a6d",
    "parent_commit": "1da8f0e1dddaf8625829e7ecca7fce93eb685c03",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "f26c4aee",
    "human_commit_full": "f26c4aeecba481ce1445be7a998b0b97460a13bb",
    "parent_commit": "8936316d587ca0afb5ef058584c407d404c0ffb0",
    "perf_command": "python3 benchmarks/benchmark_latency.py --model meta-llama/Llama-3.1-8B-Instruct --tensor-parallel-size 4  --num-iters-warmup 5 --num-iters 20  --batch-size 8 --input-len 128 --output-len 256 --max-model-len 2048 --no-enable-prefix-caching --distributed-executor-backend ray",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "fa63e710",
    "human_commit_full": "fa63e710c7fbaae3a445f669d3b5ba6b9a4ef412",
    "parent_commit": "2a0309a646b1ed83a0c40974e08c8dc628726d3c",
    "perf_command": "VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --model meta-llama/Meta-Llama-3-8B --tensor-parallel-size 1 --input-len 1000 --batch-size 32",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "fb0acb6c",
    "human_commit_full": "fb0acb6c72874e98617cabee4ff4851569374fc9",
    "parent_commit": "92b0ce2ac75e251fe683f5b720f07001782054ff",
    "perf_command": "python benchmarks/benchmark_throughput.py --model deepseek-ai/DeepSeek-R1 --load-format dummy --trust-remote-code --input-len 6000 --output-len 1000 --num-prompts 50 --tensor-parallel-size 8",
    "model": "deepseek-ai/DeepSeek-R1",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "fc542144",
    "human_commit_full": "fc542144c4477ffec1d3de6fa43e54f8fb5351e8",
    "parent_commit": "eb5741ad422f04d0bac60c9b6c07183e0431ce8c",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 1",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "fe66b347",
    "human_commit_full": "fe66b34728e5d383e3d19aefc544eeee808c99fb",
    "parent_commit": "270a5da495d24e947a71e2fa0c56635f4fad2dc3",
    "perf_command": "python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B --dtype float16 --num-prompts 300 --seed 0",
    "model": "ibm-ai-platform/Bamba-9B",
    "benchmark_type": "serving",
    "docker_throughput": 0
  },
  {
    "human_commit_short": "19d98e0c",
    "human_commit_full": "19d98e0c7db96713f0e2201649159431177a56e2",
    "parent_commit": "2b04c209ee98174f29f1fc98f0dc3222d652a7bd",
    "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct --dtype float16 --num-prompts 100",
    "model": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "benchmark_type": "serving",
    "docker_throughput": 0,
    "notes": "Recovered from PR #13625 - MoE memory optimization"
  },
  {
    "human_commit_short": "9f1710f1",
    "human_commit_full": "9f1710f1ace3535920c0bb6d4cc329c36289080e",
    "parent_commit": "e642ec962cf2283f9aa44492727e6efc17a32129",
    "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V2-Lite-Chat --dtype float16 --num-prompts 100",
    "model": "deepseek-ai/DeepSeek-V2-Lite-Chat",
    "benchmark_type": "serving",
    "docker_throughput": 0,
    "notes": "Recovered from PR #13897 - MLA prefill optimization"
  }
]