{
  "description": "Commit-specific fixes for 3-way benchmarks based on failure analysis",

  "failure_categories": {
    "HF_ACCESS_DENIED": {
      "commits": ["e206b543", "d7740ea4", "cf2f084d", "30172b49"],
      "fix": "ensure_hf_token_and_substitute_model",
      "model_sub": "meta-llama/Meta-Llama-3-8B-Instruct"
    },
    "TRANSFORMERS_LOGITS_WARPER": {
      "commits": ["9ed82e70"],
      "fix": "pip install transformers==4.44.2"
    },
    "NUMPY_V2_INCOMPATIBLE": {
      "commits": ["2f192835", "ad8d696a", "b6d10354", "30172b49"],
      "fix": "pip install numpy<2"
    },
    "VLLM_POOLING_PARAMS_MISSING": {
      "commits": ["9d72daf4"],
      "fix": "Use vllm.entrypoints.api_server instead"
    },
    "STUCK_AT_INSTALL": {
      "commits": ["e7b20426", "3b61cb45", "d55e446d", "e493e485", "83450458", "ad8d696a", "3092375e", "35fad35a"],
      "fix": "rebuild_docker_images",
      "notes": "Docker images in install loop - cannot fix without rebuild"
    }
  },

  "fixable_commits": {
    "e206b543": {
      "issue": "HF token not passed",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "fix": ["ensure HF_TOKEN env var is valid and has Llama access"]
    },
    "d7740ea4": {
      "issue": "HF token not passed",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "fix": ["ensure HF_TOKEN env var is valid"]
    },
    "cf2f084d": {
      "issue": "HF token not passed",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "fix": ["ensure HF_TOKEN env var is valid"]
    },
    "30172b49": {
      "issue": "HF token not passed",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "fix": ["ensure HF_TOKEN env var is valid", "pip install numpy<2"]
    },
    "9ed82e70": {
      "issue": "transformers LogitsWarper incompatibility",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "fix": ["pip install transformers==4.44.2"]
    },
    "2f192835": {
      "issue": "numpy 2.x incompatibility with outlines",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "fix": ["pip install numpy<2"]
    },
    "9d72daf4": {
      "issue": "vLLM PoolingParams import error",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "fix": ["use vllm.entrypoints.api_server entrypoint"]
    }
  },

  "skip_commits": {
    "b6d10354": "Llama-2-70b-hf - too large for single GPU",
    "379da6dc": "Meta-Llama-3-70B - too large for single GPU",
    "ca7a2d5f": "DeepSeek-Coder-V2-Lite - too large",
    "21d93c14": "Mixtral-8x7B-v0.1 - needs multi-GPU",
    "19d98e0c": "DeepSeek-Coder-V2-Lite - too large",
    "c0569dbc": "Qwen3-30B-A3B-FP8 - too large",
    "dcc6cfb9": "Qwen3-30B-A3B-FP8 - too large",
    "9474e89b": "Docker image has no vLLM installed",
    "ccf02fcb": "Docker image has no vLLM installed",
    "99abb8b6": "Docker image has no vLLM installed"
  },

  "needs_image_rebuild": {
    "commits": ["e7b20426", "3b61cb45", "d55e446d", "e493e485", "83450458", "ad8d696a", "3092375e", "35fad35a"],
    "reason": "Docker images stuck in package install loop"
  },

  "model_substitutions": {
    "meta-llama/Llama-3.1-8B-Instruct": "meta-llama/Meta-Llama-3-8B-Instruct"
  },

  "notes": {
    "total_failed": 30,
    "fixable_with_config": 7,
    "needs_image_rebuild": 8,
    "skip_too_large": 10,
    "skip_no_vllm": 3,
    "needs_investigation": 2
  }
}
