[
  {
    "human_short": "015069b0",
    "human_full": "015069b01741e9ecb9e604c7fe87fbdfc306ebe5",
    "parent_short": "fbefc8a78d22",
    "model": "Qwen/Qwen3-7B-Instruct",
    "benchmark_type": "serving",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen3-7B-Instruct --dataset-name sharegpt --request-rate 1"
  },
  {
    "human_short": "21d93c14",
    "human_full": "21d93c140d0a97af5f0c59e660cf04bd417fd424",
    "parent_short": "f1c852014603",
    "model": "mistralai/Mixtral-8x7B-v0.1",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1 --tensor-parallel-size 8"
  },
  {
    "human_short": "22d33bac",
    "human_full": "22d33baca2c0c639cfd45c48e99803e56c3efa74",
    "parent_short": "b0e96aaebbfb",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "serving",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "296f927f",
    "human_full": "296f927f2493908984707354e3cc5d7b2e41650b",
    "parent_short": "0032903a5bb7",
    "model": "ibm-ai-platform/Bamba-9B",
    "benchmark_type": "serving",
    "perf_command": "python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B --dtype float16 --num-prompts 300 --seed 0"
  },
  {
    "human_short": "2a052011",
    "human_full": "2a052011ca473a9dc8160f3daa1f5f63a2ad1fe3",
    "parent_short": "36fb68f94792",
    "model": "nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1 --quantization fp8"
  },
  {
    "human_short": "3476ed08",
    "human_full": "3476ed0809ec91a3457da0cb90543133a4f4b519",
    "parent_short": "54600709b6d4",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --num-prompts 300 --seed 0"
  },
  {
    "human_short": "379da6dc",
    "human_full": "379da6dcb5f5d062d0452b2fc23291e5113dcf04",
    "parent_short": "ebce310b7433",
    "model": "meta-llama/Meta-Llama-3-70B",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-70B --input-len 1000 --output-len 50 --tensor-parallel-size 4 --quantization fp8"
  },
  {
    "human_short": "3a243095",
    "human_full": "3a243095e5e7b655b63ab08fbd5936cb40850415",
    "parent_short": "64172a976c8d",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "67da5720",
    "human_full": "67da5720d4ed2aa1f615ec812031f4f3753b3f62",
    "parent_short": "5c04bb8b863b",
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "benchmark_type": "serving",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-7B-Instruct --dtype float16 --num-prompts 300 --seed 0"
  },
  {
    "human_short": "6ce01f30",
    "human_full": "6ce01f30667bbae33f112152e07a3b66b841078f",
    "parent_short": "6a11fdfbb8d6",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Meta-Llama-3-8B --backend vllm --num-prompts 100"
  },
  {
    "human_short": "6d646d08",
    "human_full": "6d646d08a2e0e73e83e313a5ae470c1f9e4f200e",
    "parent_short": "95a178f86120",
    "model": "meta-llama/Meta-Llama-3-8B",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-8B-Instruct --dataset ShareGPT_V3_unfiltered_cleaned_split.json"
  },
  {
    "human_short": "6e36f4fa",
    "human_full": "6e36f4fa6ce64619b9ea94c88a157f5783a63a65",
    "parent_short": "dd2a6a82e3f4",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "7c01f706",
    "human_full": "7c01f706418d593b3cf23d2ec9110dca7151c539",
    "parent_short": "51e971d39e12",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --num-prompts 300 --seed 0"
  },
  {
    "human_short": "80aa7e91",
    "human_full": "80aa7e91fcd547a7a1396f71b9bdce18e5c92245",
    "parent_short": "bd43973522ea",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --num-prompts 300 --seed 0"
  },
  {
    "human_short": "89a84b0b",
    "human_full": "89a84b0bb7b30706a02836234a94493ea8f780bf",
    "parent_short": "084a01fd3544",
    "model": "Qwen/Qwen1.5-0.5B",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model Qwen/Qwen1.5-0.5B --backend vllm --num-prompts 2048 --input-len 1024"
  },
  {
    "human_short": "8bc68e19",
    "human_full": "8bc68e198c4c90ddc2e54fa76eb81c2c714bb1cd",
    "parent_short": "0fca3cdcf265",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "8d75fe48",
    "human_full": "8d75fe48ca5f46b7af0f5201d8500b9604eed769",
    "parent_short": "388596c91437",
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --dataset-name sharegpt --dataset-path ./ShareGPT_V3_unfiltered_cleaned_split.json"
  },
  {
    "human_short": "93e5f3c5",
    "human_full": "93e5f3c5fb4a4bbd49610efb96aad30df95fca66",
    "parent_short": "70363bccfac1",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "9badee53",
    "human_full": "9badee53decb3d432dc805336abfb0eb81dfb48f",
    "parent_short": "beebf4742af8",
    "model": "meta-llama/Llama-3.2-1B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.2-1B-Instruct --dataset-path ShareGPT_V3_unfiltered_cleaned_split.json"
  },
  {
    "human_short": "9d72daf4",
    "human_full": "9d72daf4ced05a5fec1ad8ea2914a39296f402da",
    "parent_short": "6dd55af6c9dd",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "9ed82e70",
    "human_full": "9ed82e7074a18e25680ab106fc846364ad97bc00",
    "parent_short": "51f8aa90ad40",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "cf2f084d",
    "human_full": "cf2f084d56a1293cb08da2393984cdc7685ac019",
    "parent_short": "f721096d48a7",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100"
  },
  {
    "human_short": "e206b543",
    "human_full": "e206b5433109d298e53451015465b2bf8f03ef0a",
    "parent_short": "1d35662e6dc1",
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num-prompts 100 --guided-decoding-backend xgrammar"
  },
  {
    "human_short": "e3580537",
    "human_full": "e3580537a41a46b0f3cd750b86b633c1857a8c90",
    "parent_short": "f508e03e7f2d",
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "benchmark_type": "unknown",
    "perf_command": "python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --enable-prefix-caching --enable-chunked-prefill --max-num-batched-tokens 2048"
  }
]