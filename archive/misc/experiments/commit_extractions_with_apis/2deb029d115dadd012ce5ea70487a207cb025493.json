{
  "commit_hash": "2deb029d115dadd012ce5ea70487a207cb025493",
  "parent_hash": "029c71de11bc3bcf84a1b3cf9d91e79ab6949799",
  "message": "[Performance][BlockManagerV2] Mark prefix cache block as computed after schedule (#7822)",
  "author": "Cody Yu <hao.yu.cody@gmail.com>",
  "date": "2024-08-26 11:24:53 -0700",
  "files_changed": [
    {
      "file_path": "tests/core/block/test_prefix_caching_block.py",
      "old_content": "import math\nimport random\nfrom typing import List, Optional\nfrom unittest.mock import MagicMock\n\nimport pytest\n\nfrom vllm.core.block.interfaces import Block, BlockAllocator\nfrom vllm.core.block.prefix_caching_block import (PrefixCachingBlock,\n                                                  PrefixCachingBlockAllocator)\n\n\nclass TestPrefixCachingBlock:\n\n    @staticmethod\n    @pytest.mark.parametrize(\"seed\", list(range(10)))\n    @pytest.mark.parametrize(\"block_size\", [1, 16])\n    @pytest.mark.parametrize(\"is_curr_block_full\", [True, False])\n    def test_first_block_has_correct_content_hash(seed: int, block_size: int,\n                                                  is_curr_block_full: bool):\n        \"\"\"Verify a block which is first in the sequence has the correct hash.\n        \"\"\"\n        random.seed(seed)\n        num_to_fill = block_size if is_curr_block_full else random.randint(\n            0, block_size - 1)\n        token_ids = list(range(num_to_fill))\n        mock_allocator = MagicMock(spec=PrefixCachingBlockAllocator)\n\n        block_with_prev = PrefixCachingBlock(prev_block=None,\n                                             token_ids=token_ids,\n                                             block_size=block_size,\n                                             allocator=mock_allocator)\n\n        if is_curr_block_full:\n            # Expect hash since block is full.\n            assert block_with_prev.content_hash == (\n                PrefixCachingBlock.hash_block_tokens(\n                    is_first_block=True,\n                    prev_block_hash=None,\n                    cur_block_token_ids=token_ids))\n        else:\n            # Do not expect hash since block is not full.\n            assert block_with_prev.content_hash is None\n\n    @staticmethod\n    @pytest.mark.parametrize(\"seed\", list(range(10)))\n    @pytest.mark.parametrize(\"block_size\", [1, 16])\n    @pytest.mark.parametrize(\"is_curr_block_full\", [True, False])\n    @pytest.mark.parametrize(\"prev_block_has_hash\", [True, False])\n    def test_nth_block_has_correct_content_hash(seed: int, block_size: int,\n                                                is_curr_block_full: bool,\n                                                prev_block_has_hash: bool):\n        \"\"\"Verify a block which is not first in the sequence has the correct\n        hash.\n        \"\"\"\n\n        random.seed(seed)\n\n        previous_block = MagicMock(spec=PrefixCachingBlock)\n        prev_block_hash = random.randint(0, 1000)\n        previous_block.content_hash = (prev_block_hash\n                                       if prev_block_has_hash else None)\n\n        num_to_fill = block_size if is_curr_block_full else random.randint(\n            0, block_size - 1)\n        token_ids = list(range(num_to_fill))\n        mock_allocator = MagicMock(spec=PrefixCachingBlockAllocator)\n\n        block_with_prev = PrefixCachingBlock(\n            prev_block=previous_block,\n            token_ids=token_ids,\n            block_size=block_size,\n            allocator=mock_allocator,\n        )\n\n        if is_curr_block_full and prev_block_has_hash:\n            # Expect hash since block is full and previous block has hash.\n            assert (block_with_prev.content_hash ==\n                    PrefixCachingBlock.hash_block_tokens(\n                        is_first_block=False,\n                        prev_block_hash=prev_block_hash,\n                        cur_block_token_ids=token_ids))\n        else:\n            # Do not expect hash since block is not full or the previous block\n            # does not have a hash.\n            assert block_with_prev.content_hash is None\n\n    @staticmethod\n    @pytest.mark.parametrize(\"block_size\", [1, 2, 16])\n    @pytest.mark.parametrize(\"num_tokens\", list(range(3)))\n    @pytest.mark.parametrize(\"num_empty_trailing_blocks\", [0, 1, 10])\n    def test_blocks_have_correct_hash_in_chain(block_size: int,\n                                               num_tokens: int,\n                                               num_empty_trailing_blocks: int):\n        \"\"\"Create two chains of logical blocks with the same contents.\n        Assert the hashes are equal.\n        \"\"\"\n        random.seed(0)\n\n        token_ids = [random.randint(0, 50_000) for _ in range(num_tokens)]\n\n        first_chain, second_chain = [\n            TestPrefixCachingBlock.create_chain(\n                block_size=block_size,\n                token_ids=token_ids,\n                num_empty_trailing_blocks=num_empty_trailing_blocks)\n            for _ in range(2)\n        ]\n\n        for first_chain_block, second_chain_block in zip(\n                first_chain, second_chain):\n            assert (first_chain_block.content_hash ==\n                    second_chain_block.content_hash)\n\n        if not first_chain or not second_chain:\n            assert first_chain == second_chain\n            assert num_tokens == 0\n\n    @staticmethod\n    def create_chain(block_size: int,\n                     token_ids: List[int],\n                     num_empty_trailing_blocks=0) -> List[PrefixCachingBlock]:\n        \"\"\"Helper method which creates a chain of blocks.\n        \"\"\"\n        blocks: List[PrefixCachingBlock] = []\n        num_blocks = math.ceil(\n            len(token_ids) / block_size) + num_empty_trailing_blocks\n\n        if num_blocks == 0:\n            return []\n\n        allocator = MagicMock(spec=PrefixCachingBlockAllocator)\n\n        prev_block = None\n        for block_number in range(0, num_blocks):\n            prev_block = PrefixCachingBlock(\n                prev_block=prev_block,\n                token_ids=[],\n                block_size=block_size,\n                allocator=allocator,\n            )\n\n            tokens_to_append = token_ids[block_number *\n                                         block_size:(block_number + 1) *\n                                         block_size]\n            if tokens_to_append:\n                prev_block.append_token_ids(tokens_to_append)\n\n            blocks.append(prev_block)\n\n        return blocks\n\n\nclass TestPrefixCachingBlockAllocator:\n\n    @staticmethod\n    def create_allocate_lambda(allocate_type: str, allocator: BlockAllocator,\n                               prev_block: Optional[Block],\n                               token_ids: List[int]):\n        if allocate_type == \"immutable\":\n            allocate_block = lambda: allocator.allocate_immutable_block(\n                prev_block=prev_block, token_ids=token_ids)\n        elif allocate_type == \"mutable\":\n            allocate_block = lambda: allocator.allocate_mutable_block(\n                prev_block=prev_block)\n        else:\n            raise ValueError()\n\n        return allocate_block\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1, 1024])\n    @pytest.mark.parametrize(\"block_size\", [1, 16])\n    def test_allocate_mutable_ooms(num_blocks: int, block_size: int):\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n        allocate_block = TestPrefixCachingBlockAllocator.create_allocate_lambda(\n            allocate_type=\"mutable\",\n            allocator=allocator,\n            prev_block=None,\n            token_ids=list(range(block_size)),\n        )\n\n        [allocate_block() for _ in range(num_blocks)]\n        with pytest.raises(BlockAllocator.NoFreeBlocksError):\n            allocate_block()\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1, 1024])\n    @pytest.mark.parametrize(\"block_size\", [1, 16])\n    def test_allocate_immutable_does_not_oom_single_hash(\n            num_blocks: int, block_size: int):\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n        allocate_block = TestPrefixCachingBlockAllocator.create_allocate_lambda(\n            allocate_type=\"immutable\",\n            allocator=allocator,\n            prev_block=None,\n            token_ids=list(range(block_size)),\n        )\n\n        blocks = [allocate_block() for _ in range(num_blocks)]\n\n        # Expect no OOM. If these were mutable blocks, this would OOM.\n        non_oom_block = allocate_block()\n\n        # Expect all blocks to have same physical block index.\n        for block in blocks:\n            assert (block.block_id == non_oom_block.block_id)\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1, 1024])\n    @pytest.mark.parametrize(\"block_size\", [1, 16])\n    def test_allocate_immutable_ooms_many_hash(num_blocks: int,\n                                               block_size: int):\n        \"\"\"Consume all blocks using many different hashes/block content.\n\n        Do this by creating a sequence that is very long.\n        Expect next block to OOM.\n        \"\"\"\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n\n        # Create token ids that will exhaust all blocks.\n        token_ids = list(range(num_blocks * block_size))\n\n        chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n\n        # Expect allocation with unseen hash to fail.\n        with pytest.raises(BlockAllocator.NoFreeBlocksError):\n            allocator.allocate_immutable_block(prev_block=chain[-1],\n                                               token_ids=list(\n                                                   range(block_size)))\n\n        # Expect mutable allocation to fail.\n        with pytest.raises(BlockAllocator.NoFreeBlocksError):\n            allocator.allocate_mutable_block(prev_block=chain[-1])\n\n        # Expect allocation of exact same chain to pass.\n        second_chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n\n        # Expect physical block indices to be the same in both chains.\n        assert chain and second_chain\n        for first_chain_block, second_chain_block in zip(chain, second_chain):\n            assert (first_chain_block.block_id == second_chain_block.block_id)\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1, 1024])\n    @pytest.mark.parametrize(\"block_size\", [1, 16])\n    def test_free_prevents_oom(num_blocks: int, block_size: int):\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n\n        # Create token ids that will exhaust all blocks.\n        token_ids = list(range(num_blocks * block_size))\n\n        chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n\n        # Expect mutable allocation to fail.\n        with pytest.raises(BlockAllocator.NoFreeBlocksError):\n            allocator.allocate_mutable_block(prev_block=None)\n\n        block_to_free = chain[-1]\n\n        # Expect free/allocate loop to succeed many times.\n        for i in range(100):\n            block_id = block_to_free.block_id\n            allocator.free(block_to_free)\n            assert block_to_free.block_id is None, i\n\n            new_block = allocator.allocate_mutable_block(prev_block=None)\n            assert new_block.block_id == block_id, i\n\n            with pytest.raises(BlockAllocator.NoFreeBlocksError):\n                allocator.allocate_mutable_block(prev_block=None)\n\n            block_to_free = new_block\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1024])\n    @pytest.mark.parametrize(\"block_size\", [16])\n    @pytest.mark.parametrize(\"seed\", list(range(20)))\n    def test_get_num_free_blocks(num_blocks: int, block_size: int, seed: int):\n        random.seed(seed)\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n        num_blocks_to_consume = random.randint(1, num_blocks - 1)\n\n        # Create token ids that will exhaust all blocks.\n        token_ids = list(range(num_blocks_to_consume * block_size))\n\n        chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n\n        # Free each block in chain, assert num free blocks includes new free\n        # block.\n        for i, block in enumerate(chain):\n            assert allocator.get_num_free_blocks() == (num_blocks -\n                                                       num_blocks_to_consume +\n                                                       i)\n            allocator.free(block)\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [4])\n    @pytest.mark.parametrize(\"block_size\", [8])\n    def test_prefix_caching_block_get_num_blocks_touched(\n            num_blocks, block_size):\n        \"\"\" Verify the allocator can correctly return the number of\n        blocks touched, when there are cached prefixes and different\n        lookahead slots.\n        \"\"\"\n        allocator_src = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                    block_size=block_size)\n        allocator_dst = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                    block_size=block_size)\n\n        # Create token ids that will exhaust all blocks except the last\n        token_ids = list(range((num_blocks - 1) * block_size))\n\n        # Create a chain of cacheable blocks in the dst\n        cached_blocks = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator_dst,\n        )\n\n        # Create a chain of the same blocks in the src\n        blocks_to_swap_in = \\\n            TestPrefixCachingBlockAllocator.create_immutable_chain(\n                block_size=block_size,\n                token_ids=token_ids,\n                allocator=allocator_src,\n            )\n\n        # All blocks are cached\n        assert allocator_dst.get_num_blocks_touched(blocks_to_swap_in) == 0\n\n        # Free the first block in the dst\n        allocator_dst.free(cached_blocks[0])\n\n        # Now the first block becomes dangling, the swapped blocks need\n        # to reclaim the first block in the dst\n        assert allocator_dst.get_num_blocks_touched(blocks_to_swap_in) == 1\n\n        # Insert one non-full block in the src\n        non_full_block = allocator_src.allocate_mutable_block(\n            blocks_to_swap_in[-1])\n        non_full_block.append_token_ids([0])\n        blocks_to_swap_in.append(non_full_block)\n        assert allocator_dst.get_num_blocks_touched(blocks_to_swap_in,\n                                                    num_lookahead_slots=1) == 2\n        assert allocator_dst.get_num_blocks_touched(\n            blocks_to_swap_in, num_lookahead_slots=block_size - 1) == 2\n        assert allocator_dst.get_num_blocks_touched(\n            blocks_to_swap_in, num_lookahead_slots=block_size) == 3\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1024])\n    @pytest.mark.parametrize(\"block_size\", [16])\n    @pytest.mark.parametrize(\"seed\", list(range(20)))\n    def test_get_num_free_blocks_shared(num_blocks: int, block_size: int,\n                                        seed: int):\n        \"\"\"Verify sharing occurs by allocating two sequences that share prefixes\n        and incrementally freeing blocks.\n        \"\"\"\n        random.seed(seed)\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n        num_blocks_to_consume = random.randint(1, num_blocks - 1)\n\n        # Create token ids that will exhaust all blocks.\n        token_ids = list(range(num_blocks_to_consume * block_size))\n\n        first_chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n        second_chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n\n        # Free each block in the first chain. Since all blocks are shared, the\n        # free count should stay constant.\n        for i, block in enumerate(first_chain):\n            assert allocator.get_num_free_blocks() == (num_blocks -\n                                                       num_blocks_to_consume)\n            allocator.free(block)\n\n        # Free each block in the second chain. Since the refcount is now zero,\n        # the free count should increment with each free.\n        for i, block in enumerate(second_chain):\n            assert allocator.get_num_free_blocks() == (num_blocks -\n                                                       num_blocks_to_consume +\n                                                       i)\n            allocator.free(block)\n\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1024])\n    @pytest.mark.parametrize(\"block_size\", [16])\n    @pytest.mark.parametrize(\"seed\", list(range(20)))\n    def test_get_common_computed_block_ids(num_blocks: int, block_size: int,\n                                           seed: int):\n        \"\"\"Verify get_common_computed_block_ids could get correct result\n        by create two immutable chain sharing prefix at specified pos,\n        and compare whether we also could get right result\n        from get_common_computed_block_ids.\n        \"\"\"\n        random.seed(seed)\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks * 2,\n                                                block_size=block_size)\n        num_blocks_to_consume = random.randint(1, num_blocks - 1)\n\n        # Create token ids that will exhaust all blocks.\n        token_ids = list(range(num_blocks_to_consume * block_size))\n\n        first_chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n\n        # After zero_point, second_chain's token_ids would be set -1, which\n        # make it different from here comparing with first_chain\n        zero_point = random.randint(1, len(token_ids) - 1)\n        zero_point_blocks = zero_point // block_size\n        token_ids[zero_point:] = [-1] * (len(token_ids) - zero_point)\n\n        second_chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids,\n            allocator=allocator,\n        )\n\n        first_computed_ids = [\n            first_chain[i].block_id for i in range(num_blocks_to_consume)\n        ]\n        second_computed_ids = [\n            second_chain[i].block_id for i in range(num_blocks_to_consume)\n        ]\n        res = allocator.get_common_computed_block_ids(\n            [first_computed_ids, second_computed_ids])\n\n        assert (len(res) == zero_point_blocks)\n\n    # Test case that assume those prompted block after first immutable would\n    # be freed into hashless allocator, while first immutable block get ref\n    # increased.\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [3])\n    @pytest.mark.parametrize(\"block_size\", [16])\n    @pytest.mark.parametrize(\"seed\", list(range(10)))\n    def test_alloc_promotion(num_blocks: int, block_size: int, seed: int):\n        random.seed(seed)\n\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n        token_ids = list(range(block_size))\n\n        block = allocator.allocate_immutable_block(prev_block=None,\n                                                   token_ids=token_ids)\n\n        assert allocator._refcounter.get(block.block_id) == 1\n        m = allocator.allocate_mutable_block(prev_block=None)\n\n        block_id = m.block_id\n        for i in range(block_size):\n            m.append_token_ids([i])\n\n        # After block get promoted to immutable from mutable, if there is\n        # already same content hash block, then it shall be released into\n        # hashless_allocator\n        # And first immutable block's ref get increased by 1\n        assert m.block_id == block.block_id\n        assert block_id in allocator._hashless_allocator._free_block_indices\n        assert allocator._refcounter.get(block.block_id) == 2\n\n    # Test case when eviction and allocation are mixed,\n    # make sure they work as expected\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [3])\n    @pytest.mark.parametrize(\"block_size\", [16])\n    @pytest.mark.parametrize(\"seed\", list(range(10)))\n    def test_eviction_alloc_mixed(num_blocks: int, block_size: int, seed: int):\n        random.seed(seed)\n\n        all_blocks_list = [i for i in range(num_blocks)]\n        zero_ref = {i: 0 for i in range(num_blocks)}\n        one_ref = {i: 1 for i in range(num_blocks)}\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n        token_ids = list(range(num_blocks * block_size))\n\n        # Verify initial/pre-alloc state\n\n        # Ensure all blocks are free inside hashless allocator\n        assert list(allocator._hashless_allocator._free_block_indices\n                    ) == all_blocks_list\n        # Ensure no tracked blocks\n        assert len(allocator._block_tracker.keys()) == num_blocks\n        for block_id in range(num_blocks):\n            assert not allocator._block_tracker[block_id].active\n        # Ensure no cached blocks\n        assert len(allocator._cached_blocks.values()) == 0\n        # Ensure no evicted blocks\n        assert len(allocator.evictor.free_table.keys()) == 0\n        # Ensure 0s ref counts for all blocks\n        assert allocator._refcounter._refcounts == zero_ref\n\n        # Allocate immutable chains with only one block residuled in\n        new_block = []\n        for i in range(num_blocks):\n            block = allocator.allocate_immutable_block(\n                prev_block=None,\n                token_ids=token_ids[block_size * i:block_size * (i + 1)])\n            new_block.append(block)\n\n        # Verify post-alloc state\n\n        # Ensure no blocks are free inside hashless allocator\n        assert (len(allocator._hashless_allocator._free_block_indices) == 0)\n        # Ensure all blocks are tracked\n        assert len(allocator._block_tracker.keys()) == num_blocks\n        for block_id in range(num_blocks):\n            assert allocator._block_tracker[block_id].active\n        # Ensure all blocks are cached (all promoted)\n        assert len(allocator._cached_blocks.values()) == num_blocks\n        # Ensure no evicted blocks\n        assert len(allocator.evictor.free_table.keys()) == 0\n        # Ensure 1s ref counts for all blocks\n        assert allocator._refcounter._refcounts == one_ref\n\n        # Free all blocks, and now all blocks shall be in the evictor\n        # there shall be no tracking data left in _block_tracker\n        # all blocks shall be tracked in _cached_blocks\n        # all blocks' ref shall be zero\n        for block in new_block:\n            allocator.free(block)\n\n        # Verify post-free state\n\n        # Ensure no tracked blocks\n        assert len(allocator._block_tracker.keys()) == num_blocks\n        for block_id in range(num_blocks):\n            assert not allocator._block_tracker[block_id].active\n        # Ensure no blocks in hashless allocator (all promoted)\n        assert len(allocator._hashless_allocator._free_block_indices) == 0\n        # Ensure all blocks are cached\n        assert list(allocator._cached_blocks.values()) == all_blocks_list\n        # Ensure all blocks are inside the evictor\n        assert list(allocator.evictor.free_table.keys()) == all_blocks_list\n        # Ensure 0s refcounts\n        assert allocator._refcounter._refcounts == zero_ref\n\n        # Allocate a mutable block, and the first block shall be evicted\n        # and set its content hash into None, ref to 1\n        mutable = allocator.allocate_mutable_block(prev_block=None)\n\n        assert mutable.block_id == 0\n        assert mutable.content_hash is None\n        assert allocator._block_tracker[0].active\n        assert allocator._refcounter.get(0) == 1\n        assert 0 not in allocator._cached_blocks\n        assert 0 not in allocator.evictor\n\n        # Since this mutable block has no hash yet, it shall be released into\n        # hashless allocator\n        allocator.free(mutable)\n\n        assert not allocator._block_tracker[0].active\n        assert allocator._refcounter._refcounts == zero_ref\n        assert 0 not in allocator._cached_blocks\n        assert 0 not in allocator.evictor\n        assert 0 in allocator._hashless_allocator._free_block_indices\n\n        # When allocate immutable with first block_size tokens, we\n        # shall get free block from hashless allocator, thus no block left\n        # in hashless\n        block = allocator.allocate_immutable_block(\n            prev_block=None, token_ids=token_ids[:block_size])\n\n        assert block.block_id == 0\n        assert len(allocator._hashless_allocator._free_block_indices) == 0\n        assert allocator._block_tracker[0].active\n        assert 0 in allocator._cached_blocks.values()\n        assert allocator._refcounter.get(0) == 1\n        assert 0 not in allocator.evictor\n\n        # allocate mutable block again, it shall be popped from evictor\n        mutable = allocator.allocate_mutable_block(prev_block=None)\n        assert len(allocator._hashless_allocator._free_block_indices) == 0\n        assert mutable.block_id not in allocator.evictor.free_table\n        assert allocator._refcounter.get(mutable.block_id) == 1\n\n    # Test case where two last accessed times are equal\n    @staticmethod\n    @pytest.mark.parametrize(\"num_blocks\", [1024])\n    @pytest.mark.parametrize(\"block_size\", [16])\n    @pytest.mark.parametrize(\"seed\", list(range(20)))\n    def test_eviction_order(num_blocks: int, block_size: int, seed: int):\n        \"\"\"This test case simulate the two chain created and free in order,\n        and together they would exhaust the initial freed blocks.\n\n        So the next block created after those two chain shall use the block\n        from the first chain as that block has long access time.\n        While first chain has two blocks, it shall pick up the last one, as\n        it has larger token number.\n        \"\"\"\n\n        random.seed(seed)\n        allocator = PrefixCachingBlockAllocator(num_blocks=num_blocks,\n                                                block_size=block_size)\n        num_blocks_to_consume = num_blocks + 1\n\n        token_ids = list(range(num_blocks_to_consume * block_size))\n\n        num_blocks_in_first_chain = 2\n        num_tokens_in_first_chain = block_size * num_blocks_in_first_chain\n        # First chain takes the first block\n        first_chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids[:num_tokens_in_first_chain],\n            allocator=allocator,\n        )\n        # There should only be one block allocated at this point\n        assert allocator.get_num_free_blocks() == (num_blocks -\n                                                   num_blocks_in_first_chain)\n\n        # Set the last accessed time of the first block to 1\n        blocks_ids = [block.block_id for block in first_chain]\n        allocator.mark_blocks_as_accessed(blocks_ids, 1)\n\n        # Second chain takes the rest of the blocks\n        second_chain = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids[num_tokens_in_first_chain:-block_size],\n            allocator=allocator,\n        )\n\n        # There shouldn't be any blocks left at this point\n        assert allocator.get_num_free_blocks() == (0)\n\n        assert len(first_chain) == num_blocks_in_first_chain\n        last_block_id = first_chain[-1].block_id\n        # Free each block in the first chain.\n        for i, block in enumerate(first_chain):\n            allocator.free(block)\n\n        # Set the last accessed time on all of the blocks in the second chain\n        # to 2\n        blocks_ids = [block.block_id for block in second_chain]\n        allocator.mark_blocks_as_accessed(blocks_ids, 2)\n\n        # Free each block in the second chain.\n        for i, block in enumerate(second_chain):\n            allocator.free(block)\n\n        # Allocate a new block and check that it's the least recently used block\n        # from the first chain.\n        new_block = TestPrefixCachingBlockAllocator.create_immutable_chain(\n            block_size=block_size,\n            token_ids=token_ids[-block_size:],\n            allocator=allocator,\n        )\n\n        assert new_block[0].block_id == last_block_id\n\n    # Test case for cache mertics\n    @staticmethod\n    def test_metric():\n        block_size = 16\n        allocator = PrefixCachingBlockAllocator(num_blocks=4,\n                                                block_size=block_size)\n        # Test when no query (0/0)\n        assert allocator.get_prefix_cache_hit_rate() == 0.0\n\n        token_ids = list(range(block_size))\n        allocator.allocate_immutable_block(prev_block=None,\n                                           token_ids=token_ids)\n        # Test 0/1 hit rate\n        assert allocator.get_prefix_cache_hit_rate() == 0.0\n\n        allocator.allocate_immutable_block(prev_block=None,\n                                           token_ids=token_ids)\n        # Test 1/2 hit rate\n        assert allocator.get_prefix_cache_hit_rate() == 0.5\n\n        # Test more than one block\n        for _ in range(2, 1005):\n            allocator.allocate_immutable_block(prev_block=None,\n                                               token_ids=token_ids)\n        assert allocator.get_prefix_cache_hit_rate() > 0.99\n\n    @staticmethod\n    def create_immutable_chain(\n        block_size: int,\n        token_ids: List[int],\n        allocator: PrefixCachingBlockAllocator,\n    ) -> List[PrefixCachingBlock]:\n        \"\"\"Helper method which creates a chain of blocks.\n        \"\"\"\n        blocks: List[Block] = []\n        num_blocks = math.ceil(len(token_ids) / block_size)\n\n        if num_blocks == 0:\n            return []\n\n        prev_block = None\n        for block_number in range(0, num_blocks):\n            block_token_ids = token_ids[block_number *\n                                        block_size:(block_number + 1) *\n                                        block_size]\n            prev_block = allocator.allocate_immutable_block(\n                prev_block=prev_block, token_ids=block_token_ids)\n            blocks.append(prev_block)\n\n        return blocks\n",
      "diff": "diff --git a/tests/core/block/test_prefix_caching_block.py b/tests/core/block/test_prefix_caching_block.py\nindex c2226870c..25be2dd13 100644\n--- a/tests/core/block/test_prefix_caching_block.py\n+++ b/tests/core/block/test_prefix_caching_block.py\n@@ -708,6 +708,37 @@ class TestPrefixCachingBlockAllocator:\n                                                token_ids=token_ids)\n         assert allocator.get_prefix_cache_hit_rate() > 0.99\n \n+    # Test case for marking cache hit blocks as computed right after\n+    # a batch of prefill sequences are scheduled.\n+    @staticmethod\n+    def test_touch_block():\n+        block_size = 16\n+        common_blocks = 4\n+        allocator = PrefixCachingBlockAllocator(num_blocks=8,\n+                                                block_size=block_size)\n+\n+        common_token_ids = list(range(block_size * common_blocks))\n+\n+        # Mimic the behavior of allocating the same block chain\n+        # (i.e., common prefix) for a batch of 3 different prefill sequences.\n+        for _ in range(3):\n+            blocks = TestPrefixCachingBlockAllocator.create_immutable_chain(\n+                block_size=block_size,\n+                token_ids=common_token_ids,\n+                allocator=allocator,\n+            )\n+            block_ids = [block.block_id for block in blocks]\n+            # The allocated blocks should  be marked as touched\n+            # but not computed.\n+            computed_block_ids = allocator.get_computed_block_ids(\n+                [], block_ids, skip_last_block_id=False)\n+            assert len(computed_block_ids) == 0\n+\n+        allocator.mark_blocks_as_computed([])\n+        computed_block_ids = allocator.get_computed_block_ids(\n+            [], block_ids, skip_last_block_id=False)\n+        assert len(computed_block_ids) == common_blocks\n+\n     @staticmethod\n     def create_immutable_chain(\n         block_size: int,",
      "change_type": "modified",
      "lines_added": 32,
      "lines_removed": 1
    },
    {
      "file_path": "vllm/core/block/prefix_caching_block.py",
      "old_content": "\"\"\"Token blocks.\"\"\"\nfrom os.path import commonprefix\nfrom typing import Dict, FrozenSet, Iterable, List, Optional, Tuple\n\nfrom vllm.core.block.common import (CacheMetricData, CopyOnWriteTracker,\n                                    get_all_blocks_recursively)\nfrom vllm.core.block.interfaces import Block, BlockAllocator, BlockId, Device\nfrom vllm.core.block.naive_block import (BlockPool, NaiveBlock,\n                                         NaiveBlockAllocator)\nfrom vllm.core.evictor_v2 import EvictionPolicy, Evictor, make_evictor\nfrom vllm.utils import cdiv\n\nPrefixHash = int\n\n# By default, we init our block access time as _DEFAULT_LAST_ACCESSED_TIME\n# so that if we find one block is still hold _DEFAULT_LAST_ACCESSED_TIME,\n# then we know this block hasn't been accessed yet.\n_DEFAULT_LAST_ACCESSED_TIME = -1\n\n\nclass BlockTracker:\n    \"\"\"Used to track the status of a block inside the prefix caching allocator\n    \"\"\"\n    __slots__ = (\"active\", \"last_accessed\", \"computed\")\n\n    def reset(self):\n        self.last_accessed: float = _DEFAULT_LAST_ACCESSED_TIME\n        self.computed: bool = False\n\n    def __init__(self):\n        self.active: bool = False\n        self.reset()\n\n    def enable(self):\n        assert not self.active\n        self.active = True\n        self.reset()\n\n    def disable(self):\n        assert self.active\n        self.active = False\n        self.reset()\n\n\nclass PrefixCachingBlockAllocator(BlockAllocator):\n    \"\"\"A block allocator that implements prefix caching.\n\n    The PrefixCachingBlockAllocator maintains a cache of blocks based on their\n    content hash. It reuses blocks with the same content hash to avoid redundant\n    memory allocation. The allocator also supports copy-on-write operations.\n\n    Args:\n        num_blocks (int): The total number of blocks to manage.\n        block_size (int): The size of each block in tokens.\n        block_ids(Optional[Iterable[int]], optional): An optional iterable of\n            block IDs. If not provided, block IDs will be assigned sequentially\n            from 0 to num_blocks - 1.\n    \"\"\"\n\n    def __init__(\n        self,\n        num_blocks: int,\n        block_size: int,\n        block_ids: Optional[Iterable[int]] = None,\n        eviction_policy: EvictionPolicy = EvictionPolicy.LRU,\n    ):\n        if block_ids is None:\n            block_ids = range(num_blocks)\n\n        self._block_size = block_size\n\n        # A mapping of prefix hash to block index. All blocks which have a\n        # prefix hash will be in this dict, even if they have refcount 0.\n        self._cached_blocks: Dict[PrefixHash, BlockId] = {}\n\n        # Used to track status of each physical block id\n        self._block_tracker: Dict[BlockId, BlockTracker] = {}\n        for block_id in block_ids:\n            self._block_tracker[block_id] = BlockTracker()\n\n        # Pre-allocate \"num_blocks * extra_factor\" block objects.\n        # The \"* extra_factor\" is a buffer to allow more block objects\n        # than physical blocks\n        extra_factor = 4\n        self._block_pool = BlockPool(self._block_size, self._create_block,\n                                     self, num_blocks * extra_factor)\n\n        # An allocator for blocks that do not have prefix hashes.\n        self._hashless_allocator = NaiveBlockAllocator(\n            create_block=self._create_block,  # type: ignore\n            num_blocks=num_blocks,\n            block_size=block_size,\n            block_ids=block_ids,\n            block_pool=self._block_pool,  # Share block pool here\n        )\n\n        # Evitor used to maintain how we want to handle those computed blocks\n        # if we find memory pressure is high.\n        self.evictor: Evictor = make_evictor(eviction_policy)\n\n        # We share the refcounter between allocators. This allows us to promote\n        # blocks originally allocated in the hashless allocator to immutable\n        # blocks.\n        self._refcounter = self._hashless_allocator.refcounter\n\n        self._cow_tracker = CopyOnWriteTracker(\n            refcounter=self._refcounter.as_readonly())\n\n        self.metric_data = CacheMetricData()\n\n    # Implements Block.Factory.\n    def _create_block(\n        self,\n        prev_block: Optional[Block],\n        token_ids: List[int],\n        block_size: int,\n        allocator: BlockAllocator,\n        block_id: Optional[int] = None,\n        computed: bool = False,\n    ) -> Block:\n        # Bind block to self.\n        allocator = self\n\n        return PrefixCachingBlock(\n            prev_block=prev_block,\n            token_ids=token_ids,\n            block_size=block_size,\n            block_id=block_id,\n            allocator=allocator,\n            computed=computed,\n        )\n\n    def allocate_immutable_block(self,\n                                 prev_block: Optional[Block],\n                                 token_ids: List[int],\n                                 device: Optional[Device] = None) -> Block:\n        \"\"\"Allocates an immutable block with the given token IDs, reusing cached\n        blocks if possible.\n\n        Args:\n            prev_block (Optional[Block]): The previous block in the sequence.\n            token_ids (List[int]): The token IDs to be stored in the block.\n\n        Returns:\n            Block: The allocated immutable block.\n        \"\"\"\n        assert device is None\n        assert_prefix_caching_block_or_none(prev_block)\n\n        # First, try to create a block that points to cached data\n        block = self._block_pool.init_block(prev_block=prev_block,\n                                            token_ids=token_ids,\n                                            block_size=self._block_size,\n                                            physical_block_id=None)\n        assert block.content_hash is not None\n\n        cached_block_id = self._cached_blocks.get(block.content_hash, None)\n        if cached_block_id is not None:\n            self.metric_data.query(hit=True)\n            block.block_id = cached_block_id\n            self._incr_refcount_cached_block(block)\n            return block\n        self.metric_data.query(hit=False)\n        self._block_pool.free_block(block)\n\n        # No cached block => Allocate a new block\n        block = self.allocate_mutable_block(prev_block)\n        block.append_token_ids(token_ids)\n        return block\n\n    def allocate_immutable_blocks(\n            self,\n            prev_block: Optional[Block],\n            block_token_ids: List[List[int]],\n            device: Optional[Device] = None) -> List[Block]:\n        blocks = []\n        for token_ids in block_token_ids:\n            prev_block = self.allocate_immutable_block(prev_block=prev_block,\n                                                       token_ids=token_ids,\n                                                       device=device)\n            blocks.append(prev_block)\n        return blocks\n\n    def allocate_mutable_block(self,\n                               prev_block: Optional[Block],\n                               device: Optional[Device] = None) -> Block:\n        \"\"\"Allocates a mutable block. If there are no free blocks, this will\n        evict unused cached blocks.\n\n        Args:\n            prev_block (Block): The previous block in the sequence.\n                None is not allowed unlike it is super class.\n\n        Returns:\n            Block: The allocated mutable block.\n        \"\"\"\n        assert device is None\n        assert_prefix_caching_block_or_none(prev_block)\n\n        block_id = self._allocate_block_id()\n        block = self._block_pool.init_block(prev_block=prev_block,\n                                            token_ids=[],\n                                            block_size=self._block_size,\n                                            physical_block_id=block_id)\n        assert not block.computed\n        assert block.content_hash is None\n        return block\n\n    def _incr_refcount_cached_block(self, block: Block) -> None:\n        # Set this block to be \"computed\" since it is pointing to a\n        # cached block id (which was already computed)\n        block.computed = True\n\n        block_id = block.block_id\n        assert block_id is not None\n\n        refcount = self._refcounter.incr(block_id)\n        if refcount == 1:\n            # In case a cached block was evicted, restore its tracking\n            if block_id in self.evictor:\n                self.evictor.remove(block_id)\n\n            self._track_block_id(block_id, computed=True)\n\n    def _decr_refcount_cached_block(self, block: Block) -> None:\n        # Ensure this is immutable/cached block\n        assert block.content_hash is not None\n\n        block_id = block.block_id\n        assert block_id is not None\n\n        refcount = self._refcounter.decr(block_id)\n        if refcount > 0:\n            block.block_id = None\n            return\n        else:\n            assert refcount == 0\n\n        # No longer used\n        assert block.content_hash in self._cached_blocks\n\n        # Add the cached block to the evictor\n        # (This keeps the cached block around so it can be reused)\n        self.evictor.add(block_id, block.content_hash, block.num_tokens_total,\n                         self._block_tracker[block_id].last_accessed)\n\n        # Stop tracking the block\n        self._untrack_block_id(block_id)\n\n        block.block_id = None\n\n    def _decr_refcount_hashless_block(self, block: Block) -> None:\n        block_id = block.block_id\n        assert block_id is not None\n\n        # We may have a fork case where block is shared,\n        # in which case, we cannot remove it from tracking\n        refcount = self._refcounter.get(block_id)\n        if refcount == 1:\n            self._untrack_block_id(block_id)\n\n        # Decrement refcount of the block_id, but do not free the block object\n        # itself (will be handled by the caller)\n        self._hashless_allocator.free(block, keep_block_object=True)\n\n    def _allocate_block_id(self) -> BlockId:\n        \"\"\"First tries to allocate a block id from the hashless allocator,\n        and if there are no blocks, then tries to evict an unused cached block.\n        \"\"\"\n        hashless_block_id = self._maybe_allocate_hashless_block_id()\n        if hashless_block_id is not None:\n            return hashless_block_id\n\n        evicted_block_id = self._maybe_allocate_evicted_block_id()\n        if evicted_block_id is not None:\n            return evicted_block_id\n\n        # No block available in hashless allocator, nor in unused cache blocks.\n        raise BlockAllocator.NoFreeBlocksError()\n\n    def _maybe_allocate_hashless_block_id(self) -> Optional[BlockId]:\n        try:\n            # Allocate mutable block and extract its block_id\n            block = self._hashless_allocator.allocate_mutable_block(\n                prev_block=None)\n            block_id = block.block_id\n            self._block_pool.free_block(block)\n\n            self._track_block_id(block_id, computed=False)\n            return block_id\n        except BlockAllocator.NoFreeBlocksError:\n            return None\n\n    def _maybe_allocate_evicted_block_id(self) -> Optional[BlockId]:\n        if self.evictor.num_blocks == 0:\n            return None\n\n        # Here we get an evicted block, which is only added\n        # into evictor if its ref counter is 0\n        # and since its content would be changed, we need\n        # to remove it from _cached_blocks's tracking list\n        block_id, content_hash_to_evict = self.evictor.evict()\n\n        # Sanity checks\n        assert content_hash_to_evict in self._cached_blocks\n        _block_id = self._cached_blocks[content_hash_to_evict]\n        assert self._refcounter.get(_block_id) == 0\n        assert _block_id == block_id\n\n        self._cached_blocks.pop(content_hash_to_evict)\n\n        self._refcounter.incr(block_id)\n        self._track_block_id(block_id, computed=False)\n\n        return block_id\n\n    def _free_block_id(self, block: Block) -> None:\n        \"\"\"Decrements the refcount of the block. The block may be in two \n        possible states: (1) immutable/cached or (2) mutable/hashless. \n        In the first case, the refcount is decremented directly and the block\n        may be possibly added to the evictor. In other case, hashless \n        allocator free(..) with keep_block_object=True is called to only free\n        the block id (since the block object may be reused by the caller)\n        \"\"\"\n        block_id = block.block_id\n        assert block_id is not None, \"Freeing unallocated block is undefined\"\n\n        if block.content_hash is not None:\n            # Immutable: This type of block is always cached, and we want to\n            # keep it in the evictor for future reuse\n            self._decr_refcount_cached_block(block)\n        else:\n            # Mutable: This type of block is not cached, so we release it\n            # directly to the hashless allocator\n            self._decr_refcount_hashless_block(block)\n\n        assert block.block_id is None\n\n    def free(self, block: Block, keep_block_object: bool = False) -> None:\n        \"\"\"Release the block (look at free_block_id(..) docs)\n        \"\"\"\n        # Release the physical block index\n        self._free_block_id(block)\n\n        # Release the block object to the pool\n        if not keep_block_object:\n            self._block_pool.free_block(block)\n\n    def fork(self, last_block: Block) -> List[Block]:\n        \"\"\"Creates a new sequence of blocks that shares the same underlying\n        memory as the original sequence.\n\n        Args:\n            last_block (Block): The last block in the original sequence.\n\n        Returns:\n            List[Block]: The new sequence of blocks that shares the same memory\n                as the original sequence.\n        \"\"\"\n        source_blocks = get_all_blocks_recursively(last_block)\n\n        forked_blocks: List[Block] = []\n        prev_block = None\n        for block in source_blocks:\n            block_id = block.block_id\n            assert block_id is not None\n\n            refcount = self._refcounter.incr(block_id)\n            assert refcount != 1, \"can't fork free'd block_id = {}\".format(\n                block_id)\n\n            forked_block = self._block_pool.init_block(\n                prev_block=prev_block,\n                token_ids=block.token_ids,\n                block_size=self._block_size,\n                physical_block_id=block_id)\n\n            forked_blocks.append(forked_block)\n            prev_block = forked_blocks[-1]\n\n        return forked_blocks\n\n    def get_num_free_blocks(self, device: Optional[Device] = None) -> int:\n        assert device is None\n        # The number of free blocks is the number of hashless free blocks\n        # plus the number of blocks evictor could free from its list.\n        return self._hashless_allocator.get_num_free_blocks(\n        ) + self.evictor.num_blocks\n\n    def get_num_total_blocks(self) -> int:\n        return self._hashless_allocator.get_num_total_blocks()\n\n    def get_physical_block_id(self, absolute_id: int) -> int:\n        \"\"\"Returns the zero-offset block id on certain block allocator\n        given the absolute block id.\n\n        Args:\n            absolute_id (int): The absolute block id for the block \n                in whole allocator.\n\n        Returns:\n            int: The rzero-offset block id on certain device.\n        \"\"\"\n        return sorted(self.all_block_ids).index(absolute_id)\n\n    @property\n    def all_block_ids(self) -> FrozenSet[int]:\n        return self._hashless_allocator.all_block_ids\n\n    def get_prefix_cache_hit_rate(self) -> float:\n        return self.metric_data.get_hit_rate()\n\n    def is_block_cached(self, block: Block) -> bool:\n        assert block.content_hash is not None\n        if block.content_hash in self._cached_blocks:\n            return True\n        return False\n\n    def promote_to_immutable_block(self, block: Block) -> BlockId:\n        \"\"\"Once a mutable block is full, it can be promoted to an immutable\n        block. This means that its content can be referenced by future blocks\n        having the same prefix.\n\n        Note that if we already have a cached block with the same content, we\n        will replace the newly-promoted block's mapping with the existing cached\n        block id.\n\n        Args:\n            block: The mutable block to be promoted.\n\n        Returns:\n            BlockId: Either the original block index, or the block index of\n                the previously cached block matching the same content.\n        \"\"\"\n        # Ensure block can be promoted\n        assert block.content_hash is not None\n        assert block.block_id is not None\n        assert self._refcounter.get(block.block_id) > 0\n\n        if block.content_hash not in self._cached_blocks:\n            # No cached content hash => Set this block as cached\n            # (Note that this block is not computed yet =>\n            #  Will be computed after free())\n            self._cached_blocks[block.content_hash] = block.block_id\n            return block.block_id\n\n        # Reuse the cached content hash\n        self._decr_refcount_hashless_block(block)\n        block.block_id = self._cached_blocks[block.content_hash]\n\n        # Increment refcount of the cached block and (possibly) restore\n        # it from the evictor.\n        # Note that in this case, the block is marked as computed\n        self._incr_refcount_cached_block(block)\n\n        return block.block_id\n\n    def cow_block_if_not_appendable(self, block: Block) -> BlockId:\n        \"\"\"Performs a copy-on-write operation on the given block if it is not\n        appendable.\n\n        Args:\n            block (Block): The block to check for copy-on-write.\n\n        Returns:\n            BlockId: The block index of the new block if a copy-on-write \n                operation was performed, or the original block index if\n                no copy-on-write was necessary.\n        \"\"\"\n        src_block_id = block.block_id\n        assert src_block_id is not None\n\n        if self._cow_tracker.is_appendable(block):\n            return src_block_id\n\n        self._free_block_id(block)\n        trg_block_id = self._allocate_block_id()\n\n        self._cow_tracker.record_cow(src_block_id, trg_block_id)\n\n        return trg_block_id\n\n    def clear_copy_on_writes(self) -> List[Tuple[BlockId, BlockId]]:\n        \"\"\"Returns the copy-on-write source->destination mapping and clears it.\n\n        Returns:\n            List[Tuple[BlockId, BlockId]]: A list mapping source\n                block indices to destination block indices.\n        \"\"\"\n        return self._cow_tracker.clear_cows()\n\n    def mark_blocks_as_accessed(self, block_ids: List[int],\n                                now: float) -> None:\n        \"\"\"Mark blocks as accessed, used in prefix caching.\n\n        If the block is added into evictor, we need to update corresponding\n        info in evictor's metadata.\n        \"\"\"\n\n        for block_id in block_ids:\n            if self._block_tracker[block_id].active:\n                self._block_tracker[block_id].last_accessed = now\n            elif block_id in self.evictor:\n                self.evictor.update(block_id, now)\n            else:\n                raise ValueError(\n                    \"Mark block as accessed which is not belonged to GPU\")\n\n    def mark_blocks_as_computed(self, block_ids: List[int]) -> None:\n        raise NotImplementedError(\"Marking as computed is incremental\")\n\n    def _track_block_id(self, block_id: Optional[BlockId],\n                        computed: bool) -> None:\n        assert block_id is not None\n        self._block_tracker[block_id].enable()\n        self._block_tracker[block_id].computed = computed\n\n    def _untrack_block_id(self, block_id: Optional[BlockId]) -> None:\n        assert block_id is not None\n        self._block_tracker[block_id].disable()\n\n    def block_is_computed(self, block_id: int) -> bool:\n        if self._block_tracker[block_id].active:\n            return self._block_tracker[block_id].computed\n        else:\n            return block_id in self.evictor\n\n    def get_computed_block_ids(self,\n                               prev_computed_block_ids: List[int],\n                               block_ids: List[int],\n                               skip_last_block_id: bool = True) -> List[int]:\n        prev_prefix_size = len(prev_computed_block_ids)\n        cur_size = len(block_ids)\n        if skip_last_block_id:\n            cur_size -= 1\n\n        # Sanity checks\n        assert cur_size >= 0\n        assert prev_prefix_size <= cur_size\n\n        ret = prev_computed_block_ids\n        for i in range(prev_prefix_size, cur_size):\n            block_id = block_ids[i]\n            if self.block_is_computed(block_id):\n                ret.append(block_id)\n        return ret\n\n    def get_common_computed_block_ids(\n            self, computed_seq_block_ids: List[List[int]]) -> List[int]:\n        \"\"\"Return the block ids that are common for a given sequence group.\n\n        Only those blocks that are immutable and already be marked\n        compyted would be taken consideration.\n        \"\"\"\n\n        # NOTE We exclude the last block to avoid the case where the entire\n        # prompt is cached. This would cause erroneous behavior in model\n        # runner.\n\n        # It returns a list of int although type annotation says list of string.\n        if len(computed_seq_block_ids) == 1:\n            return computed_seq_block_ids[0]\n\n        return commonprefix([\n            ids for ids in computed_seq_block_ids  # type: ignore\n            if ids\n        ])\n\n    def get_num_blocks_touched(self,\n                               blocks: List[Block],\n                               num_lookahead_slots: int = 0) -> int:\n        \"\"\"Determine the number of blocks that will be touched by\n        swapping in/out the given blocks from certain sequence\n        group with the provided num_lookahead_slots.\n\n        Args:\n            blocks (List[Block]): The potential blocks to swap.\n            num_lookahead_slots (int): number of lookahead slots (0 for \n                swap out).\n        \n        Returns:\n            int: the number of blocks that will be touched by\n                swapping in/out the given blocks and num_lookahead_slots.\n        \"\"\"\n        num_touched_blocks = 0\n        for block in blocks:\n            if not block.is_full:\n                num_touched_blocks += 1\n                if num_lookahead_slots > block.num_empty_slots:\n                    num_touched_blocks += cdiv(\n                        num_lookahead_slots - block.num_empty_slots,\n                        self._block_size)\n            else:\n                # If the block has a match in the cache and the cached block\n                # is not referenced, then we still count it as a touched block\n                if not self.is_block_cached(block) or \\\n                    (block.content_hash is not None and \\\n                     self._cached_blocks[block.content_hash] in self.evictor):\n                    num_touched_blocks += 1\n        return num_touched_blocks\n\n    def swap_out(self, blocks: List[Block]) -> None:\n        \"\"\"Execute the swap out actions. Basically just free the \n        given blocks.\n\n        Args:\n            blocks: List of blocks to be swapped out.\n        \"\"\"\n        for block in blocks:\n            self._free_block_id(block)\n\n    def swap_in(self, blocks: List[Block]) -> None:\n        \"\"\"Execute the swap in actions. Change the block id from \n        old allocator to current allocator for each block to finish \n        the block table update. \n\n        Args:\n            blocks: List of blocks to be swapped in.\n        \"\"\"\n        for block in blocks:\n            # Here we allocate either immutable or mutable block and then\n            # extract its block_id. Note that the block object is released\n            # and the block_id is assigned to \"block\" to allow reusing the\n            # existing \"block\" object\n            if block.is_full:\n                tmp_block = self.allocate_immutable_block(\n                    prev_block=block.prev_block, token_ids=block.token_ids)\n            else:\n                tmp_block = self.allocate_mutable_block(\n                    prev_block=block.prev_block)\n                tmp_block.append_token_ids(block.token_ids)\n\n            block_id = tmp_block.block_id\n            self._block_pool.free_block(tmp_block)\n\n            block.block_id = block_id  # Assign block_id\n\n\nclass PrefixCachingBlock(Block):\n    \"\"\"A block implementation that supports prefix caching.\n\n    The PrefixCachingBlock class represents a block of token IDs with prefix\n    caching capabilities. It wraps a NaiveBlock internally and provides\n    additional functionality for content hashing and promoting immutable blocks\n    with the prefix caching allocator.\n\n    Args:\n        prev_block (Optional[PrefixCachingBlock]): The previous block in the\n            sequence.\n        token_ids (List[int]): The initial token IDs to be stored in the block.\n        block_size (int): The maximum number of token IDs that can be stored in\n            the block.\n        allocator (BlockAllocator): The prefix\n            caching block allocator associated with this block.\n        block_id (Optional[int], optional): The physical block index\n            of this block. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        prev_block: Optional[Block],\n        token_ids: List[int],\n        block_size: int,\n        allocator: BlockAllocator,\n        block_id: Optional[int] = None,\n        computed: bool = False,\n    ):\n        assert isinstance(allocator, PrefixCachingBlockAllocator), (\n            \"Currently this class is only tested with \"\n            \"PrefixCachingBlockAllocator. Got instead allocator = {}\".format(\n                allocator))\n        assert_prefix_caching_block_or_none(prev_block)\n\n        self._prev_block = prev_block\n        self._cached_content_hash: Optional[int] = None\n        self._cached_num_tokens_total: int = 0\n        self._allocator = allocator\n        self._last_accessed: float = _DEFAULT_LAST_ACCESSED_TIME\n        self._computed = computed\n\n        # On the first time, we create the block object, and next we only\n        # reinitialize it\n        if hasattr(self, \"_block\"):\n            self._block.__init__(  # type: ignore[has-type]\n                prev_block=prev_block,\n                token_ids=token_ids,\n                block_size=block_size,\n                block_id=block_id,\n                allocator=self._allocator)\n        else:\n            self._block = NaiveBlock(prev_block=prev_block,\n                                     token_ids=token_ids,\n                                     block_size=block_size,\n                                     block_id=block_id,\n                                     allocator=self._allocator)\n\n        self._update_num_tokens_total()\n\n    def _update_num_tokens_total(self):\n        \"\"\"Incrementally computes the number of tokens that there is\n        till the current block (included)\n        \"\"\"\n        res = 0\n\n        # Add all previous blocks\n        if self._prev_block is not None:\n            res += self._prev_block.num_tokens_total\n\n        # Add current block\n        res += len(self.token_ids)\n\n        self._cached_num_tokens_total = res\n\n    @property\n    def computed(self) -> bool:\n        return self._computed\n\n    @computed.setter\n    def computed(self, value) -> None:\n        self._computed = value\n\n    @property\n    def last_accessed(self) -> float:\n        return self._last_accessed\n\n    @last_accessed.setter\n    def last_accessed(self, last_accessed_ts: float):\n        self._last_accessed = last_accessed_ts\n\n    def append_token_ids(self, token_ids: List[int]) -> None:\n        \"\"\"Appends the given token IDs to the block and registers the block as\n        immutable if the block becomes full.\n\n        Args:\n            token_ids (List[int]): The token IDs to be appended to the block.\n        \"\"\"\n        # Ensure this is mutable block (not promoted)\n        assert self.content_hash is None\n        assert not self.computed\n\n        if len(token_ids) == 0:\n            return\n\n        # Ensure there are input tokens\n        assert token_ids, \"Got token_ids = {}\".format(token_ids)\n\n        # Naive block handles CoW.\n        self._block.append_token_ids(token_ids)\n        self._update_num_tokens_total()\n\n        # If the content hash is present, then the block can be made immutable.\n        # Register ourselves with the allocator, potentially replacing the\n        # physical block index.\n        if self.content_hash is not None:\n            self.block_id = self._allocator.promote_to_immutable_block(self)\n\n    @property\n    def block_id(self) -> Optional[int]:\n        return self._block.block_id\n\n    @block_id.setter\n    def block_id(self, value) -> None:\n        self._block.block_id = value\n\n    @property\n    def is_full(self) -> bool:\n        return self._block.is_full\n\n    @property\n    def num_empty_slots(self) -> int:\n        return self._block.num_empty_slots\n\n    @property\n    def num_tokens_total(self) -> int:\n        return self._cached_num_tokens_total\n\n    @property\n    def block_size(self) -> int:\n        return self._block.block_size\n\n    @property\n    def token_ids(self) -> List[int]:\n        return self._block.token_ids\n\n    @property\n    def prev_block(self) -> Optional[Block]:\n        return self._prev_block\n\n    @property\n    def content_hash(self) -> Optional[int]:\n        \"\"\"Return the content-based hash of the current block, or None if it is\n        not yet defined.\n\n        For the content-based hash to be defined, the current block must be\n        full.\n        \"\"\"\n        # If the hash is already computed, return it.\n        if self._cached_content_hash is not None:\n            return self._cached_content_hash\n\n        # We cannot compute a hash for the current block because it is not full.\n        if not self.is_full:\n            return None\n\n        is_first_block = self._prev_block is None\n        prev_block_hash = (\n            None if is_first_block else\n            self._prev_block.content_hash  # type: ignore\n        )\n\n        # Previous block exists but does not yet have a hash.\n        # Return no hash in this case.\n        if prev_block_hash is None and not is_first_block:\n            return None\n\n        self._cached_content_hash = PrefixCachingBlock.hash_block_tokens(\n            is_first_block,\n            prev_block_hash,\n            cur_block_token_ids=self.token_ids)\n        return self._cached_content_hash\n\n    @staticmethod\n    def hash_block_tokens(is_first_block: bool, prev_block_hash: Optional[int],\n                          cur_block_token_ids: List[int]) -> int:\n        \"\"\"Computes a hash value corresponding to the contents of a block and\n        the contents of the preceding block(s). The hash value is used for\n        prefix caching.\n\n        NOTE: Content-based hashing does not yet support LoRA.\n\n        Parameters:\n        - is_first_block (bool): A flag indicating if the block is the first in\n            the sequence.\n        - prev_block_hash (Optional[int]): The hash of the previous block. None\n            if this is the first block.\n        - cur_block_token_ids (List[int]): A list of token ids in the current\n            block. The current block is assumed to be full.\n\n        Returns:\n        - int: The computed hash value for the block.\n        \"\"\"\n        assert (prev_block_hash is None) == is_first_block\n        return hash((is_first_block, prev_block_hash, *cur_block_token_ids))\n\n\nclass ComputedBlocksTracker:\n    \"\"\"Handles caching of per-sequence computed block ids. \n        When a sequence appears for the first time, it traverses all of the \n        blocks and detects the prefix of blocks that is computed. On the\n        subsequent times, it only traverses the new blocks that were added \n        and updates the already recorded prefix of blocks with the newly \n        computed blocks.\n\n        To avoid redundant traversals, the algorithm also detects when there\n        is a \"gap\" in the computed prefix. For example, if we have blocks =\n        [1,2,3,4,5], and we have detected [1,2,3] as the computed prefix, then\n        we won't try to add more computed blocks to [1,2,3] in this sequence\n        iteration, and will add more computed blocks only after the sequence is\n        freed and reused again.\n\n        Note that currently, for a given sequence, we also skip the last \n        block id for caching purposes, to avoid caching of a full sequence\n    \"\"\"\n\n    def __init__(self, allocator):\n        self._allocator = allocator\n        self._cached_computed_seq_blocks: Dict[int, Tuple[List[int],\n                                                          bool]] = {}\n\n    def add_seq(self, seq_id: int) -> None:\n        \"\"\"Start tracking seq_id\n        \"\"\"\n        assert seq_id not in self._cached_computed_seq_blocks\n        self._cached_computed_seq_blocks[seq_id] = ([], False)\n\n    def remove_seq(self, seq_id: int) -> None:\n        \"\"\"Stop tracking seq_id\n        \"\"\"\n        assert seq_id in self._cached_computed_seq_blocks\n        del self._cached_computed_seq_blocks[seq_id]\n\n    def get_cached_computed_blocks_and_update(\n            self, seq_id: int, block_ids: List[int]) -> List[int]:\n        \"\"\" Look at the class documentation for details\n        \"\"\"\n        # Ensure seq_id is already tracked\n        assert seq_id in self._cached_computed_seq_blocks\n\n        # Get cached data (may be empty on the first time)\n        prev_computed_block_ids, has_gap = self._cached_computed_seq_blocks[\n            seq_id]\n\n        if has_gap:\n            # When gap is detected, we do not add more computed blocks at this\n            # sequence iteration\n            return prev_computed_block_ids\n\n        # We do not consider the last block id for caching purposes.\n        num_cur_blocks = len(block_ids) - 1\n        assert num_cur_blocks >= 0\n\n        if len(prev_computed_block_ids) >= num_cur_blocks:\n            # Cache HIT\n            assert len(prev_computed_block_ids) == num_cur_blocks\n            return prev_computed_block_ids\n\n        # If here, then we may possibly add more computed blocks. As a result,\n        # traverse the additional blocks after prev_computed_block_ids to\n        # detect more computed blocks and add them.\n\n        # Incremental init for seq_id => Look only at the new blocks\n        computed_block_ids = self._allocator.get_computed_block_ids(  # noqa: E501\n            prev_computed_block_ids,\n            block_ids,\n            skip_last_block_id=\n            True,  # We skip last block id to avoid caching of full seq\n        )\n\n        # Detect if there is a \"gap\"\n        has_gap = len(computed_block_ids) < num_cur_blocks\n\n        # Record\n        self._cached_computed_seq_blocks[seq_id] = (computed_block_ids,\n                                                    has_gap)\n\n        return computed_block_ids\n\n\nclass LastAccessBlocksTracker:\n    \"\"\"Manages the last access time of the tracked sequences, in order to allow\n    an efficient update of allocator's block last access times\n    \"\"\"\n\n    def __init__(self, allocator):\n        self._allocator = allocator\n        self._seq_last_access: Dict[int, Optional[float]] = {}\n\n    def add_seq(self, seq_id: int) -> None:\n        \"\"\"Start tracking seq_id\n        \"\"\"\n        assert seq_id not in self._seq_last_access\n        self._seq_last_access[seq_id] = None\n\n    def remove_seq(self, seq_id: int) -> None:\n        \"\"\"Stop tracking seq_id\n        \"\"\"\n        assert seq_id in self._seq_last_access\n        del self._seq_last_access[seq_id]\n\n    def update_last_access(self, seq_id: int, time: float) -> None:\n        assert seq_id in self._seq_last_access\n        self._seq_last_access[seq_id] = time\n\n    def update_seq_blocks_last_access(self, seq_id: int,\n                                      block_ids: List[int]) -> None:\n        assert seq_id in self._seq_last_access\n\n        ts = self._seq_last_access[seq_id]\n\n        if ts is None:\n            # No last access was recorded, no need to update.\n            return\n\n        self._allocator.mark_blocks_as_accessed(block_ids, ts)\n\n\ndef assert_prefix_caching_block_or_none(block: Optional[Block]):\n    if block is None:\n        return\n    assert isinstance(block,\n                      PrefixCachingBlock), \"Got block = {}\".format(block)\n",
      "diff": "diff --git a/vllm/core/block/prefix_caching_block.py b/vllm/core/block/prefix_caching_block.py\nindex 432a6651a..a87e814cf 100644\n--- a/vllm/core/block/prefix_caching_block.py\n+++ b/vllm/core/block/prefix_caching_block.py\n@@ -1,6 +1,6 @@\n \"\"\"Token blocks.\"\"\"\n from os.path import commonprefix\n-from typing import Dict, FrozenSet, Iterable, List, Optional, Tuple\n+from typing import Dict, FrozenSet, Iterable, List, Optional, Set, Tuple\n \n from vllm.core.block.common import (CacheMetricData, CopyOnWriteTracker,\n                                     get_all_blocks_recursively)\n@@ -73,6 +73,11 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         # prefix hash will be in this dict, even if they have refcount 0.\n         self._cached_blocks: Dict[PrefixHash, BlockId] = {}\n \n+        # A list of immutable block IDs that have been touched by scheduler\n+        # and should be marked as computed after an entire batch of sequences\n+        # are scheduled.\n+        self._touched_blocks: Set[BlockId] = set()\n+\n         # Used to track status of each physical block id\n         self._block_tracker: Dict[BlockId, BlockTracker] = {}\n         for block_id in block_ids:\n@@ -438,10 +443,14 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         assert self._refcounter.get(block.block_id) > 0\n \n         if block.content_hash not in self._cached_blocks:\n-            # No cached content hash => Set this block as cached\n-            # (Note that this block is not computed yet =>\n-            #  Will be computed after free())\n+            # No cached content hash => Set this block as cached.\n+            # Note that this block cannot be marked as computed yet\n+            # because other sequences in the same batch cannot reuse\n+            # this block.\n             self._cached_blocks[block.content_hash] = block.block_id\n+            # Mark this block as touched so that it can be marked as\n+            # computed after the entire batch of sequences are scheduled.\n+            self._touched_blocks.add(block.block_id)\n             return block.block_id\n \n         # Reuse the cached content hash\n@@ -507,7 +516,10 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n                     \"Mark block as accessed which is not belonged to GPU\")\n \n     def mark_blocks_as_computed(self, block_ids: List[int]) -> None:\n-        raise NotImplementedError(\"Marking as computed is incremental\")\n+        # Mark all touched blocks as computed.\n+        for block_id in self._touched_blocks:\n+            self._block_tracker[block_id].computed = True\n+        self._touched_blocks.clear()\n \n     def _track_block_id(self, block_id: Optional[BlockId],\n                         computed: bool) -> None:",
      "change_type": "modified",
      "lines_added": 18,
      "lines_removed": 6
    },
    {
      "file_path": "vllm/core/block_manager_v2.py",
      "old_content": "\"\"\"A block manager that manages token blocks.\"\"\"\nfrom itertools import chain\nfrom typing import Dict, List, Optional\nfrom typing import Sequence as GenericSequence\nfrom typing import Tuple\n\nfrom vllm.core.block.block_table import BlockTable\nfrom vllm.core.block.cpu_gpu_block_allocator import CpuGpuBlockAllocator\nfrom vllm.core.block.interfaces import Block\nfrom vllm.core.block.prefix_caching_block import (ComputedBlocksTracker,\n                                                  LastAccessBlocksTracker)\nfrom vllm.core.block.utils import check_no_caching_or_swa_for_blockmgr_encdec\nfrom vllm.core.interfaces import AllocStatus, BlockSpaceManager\nfrom vllm.sequence import Sequence, SequenceGroup, SequenceStatus\nfrom vllm.utils import Device\n\nSeqId = int\nEncoderSeqId = str\n\n\nclass BlockSpaceManagerV2(BlockSpaceManager):\n    \"\"\"BlockSpaceManager which manages the allocation of KV cache.\n\n    It owns responsibility for allocation, swapping, allocating memory for\n    autoregressively-generated tokens, and other advanced features such as\n    prefix caching, forking/copy-on-write, and sliding-window memory allocation.\n\n    The current implementation is partial; in particular prefix caching and\n    sliding-window are not feature complete. This class implements the design\n    described in https://github.com/vllm-project/vllm/pull/3492.\n\n    Lookahead slots\n        The block manager has the notion of a \"lookahead slot\". These are slots\n        in the KV cache that are allocated for a sequence. Unlike the other\n        allocated slots, the content of these slots is undefined -- the worker\n        may use the memory allocations in any way.\n\n        In practice, a worker could use these lookahead slots to run multiple\n        forward passes for a single scheduler invocation. Each successive\n        forward pass would write KV activations to the corresponding lookahead\n        slot. This allows low inter-token latency use-cases, where the overhead\n        of continuous batching scheduling is amortized over >1 generated tokens.\n\n        Speculative decoding uses lookahead slots to store KV activations of\n        proposal tokens.\n\n        See https://github.com/vllm-project/vllm/pull/3250 for more information\n        on lookahead scheduling.\n\n    Args:\n        block_size (int): The size of each memory block.\n        num_gpu_blocks (int): The number of memory blocks allocated on GPU.\n        num_cpu_blocks (int): The number of memory blocks allocated on CPU.\n        watermark (float, optional): The threshold used for memory swapping.\n            Defaults to 0.01.\n        sliding_window (Optional[int], optional): The size of the sliding\n            window. Defaults to None.\n        enable_caching (bool, optional): Flag indicating whether caching is\n            enabled. Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        block_size: int,\n        num_gpu_blocks: int,\n        num_cpu_blocks: int,\n        watermark: float = 0.01,\n        sliding_window: Optional[int] = None,\n        enable_caching: bool = False,\n    ) -> None:\n        self.block_size = block_size\n        self.num_total_gpu_blocks = num_gpu_blocks\n        self.num_total_cpu_blocks = num_cpu_blocks\n\n        self.sliding_window = sliding_window\n        # max_block_sliding_window is the max number of blocks that need to be\n        # allocated\n        self.max_block_sliding_window = None\n        if sliding_window is not None:\n            # +1 here because // rounds down\n            num_blocks = sliding_window // block_size + 1\n            # +1 here because the last block may not be full,\n            # and so the sequence stretches one more block at the beginning\n            # For example, if sliding_window is 3 and block_size is 4,\n            # we may need 2 blocks when the second block only holds 1 token.\n            self.max_block_sliding_window = num_blocks + 1\n\n        self.watermark = watermark\n        assert watermark >= 0.0\n\n        self.enable_caching = enable_caching\n\n        self.watermark_blocks = int(watermark * num_gpu_blocks)\n\n        self.block_allocator = CpuGpuBlockAllocator.create(\n            allocator_type=\"prefix_caching\" if enable_caching else \"naive\",\n            num_gpu_blocks=num_gpu_blocks,\n            num_cpu_blocks=num_cpu_blocks,\n            block_size=block_size,\n        )\n\n        self.block_tables: Dict[SeqId, BlockTable] = {}\n        self.cross_block_tables: Dict[EncoderSeqId, BlockTable] = {}\n\n        self._computed_blocks_tracker = ComputedBlocksTracker(\n            self.block_allocator)\n        self._last_access_blocks_tracker = LastAccessBlocksTracker(\n            self.block_allocator)\n\n    def can_allocate(self, seq_group: SequenceGroup) -> AllocStatus:\n        # FIXME(woosuk): Here we assume that all sequences in the group share\n        # the same prompt. This may not be true for preempted sequences.\n\n        check_no_caching_or_swa_for_blockmgr_encdec(self, seq_group)\n\n        seq = seq_group.get_seqs(status=SequenceStatus.WAITING)[0]\n        num_required_blocks = BlockTable.get_num_required_blocks(\n            seq.get_token_ids(),\n            block_size=self.block_size,\n        )\n\n        if seq_group.is_encoder_decoder():\n            num_required_blocks += BlockTable.get_num_required_blocks(\n                seq_group.get_encoder_seq().get_token_ids(),\n                block_size=self.block_size,\n            )\n\n        if self.max_block_sliding_window is not None:\n            num_required_blocks = min(num_required_blocks,\n                                      self.max_block_sliding_window)\n\n        num_free_gpu_blocks = self.block_allocator.get_num_free_blocks(\n            device=Device.GPU)\n\n        # Use watermark to avoid frequent cache eviction.\n        if (self.num_total_gpu_blocks - num_required_blocks <\n                self.watermark_blocks):\n            return AllocStatus.NEVER\n        if num_free_gpu_blocks - num_required_blocks >= self.watermark_blocks:\n            return AllocStatus.OK\n        else:\n            return AllocStatus.LATER\n\n    def _allocate_sequence(self, seq: Sequence) -> BlockTable:\n        block_table = BlockTable(\n            block_size=self.block_size,\n            block_allocator=self.block_allocator,\n            max_block_sliding_window=self.max_block_sliding_window,\n        )\n        block_table.allocate(seq.get_token_ids())\n\n        return block_table\n\n    def allocate(self, seq_group: SequenceGroup) -> None:\n\n        # Allocate self-attention block tables for decoder sequences\n        waiting_seqs = seq_group.get_seqs(status=SequenceStatus.WAITING)\n        assert not (set(seq.seq_id for seq in waiting_seqs)\n                    & self.block_tables.keys()), \"block table already exists\"\n\n        # NOTE: Here we assume that all sequences in the group have the same\n        # prompt.\n        seq = waiting_seqs[0]\n        block_table: BlockTable = self._allocate_sequence(seq)\n        self.block_tables[seq.seq_id] = block_table\n\n        # Track seq\n        self._computed_blocks_tracker.add_seq(seq.seq_id)\n        self._last_access_blocks_tracker.add_seq(seq.seq_id)\n\n        # Assign the block table for each sequence.\n        for seq in waiting_seqs[1:]:\n            self.block_tables[seq.seq_id] = block_table.fork()\n\n            # Track seq\n            self._computed_blocks_tracker.add_seq(seq.seq_id)\n            self._last_access_blocks_tracker.add_seq(seq.seq_id)\n\n        # Allocate cross-attention block table for encoder sequence\n        #\n        # NOTE: Here we assume that all sequences in the group have the same\n        # encoder prompt.\n        request_id = seq_group.request_id\n\n        assert (request_id\n                not in self.cross_block_tables), \\\n                \"block table already exists\"\n\n        check_no_caching_or_swa_for_blockmgr_encdec(self, seq_group)\n\n        if seq_group.is_encoder_decoder():\n            block_table = self._allocate_sequence(seq_group.get_encoder_seq())\n            self.cross_block_tables[request_id] = block_table\n\n    def can_append_slots(self, seq_group: SequenceGroup,\n                         num_lookahead_slots: int) -> bool:\n        \"\"\"Determine if there is enough space in the GPU KV cache to continue\n        generation of the specified sequence group.\n\n        We use a worst-case heuristic: assume each touched block will require a\n        new allocation (either via CoW or new block). We can append slots if the\n        number of touched blocks is less than the number of free blocks.\n\n        \"Lookahead slots\" are slots that are allocated in addition to the slots\n        for known tokens. The contents of the lookahead slots are not defined.\n        This is used by speculative decoding when speculating future tokens.\n        \"\"\"\n\n        num_touched_blocks = 0\n        for seq in seq_group.get_seqs(status=SequenceStatus.RUNNING):\n            block_table = self.block_tables[seq.seq_id]\n\n            num_touched_blocks += (\n                block_table.get_num_blocks_touched_by_append_slots(\n                    token_ids=block_table.get_unseen_token_ids(\n                        seq.get_token_ids()),\n                    num_lookahead_slots=num_lookahead_slots,\n                ))\n\n        num_free_gpu_blocks = self.block_allocator.get_num_free_blocks(\n            Device.GPU)\n        return num_touched_blocks <= num_free_gpu_blocks\n\n    def append_slots(\n        self,\n        seq: Sequence,\n        num_lookahead_slots: int,\n    ) -> List[Tuple[int, int]]:\n\n        block_table = self.block_tables[seq.seq_id]\n\n        block_table.append_token_ids(\n            token_ids=block_table.get_unseen_token_ids(seq.get_token_ids()),\n            num_lookahead_slots=num_lookahead_slots,\n            num_computed_slots=seq.data.get_num_computed_tokens(),\n        )\n        # Return any new copy-on-writes.\n        new_cows = self.block_allocator.clear_copy_on_writes()\n        return new_cows\n\n    def free(self, seq: Sequence) -> None:\n        seq_id = seq.seq_id\n\n        if seq_id not in self.block_tables:\n            # Already freed or haven't been scheduled yet.\n            return\n\n        # Update seq block ids with the latest access time\n        self._last_access_blocks_tracker.update_seq_blocks_last_access(\n            seq_id, self.block_tables[seq.seq_id].physical_block_ids)\n\n        # Untrack seq\n        self._last_access_blocks_tracker.remove_seq(seq_id)\n        self._computed_blocks_tracker.remove_seq(seq_id)\n\n        # Free table/blocks\n        self.block_tables[seq_id].free()\n        del self.block_tables[seq_id]\n\n    def free_cross(self, seq_group: SequenceGroup) -> None:\n        request_id = seq_group.request_id\n        if request_id not in self.cross_block_tables:\n            # Already freed or hasn't been scheduled yet.\n            return\n        self.cross_block_tables[request_id].free()\n        del self.cross_block_tables[request_id]\n\n    def get_block_table(self, seq: Sequence) -> List[int]:\n        block_ids = self.block_tables[seq.seq_id].physical_block_ids\n        return block_ids  # type: ignore\n\n    def get_cross_block_table(self, seq_group: SequenceGroup) -> List[int]:\n        request_id = seq_group.request_id\n        assert request_id in self.cross_block_tables\n        block_ids = self.cross_block_tables[request_id].physical_block_ids\n        assert all(b is not None for b in block_ids)\n        return block_ids  # type: ignore\n\n    def access_all_blocks_in_seq(self, seq: Sequence, now: float):\n        if self.enable_caching:\n            # Record the latest access time for the sequence. The actual update\n            # of the block ids is deferred to the sequence free(..) call, since\n            # only during freeing of block ids, the blocks are actually added to\n            # the evictor (which is when the most updated time is required)\n            # (This avoids expensive calls to mark_blocks_as_accessed(..))\n            self._last_access_blocks_tracker.update_last_access(\n                seq.seq_id, now)\n\n    def mark_blocks_as_computed(self, seq_group: SequenceGroup):\n        # The only need for mark block as computed is for prefix caching,\n        # while currently we could determine whether one block is computed\n        # or not by check whether it has content hash.\n        # So this function is useless for block_v2.\n        pass\n\n    def get_common_computed_block_ids(\n            self, seqs: List[Sequence]) -> GenericSequence[int]:\n        \"\"\"Determine which blocks for which we skip prefill.\n\n        With prefix caching we can skip prefill for previously-generated blocks.\n        Currently, the attention implementation only supports skipping cached\n        blocks if they are a contiguous prefix of cached blocks.\n\n        This method determines which blocks can be safely skipped for all\n        sequences in the sequence group.\n        \"\"\"\n        computed_seq_block_ids = []\n        for seq in seqs:\n            computed_seq_block_ids.append(\n                self._computed_blocks_tracker.\n                get_cached_computed_blocks_and_update(\n                    seq.seq_id,\n                    self.block_tables[seq.seq_id].physical_block_ids))\n\n        # NOTE(sang): This assumes seq_block_ids doesn't contain any None.\n        return self.block_allocator.get_common_computed_block_ids(\n            computed_seq_block_ids)  # type: ignore\n\n    def fork(self, parent_seq: Sequence, child_seq: Sequence) -> None:\n        if parent_seq.seq_id not in self.block_tables:\n            # Parent sequence has either been freed or never existed.\n            return\n        src_block_table = self.block_tables[parent_seq.seq_id]\n        self.block_tables[child_seq.seq_id] = src_block_table.fork()\n\n        # Track child seq\n        self._computed_blocks_tracker.add_seq(child_seq.seq_id)\n        self._last_access_blocks_tracker.add_seq(child_seq.seq_id)\n\n    def can_swap_in(self, seq_group: SequenceGroup,\n                    num_lookahead_slots: int) -> AllocStatus:\n        \"\"\"Returns the AllocStatus for the given sequence_group \n        with num_lookahead_slots.\n\n        Args:\n            sequence_group (SequenceGroup): The sequence group to swap in.\n            num_lookahead_slots (int): Number of lookahead slots used in \n                speculative decoding, default to 0.\n\n        Returns:\n            AllocStatus: The AllocStatus for the given sequence group.\n        \"\"\"\n        return self._can_swap(seq_group, Device.GPU, SequenceStatus.SWAPPED,\n                              num_lookahead_slots)\n\n    def swap_in(self, seq_group: SequenceGroup) -> List[Tuple[int, int]]:\n        \"\"\"Returns the block id mapping (from CPU to GPU) generated by\n        swapping in the given seq_group with num_lookahead_slots.\n\n        Args:\n            seq_group (SequenceGroup): The sequence group to swap in.\n\n        Returns:\n            List[Tuple[int, int]]: The mapping of swapping block from CPU \n                to GPU.\n        \"\"\"\n        physical_block_id_mapping = []\n        for seq in seq_group.get_seqs(status=SequenceStatus.SWAPPED):\n            blocks = self.block_tables[seq.seq_id].blocks\n            if len(blocks) == 0:\n                continue\n\n            seq_swap_mapping = self.block_allocator.swap(blocks=blocks,\n                                                         src_device=Device.CPU,\n                                                         dst_device=Device.GPU)\n\n            # Refresh the block ids of the table (post-swap)\n            self.block_tables[seq.seq_id].update(blocks)\n\n            seq_physical_block_id_mapping = {\n                self.block_allocator.get_physical_block_id(\n                    Device.CPU, cpu_block_id):\n                self.block_allocator.get_physical_block_id(\n                    Device.GPU, gpu_block_id)\n                for cpu_block_id, gpu_block_id in seq_swap_mapping.items()\n            }\n\n            physical_block_id_mapping.extend(\n                list(seq_physical_block_id_mapping.items()))\n\n        return physical_block_id_mapping\n\n    def can_swap_out(self, seq_group: SequenceGroup) -> bool:\n        \"\"\"Returns whether we can swap out the given sequence_group \n        with num_lookahead_slots.\n\n        Args:\n            seq_group (SequenceGroup): The sequence group to swap in.\n            num_lookahead_slots (int): Number of lookahead slots used in \n                speculative decoding, default to 0.\n\n        Returns:\n            bool: Whether it's possible to swap out current sequence group.\n        \"\"\"\n        alloc_status = self._can_swap(seq_group, Device.CPU,\n                                      SequenceStatus.RUNNING)\n        if alloc_status == AllocStatus.OK:\n            return True\n        return False\n\n    def swap_out(self, seq_group: SequenceGroup) -> List[Tuple[int, int]]:\n        \"\"\"Returns the block id mapping (from GPU to CPU) generated by\n        swapping out the given sequence_group with num_lookahead_slots.\n\n        Args:\n            sequence_group (SequenceGroup): The sequence group to swap in.\n\n        Returns:\n            List[Tuple[int, int]]: The mapping of swapping block from \n                GPU to CPU.\n        \"\"\"\n        physical_block_id_mapping = []\n        for seq in seq_group.get_seqs(status=SequenceStatus.RUNNING):\n            blocks = self.block_tables[seq.seq_id].blocks\n            if len(blocks) == 0:\n                continue\n\n            seq_swap_mapping = self.block_allocator.swap(blocks=blocks,\n                                                         src_device=Device.GPU,\n                                                         dst_device=Device.CPU)\n\n            # Refresh the block ids of the table (post-swap)\n            self.block_tables[seq.seq_id].update(blocks)\n\n            seq_physical_block_id_mapping = {\n                self.block_allocator.get_physical_block_id(\n                    Device.GPU, gpu_block_id):\n                self.block_allocator.get_physical_block_id(\n                    Device.CPU, cpu_block_id)\n                for gpu_block_id, cpu_block_id in seq_swap_mapping.items()\n            }\n\n            physical_block_id_mapping.extend(\n                list(seq_physical_block_id_mapping.items()))\n\n        return physical_block_id_mapping\n\n    def get_num_free_gpu_blocks(self) -> int:\n        return self.block_allocator.get_num_free_blocks(Device.GPU)\n\n    def get_num_free_cpu_blocks(self) -> int:\n        return self.block_allocator.get_num_free_blocks(Device.CPU)\n\n    def get_prefix_cache_hit_rate(self, device: Device) -> float:\n        return self.block_allocator.get_prefix_cache_hit_rate(device)\n\n    def _can_swap(self,\n                  seq_group: SequenceGroup,\n                  device: Device,\n                  status: SequenceStatus,\n                  num_lookahead_slots: int = 0) -> AllocStatus:\n        \"\"\"Returns the AllocStatus for swapping in/out the given sequence_group \n        on to the 'device'.\n\n        Args:\n            sequence_group (SequenceGroup): The sequence group to swap in.\n            device (Device): device to swap the 'seq_group' on.\n            status (SequenceStatus): The status of sequence which is needed\n                for action. RUNNING for swap out and SWAPPED for swap in\n            num_lookahead_slots (int): Number of lookahead slots used in \n                speculative decoding, default to 0.\n\n        Returns:\n            AllocStatus: The AllocStatus for swapping in/out the given \n                sequence_group on to the 'device'.\n        \"\"\"\n        blocks = self._get_blocks_for_swap(seq_group, status)\n        num_blocks_touched = self.block_allocator.get_num_blocks_touched(\n            blocks, device, num_lookahead_slots)\n        watermark_blocks = 0\n        if device == Device.GPU:\n            watermark_blocks = self.watermark_blocks\n        if self.block_allocator.get_num_total_blocks(\n                device) < num_blocks_touched:\n            return AllocStatus.NEVER\n        elif self.block_allocator.get_num_free_blocks(\n                device) - num_blocks_touched >= watermark_blocks:\n            return AllocStatus.OK\n        else:\n            return AllocStatus.LATER\n\n    def _get_blocks_for_swap(self, seq_group: SequenceGroup,\n                             status: SequenceStatus) -> List[Block]:\n        \"\"\"Returns the list of blocks those are touched by the seq_group\n        \n        Args:\n            sequence_group (SequenceGroup): The sequence group to swap in.\n            status (SequenceStatus): The status of sequence which is needed\n                for action. RUNNING for swap out and SWAPPED for swap in\n        \n        Returns:\n            The list of blocks those are touched by the seq_group.\n        \"\"\"\n        blocks: Dict[int, List[Block]] = {}\n        for seq in seq_group.get_seqs(status=status):\n            block_table = self.block_tables[seq.seq_id]\n            if block_table.blocks is not None:\n                blocks[seq.seq_id] = block_table.blocks\n        combined_blocks = list(chain(*blocks.values()))\n        return combined_blocks\n",
      "diff": "diff --git a/vllm/core/block_manager_v2.py b/vllm/core/block_manager_v2.py\nindex b7d9451f1..7d4919a0d 100644\n--- a/vllm/core/block_manager_v2.py\n+++ b/vllm/core/block_manager_v2.py\n@@ -287,11 +287,11 @@ class BlockSpaceManagerV2(BlockSpaceManager):\n                 seq.seq_id, now)\n \n     def mark_blocks_as_computed(self, seq_group: SequenceGroup):\n-        # The only need for mark block as computed is for prefix caching,\n-        # while currently we could determine whether one block is computed\n-        # or not by check whether it has content hash.\n-        # So this function is useless for block_v2.\n-        pass\n+        # If prefix caching is enabled, mark immutable blocks as computed\n+        # right after they have been scheduled (for prefill). This assumes\n+        # the scheduler is synchronous so blocks are actually computed when\n+        # scheduling the next batch.\n+        self.block_allocator.mark_blocks_as_computed([])\n \n     def get_common_computed_block_ids(\n             self, seqs: List[Sequence]) -> GenericSequence[int]:",
      "change_type": "modified",
      "lines_added": 6,
      "lines_removed": 6
    }
  ],
  "affected_apis": [
    "PrefixCachingBlockAllocator.mark_blocks_as_computed",
    "PrefixCachingBlockAllocator.get_computed_block_ids",
    "BlockSpaceManagerV2.mark_blocks_as_computed"
  ],
  "summary": {
    "total_files": 3,
    "files_added": 0,
    "files_deleted": 0,
    "files_modified": 3
  },
  "csv_metadata": {
    "category": "miscellaneous",
    "json_has_tests": "TRUE",
    "json_has_benchmarks": "FALSE",
    "is_test_actually_there": "Yes (test_prefix_caching_block)",
    "is_benchmark_actually_there": "",
    "sample_clues": "block_manager_v2, blocks, blockspacemanagerv2"
  }
}