{
  "commit_hash": "9c088829ee2a28263f36d0814fde448c6090b5bc",
  "pr_url": "https://github.com/sgl-project/sglang/pull/5786",
  "pr_date": "2025-04-27",
  "timeline_text": "Copy link Contributor merrymercy commented Apr 27, 2025 \u2022 edited Loading Uh oh! There was an error while loading. Please reload this page . Reverts #5728 . It introduces many problems. See the original thread. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . All reactions Revert \"Use device_id in dist init to reduce NCCL communicator warmup\u2026 \u2026 db69a9a \u2026 & creat\u2026\"\n\nThis reverts commit dfb3226 . merrymercy requested review from Ying1123 , hnyls2002 , zhyncs , ispobock and ByronHsu as code owners April 27, 2025 11:02 Hide details View details merrymercy merged commit 9c08882 into main Apr 27, 2025 0 of 6 checks passed Uh oh! There was an error while loading. Please reload this page . merrymercy deleted the revert-5728-dist_init branch April 27, 2025 11:03 pi314ever pushed a commit\n        to pi314ever/sglang\n      that referenced\n      this pull request May 16, 2025 Rebase_4_6_0_post_1 to master_next ( sgl-project#31 ) \u2026 8ef8859 * fix: update pr-test-sgl-kernel ( sgl-project#5399 )\n\n* kernel: support slightly faster merge_state_v2 cuda kernel ( sgl-project#5381 )\n\n* chore: bump sgl-kernel 0.0.9 ( sgl-project#5400 )\n\n* chore: upgrade sgl-kernel 0.0.9 ( sgl-project#5401 )\n\n* Tiny fix DeepseekScalingRotaryEmbedding always use forward_native ( sgl-project#5406 )\n\n* Fix bench_serving with random-ids ( sgl-project#5214 )\n\n* [misc] fix ci flaky case ( sgl-project#5352 )\n\n* [FIX] Fix concatenation error in capture_bs when open --disable-cuda-graph-padding and without MTP ( sgl-project#5412 )\n\n* Support dynamic connection and TP 16 ( sgl-project#5351 )\n\nCo-authored-by: luoyuan.luo <luoyuan.luo@antgroup.com>\n\n* Fix broadcast use cuda device lead to memory capacity unbalanced ( sgl-project#5416 )\n\n* [PD] Fix dynamic port support and MLA buffer for Mooncake ( sgl-project#5415 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\nCo-authored-by: ybyang <ybyang7@iflytek.com>\n\n* Distinguish bootstrap key only in decode server ( sgl-project#5422 )\n\n* [PD] Remove unused bootstrap param and fix port table type ( sgl-project#5423 )\n\n* [minor] cleanup cmakelists.txt ( sgl-project#5420 )\n\n* bugfix: fix merge_state_v2 cuda graph ( sgl-project#5419 )\n\n* chore: bump sgl-kernel v0.0.9.post1 ( sgl-project#5430 )\n\n* fix: solve release issue ( sgl-project#5434 )\n\n* BLackwell cutlass mla: Add check for bad page size/block num combinations ( sgl-project#5431 )\n\n* feat: update model_specific_adjustment ( sgl-project#5344 )\n\nCo-authored-by: hebiao064 <hebiaobuaa@gmail.com>\n\n* chore: upgrade sgl-kernel 0.0.9.post1 ( sgl-project#5436 )\n\n* Fix ignore_eos parameter when loading a chat template ( sgl-project#5264 )\n\n* add attention backend supporting matrix in the doc ( sgl-project#5211 )\n\nCo-authored-by: Stefan He <hebiaobuaa@gmail.com>\n\n* Support BNB quantization for llama/mllama ( sgl-project#5038 )\n\nCo-authored-by: Yuhao Yang <yyh073@foxmail.com>\n\n* [Docs] Update start/install.md ( sgl-project#5398 )\n\n* [Minor] Move torch.compile patch to a better place ( sgl-project#5397 )\n\n* [Bug fix] need record start time in pd mode ( sgl-project#5425 )\n\n* Support MHA with chunked prefix cache for DeepSeek chunked prefill ( sgl-project#5113 )\n\n* chore: bump v0.4.5.post1 ( sgl-project#5445 )\n\n* Fix several minor issues in PD disaggregation ( sgl-project#5444 )\n\n* [doc] Update benchmark_and_profiling.md ( sgl-project#5449 )\n\n* Update cutlass dependency. ( sgl-project#5447 )\n\n* add multi-lora feature in README.md ( sgl-project#5463 )\n\n* Clean up imports ( sgl-project#5467 )\n\n* [verl] Modify the update_weights func to align with verl's resharding ( sgl-project#5345 )\n\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\n\n* [Model Support] unsloth/Phi-4-mini bnb model ( sgl-project#4982 )\n\nCo-authored-by: yhyang201 <yhyang201@gmail.com>\nCo-authored-by: Liangsheng Yin <hnyls2002@gmail.com>\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\nCo-authored-by: Yineng Zhang <me@zhyncs.com>\n\n* Update attention_backend.md: plural form ( sgl-project#5489 )\n\n* Add test for flash_attn_varlen_func kernel ( sgl-project#5484 )\n\n* Deprecate disable-mla ( sgl-project#5481 )\n\n* Deprecate enable-flashinfer-mla and enable-flashmla ( sgl-project#5480 )\n\n* Feat/support encoder model (like bert) ( sgl-project#4887 )\n\n* Enable local attention during decode ( sgl-project#5479 )\n\n* Refactor DeepSeek decoder layer branches ( sgl-project#5205 )\n\n* Fix a link in sgl-kernel/README.md ( sgl-project#5493 )\n\n* [Bug fix] use correct func path in deepseek ( sgl-project#5496 )\n\nSigned-off-by: Xuchun Shang <xuchun.shang@linux.alibaba.com>\n\n* Doc: fix problems of the 'Execute Notebooks / run-all-notebooks' ci caused by the unstability of deepseek-ai/DeepSeek-R1-Distill-Qwen-7B ( sgl-project#5503 )\n\n* [Feat] Update sgl-kernel flashinfer to latest main version ( sgl-project#5500 )\n\nCo-authored-by: zhyncs <me@zhyncs.com>\n\n* Fix: Incorrect parameters passed to forward_batch_generation ( sgl-project#5506 ) ( sgl-project#5511 )\n\n* Fix: fix the exception 'the memory capacity is unbalanced. Some GPUs \u2026 ( sgl-project#5426 )\n\nCo-authored-by: ocss884 <ocss.lin@gmail.com>\n\n* [docs] Fix several consistency issues in sampling_params.md ( sgl-project#5373 )\n\nSigned-off-by: windsonsea <haifeng.yao@daocloud.io>\nCo-authored-by: Baizhou Zhang <sobereddiezhang@gmail.com>\n\n* Configuration qwen2_moe.py - qkv_bias now in transformers ( sgl-project#5512 )\n\n* Introduce moe_dense_tp_size to fix dense layer errors in DeepSeek V3 + 4x8xH100 ( sgl-project#4836 )\n\n* Sgl kernel fused_moe_gate support n_shared_experts ( sgl-project#5440 )\n\n* chore: bump sgl-kernel 0.0.9.post2 ( sgl-project#5518 )\n\n* use sglang_per_token_group_quant_fp8 from sgl-kernel instead of trion kernel ( sgl-project#5473 )\n\nCo-authored-by: Zhang Kaihong <zhangkaihong.zkh@alibaba-inc.com>\n\n* fix kimi vl running bug after rebase main ( sgl-project#5461 )\n\n* fix bug of VLLM_AVAILABLE not defined ( sgl-project#5497 )\n\n* Avoid computing lse in Ragged Prefill when there's no prefix. ( sgl-project#5476 )\n\nCo-authored-by: Baizhou Zhang <sobereddiezhang@gmail.com>\n\n* [Model] Adding Qwen3 and Qwen3MoE ( sgl-project#4693 )\n\n* fix util import ( sgl-project#5542 )\n\n* Revert \"Avoid computing lse in Ragged Prefill when there's no prefix.\u2026 ( sgl-project#5544 )\n\n* chore: upgrade sgl-kernel 0.0.9.post2 ( sgl-project#5540 )\n\n* Fix DeepGEMM masked cannot be run on groups not being multiple or 4 ( sgl-project#5340 )\n\n* Make profiler output file names consistent ( sgl-project#5548 )\n\n* [PD] Tiny fix timeout error when generate ( sgl-project#5545 )\n\n* [PD] Fix no cache connect for recevier ( sgl-project#5534 )\n\n* feat: use flashinfer jit package ( sgl-project#5547 )\n\n* [PD] Remove the requirement of config file for mooncake backend  ( sgl-project#5460 )\n\n* restruct compressed_tensors_w8a8_fp8 ( sgl-project#5475 )\n\n* simplify the control logic for using shared experts fusion ( sgl-project#5504 )\n\n* Remove one kernel in per_tensor_quant_mla_fp8 ( sgl-project#5549 )\n\n* Fix sampler nan check when calling top_k_top_p_sampling_from_probs ( sgl-project#5546 )\n\n* [PD] Support page size > 1 ( sgl-project#5561 )\n\n* fix hicache write back ( sgl-project#5543 )\n\n* Minor update for ROCm variable style ( sgl-project#5562 )\n\n* Fix bench_one_batch producing unnatural results for expert parallel ( sgl-project#5149 )\n\n* [perf] introduce deep gemm group_gemm_masked as bmm ( sgl-project#5432 )\n\n* [PD] Fix DeepSeek cannot be run on latest master ( sgl-project#5568 )\n\n* Fix BumpAllocator error when no input_ids ( sgl-project#5564 )\n\n* enable DeepSeek V3 shared_experts_fusion in sm90 ( sgl-project#5571 )\n\n* [Fix] fix outlines and xgrammar ( sgl-project#4947 )\n\n* [Doc]Add instruction for profiling with bench_one_batch ( sgl-project#5581 )\n\n* Release v0.4.5.post2 ( sgl-project#5582 )\n\n* Fix bench_serving fail when zero warmup requests ( sgl-project#5574 )\n\n* Fix DeepEP cannot run on latest master ( sgl-project#5567 )\n\n* Fix torch memory saver not enabled in DP scenario ( sgl-project#5560 )\n\n* Super tiny fix typo ( sgl-project#5559 )\n\n* Add document for LoRA serving ( sgl-project#5521 )\n\n* Tiny improve error message ( sgl-project#5526 )\n\n* [PD] Fix server crash when using batch requests ( sgl-project#5531 )\n\n* [Feat] upgrade pytorch2.6 ( sgl-project#5417 )\n\n* Fix enable chunked prefill for Llama4 ( sgl-project#5575 )\n\n* fix: use fa3 for gemma2 ( sgl-project#5586 )\n\n* Fix ChatCompletionMessageGenericParam to allow for None content ( sgl-project#5452 )\n\n* [PD] Fix large page size + chunk prefill ( sgl-project#5588 )\n\n* Add test config yamls for Deepseek v3 ( sgl-project#5433 )\n\n* [Feature] Prefill assistant response - add continue_final_message parameter ( sgl-project#4226 )\n\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\n\n* add function call parser for DeepSeek V3 ( sgl-project#5224 )\n\n* smaller and non gated models for docs ( sgl-project#5378 )\n\n* Feat: Implement JSON Mode (response_format.type=\"json_object\") ( sgl-project#4733 )\n\nCo-authored-by: Kyle Pena <kylepena@kyles-macbook-pro.turkey-marlin.ts.net>\n\n* check marlin format before attempting conversion ( sgl-project#4675 )\n\n* compressed_tensors: port w8a16 fp8 from vllm ( sgl-project#4852 )\n\n* Fix one more issue reported by torchfix ( sgl-project#4859 )\n\n* Add sanity check for max_running_requests ( sgl-project#5016 )\n\n* Correct grafana heatmap. ( sgl-project#5019 )\n\n* Perform Batch Tokenization. ( sgl-project#5141 )\n\n* Speedup shared expert weight construction by avoid cloning ( sgl-project#5188 )\n\n* Tiny add Engine.flush_cache API ( sgl-project#5241 )\n\n* [misc] remove is_cuda_available ( sgl-project#5319 )\n\n* Fix flush cache ( sgl-project#5590 )\n\n* Add Speculative Decoding Eagle3 topk > 1 ( sgl-project#5318 )\n\nCo-authored-by: Stefan He <hebiaobuaa@gmail.com>\nCo-authored-by: Yubo Wang <yubowang2019@gmail.com>\n\n* upstream hicache fixes ( sgl-project#5570 )\n\n* Tiny add warning when cannot recognize bool env var ( sgl-project#5348 )\n\n* Modify metrics service endpoint ( sgl-project#3443 )\n\n* Update protocol.py to fix sgl-project#4589 ( sgl-project#4590 )\n\n* [Feat.] Enable grafana to show metrics ( sgl-project#4718 )\n\nCo-authored-by: zhaochenyang20 <zhaochen20@outlook.com>\n\n* [Fix] Enhance DP Attention for IPv6 Compatibility ( sgl-project#4937 )\n\n* Support o1 model on Azure ( sgl-project#4980 )\n\nCo-authored-by: Shan Yu <shanyu1@g.ucla.edu>\n\n* Tiny remove duplicated code ( sgl-project#5021 )\n\n* Tiny update error hint ( sgl-project#5037 )\n\n* Support PD bootstrap fields on /v1/chat/completions endpoint ( sgl-project#5488 )\n\n* [PD] Fix generate endpoint of min_lb for PD ( sgl-project#5598 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\n\n* [PD] Fix edge case and simplify large page size + chunked prefill ( sgl-project#5589 )\n\n* [PD] Add NIXL transfer backend  ( sgl-project#5477 )\n\n* [PD] Support decode overlap schedule ( sgl-project#5608 )\n\n* [PD] Support prefill overlap + Ensure no race condition ( sgl-project#5609 )\n\n* Enhance GPU memory settings ( sgl-project#5604 )\n\n* [feature] enable pre compile jit deep_gemm ( sgl-project#5580 )\n\n* Clean up mem settings ( sgl-project#5610 )\n\n* Support aiter RMSNorm in AMD ( sgl-project#5510 )\n\nCo-authored-by: JieXin Liang <Alcanderian@users.noreply.github.com>\n\n* chore: bump v0.4.5.post3 ( sgl-project#5611 )\n\n* Remove extra copy in deepseek forward absorb ( sgl-project#5578 )\n\nCo-authored-by: saienduri <saimanas.enduri@amd.com>\n\n* [Doc] Fix a 404 link to llama-405b ( sgl-project#5615 )\n\nSigned-off-by: windsonsea <haifeng.yao@daocloud.io>\n\n* [fix] force use deepgemm in compile_deep_gemm ( sgl-project#5618 )\n\n* [fix] fix compile_deep_gemm missing kv_b_proj ( sgl-project#5620 )\n\n* fix: gemma 3 not use softcap ( sgl-project#5622 )\n\n* Fix FA3 DeepSeek prefill performance regression ( sgl-project#5624 )\n\nCo-authored-by: ispobock <ispobaoke@gmail.com>\n\n* [NFC] Remove duplicate `compressed-tensors` ( sgl-project#5640 )\n\n* Fix shared experts fusion error without quantization ( sgl-project#5632 )\n\n* [feature] Add H20 fp8_w8a8 FusedMoE config for --n-share-experts-fusion=16 ( sgl-project#5641 )\n\nCo-authored-by: yuethe <yuethe@tencent.com>\n\n* fix flashmla bug ( sgl-project#5272 )\n\n* [fix] reduce dp capture bs ( sgl-project#5634 )\n\nCo-authored-by: alcanerian <alcanerian@gmail.com>\n\n* Remove q concat in FA3 backend for DeepSeek decode ( sgl-project#5638 )\n\n* Revert \"Support aiter RMSNorm in AMD\" ( sgl-project#5646 )\n\n* fix: update bench_speculative ( sgl-project#5649 )\n\n* Turn on DeepGemm By Default and Update Doc ( sgl-project#5628 )\n\n* Fuse q_a_proj and kv_a_proj ( sgl-project#5619 )\n\n* Remove unnecessary `torch.full` in DeepSeek ( sgl-project#5601 )\n\n* [1/2] Add FP8 Blockscale MoE CUTLASS kernel for Blackwell ( sgl-project#5281 )\n\n* fix sgl-kernel unit tests ( sgl-project#5666 )\n\n* fix awq_dequantize import ( sgl-project#5669 )\n\n* Integrating PD disaggregation with DP attention and DeepEP ( sgl-project#5435 )\n\nCo-authored-by: Byron Hsu <byronhsu1230@gmail.com>\n\n* fix gemma3 unit test ( sgl-project#5670 )\n\n* fix torchvision::nms not exist ( sgl-project#5671 )\n\n* [PD] Add support for dp attention with mooncake ( sgl-project#5530 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\n\n* tune the threshold of gemma-2-27b-it in test_nightly_gsm8k_eval.py ( sgl-project#5677 )\n\n* [Doc] Fix two 404 links caused by sglang typo ( sgl-project#5667 )\n\nSigned-off-by: windsonsea <haifeng.yao@daocloud.io>\n\n* fix: update truss bench_serving ( sgl-project#5683 )\n\n* fix: only compile ApplyTokenBitmaskInplace cu124+ ( sgl-project#5686 )\n\n* chore: bump sgl-kernel 0.1.0 ( sgl-project#5688 )\n\n* vlm: enable radix cache for qwen-vl models ( sgl-project#5349 )\n\nCo-authored-by: Xinyuan Tong <justinning0323@outlook.com>\n\n* [BugFix] Fix combination of MTP and `--n-share-experts-fusion`with R1 ( sgl-project#5707 )\n\n* Fix weight loading bug for Deepseek v3+nextn ( sgl-project#5684 )\n\n* Add example to use sgl engine with fastapi ( sgl-project#5648 )\n\nCo-authored-by: Ravi Theja Desetty <ravitheja@Ravis-MacBook-Pro.local>\n\n* [Doc] Fix a link to Weilin Zhao ( sgl-project#5706 )\n\nSigned-off-by: windsonsea <haifeng.yao@daocloud.io>\n\n* Add MMMU benchmark results ( sgl-project#4491 )\n\nCo-authored-by: Ravi Theja Desetty <ravitheja@Ravis-MacBook-Pro.local>\n\n* [Model] Support `ArcticForCausalLM` architecture (Snowflake/snowflake-arctic-instruct) ( sgl-project#5078 )\n\nCo-authored-by: vincent-4 <vincentzhongy+githubvincent4@gmail.com>\n\n* [PD] Better logs ( sgl-project#5715 )\n\n* [PD] Add kvargs table and thread pool for kvcache sender of mooncake ( sgl-project#5738 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\n\n* [PD]: Support Muti Prefill in one node ( sgl-project#5704 )\n\nCo-authored-by: shuaills <shishuaiuoe@gmail.com>\n\n* Fix: deepseek forward absorb ( sgl-project#5723 )\n\nCo-authored-by: ispobock <ispobaoke@163.com>\n\n* Pin torch audio to 2.6.0 ( sgl-project#5750 )\n\n* Revert \"[Model] Support `ArcticForCausalLM` architecture (Snowflake/snowflake-arctic-instruct)\" ( sgl-project#5754 )\n\n* Disable flaky eagle tests ( sgl-project#5753 )\n\n* update triton 3.2.0 h200 fused moe triton config and add warning about triton fused_moe_kernel performance degradation due to different Triton versions. ( sgl-project#5740 )\n\n* [Docs] Update runtime/engine/readme.md ( sgl-project#5737 )\n\nSigned-off-by: windsonsea <haifeng.yao@daocloud.io>\n\n* Reorder loop in shared expert weight loading ( sgl-project#5719 )\n\n* fix: fix one more bug from merging mm_inputs ( sgl-project#5718 )\n\nCo-authored-by: Xinyuan Tong <justinning0323@outlook.com>\nCo-authored-by: XinyuanTong <115166877+JustinTong0323@users.noreply.github.com>\n\n* [Fix]: support deepseek-vl2-tiny model ( sgl-project#5552 )\n\nCo-authored-by: bppps <zouyu.zzx@alibaba-inc.com>\n\n* Bugfix for minicpmo vision test ( sgl-project#5760 )\n\n* [Minor] fix documentations ( sgl-project#5756 )\n\n* Add an assertion to enhance the robustness of the operator ( sgl-project#5736 )\n\n* fix: import vllm_rotary_embedding error when head_size not in 64, 128, 256, 512 ( sgl-project#5733 )\n\n* Use device_id in dist init to reduce NCCL communicator warmup & creation overhead ( sgl-project#5728 )\n\n* [fix] fix potential bumpy throughtput with deepgemm ( sgl-project#5722 )\n\n* Resolves the `404 Not Found` error when running `compile_deep_gemm.py` in multi-node setups ( sgl-project#5720 )\n\n* perf: update H20 fused_moe_triton kernel config to get higher throughput during prefilling ( sgl-project#5716 )\n\n* we fix the non existent access of `decrypted_config_file` ( sgl-project#5685 )\n\n* CI: rewrite test_vision_chunked_prefill to speedup ( sgl-project#5682 )\n\n* Fuse MLA set kv cache kernel ( sgl-project#5748 )\n\n* Update amd docker image to `sglang:v0.4.5.post3-rocm630`. ( sgl-project#5697 )\n\n* [feature] support for roberta embedding models ( sgl-project#5730 )\n\n* [fix] fix bench_one_batch_server ( sgl-project#5607 )\n\n* support for the DeepSeek model by enabling streaming response parsing ( sgl-project#5592 )\n\n* fix: Use `is not None` instead of `!= None` for None checks. ( sgl-project#5687 )\n\n* Add Llama 4 to FA3 test ( sgl-project#5509 )\n\n* [misc] more decode step log for batch_one_batch ( sgl-project#5565 )\n\n* Handle JSONDecodeError while processing request data ( sgl-project#5599 )\n\n* fix(srt): check if sample_indices is not None before usage. ( sgl-project#5633 )\n\n* update llguidance to 0.7.11; adds StructTag ( sgl-project#4870 )\n\n* Use sgl-kernel sgl_per_token_group_quant_int8 ( sgl-project#4971 )\n\n* Add memory_saver check ( sgl-project#4986 )\n\nSigned-off-by: Kebe <mail@kebe7jun.com>\n\n* add switch to disable open api doc ( sgl-project#3744 )\n\nSigned-off-by: congcongke <zhanweidu@163.com>\n\n* Revert \"fix: import vllm_rotary_embedding error when head_size not in 64, 128, 256, 512\" ( sgl-project#5772 )\n\n* Fix eagle test case ( sgl-project#5776 )\n\n* Split local attention test from fa3 test ( sgl-project#5774 )\n\n* Revert \"Revert \"fix: import vllm_rotary_embedding error when head_size not in 64, 128, 256, 512\"\" ( sgl-project#5777 )\n\n* Simplify FA3 tests ( sgl-project#5779 )\n\n* Revert \"[fix] fix bench_one_batch_server\" ( sgl-project#5785 )\n\n* Revert \"Use device_id in dist init to reduce NCCL communicator warmup & creation overhead\" ( sgl-project#5786 )\n\n* [CI] Tune threshold ( sgl-project#5787 )\n\n* [CI] fix port conflicts ( sgl-project#5789 )\n\n* [CI] Fix ci tests ( sgl-project#5769 )\n\n* [PD]Reduce kv transfer threads ( sgl-project#5791 )\n\n* [CI] Fix test case ( sgl-project#5790 )\n\n* Add 8-GPU Test for Deepseek-V3  ( sgl-project#5691 )\n\nCo-authored-by: Lianmin Zheng <lianminzheng@gmail.com>\n\n* Release v0.4.6 ( sgl-project#5795 )\n\n* Update nightly-test.yml ( sgl-project#5797 )\n\n* [CI] Improve github summary & enable fa3 for more models ( sgl-project#5796 )\n\n* [Docs] update grafana setup guide in production metrics ( sgl-project#5643 )\n\nCo-authored-by: NoahM <88418672+zhudianGG@users.noreply.github.com>\n\n* [Misc] add structure logging, write to file and log tracing for SGL Router\n\n* Improve overlap scheduling ( sgl-project#5788 )\n\n* Add Cutlass MLA attention backend ( sgl-project#5390 )\n\n* chore: upgrade sgl-kernel 0.1.0 ( sgl-project#5690 )\n\n* Dockerfile.dev pip scikit_build_core ( sgl-project#5807 )\n\n* Add a doc to fix sgl-kernel build link error in py39 with ccache ( sgl-project#5809 )\n\n* Turn on overlap scheduler for multimodal models ( sgl-project#5771 )\n\n* Tiny refactor DefaultModelLoader.Source ( sgl-project#5482 )\n\n* [Docs] Replace lists with tables for cleanup and readability in server_arguments ( sgl-project#5276 )\n\n* Revert \"Tiny refactor DefaultModelLoader.Source\" ( sgl-project#5825 )\n\n* Feat: add support for thinking mode via chat_template_kwargs.enable_t\u2026 ( sgl-project#5551 )\n\nCo-authored-by: shuaills <shishuaiuoe@gmail.com>\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\nCo-authored-by: Lianmin Zheng <lianminzheng@gmail.com>\nCo-authored-by: Yineng Zhang <me@zhyncs.com>\n\n* fix: fix the error where the content is None when reasoning and tool \u2026 ( sgl-project#5838 )\n\n* feat: Add fused moe triton config for qwen3 moe on h100 ( sgl-project#5833 )\n\n* fused moe triton tuning script support qwen3 ( sgl-project#5842 )\n\n* feat: Add fused moe triton config for qwen3bf16 moe on h20 ( sgl-project#5839 )\n\n* [PD] support pd fake transfer for warmup ( sgl-project#5726 )\n\n* [config] qwen3moe_tune_h20 fp8 tp4 ( sgl-project#5846 )\n\n* [Doc] Recover history of server_arguments.md ( sgl-project#5851 )\n\n* feat: Add fused moe triton config for qwen3-30b-fp8 moe on h20 ( sgl-project#5850 )\n\n* [CI] test chunked prefill more ( sgl-project#5798 )\n\n* ROCm: update AITER ( sgl-project#5816 )\n\n* [Feat] QWen-1M context support[1/2]: Update block sparse attention backend utils kernel ( sgl-project#5847 )\n\nCo-authored-by: sighingnow <sighingnow@gmail.com>\n\n* [Fix] Missing bootstrap_port field ( sgl-project#5823 )\n\n* feat: update is_fa3_default_architecture ( sgl-project#5854 )\n\n* add fused moe config for qwen3moe fp8/bf16 ( sgl-project#5849 )\n\n* chore: bump v0.4.6.post1 ( sgl-project#5845 )\n\n* fix for hpu backend in model runner and server args\n\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\n\n* rebase formatting issue\n\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\n\n* [SW-228218]: Fix device mismatch in frequency penalty.\n\nEnsure tensors in BatchedFrequencyPenalizer are on the same device by\nmoving output_ids and frequency_penalties to the device of\ncumulated_frequency_penalties. This resolves a RuntimeError\ncaused by tensors on cpu and hpu:0 during logits subtraction.\n\n---------\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\nSigned-off-by: Xuchun Shang <xuchun.shang@linux.alibaba.com>\nSigned-off-by: windsonsea <haifeng.yao@daocloud.io>\nSigned-off-by: Kebe <mail@kebe7jun.com>\nSigned-off-by: congcongke <zhanweidu@163.com>\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\nCo-authored-by: Yineng Zhang <me@zhyncs.com>\nCo-authored-by: DefTruth <31974251+DefTruth@users.noreply.github.com>\nCo-authored-by: fzyzcjy <5236035+fzyzcjy@users.noreply.github.com>\nCo-authored-by: Yuhong Guo <yuhong.gyh@antgroup.com>\nCo-authored-by: JieXin Liang <Alcanderian@users.noreply.github.com>\nCo-authored-by: Zhaoyang Hao <77828610+Muuuchen@users.noreply.github.com>\nCo-authored-by: Yuan Luo <yuan.luo@hotmail.com>\nCo-authored-by: luoyuan.luo <luoyuan.luo@antgroup.com>\nCo-authored-by: lambert0312 <lambert80.ios@gmail.com>\nCo-authored-by: shangmingc <caishangming@linux.alibaba.com>\nCo-authored-by: ybyang <ybyang7@iflytek.com>\nCo-authored-by: Liangsheng Yin <hnyls2002@gmail.com>\nCo-authored-by: Lianmin Zheng <lianminzheng@gmail.com>\nCo-authored-by: Trevor Morris <tmorris@nvidia.com>\nCo-authored-by: hebiao064 <hebiaobuaa@gmail.com>\nCo-authored-by: Chang Su <chang.s.su@oracle.com>\nCo-authored-by: mRSun15 <3150105645@zju.edu.cn>\nCo-authored-by: ryang <38470282+ryang-max@users.noreply.github.com>\nCo-authored-by: Yuhao Yang <yyh073@foxmail.com>\nCo-authored-by: Michael Yao <haifeng.yao@daocloud.io>\nCo-authored-by: ybyang <10629930+whybeyoung@users.noreply.github.com>\nCo-authored-by: Baizhou Zhang <sobereddiezhang@gmail.com>\nCo-authored-by: Cheng Wan <54331508+ch-wan@users.noreply.github.com>\nCo-authored-by: Xiaoyu Zhang <35585791+BBuf@users.noreply.github.com>\nCo-authored-by: Elfie Guo <164945471+elfiegg@users.noreply.github.com>\nCo-authored-by: Ying Sheng <sqy1415@gmail.com>\nCo-authored-by: BearBiscuit <55008898+BearBiscuit05@users.noreply.github.com>\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\nCo-authored-by: eigen <52445717+yyihuang@users.noreply.github.com>\nCo-authored-by: yhyang201 <yhyang201@gmail.com>\nCo-authored-by: Didier Durand <durand.didier@gmail.com>\nCo-authored-by: woodx <124784234+woodx9@users.noreply.github.com>\nCo-authored-by: Xuchun Shang <xuchun.shang@linux.alibaba.com>\nCo-authored-by: mlmz <54172054+minleminzui@users.noreply.github.com>\nCo-authored-by: PGFLMG <1106310035@qq.com>\nCo-authored-by: u4lr451 <u4lr451@gmail.com>\nCo-authored-by: ocss884 <ocss.lin@gmail.com>\nCo-authored-by: Michael Feil <63565275+michaelfeil@users.noreply.github.com>\nCo-authored-by: strgrb <zhangkaihong.zkh@antgroup.com>\nCo-authored-by: Zhang Kaihong <zhangkaihong.zkh@alibaba-inc.com>\nCo-authored-by: liwenju0 <like4hub@gmail.com>\nCo-authored-by: Wenxuan Tan <wtan45@wisc.edu>\nCo-authored-by: yhyang201 <47235274+yhyang201@users.noreply.github.com>\nCo-authored-by: Yubo Wang <yubowang2019@gmail.com>\nCo-authored-by: Byron Hsu <byronhsu1230@gmail.com>\nCo-authored-by: Zhiqiang Xie <xiezhq@stanford.edu>\nCo-authored-by: Zhaoyi Li <36555117+Lzy17@users.noreply.github.com>\nCo-authored-by: lukec <118525388+sleepcoo@users.noreply.github.com>\nCo-authored-by: tarinkk <129432511+tarinkk@users.noreply.github.com>\nCo-authored-by: AmadeusW <41280211+Amadeus-Winarto@users.noreply.github.com>\nCo-authored-by: Adarsh Shirawalmath <114558126+adarshxs@users.noreply.github.com>\nCo-authored-by: Yi Zhou <zhouyi920521@gmail.com>\nCo-authored-by: simveit <69345428+simveit@users.noreply.github.com>\nCo-authored-by: kyle-pena-kuzco <kyle.pena@kuzco.xyz>\nCo-authored-by: Kyle Pena <kylepena@kyles-macbook-pro.turkey-marlin.ts.net>\nCo-authored-by: Enrique Shockwave <33002121+qeternity@users.noreply.github.com>\nCo-authored-by: Juwan Yoo <ryan@tmfi.us>\nCo-authored-by: Brayden Zhong <b8zhong@uwaterloo.ca>\nCo-authored-by: mac0ne <mac0ne@users.noreply.github.com>\nCo-authored-by: Sundara Raman Ramachandran <sundar24295@gmail.com>\nCo-authored-by: Qingquan Song <ustcsqq@gmail.com>\nCo-authored-by: moontidef <53668275+relic-yuexi@users.noreply.github.com>\nCo-authored-by: Huapeng Zhou <73010314+PopSoda2002@users.noreply.github.com>\nCo-authored-by: Lucius <souzou@foxmail.com>\nCo-authored-by: Chuyue Sun <33578456+ChuyueSun@users.noreply.github.com>\nCo-authored-by: Shan Yu <shanyu1@g.ucla.edu>\nCo-authored-by: Yongtong Wu <914554688@qq.com>\nCo-authored-by: michael-amd <Michael.Zhang@amd.com>\nCo-authored-by: Ke Bao <ISPObaoke@163.com>\nCo-authored-by: saienduri <saimanas.enduri@amd.com>\nCo-authored-by: ispobock <ispobaoke@gmail.com>\nCo-authored-by: Connector Switch <c8ef@outlook.com>\nCo-authored-by: saltyfish66 <38240284+saltyfish66@users.noreply.github.com>\nCo-authored-by: yuethe <yuethe@tencent.com>\nCo-authored-by: alcanerian <alcanerian@gmail.com>\nCo-authored-by: HAI <hixiao@gmail.com>\nCo-authored-by: Mick <mickjagger19@icloud.com>\nCo-authored-by: Xinyuan Tong <justinning0323@outlook.com>\nCo-authored-by: Ravi Theja <ravi03071991@gmail.com>\nCo-authored-by: Ravi Theja Desetty <ravitheja@Ravis-MacBook-Pro.local>\nCo-authored-by: vincent-4 <vincentzhongy+githubvincent4@gmail.com>\nCo-authored-by: IAN <50618241+hcyz33@users.noreply.github.com>\nCo-authored-by: shuaills <shishuaiuoe@gmail.com>\nCo-authored-by: XinyuanTong <115166877+JustinTong0323@users.noreply.github.com>\nCo-authored-by: ZXN <44322223+bppps@users.noreply.github.com>\nCo-authored-by: bppps <zouyu.zzx@alibaba-inc.com>\nCo-authored-by: Yi Zhang <1109276519@qq.com>\nCo-authored-by: Kyungmin Lee <30465912+lkm2835@users.noreply.github.com>\nCo-authored-by: vzed <207368749+vincentzed@users.noreply.github.com>\nCo-authored-by: DavidBao <121073073+DavidBao03@users.noreply.github.com>\nCo-authored-by: Frankey_8080 <32973306+Frank-Jie@users.noreply.github.com>\nCo-authored-by: yan97ao <580776+yan97ao@users.noreply.github.com>\nCo-authored-by: aoshen524 <aoshen524@gmail.com>\nCo-authored-by: Micha\u0142 Moskal <michal@moskal.me>\nCo-authored-by: Kebe <mail@kebe7jun.com>\nCo-authored-by: zhanweidu <zhanweidu@163.com>\nCo-authored-by: NoahM <88418672+zhudianGG@users.noreply.github.com>\nCo-authored-by: Simo Lin <linsimo.mark@gmail.com>\nCo-authored-by: JiLi <leege233@gmail.com>\nCo-authored-by: sighingnow <sighingnow@gmail.com>\nCo-authored-by: XTY <xutianyi1999@live.com>\nCo-authored-by: vikram singh shekhawat <vshekhawat@habana.ai> pi314ever pushed a commit\n        to pi314ever/sglang\n      that referenced\n      this pull request May 23, 2025 Rebase 4_6_post_4 to master_next ( sgl-project#47 ) \u2026 bc7d46c * Use device_id in dist init to reduce NCCL communicator warmup & creation overhead ( sgl-project#5728 )\n\n* [fix] fix potential bumpy throughtput with deepgemm ( sgl-project#5722 )\n\n* Resolves the `404 Not Found` error when running `compile_deep_gemm.py` in multi-node setups ( sgl-project#5720 )\n\n* perf: update H20 fused_moe_triton kernel config to get higher throughput during prefilling ( sgl-project#5716 )\n\n* we fix the non existent access of `decrypted_config_file` ( sgl-project#5685 )\n\n* CI: rewrite test_vision_chunked_prefill to speedup ( sgl-project#5682 )\n\n* Fuse MLA set kv cache kernel ( sgl-project#5748 )\n\n* Update amd docker image to `sglang:v0.4.5.post3-rocm630`. ( sgl-project#5697 )\n\n* [feature] support for roberta embedding models ( sgl-project#5730 )\n\n* [fix] fix bench_one_batch_server ( sgl-project#5607 )\n\n* support for the DeepSeek model by enabling streaming response parsing ( sgl-project#5592 )\n\n* fix: Use `is not None` instead of `!= None` for None checks. ( sgl-project#5687 )\n\n* Add Llama 4 to FA3 test ( sgl-project#5509 )\n\n* [misc] more decode step log for batch_one_batch ( sgl-project#5565 )\n\n* Handle JSONDecodeError while processing request data ( sgl-project#5599 )\n\n* fix(srt): check if sample_indices is not None before usage. ( sgl-project#5633 )\n\n* update llguidance to 0.7.11; adds StructTag ( sgl-project#4870 )\n\n* Use sgl-kernel sgl_per_token_group_quant_int8 ( sgl-project#4971 )\n\n* Add memory_saver check ( sgl-project#4986 )\n\nSigned-off-by: Kebe <mail@kebe7jun.com>\n\n* add switch to disable open api doc ( sgl-project#3744 )\n\nSigned-off-by: congcongke <zhanweidu@163.com>\n\n* Revert \"fix: import vllm_rotary_embedding error when head_size not in 64, 128, 256, 512\" ( sgl-project#5772 )\n\n* Fix eagle test case ( sgl-project#5776 )\n\n* Split local attention test from fa3 test ( sgl-project#5774 )\n\n* Revert \"Revert \"fix: import vllm_rotary_embedding error when head_size not in 64, 128, 256, 512\"\" ( sgl-project#5777 )\n\n* Simplify FA3 tests ( sgl-project#5779 )\n\n* Revert \"[fix] fix bench_one_batch_server\" ( sgl-project#5785 )\n\n* Revert \"Use device_id in dist init to reduce NCCL communicator warmup & creation overhead\" ( sgl-project#5786 )\n\n* [CI] Tune threshold ( sgl-project#5787 )\n\n* [CI] fix port conflicts ( sgl-project#5789 )\n\n* [CI] Fix ci tests ( sgl-project#5769 )\n\n* [PD]Reduce kv transfer threads ( sgl-project#5791 )\n\n* [CI] Fix test case ( sgl-project#5790 )\n\n* Add 8-GPU Test for Deepseek-V3  ( sgl-project#5691 )\n\nCo-authored-by: Lianmin Zheng <lianminzheng@gmail.com>\n\n* Release v0.4.6 ( sgl-project#5795 )\n\n* Update nightly-test.yml ( sgl-project#5797 )\n\n* [CI] Improve github summary & enable fa3 for more models ( sgl-project#5796 )\n\n* [Docs] update grafana setup guide in production metrics ( sgl-project#5643 )\n\nCo-authored-by: NoahM <88418672+zhudianGG@users.noreply.github.com>\n\n* [Misc] add structure logging, write to file and log tracing for SGL Router\n\n* Improve overlap scheduling ( sgl-project#5788 )\n\n* Add Cutlass MLA attention backend ( sgl-project#5390 )\n\n* chore: upgrade sgl-kernel 0.1.0 ( sgl-project#5690 )\n\n* Dockerfile.dev pip scikit_build_core ( sgl-project#5807 )\n\n* Add a doc to fix sgl-kernel build link error in py39 with ccache ( sgl-project#5809 )\n\n* Turn on overlap scheduler for multimodal models ( sgl-project#5771 )\n\n* Tiny refactor DefaultModelLoader.Source ( sgl-project#5482 )\n\n* [Docs] Replace lists with tables for cleanup and readability in server_arguments ( sgl-project#5276 )\n\n* Revert \"Tiny refactor DefaultModelLoader.Source\" ( sgl-project#5825 )\n\n* Feat: add support for thinking mode via chat_template_kwargs.enable_t\u2026 ( sgl-project#5551 )\n\nCo-authored-by: shuaills <shishuaiuoe@gmail.com>\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\nCo-authored-by: Lianmin Zheng <lianminzheng@gmail.com>\nCo-authored-by: Yineng Zhang <me@zhyncs.com>\n\n* fix: fix the error where the content is None when reasoning and tool \u2026 ( sgl-project#5838 )\n\n* feat: Add fused moe triton config for qwen3 moe on h100 ( sgl-project#5833 )\n\n* fused moe triton tuning script support qwen3 ( sgl-project#5842 )\n\n* feat: Add fused moe triton config for qwen3bf16 moe on h20 ( sgl-project#5839 )\n\n* [PD] support pd fake transfer for warmup ( sgl-project#5726 )\n\n* [config] qwen3moe_tune_h20 fp8 tp4 ( sgl-project#5846 )\n\n* [Doc] Recover history of server_arguments.md ( sgl-project#5851 )\n\n* feat: Add fused moe triton config for qwen3-30b-fp8 moe on h20 ( sgl-project#5850 )\n\n* [CI] test chunked prefill more ( sgl-project#5798 )\n\n* ROCm: update AITER ( sgl-project#5816 )\n\n* [Feat] QWen-1M context support[1/2]: Update block sparse attention backend utils kernel ( sgl-project#5847 )\n\nCo-authored-by: sighingnow <sighingnow@gmail.com>\n\n* [Fix] Missing bootstrap_port field ( sgl-project#5823 )\n\n* feat: update is_fa3_default_architecture ( sgl-project#5854 )\n\n* add fused moe config for qwen3moe fp8/bf16 ( sgl-project#5849 )\n\n* chore: bump v0.4.6.post1 ( sgl-project#5845 )\n\n* Support `max_completion_tokens` for OpenAIChatCompletions ( sgl-project#5857 )\n\n* simplify fused_moe config logging ( sgl-project#5801 )\n\n* [CI] tune the test order to warmup the server ( sgl-project#5860 )\n\n* Cutlass MLA decode - fix dtype error ( sgl-project#5868 )\n\n* cutlass 3.9 supported to improve fp8_blockwise_gemm ( sgl-project#5820 )\n\n* [Feature] support auto chat template ( sgl-project#4949 )\n\n* Feat: support cuda graph for LoRA ( sgl-project#4115 )\n\nCo-authored-by: Beichen Ma <mabeichen12@gmail.com>\n\n* Add qwen3 30b fused moe config ( sgl-project#5859 )\n\n* [Fix] Fix a bug for flashmla to run R1 model ( sgl-project#5875 )\n\nCo-authored-by: pengcuo <dgpengcuo@gmail.com>\n\n* Add A800 fused moe config for qwen3 30b ( sgl-project#5880 )\n\n* [Misc] add service discovery for sgl router\n\n* [fix]: PyO3 macOS linking and consolidate on tracing for logging\n\n* chore: update Dockerfile ( sgl-project#5894 )\n\n* [Docs] Update docs for Qwen3 and Qwen3MoE ( sgl-project#5836 )\n\n* [Doc] Tables instead of bulletpoints for sampling doc ( sgl-project#5841 )\n\n* chore: update CODEOWNERS ( sgl-project#5895 )\n\n* [FEATURE] Enhance platform compatibility for ARM ( sgl-project#5746 )\n\n* [CI] Add test_function_calling.py to run_suite.py ( sgl-project#5896 )\n\n* Auto set draft model path for MTP ( sgl-project#5793 )\n\n* [fix] relax mem_fraction_static for h200 ( sgl-project#5893 )\n\nCo-authored-by: alcanerian <alcanerian@gmail.com>\n\n* feat: support pythonic tool call and index in tool call streaming ( sgl-project#5725 )\n\n* [Bugfix]: fix missing queue_time_start for requests from grammar_queue ( sgl-project#5696 )\n\n* Add AMD MI300x Nightly Testing. ( sgl-project#5861 )\n\n* chore: use torch 2.6 for sgl-kernel build ( sgl-project#5898 )\n\n* Fix check_env script ( sgl-project#5901 )\n\n* [PD] Fix Assertion failed: /DeepEP/csrc/kernels/internode.cu:483, condition: ibgda_get_state()->num_rc_per_pe >= num_channels sgl-project#134 ( sgl-project#5830 )\n\n* Bump Flashinfer to 0.2.5 ( sgl-project#5870 )\n\nCo-authored-by: Yuhao Chen <yxckeis8@gmail.com>\n\n* [Fix] Unload lora in HF_Runner if needed ( sgl-project#5899 )\n\n* Add A800 fused moe config for qwen3 235b ( sgl-project#5900 )\n\n* Add sm_120 for blackwell ( sgl-project#5903 )\n\n* [Feature] add support kimi vl model ( sgl-project#5383 )\n\nCo-authored-by: wenju.li <wenju.li@deepctr.cn>\n\n* support vlm benchmark profile ( sgl-project#5905 )\n\n* [fix] kimi-vl test in test_vision_openai_server.py ( sgl-project#5910 )\n\n* [Misc] use parallel build for cmake in sgl-kernel ( sgl-project#5919 )\n\n* [qwen3] support qwen3 ep moe ( sgl-project#5917 )\n\nCo-authored-by: sleepcoo <sleepcoo@gmail.com>\n\n* Add TP2 MOE benchmarks for AMD. ( sgl-project#5909 )\n\n* [Feat] Scale up fa3 kernel to sm8x arch ( sgl-project#5912 )\n\nCo-authored-by: zhyncs <me@zhyncs.com>\n\n* chore: bump sgl-kernel 0.1.1 ( sgl-project#5932 )\n\n* chore: upgrade sgl-kernel 0.1.1 ( sgl-project#5933 )\n\n* Remove unused method `calculate_num_image_tokens` from qwen2_vl.py ( sgl-project#5783 )\n\n* [PP] Add pipeline parallelism ( sgl-project#5724 )\n\n* Fix lora batch processing when input lora_path contains None ( sgl-project#5930 )\n\n* add Thor & Spark ( sgl-project#5915 )\n\n* fix: correct stream response when enable_thinking is set to false ( sgl-project#5881 )\n\n* fix: update model runner ( sgl-project#5934 )\n\n* chore: bump v0.4.6.post2 ( sgl-project#5939 )\n\n* Support XiaomiMiMo/MiMo model inference ( sgl-project#5921 )\n\n* [PD] Vectorise group_concurrent_contiguous in NumPy ( sgl-project#5834 )\n\nCo-authored-by: luoyuan.luo <luoyuan.luo@antgroup.com>\n\n* Remove extra contiguous ( sgl-project#5953 )\n\n* Update ci test and doc for MTP api change ( sgl-project#5952 )\n\n* docs: Fix Qwen model typo ( sgl-project#5944 )\n\nSigned-off-by: JiangJiaWei1103 <waynechuang97@gmail.com>\n\n* Optimize a pad operation to accelerate 25us ( sgl-project#5945 )\n\n* Properly return error response in vertex_generate HTTP endpoint ( sgl-project#5956 )\n\n* feat: add concurrency evaluation logic in mmmu benchmark ( sgl-project#5782 )\n\n* Add 1 gpu perf and 2 gpu accuracy tests for AMD MI300x CI. ( sgl-project#5960 )\n\n* feat: Refactor DeepSeekV3 function call ( sgl-project#5908 )\n\n* Remove token in token out in Native API ( sgl-project#5967 )\n\n* Support InternVL3 ( sgl-project#5350 )\n\nCo-authored-by: Mick <mickjagger19@icloud.com>\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\n\n* Support MMMU benchmark for  InternVL ( sgl-project#5968 )\n\n* FA3 speed up: skip len operation and get batch size directly from forward batch ( sgl-project#5969 )\n\nSigned-off-by: Lifu Huang <lifu.hlf@gmail.com>\n\n* [PD] NIXL backend Prefill TP & Decode TP+DP ( sgl-project#5681 )\n\n* Fix set kv cache multi-stream ( sgl-project#5975 )\n\n* Overlap qk norm with two streams ( sgl-project#5977 )\n\n* fix: only upgrade nccl for cu128 ( sgl-project#5986 )\n\n* Fix Phi3 serving which was broke by earlier change ( sgl-project#5991 )\n\nCo-authored-by: Lifu Huang <lifu.hlf@gmail.com>\n\n* [perf] H100 DeepSeek-V3 fused moe tuned config ( sgl-project#5998 )\n\n* [Fix] Suppress dynamo logging when using flashinfer backend with torch compile ( sgl-project#5992 )\n\n* [Minor] Fix duplicate method definitions in conversation.py ( sgl-project#6012 )\n\nSigned-off-by: Lifu Huang <lifu.hlf@gmail.com>\n\n* Fix flaky issues of lora and add multi batch tests ( sgl-project#5957 )\n\n* Tool Call: Add `chat_template_kwargs` documentation ( sgl-project#5679 )\n\n* fix: fix broadcast_pyobj breaking VerlEngine ( sgl-project#5997 )\n\n* [PD] Allow customizing reserved tokens to avoid KV cache waste ( sgl-project#6002 )\n\n* Update dev container config to support live code sync and improve docker setup guide   ( sgl-project#6018 )\n\nSigned-off-by: Lifu Huang <lifu.hlf@gmail.com>\n\n* [PD] Optimize disaggregation ib device help info ( sgl-project#5781 )\n\n* [Test] Add flashmla attention backend test ( sgl-project#5587 )\n\n* Fix \"Avoid computing lse in Ragged Prefill when there's no prefix match\" ( sgl-project#5555 )\n\n* feat: Add a unified merge_state API ( sgl-project#5428 )\n\n* feat: append more comprehensive fields in messages instead of merely role and content ( sgl-project#5996 )\n\n* [Security][Bug] Prevent binding to all TCP interfaces ( sgl-project#5752 )\n\n* Fix prefill OOM error in the case of large page size ( sgl-project#5081 )\n\n* Fix problem of large page size with chunked prefill ( sgl-project#6046 )\n\n* docs: add Google Cloud Vertex AI in Adoption and Sponsorship ( sgl-project#6047 )\n\n* docs: add new blog ( sgl-project#6048 )\n\n* Fix not \"import os\" ( sgl-project#6057 )\n\n* Better PD initialization ( sgl-project#5751 )\n\n* fix: deepep dockerfile, use pip install deepep. ( sgl-project#5885 )\n\n* [Fix] Fix and rename flashmla CI test ( sgl-project#6045 )\n\n* chore: upgrade cutlass 3.9.2 ( sgl-project#6004 )\n\nCo-authored-by: yizhang2077 <1109276519@qq.com>\n\n* Fix sgl-kernel build on aarch64 platforms ( sgl-project#6062 )\n\n* Add DeepEP to CI PR Test ( sgl-project#5655 )\n\nCo-authored-by: Jinyan Chen <jinyanc@nvidia.com>\n\n* fix custom_allreduce namespace ( sgl-project#6039 )\n\n* feat: add release workflow for SGLang kernels on aarch64 ( sgl-project#6010 )\n\nCo-authored-by: Qiaolin-Yu <liin1211@outlook.com>\nCo-authored-by: Yineng Zhang <me@zhyncs.com>\n\n* [Feature] Support for Ascend NPU backend ( sgl-project#3853 )\n\nSigned-off-by: Song Zhang <gepin.zs@antgroup.com>\nCo-authored-by: 22dimensions <waitingwind@foxmail.com>\n\n* Fix the timeout for 8 gpu tests ( sgl-project#6084 )\n\n* Hint users DeepEP normal mode is incompatible with CUDA Graph ( sgl-project#5014 )\n\n* Super tiny fix doc ( sgl-project#5233 )\n\n* [Doc]Fix description for dp_size argument ( sgl-project#6063 )\n\n* feat(engine): add bootstrap parameters to generate methods (dynamo) ( sgl-project#6075 )\n\n* [refactor] slightly tidy fp8 module ( sgl-project#5993 )\n\n* Clean up fa3 test from 8 gpus ( sgl-project#6105 )\n\n* Deferring 8 GPU test ( sgl-project#6102 )\n\n* Update doc for MLA attention backends ( sgl-project#6034 )\n\n* Clean logs for DeepSeek-V3 launching ( sgl-project#6079 )\n\n* [CI]Add performance CI for VLM ( sgl-project#6038 )\n\nSigned-off-by: Xinyuan Tong <justinning0323@outlook.com>\n\n* adding Triton configs for DeepSeekV3 FusedMoE kernel on Blackwell ( sgl-project#6111 )\n\n* optimize pad operations in fa3 to accelarate 100+us ( sgl-project#6077 )\n\n* Overlap shared expert and routed expert computations ( sgl-project#5121 )\n\n* Tiny refactor ModelConfig.from_server_args ( sgl-project#5219 )\n\n* Tiny refactor weight loading logic ( sgl-project#5232 )\n\n* [PD] Add control to slow down a server ( sgl-project#5572 )\n\n* Change AMD test threshold ( sgl-project#6091 )\n\n* DeepEP normal support deepgemm-contiguous ( sgl-project#5626 )\n\nCo-authored-by: Yingyi Huang <yingyihuang2000@outlook.com>\nCo-authored-by: Cheng Wan <54331508+ch-wan@users.noreply.github.com>\nCo-authored-by: Xuting Zhou <xutingz@nvidia.com>\nCo-authored-by: ZhengHSI <zhenghsi@qq.com>\n\n* [fix] fix pyproject.toml dependencies ( sgl-project#6119 )\n\n* [Feature] Add FlashAttention3 as a backend for VisionAttention ( sgl-project#5764 )\n\nCo-authored-by: othame <chenzhu_912@zju.edu.cn>\nCo-authored-by: Mick <mickjagger19@icloud.com>\nCo-authored-by: Yi Zhang <1109276519@qq.com>\n\n* [perf] dsv3 bmm fallback to bf16 ( sgl-project#5662 )\n\n* [AMD] switch to custom allreduce regardless of MSCCL setting on ROCm ( sgl-project#6097 )\n\n* [sgl-kernel] fix: fix cu118 compile error ( sgl-project#6123 )\n\nCo-authored-by: zhyncs <me@zhyncs.com>\n\n* upgrade xgrammar to 0.1.19 ( sgl-project#6129 )\n\n* Remove unecessary is_fa3_supported check ( sgl-project#6112 )\n\n* chore: bump sgl-kernel 0.1.2 ( sgl-project#6131 )\n\n* docs: update README ( sgl-project#6132 )\n\n* [Fix] Incorrect Memory Allocation on CUDA:0 by Non-Zero CUDA Processes in TP/DP ( sgl-project#5745 )\n\n* Cutlass MLA: Disable split kv due to NVIDIA/cutlass#2274 ( sgl-project#6101 )\n\n* opt flashinfer mla cat ( sgl-project#5822 )\n\nCo-authored-by: xuyongfei.xyf <xuyongfei.xyf@antgroup.com>\n\n* Update amd nightly concurrency. ( sgl-project#6141 )\n\n* feat: add thinking_budget ( sgl-project#6089 )\n\n* [Bugfix] Fix Llama4 gibberish output with long context and CUDA graph ( sgl-project#6162 )\n\n* fix bug that gpu0 occupies more memory when hicache is turned on ( sgl-project#5778 )\n\nCo-authored-by: Zhiqiang Xie <xiezhq@stanford.edu>\n\n* chore: bump v0.4.6.post3 ( sgl-project#6165 )\n\n* KV\u2011Cache\u202f(MHA, MLA): add missing start_layer\u202f/\u202fend_layer fields to MHATokenToKVPoolHost and MLATokenToKVPoolHost ( sgl-project#6016 )\n\nCo-authored-by: \u7ee7\u4f18 <jiyou.ljy@alibaba-inc.com>\nCo-authored-by: chus-chus <chus-chus@users.noreply.github.com>\nCo-authored-by: Zhiqiang Xie <xiezhq@stanford.edu>\n\n* [fix] fix determine_n_share_experts_fusion ( sgl-project#6118 )\n\n* Fix and Clean up chat-template requirement for VLM ( sgl-project#6114 )\n\nSigned-off-by: Xinyuan Tong <justinning0323@outlook.com>\n\n* [Docs]Delete duplicate content ( sgl-project#6146 )\n\nCo-authored-by: ximing.wxm <ximing.wxm@antgroup.com>\n\n* Revert \"feat: add thinking_budget ( sgl-project#6089 )\" ( sgl-project#6181 )\n\n* Added async_encode method to Engine ( sgl-project#4701 )\n\n* Fix data parallel perf regression ( sgl-project#6183 )\n\n* Fix request abortion ( sgl-project#6184 )\n\n* Add typo checker in pre-commit ( sgl-project#6179 )\n\nCo-authored-by: Brayden Zhong <b8zhong@uwaterloo.ca>\n\n* Remove duplicate IO Struct test ( sgl-project#6180 )\n\nSigned-off-by: Emmanuel Ferdman <emmanuelferdman@gmail.com>\n\n* [PD] Add simple unit test for disaggregation feature ( sgl-project#5654 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\n\n* [CI] Disabled deepep tests temporarily because it takes too much time. ( sgl-project#6186 )\n\n* feat: support loogle eval ( sgl-project#6190 )\n\n* [fix] remove mixtral from is_fa3_default_architecture ( sgl-project#6191 )\n\n* fix: handle None multimodal_inputs during merging and filtering batches in disaggregation decode mode ( sgl-project#6169 )\n\n* chore: upgrade deepgemm ( sgl-project#6073 )\n\n* chore: bump sgl-kernel v0.1.2.post1 ( sgl-project#6195 )\n\n* chore: upgrade sgl-kernel v0.1.2.post1 ( sgl-project#6196 )\n\nCo-authored-by: alcanderian <alcanderian@gmail.com>\n\n* Handle empty input string for embedding models ( sgl-project#5621 )\n\nCo-authored-by: Ravi Theja Desetty <ravitheja@Ravis-MacBook-Pro.local>\n\n* doc: fix the erroneous documents and example codes about Alibaba-NLP/gme-Qwen2-VL-2B-Instruct ( sgl-project#6199 )\n\n* [Docs] minor Qwen3 and reasoning parser docs fix ( sgl-project#6032 )\n\n* Improve structured outputs: fix race condition, server crash, metrics and style ( sgl-project#6188 )\n\n* [CI] Reorganize the 8 gpu tests ( sgl-project#6192 )\n\n* Add dev-deepep docker image ( sgl-project#6198 )\n\n* Replace time.time() to time.perf_counter() for benchmarking. ( sgl-project#6178 )\n\nSigned-off-by: Lifu Huang <lifu.hlf@gmail.com>\n\n* Update README.md ( sgl-project#6202 )\n\n* Fix release-docs.yml to not use python 3.9 ( sgl-project#6204 )\n\n* Fix start_profile does not support with_stack and record_shapes ( sgl-project#6043 )\n\n* [doc] add a note for --n-share-experts-fusion args ( sgl-project#6154 )\n\n* Performing Vocabulary Parallelism for LM Head across Attention TP Groups ( sgl-project#5558 )\n\nCo-authored-by: liusy58 <liusy58@linux.alibaba.com>\n\n* Update AMD CI docker to v0.4.6.post3-rocm630. ( sgl-project#6213 )\n\n* Log if cuda graph is used & extend cuda graph capture to cuda-graph-max-bs ( sgl-project#6201 )\n\nCo-authored-by: SangBin Cho <rkooo567@gmail.com>\n\n* [CI] Fix PD mooncake dependency error ( sgl-project#6212 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\n\n* [CI] Re-enable pd disaggregation test ( sgl-project#6231 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\n\n* fix some typos ( sgl-project#6209 )\n\nCo-authored-by: Brayden Zhong <b8zhong@uwaterloo.ca>\n\n* [Docs] Add docs for `SGLANG_` and `SGL_` environment variables ( sgl-project#6206 )\n\n* [PP] Fix init_memory_pool desync & add PP for mixtral ( sgl-project#6223 )\n\n* Revert \"fix some typos\" ( sgl-project#6244 )\n\n* chore: add hf_xet dep ( sgl-project#6243 )\n\n* Update AMD nightly deps. ( sgl-project#6241 )\n\n* [PD] Add support for different TP sizes per DP rank ( sgl-project#5922 )\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\n\n* Support incremental streaming of logprob/token_ids between scheduler and detokenizer ( sgl-project#6225 )\n\nCo-authored-by: SangBin Cho <rkooo567@gmail.com>\n\n* fix typo ( sgl-project#6248 )\n\n* Support tuning moe for llama 4 model ( sgl-project#6042 )\n\n* Skip the flaky test_stateful_custom_logit_processor ( sgl-project#6251 )\n\n* [Llama4] Add docs note about enable multimodal ( sgl-project#6235 )\n\n* [VERL Use Case] Add torch_memory_saver into deps ( sgl-project#6247 )\n\n* Fix two issues related to `--moe-dense-tp-size=1` ( sgl-project#5657 )\n\nCo-authored-by: liusy58 <liusy58@linux.alibaba.com>\nCo-authored-by: \u9889\u6c86 <xiehang.lsy@alibaba-inc.com>\n\n* model(vlm): pixtral ( sgl-project#5084 )\n\n* [misc] deep_gemm fallback to NVRTC when NVCC not found ( sgl-project#6252 )\n\n* Enable MI325X AMD CI. ( sgl-project#6259 )\n\n* chore: bump v0.4.6.post4 ( sgl-project#6245 )\n\n* formatting fix for the rebased commit for 4.6.0_post4\n\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\n\n* fix issues in model runner and python packages\n\nfix for following issues:\n> vLLM dependency for xgrammar==0.1.17\n> 'Scheduler' object has no attribute 'device\n> 'pp_proxy_tensors' unexpected arg in HPUGraphRunner\n> TODO: Add pipeline parallelism support in HPUGraphRunner\n\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\n\n* fix formatting in model runner\n\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\n\n* base grammar fix for the is_terminated case\n\n>  'OutlinesGrammar' object has no attribute 'is_terminated'\n\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\n\n---------\n\nSigned-off-by: Kebe <mail@kebe7jun.com>\nSigned-off-by: congcongke <zhanweidu@163.com>\nSigned-off-by: JiangJiaWei1103 <waynechuang97@gmail.com>\nSigned-off-by: Lifu Huang <lifu.hlf@gmail.com>\nSigned-off-by: Song Zhang <gepin.zs@antgroup.com>\nSigned-off-by: Xinyuan Tong <justinning0323@outlook.com>\nSigned-off-by: Emmanuel Ferdman <emmanuelferdman@gmail.com>\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\nSigned-off-by: Mohit Sinha <msinha@habana.ai>\nCo-authored-by: Wenxuan Tan <wtan45@wisc.edu>\nCo-authored-by: JieXin Liang <Alcanderian@users.noreply.github.com>\nCo-authored-by: Yuhong Guo <yuhong.gyh@antgroup.com>\nCo-authored-by: saltyfish66 <38240284+saltyfish66@users.noreply.github.com>\nCo-authored-by: vzed <207368749+vincentzed@users.noreply.github.com>\nCo-authored-by: Mick <mickjagger19@icloud.com>\nCo-authored-by: Ke Bao <ISPObaoke@163.com>\nCo-authored-by: saienduri <saimanas.enduri@amd.com>\nCo-authored-by: DavidBao <121073073+DavidBao03@users.noreply.github.com>\nCo-authored-by: Frankey_8080 <32973306+Frank-Jie@users.noreply.github.com>\nCo-authored-by: Stefan He <hebiaobuaa@gmail.com>\nCo-authored-by: yan97ao <580776+yan97ao@users.noreply.github.com>\nCo-authored-by: aoshen524 <aoshen524@gmail.com>\nCo-authored-by: Micha\u0142 Moskal <michal@moskal.me>\nCo-authored-by: lambert0312 <lambert80.ios@gmail.com>\nCo-authored-by: Kebe <mail@kebe7jun.com>\nCo-authored-by: zhanweidu <zhanweidu@163.com>\nCo-authored-by: Lianmin Zheng <lianminzheng@gmail.com>\nCo-authored-by: Baizhou Zhang <sobereddiezhang@gmail.com>\nCo-authored-by: Liangsheng Yin <hnyls2002@gmail.com>\nCo-authored-by: Huapeng Zhou <73010314+PopSoda2002@users.noreply.github.com>\nCo-authored-by: NoahM <88418672+zhudianGG@users.noreply.github.com>\nCo-authored-by: Simo Lin <linsimo.mark@gmail.com>\nCo-authored-by: Trevor Morris <tmorris@nvidia.com>\nCo-authored-by: Yineng Zhang <me@zhyncs.com>\nCo-authored-by: Xiaoyu Zhang <35585791+BBuf@users.noreply.github.com>\nCo-authored-by: fzyzcjy <5236035+fzyzcjy@users.noreply.github.com>\nCo-authored-by: Michael Yao <haifeng.yao@daocloud.io>\nCo-authored-by: mlmz <54172054+minleminzui@users.noreply.github.com>\nCo-authored-by: shuaills <shishuaiuoe@gmail.com>\nCo-authored-by: Chayenne <zhaochen20@outlook.com>\nCo-authored-by: XinyuanTong <115166877+JustinTong0323@users.noreply.github.com>\nCo-authored-by: yhyang201 <47235274+yhyang201@users.noreply.github.com>\nCo-authored-by: ybyang <10629930+whybeyoung@users.noreply.github.com>\nCo-authored-by: JiLi <leege233@gmail.com>\nCo-authored-by: HAI <hixiao@gmail.com>\nCo-authored-by: PGFLMG <1106310035@qq.com>\nCo-authored-by: sighingnow <sighingnow@gmail.com>\nCo-authored-by: XTY <xutianyi1999@live.com>\nCo-authored-by: Yi Zhang <1109276519@qq.com>\nCo-authored-by: Chang Su <chang.s.su@oracle.com>\nCo-authored-by: woodx <124784234+woodx9@users.noreply.github.com>\nCo-authored-by: Qiaolin Yu <qy254@cornell.edu>\nCo-authored-by: Beichen Ma <mabeichen12@gmail.com>\nCo-authored-by: pengcuo <pengcbupt@163.com>\nCo-authored-by: pengcuo <dgpengcuo@gmail.com>\nCo-authored-by: Adarsh Shirawalmath <114558126+adarshxs@users.noreply.github.com>\nCo-authored-by: simveit <69345428+simveit@users.noreply.github.com>\nCo-authored-by: Johnny <johnnync13@gmail.com>\nCo-authored-by: alcanerian <alcanerian@gmail.com>\nCo-authored-by: Yuhao Chen <yxckeis8@gmail.com>\nCo-authored-by: zhjunqin <zhjunqin@users.noreply.github.com>\nCo-authored-by: liwenju0 <like4hub@gmail.com>\nCo-authored-by: wenju.li <wenju.li@deepctr.cn>\nCo-authored-by: laixin <xielx@shanghaitech.edu.cn>\nCo-authored-by: sleepcoo <sleepcoo@gmail.com>\nCo-authored-by: Ying Sheng <sqy1415@gmail.com>\nCo-authored-by: ryang <38470282+ryang-max@users.noreply.github.com>\nCo-authored-by: Yuan Luo <yuan.luo@hotmail.com>\nCo-authored-by: luoyuan.luo <luoyuan.luo@antgroup.com>\nCo-authored-by: \u6c5f\u5bb6\u744b <36886416+JiangJiaWei1103@users.noreply.github.com>\nCo-authored-by: KCFindstr <shimakaze@google.com>\nCo-authored-by: xm:D <38322020+xiaomin-D@users.noreply.github.com>\nCo-authored-by: Lifu Huang <lifu.hlf@gmail.com>\nCo-authored-by: Yongtong Wu <914554688@qq.com>\nCo-authored-by: Junrong Lin <33685709+ocss884@users.noreply.github.com>\nCo-authored-by: shangmingc <caishangming@linux.alibaba.com>\nCo-authored-by: DefTruth <31974251+DefTruth@users.noreply.github.com>\nCo-authored-by: Zhiqiang Xie <xiezhq@stanford.edu>\nCo-authored-by: Hank Han <54751605+HanHan009527@users.noreply.github.com>\nCo-authored-by: Qiaolin Yu <liin1211@outlook.com>\nCo-authored-by: Jinyan Chen <93358689+liz-badada@users.noreply.github.com>\nCo-authored-by: Jinyan Chen <jinyanc@nvidia.com>\nCo-authored-by: Johnny <johnnynuca14@gmail.com>\nCo-authored-by: Song Zhang <70674731+botieking98@users.noreply.github.com>\nCo-authored-by: 22dimensions <waitingwind@foxmail.com>\nCo-authored-by: ishandhanani <82981111+ishandhanani@users.noreply.github.com>\nCo-authored-by: Cheng Wan <54331508+ch-wan@users.noreply.github.com>\nCo-authored-by: Minglei Zhu <mingleizhu1122@gmail.com>\nCo-authored-by: lukec <118525388+sleepcoo@users.noreply.github.com>\nCo-authored-by: Yingyi Huang <yingyihuang2000@outlook.com>\nCo-authored-by: Xuting Zhou <xutingz@nvidia.com>\nCo-authored-by: ZhengHSI <zhenghsi@qq.com>\nCo-authored-by: Zhu Chen <51010608+Othame@users.noreply.github.com>\nCo-authored-by: othame <chenzhu_912@zju.edu.cn>\nCo-authored-by: Hubert Lu <55214931+hubertlu-tw@users.noreply.github.com>\nCo-authored-by: Yixin Dong <ubospica@gmail.com>\nCo-authored-by: xu-yfei <xu_yfei@qq.com>\nCo-authored-by: xuyongfei.xyf <xuyongfei.xyf@antgroup.com>\nCo-authored-by: thyecust <tienhoayu@gmail.com>\nCo-authored-by: huangtingwei <141888744+huangtingwei9988@users.noreply.github.com>\nCo-authored-by: Simon (Jiyou) Li <Simon-Li@users.noreply.github.com>\nCo-authored-by: \u7ee7\u4f18 <jiyou.ljy@alibaba-inc.com>\nCo-authored-by: chus-chus <chus-chus@users.noreply.github.com>\nCo-authored-by: Ximingwang-09 <72070413+Ximingwang-09@users.noreply.github.com>\nCo-authored-by: ximing.wxm <ximing.wxm@antgroup.com>\nCo-authored-by: Steven Shimizu <shimizust@gmail.com>\nCo-authored-by: applesaucethebun <113181361+applesaucethebun@users.noreply.github.com>\nCo-authored-by: Brayden Zhong <b8zhong@uwaterloo.ca>\nCo-authored-by: Emmanuel Ferdman <emmanuelferdman@gmail.com>\nCo-authored-by: Yusong Gao <yusong.gao@gmail.com>\nCo-authored-by: alcanderian <alcanderian@gmail.com>\nCo-authored-by: Ravi Theja <ravi03071991@gmail.com>\nCo-authored-by: Ravi Theja Desetty <ravitheja@Ravis-MacBook-Pro.local>\nCo-authored-by: liusy58 <liusy58@linux.alibaba.com>\nCo-authored-by: SangBin Cho <rkooo567@gmail.com>\nCo-authored-by: \u9889\u6c86 <xiehang.lsy@alibaba-inc.com>\nCo-authored-by: Kiv Chen <34561254+KivenChen@users.noreply.github.com> Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-11 18:58:21",
  "has_lm_eval": false,
  "has_performance": true,
  "has_serving": true,
  "has_general_test": true,
  "test_details": "PERF | SERVING | TEST",
  "analysis_extracted_at": null,
  "models": [
    "N/A"
  ],
  "lm_eval_commands": null,
  "perf_command": null,
  "commit_subject": "Revert \"Use device_id in dist init to reduce NCCL communicator warmup & creation overhead\" (#5786)",
  "commit_message": "Revert \"Use device_id in dist init to reduce NCCL communicator warmup & creation overhead\" (#5786)",
  "commit_date": "2025-04-27T04:03:02-07:00",
  "files_changed": [
    "python/sglang/srt/distributed/parallel_state.py"
  ],
  "functions_changed": [],
  "stats": {
    "commit_year": 2025,
    "num_edited_lines": 5,
    "num_files": 1,
    "num_hunks": 1,
    "num_non_test_edited_lines": 5,
    "num_non_test_files": 1,
    "num_test_files": 0,
    "only_non_test_files": 1,
    "only_test_files": 0
  },
  "diff_text": "diff --git a/python/sglang/srt/distributed/parallel_state.py b/python/sglang/srt/distributed/parallel_state.py\nindex fdde7dde8..e43bc0000 100644\n--- a/python/sglang/srt/distributed/parallel_state.py\n+++ b/python/sglang/srt/distributed/parallel_state.py\n@@ -1055,11 +1055,6 @@ def init_distributed_environment(\n             world_size=world_size,\n             rank=rank,\n             timeout=timeout,\n-            device_id=torch.device(\n-                f\"cuda:{torch.cuda.current_device()}\"\n-                if hasattr(torch, \"cuda\") and torch.cuda.is_available()\n-                else None\n-            ),  # Allow NCCL to eagerly init communicator\n         )\n \n     # set the local rank",
  "apis": [
    "None"
  ],
  "affected_paths": [],
  "repo_path": "/path/to/repos/sglang",
  "llm_reason": "This commit reverts a previous change that was specifically intended to reduce NCCL communicator warmup and creation overhead, which is a performance-related optimization. It modifies a non-test file (the distributed module) and impacts the performance behavior of high-level distributed initialization. Although it is undoing an optimization rather than adding one, the change is clearly performance-related.",
  "llm_api_reason": "The commit reverts a previous change in the internal function 'init_distributed_environment' within the 'sglang/srt/distributed/parallel_state.py' file. This change pertains to how the device_id is set for distributed initialization and does not affect any of the public, high-level SGLang APIs listed (e.g., sglang.srt.server.Server or sglang.api.gen). Thus, no top-level Python API is impacted by this revert."
}