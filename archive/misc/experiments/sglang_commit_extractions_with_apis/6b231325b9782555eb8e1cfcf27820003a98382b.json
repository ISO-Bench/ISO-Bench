{
  "commit_hash": "6b231325b9782555eb8e1cfcf27820003a98382b",
  "pr_url": "https://github.com/sgl-project/sglang/pull/6649",
  "pr_date": "2025-05-28",
  "timeline_text": "Copy link Collaborator whybeyoung commented May 27, 2025 \u2022 edited Loading Uh oh! There was an error while loading. Please reload this page . The original while True queue polling implementation caused some CPU overhead under high concurrency. To minimize CPU usage, a more efficient approach using a deque combined with a Condition mechanism was adopted. -            while True:\n-                try:\n-                    kv_chunk: TransferKVChunk = self.transfer_queue.get(timeout=0.01)\n-                    reqs_to_be_processed = (\n-                        self.transfer_infos[kv_chunk.room].values()\n-                        if kv_chunk.room in self.transfer_infos See the commit .. CC @ByronHsu @ShangmingCai @zhyncs @fzyzcjy Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . \ud83d\udc4d 2 zhyncs and yuan-luo reacted with thumbs up emoji All reactions \ud83d\udc4d 2 reactions [PD Perf] replace Queue to FastQueue 2fa21ff whybeyoung requested review from hnyls2002 and ByronHsu as code owners May 27, 2025 04:04 zhyncs reviewed May 27, 2025 View reviewed changes python/sglang/srt/disaggregation/mooncake/conn.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . Copy link Member zhyncs commented May 27, 2025 @whybeyoung May you help fix the conflicts? QQ can you also share some performance results? All reactions Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . zhyncs assigned hnyls2002 and ShangmingCai May 27, 2025 ShangmingCai reviewed May 27, 2025 View reviewed changes python/sglang/srt/disaggregation/mooncake/conn.py Outdated Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . ShangmingCai reviewed May 27, 2025 View reviewed changes python/sglang/srt/disaggregation/mooncake/conn.py Show resolved Hide resolved Uh oh! There was an error while loading. Please reload this page . ShangmingCai added 2 commits May 27, 2025 15:09 Fix shard rule and remove inner loop thread pool \u2026 0f7548f Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com> Merge branch 'main' into deque-conn 7b63211 ShangmingCai force-pushed the deque-conn branch\n    from ce2c5a4 to 7b63211 Compare May 27, 2025 09:54 ShangmingCai added 5 commits May 27, 2025 19:18 Merge branch 'main' into deque-conn c5b5e85 Add per queue thread pool back and add a queue size env var \u2026 a4aed03 Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com> Add env var assertion \u2026 bd5d39d Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com> Merge branch 'main' into deque-conn 0046fca fix merge \u2026 7c16813 Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com> zhyncs approved these changes May 28, 2025 View reviewed changes zhyncs added\n  the high priority label May 28, 2025 Merge branch 'main' into deque-conn 74d5140 Hide details View details zhyncs merged commit 6b23132 into sgl-project : main May 28, 2025 30 of 40 checks passed Uh oh! There was an error while loading. Please reload this page . Hongbosherlock mentioned this pull request May 28, 2025 [PD] Remove Unnecessary Exception Handling for FastQueue.get() #6712 Merged 6 tasks ChangyiYang pushed a commit\n        to ChangyiYang/sglang-changyi\n      that referenced\n      this pull request May 29, 2025 [PD Perf] replace Queue to FastQueue ( sgl-project#6649 ) \u2026 bdab9a1 Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com>\nCo-authored-by: Shangming Cai <caishangming@linux.alibaba.com> Layssy pushed a commit\n        to Layssy/sglang-iaas\n      that referenced\n      this pull request Jun 9, 2025 [PD Perf] replace Queue to FastQueue ( sgl-project#6649 ) \u2026 e64a2ed Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com>\nCo-authored-by: Shangming Cai <caishangming@linux.alibaba.com> xwu-intel pushed a commit\n        to xwu-intel/sglang\n      that referenced\n      this pull request Jun 17, 2025 [PD Perf] replace Queue to FastQueue ( sgl-project#6649 ) \u2026 da608b7 Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com>\nCo-authored-by: Shangming Cai <caishangming@linux.alibaba.com> Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-11 18:57:16",
  "has_lm_eval": false,
  "has_performance": false,
  "has_serving": false,
  "has_general_test": false,
  "test_details": "NONE",
  "analysis_extracted_at": null,
  "models": [
    "N/A"
  ],
  "lm_eval_commands": null,
  "perf_command": null,
  "commit_subject": "[PD Perf] replace Queue to FastQueue (#6649)",
  "commit_message": "[PD Perf] replace Queue to FastQueue (#6649)\n\nSigned-off-by: Shangming Cai <caishangming@linux.alibaba.com>\nCo-authored-by: Shangming Cai <caishangming@linux.alibaba.com>",
  "commit_date": "2025-05-28T01:37:51-07:00",
  "files_changed": [
    "python/sglang/srt/disaggregation/mooncake/conn.py",
    "python/sglang/srt/disaggregation/utils.py"
  ],
  "functions_changed": [],
  "stats": {
    "commit_year": 2025,
    "num_edited_lines": 308,
    "num_files": 2,
    "num_hunks": 11,
    "num_non_test_edited_lines": 308,
    "num_non_test_files": 2,
    "num_test_files": 0,
    "only_non_test_files": 1,
    "only_test_files": 0
  },
  "diff_text": "diff --git a/python/sglang/srt/disaggregation/mooncake/conn.py b/python/sglang/srt/disaggregation/mooncake/conn.py\nindex 8ab5066ec..9ebdd60f0 100644\n--- a/python/sglang/srt/disaggregation/mooncake/conn.py\n+++ b/python/sglang/srt/disaggregation/mooncake/conn.py\n@@ -31,6 +31,7 @@ from sglang.srt.disaggregation.base.conn import (\n from sglang.srt.disaggregation.mooncake.transfer_engine import MooncakeTransferEngine\n from sglang.srt.disaggregation.utils import (\n     DisaggregationMode,\n+    FastQueue,\n     group_concurrent_contiguous,\n )\n from sglang.srt.server_args import ServerArgs\n@@ -151,7 +152,6 @@ class MooncakeKVManager(BaseKVManager):\n         self.server_socket = zmq.Context().socket(zmq.PULL)\n         self.register_buffer_to_engine()\n         if self.disaggregation_mode == DisaggregationMode.PREFILL:\n-            self.transfer_queue = queue.Queue()\n             self.transfer_infos: Dict[int, Dict[str, TransferInfo]] = {}\n             self.decode_kv_args_table: Dict[str, KVArgsRegisterInfo] = {}\n             self.start_prefill_thread()\n@@ -159,15 +159,31 @@ class MooncakeKVManager(BaseKVManager):\n             self.session_failures = defaultdict(int)\n             self.failed_sessions = set()\n             self.session_lock = threading.Lock()\n-\n             # Determine the number of threads to use for kv sender\n             cpu_count = os.cpu_count()\n-            self.executor = concurrent.futures.ThreadPoolExecutor(\n-                get_int_env_var(\n-                    \"SGLANG_DISAGGREGATION_THREAD_POOL_SIZE\",\n-                    min(max(1, cpu_count // 8), 8),\n-                )\n+            transfer_thread_pool_size = get_int_env_var(\n+                \"SGLANG_DISAGGREGATION_THREAD_POOL_SIZE\",\n+                min(max(4, int(0.75 * cpu_count) // 8), 12),\n             )\n+            transfer_queue_size = get_int_env_var(\"SGLANG_DISAGGREGATION_QUEUE_SIZE\", 4)\n+            self.transfer_queues: List[FastQueue] = [\n+                FastQueue() for _ in range(transfer_queue_size)\n+            ]\n+            assert transfer_thread_pool_size >= transfer_queue_size, (\n+                f\"The environment variable SGLANG_DISAGGREGATION_THREAD_POOL_SIZE={transfer_thread_pool_size} must be \"\n+                f\"greater than or equal to SGLANG_DISAGGREGATION_QUEUE_SIZE={transfer_queue_size}.\"\n+            )\n+            self.executors = [\n+                concurrent.futures.ThreadPoolExecutor(\n+                    transfer_thread_pool_size // transfer_queue_size\n+                )\n+                for _ in range(transfer_queue_size)\n+            ]\n+            for queue, executor in zip(self.transfer_queues, self.executors):\n+                threading.Thread(\n+                    target=self.transfer_worker, args=(queue, executor), daemon=True\n+                ).start()\n+\n             self.bootstrap_time_out = get_int_env_var(\n                 \"SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT\", 30\n             )\n@@ -183,7 +199,7 @@ class MooncakeKVManager(BaseKVManager):\n             )\n             # Heartbeat failure should be at least 1\n             self.max_failures = max(\n-                int(os.getenv(\"SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE\", 2)), 1\n+                get_int_env_var(\"SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE\", 2), 1\n             )\n             self.start_decode_thread()\n             self.connection_pool: Dict[str, Dict[str, Union[str, int]]] = {}\n@@ -220,6 +236,7 @@ class MooncakeKVManager(BaseKVManager):\n         prefill_kv_indices: npt.NDArray[np.int64],\n         dst_kv_ptrs: list[int],\n         dst_kv_indices: npt.NDArray[np.int64],\n+        executor: concurrent.futures.ThreadPoolExecutor,\n     ):\n         # Group by indices\n         prefill_kv_blocks, dst_kv_blocks = group_concurrent_contiguous(\n@@ -251,7 +268,7 @@ class MooncakeKVManager(BaseKVManager):\n             return 0\n \n         futures = [\n-            self.executor.submit(\n+            executor.submit(\n                 process_layer,\n                 src_ptr,\n                 dst_ptr,\n@@ -298,6 +315,123 @@ class MooncakeKVManager(BaseKVManager):\n             ]\n         )\n \n+    def transfer_worker(\n+        self, queue: FastQueue, executor: concurrent.futures.ThreadPoolExecutor\n+    ):\n+        while True:\n+            try:\n+                kv_chunk: TransferKVChunk = queue.get()\n+                reqs_to_be_processed = (\n+                    self.transfer_infos[kv_chunk.room].values()\n+                    if kv_chunk.room in self.transfer_infos\n+                    else []\n+                )\n+                polls = []\n+                dst_ranks_infos = []\n+                for req in reqs_to_be_processed:\n+                    if not req.is_dummy:\n+                        # Early exit if the request has failed\n+                        with self.session_lock:\n+                            if req.mooncake_session_id in self.failed_sessions:\n+                                self.record_failure(\n+                                    kv_chunk.room,\n+                                    f\"Decode instance could be dead, remote mooncake session {req.mooncake_session_id} is not alive\",\n+                                )\n+                                self.update_status(kv_chunk.room, KVPoll.Failed)\n+                                self.sync_status_to_decode_endpoint(\n+                                    req.endpoint,\n+                                    req.dst_port,\n+                                    req.room,\n+                                    KVPoll.Failed,\n+                                )\n+                                break\n+\n+                        chunked_dst_kv_indice = req.dst_kv_indices[kv_chunk.index_slice]\n+\n+                        # NOTE: This is temporarily a workaround to deal with the case where the prefill_kv_indices\n+                        # is mismatched with the dst_kv_indices when page size > 1, this should never happen.\n+                        if len(chunked_dst_kv_indice) < len(\n+                            kv_chunk.prefill_kv_indices\n+                        ):\n+                            kv_chunk.prefill_kv_indices = kv_chunk.prefill_kv_indices[\n+                                len(chunked_dst_kv_indice)\n+                            ]\n+                            logger.warning(\n+                                f\"len(chunked_dst_kv_indice) = {len(chunked_dst_kv_indice)}, len(kv_chunk.prefill_kv_indices) = {len(kv_chunk.prefill_kv_indices)}\"\n+                            )\n+\n+                        ret = self.send_kvcache(\n+                            req.mooncake_session_id,\n+                            kv_chunk.prefill_kv_indices,\n+                            self.decode_kv_args_table[\n+                                req.mooncake_session_id\n+                            ].dst_kv_ptrs,\n+                            chunked_dst_kv_indice,\n+                            executor,\n+                        )\n+                        if ret != 0:\n+                            with self.session_lock:\n+                                self.session_failures[req.mooncake_session_id] += 1\n+                                # Failures should never happen if the session is not dead, if the session fails once, mark it as failed\n+                                if self.session_failures[req.mooncake_session_id] >= 1:\n+                                    self.failed_sessions.add(req.mooncake_session_id)\n+                                    logger.error(\n+                                        f\"Session {req.mooncake_session_id} failed.\"\n+                                    )\n+                            self.record_failure(\n+                                kv_chunk.room,\n+                                f\"Failed to send kv chunk of {kv_chunk.room} to {req.endpoint}:{req.dst_port}\",\n+                            )\n+                            self.update_status(kv_chunk.room, KVPoll.Failed)\n+                            self.sync_status_to_decode_endpoint(\n+                                req.endpoint, req.dst_port, req.room, KVPoll.Failed\n+                            )\n+                            break\n+\n+                        if kv_chunk.is_last:\n+                            # Only the last chunk we need to send the aux data\n+                            ret = self.send_aux(\n+                                req.mooncake_session_id,\n+                                kv_chunk.prefill_aux_index,\n+                                self.decode_kv_args_table[\n+                                    req.mooncake_session_id\n+                                ].dst_aux_ptrs,\n+                                req.dst_aux_index,\n+                            )\n+                            polls.append(True if ret == 0 else False)\n+                            dst_ranks_infos.append(\n+                                (req.endpoint, req.dst_port, req.room)\n+                            )\n+\n+                            # Only sync status when all the dst ranks have received the kvcache\n+                            if len(polls) == req.required_dst_info_num:\n+                                status = KVPoll.Success if all(polls) else KVPoll.Failed\n+                                self.update_status(req.room, status)\n+                                for endpoint, dst_port, room in dst_ranks_infos:\n+                                    self.sync_status_to_decode_endpoint(\n+                                        endpoint, dst_port, room, status\n+                                    )\n+                    else:\n+                        # Dummy request means the decode instance is not used, so its status can be marked as success directly\n+                        # Dummy request does not need to sync status to decode endpoint\n+                        if kv_chunk.is_last and req.room in self.request_status:\n+                            self.update_status(req.room, KVPoll.Success)\n+\n+                if (\n+                    kv_chunk.room not in self.request_status\n+                    or self.check_status(kv_chunk.room) == KVPoll.Success\n+                ):\n+                    if kv_chunk.room in self.transfer_infos:\n+                        self.transfer_infos.pop(kv_chunk.room)\n+\n+            except queue.Empty:\n+                continue\n+            except Exception as e:\n+                # NOTE(shangming): Remove this when we make sure the transfer thread is bug-free\n+                raise RuntimeError(\n+                    f\"Transfer thread failed because of {e}. Prefill instance with bootstrap_port={self.bootstrap_port} is dead.\"\n+                )\n+\n     def start_prefill_thread(self):\n         self.rank_port = get_free_port()\n         self.server_socket.bind(f\"tcp://{get_local_ip_by_remote()}:{self.rank_port}\")\n@@ -335,134 +469,7 @@ class MooncakeKVManager(BaseKVManager):\n                     if len(self.transfer_infos[room]) == required_dst_info_num:\n                         self.update_status(room, KVPoll.WaitingForInput)\n \n-        def transfer_thread():\n-            # TODO: Shall we use KVPoll.Transferring state?\n-            while True:\n-                try:\n-                    kv_chunk: TransferKVChunk = self.transfer_queue.get(timeout=0.01)\n-                    reqs_to_be_processed = (\n-                        self.transfer_infos[kv_chunk.room].values()\n-                        if kv_chunk.room in self.transfer_infos\n-                        else []\n-                    )\n-                    polls = []\n-                    dst_ranks_infos = []\n-                    for req in reqs_to_be_processed:\n-                        if not req.is_dummy:\n-                            # Early exit if the request has failed\n-                            with self.session_lock:\n-                                if req.mooncake_session_id in self.failed_sessions:\n-                                    self.record_failure(\n-                                        kv_chunk.room,\n-                                        f\"Decode instance could be dead, remote mooncake session {req.mooncake_session_id} is not alive\",\n-                                    )\n-                                    self.update_status(kv_chunk.room, KVPoll.Failed)\n-                                    self.sync_status_to_decode_endpoint(\n-                                        req.endpoint,\n-                                        req.dst_port,\n-                                        req.room,\n-                                        KVPoll.Failed,\n-                                    )\n-                                    break\n-\n-                            chunked_dst_kv_indice = req.dst_kv_indices[\n-                                kv_chunk.index_slice\n-                            ]\n-\n-                            # NOTE: This is temporarily a workaround to deal with the case where the prefill_kv_indices\n-                            # is mismatched with the dst_kv_indices when page size > 1, this should never happen.\n-                            if len(chunked_dst_kv_indice) < len(\n-                                kv_chunk.prefill_kv_indices\n-                            ):\n-                                kv_chunk.prefill_kv_indices = (\n-                                    kv_chunk.prefill_kv_indices[\n-                                        len(chunked_dst_kv_indice)\n-                                    ]\n-                                )\n-                                logger.warning(\n-                                    f\"len(chunked_dst_kv_indice) = {len(chunked_dst_kv_indice)}, len(kv_chunk.prefill_kv_indices) = {len(kv_chunk.prefill_kv_indices)}\"\n-                                )\n-\n-                            ret = self.send_kvcache(\n-                                req.mooncake_session_id,\n-                                kv_chunk.prefill_kv_indices,\n-                                self.decode_kv_args_table[\n-                                    req.mooncake_session_id\n-                                ].dst_kv_ptrs,\n-                                chunked_dst_kv_indice,\n-                            )\n-                            if ret != 0:\n-                                with self.session_lock:\n-                                    self.session_failures[req.mooncake_session_id] += 1\n-                                    # Failures should never happen if the session is not dead, if the session fails once, mark it as failed\n-                                    if (\n-                                        self.session_failures[req.mooncake_session_id]\n-                                        >= 1\n-                                    ):\n-                                        self.failed_sessions.add(\n-                                            req.mooncake_session_id\n-                                        )\n-                                        logger.error(\n-                                            f\"Session {req.mooncake_session_id} failed.\"\n-                                        )\n-                                self.record_failure(\n-                                    kv_chunk.room,\n-                                    f\"Failed to send kv chunk of {kv_chunk.room} to {req.endpoint}:{req.dst_port}\",\n-                                )\n-                                self.update_status(kv_chunk.room, KVPoll.Failed)\n-                                self.sync_status_to_decode_endpoint(\n-                                    req.endpoint, req.dst_port, req.room, KVPoll.Failed\n-                                )\n-                                break\n-\n-                            if kv_chunk.is_last:\n-                                # Only the last chunk we need to send the aux data\n-                                ret = self.send_aux(\n-                                    req.mooncake_session_id,\n-                                    kv_chunk.prefill_aux_index,\n-                                    self.decode_kv_args_table[\n-                                        req.mooncake_session_id\n-                                    ].dst_aux_ptrs,\n-                                    req.dst_aux_index,\n-                                )\n-                                polls.append(True if ret == 0 else False)\n-                                dst_ranks_infos.append(\n-                                    (req.endpoint, req.dst_port, req.room)\n-                                )\n-\n-                                # Only sync status when all the dst ranks have received the kvcache\n-                                if len(polls) == req.required_dst_info_num:\n-                                    status = (\n-                                        KVPoll.Success if all(polls) else KVPoll.Failed\n-                                    )\n-                                    self.update_status(req.room, status)\n-                                    for endpoint, dst_port, room in dst_ranks_infos:\n-                                        self.sync_status_to_decode_endpoint(\n-                                            endpoint, dst_port, room, status\n-                                        )\n-                        else:\n-                            # Dummy request means the decode instance is not used, so its status can be marked as success directly\n-                            # Dummy request does not need to sync status to decode endpoint\n-                            if kv_chunk.is_last and req.room in self.request_status:\n-                                self.update_status(req.room, KVPoll.Success)\n-\n-                    if (\n-                        kv_chunk.room not in self.request_status\n-                        or self.check_status(kv_chunk.room) == KVPoll.Success\n-                    ):\n-                        if kv_chunk.room in self.transfer_infos:\n-                            self.transfer_infos.pop(kv_chunk.room)\n-\n-                except queue.Empty:\n-                    continue\n-                except Exception as e:\n-                    # NOTE(shangming): Remove this when we make sure the transfer thread is bug-free\n-                    raise RuntimeError(\n-                        f\"Transfer thread failed because of {e}. Prefill instance with bootstrap_port={self.bootstrap_port} is dead.\"\n-                    )\n-\n         threading.Thread(target=bootstrap_thread).start()\n-        threading.Thread(target=transfer_thread).start()\n \n     def start_decode_thread(self):\n         self.rank_port = get_free_port()\n@@ -555,7 +562,14 @@ class MooncakeKVManager(BaseKVManager):\n             )\n             return\n \n-        self.transfer_queue.put(\n+        # NOTE(shangming): sharding according to the dst_infos to make sure\n+        # requests with the same dst_sessions will be added into the same\n+        # queue, which enables early abort with failed sessions.\n+        dst_infos = self.transfer_infos[bootstrap_room].keys()\n+        session_port_sum = sum(int(session.split(\":\")[1]) for session in dst_infos)\n+        shard_idx = session_port_sum % len(self.transfer_queues)\n+\n+        self.transfer_queues[shard_idx].put(\n             TransferKVChunk(\n                 room=bootstrap_room,\n                 prefill_kv_indices=kv_indices,\ndiff --git a/python/sglang/srt/disaggregation/utils.py b/python/sglang/srt/disaggregation/utils.py\nindex 8841d5f1a..db7dd3239 100644\n--- a/python/sglang/srt/disaggregation/utils.py\n+++ b/python/sglang/srt/disaggregation/utils.py\n@@ -3,6 +3,7 @@ from __future__ import annotations\n import dataclasses\n import os\n import random\n+import threading\n import warnings\n from collections import deque\n from enum import Enum\n@@ -281,6 +282,25 @@ class MetadataBuffers:\n                 )\n \n \n+class FastQueue:\n+    def __init__(self):\n+        self._buf = deque()\n+        self._cond = threading.Condition()\n+\n+    def put(self, item):\n+        with self._cond:\n+            self._buf.append(item)\n+            # wake up a thread of wait()\n+            self._cond.notify()\n+\n+    def get(self):\n+        with self._cond:\n+            # if queue is empty  ,block until is notified()\n+            while not self._buf:\n+                self._cond.wait()\n+            return self._buf.popleft()\n+\n+\n def group_concurrent_contiguous(\n     src_indices: npt.NDArray[np.int64], dst_indices: npt.NDArray[np.int64]\n ) -> Tuple[List[npt.NDArray[np.int64]], List[npt.NDArray[np.int64]]]:",
  "apis": [
    "MooncakeKVManager.add_transfer_request",
    "MooncakeKVManager.transfer_worker",
    "FastQueue"
  ],
  "affected_paths": [
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/nixl/conn.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/mooncake/conn.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/ascend/conn.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/common/conn.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/fake/conn.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/base/conn.py",
    "/path/to/repos/sglang/python/sglang/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/utils.py",
    "/path/to/repos/sglang/sgl-kernel/python/sgl_kernel/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/weight_sync/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/layers/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/distributed/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/managers/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/function_call/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/configs/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/connector/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/model_loader/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/lora/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/common/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/layers/attention/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/layers/quantization/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/layers/moe/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/entrypoints/openai/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/layers/quantization/compressed_tensors/utils.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/mooncake/transfer_engine.py",
    "/path/to/repos/sglang/python/sglang/srt/disaggregation/ascend/transfer_engine.py"
  ],
  "repo_path": "/path/to/repos/sglang",
  "llm_reason": "The commit modifies non-test source files in the repository (e.g., files under sglang/srt/disaggregation) by replacing the standard Queue with a custom FastQueue and reworking the thread pool and work distribution logic. The changes appear to target the performance of work dispatching/processing (e.g., sharding based on session ports and using multiple executors) and thus aim to improve throughput and latency in the key code path. There is a clear focus on modifying the underlying threading and queuing system to optimize the performance of existing APIs, and the changes are not merely documentation fixes or trivial refactors. The enhancements are CPU-centric, and there is no reliance on GPU-specific code. Overall, the commit appears to be a performance optimization.",
  "llm_api_reason": "This commit removes the use of Python\u2019s standard queue.Queue in favor of a new, high\u2010performance FastQueue class for dispatching KV transfer chunks in the Mooncake disaggregation backend. It changes the MooncakeKVManager\u2019s logic in add_transfer_request to compute a shard index and put the transfer chunk into one of several FastQueue instances, and it adds a new transfer_worker method that processes items from FastQueue using a dedicated thread pool. Additionally, the FastQueue utility itself is introduced into the disaggregation utilities for more efficient inter\u2010thread communication."
}