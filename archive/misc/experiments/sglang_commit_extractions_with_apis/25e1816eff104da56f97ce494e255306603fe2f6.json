{
  "commit_hash": "25e1816eff104da56f97ce494e255306603fe2f6",
  "pr_url": "https://github.com/sgl-project/sglang/pull/4477",
  "pr_date": "2025-03-16",
  "timeline_text": "Copy link Collaborator yizhang2077 commented Mar 16, 2025 \u2022 edited Loading Uh oh! There was an error while loading. Please reload this page . Motivation Fix accuracy/performance problem for custom allreduce, see #4441 Modifications change the thread_per_block/block_per_grid calculation style change block barrier/sync place as vllm does performance python3 - m sglang . launch_server - - model meta - llama / Llama - 3.1 - 8 B - Instruct - - disable - radix - cache - - tp 8 python3 - m sglang . bench_serving - - backend sglang - - dataset - name sharegpt - - num - prompts 5000 custom allreduce python3 - m sglang . bench_serving - - backend sglang - - dataset - name sharegpt - - num - prompts 5000 == == == == == == Serving Benchmark Result == == == == == == Backend : sglang Traffic request rate : inf Max reqeuest concurrency : not set Successful requests : 5000 Benchmark duration ( s ): 49.19 Total input tokens : 1553911 Total generated tokens : 944949 Total generated tokens ( retokenized ): 944635 Request throughput ( req / s ): 101.65 Input token throughput ( tok / s ): 31591.81 Output token throughput ( tok / s ): 19211.30 Total token throughput ( tok / s ): 50803.11 Concurrency : 3143.75 vllm allreduce Backend : sglang Traffic request rate : inf Max reqeuest concurrency : not set Successful requests : 5000 Benchmark duration ( s ): 50.39 Total input tokens : 1553911 Total generated tokens : 944949 Total generated tokens ( retokenized ): 944661 Request throughput ( req / s ): 99.23 Input token throughput ( tok / s ): 30839.09 Output token throughput ( tok / s ): 18753.56 Total token throughput ( tok / s ): 49592.65 Concurrency : 3051.93 accuracy unittest test_verl_engine.py compare logprobs with huggingface, this test can pass locally gsm8k/mmmlu python3 - m sglang . launch_server - - model meta - llama / Llama - 3.1 - 8 B - Instruct - - disable - radix - cache - - tp 8 # gsm8k python3 benchmark / gsm8k / bench_sglang . py - - num - shots 8 - - num - questions 1319 - - parallel 1319 # mmlu bash benchmark / mmlu / download_data . sh python3 benchmark / mmlu / bench_sglang . py - - nsub 100 - - ntrain 5 - - parallel 2000 custom allreduce # env export USE_VLLM_CUSTOM_ALLREDUCE = 0 # gsm8k Accuracy : 0.788 Invalid : 0.001 Latency : 23.048 s Output throughput : 5825.797 token / s # mmlu subject : abstract_algebra , #q:100, acc: 0.320                                                                                                                                 subject: anatomy, #q:135, acc: 0.681                                                                                                                                          subject: astronomy, #q:152, acc: 0.770                                                                                                                                        subject: business_ethics, #q:100, acc: 0.740                                                                                                                                  subject: clinical_knowledge, #q:265, acc: 0.743                                                                                                                               subject: college_biology, #q:144, acc: 0.812                                                                                                                                  subject: college_chemistry, #q:100, acc: 0.470                                                                                                                                subject: college_computer_science, #q:100, acc: 0.580 subject : college_mathematics , #q:100, acc: 0.400 subject : college_medicine , #q:173, acc: 0.665 subject : college_physics , #q:102, acc: 0.441 subject : computer_security , #q:100, acc: 0.800 subject : conceptual_physics , #q:235, acc: 0.621 subject : econometrics , #q:114, acc: 0.518 subject : electrical_engineering , #q:145, acc: 0.703 subject : elementary_mathematics , #q:378, acc: 0.497 subject : formal_logic , #q:126, acc: 0.587 subject : global_facts , #q:100, acc: 0.340 subject : high_school_biology , #q:310, acc: 0.813 subject : high_school_chemistry , #q:203, acc: 0.626 subject : high_school_computer_science , #q:100, acc: 0.740 subject : high_school_european_history , #q:165, acc: 0.752 subject : high_school_geography , #q:198, acc: 0.848 subject : high_school_government_and_politics , #q:193, acc: 0.917 subject : high_school_macroeconomics , #q:390, acc: 0.685 subject : high_school_mathematics , #q:270, acc: 0.456 subject : high_school_microeconomics , #q:238, acc: 0.773 subject : high_school_physics , #q:151, acc: 0.457 subject : high_school_psychology , #q:545, acc: 0.864 subject : high_school_statistics , #q:216, acc: 0.588 subject : high_school_us_history , #q:204, acc: 0.833 subject : high_school_world_history , #q:237, acc: 0.852 subject : human_aging , #q:223, acc: 0.686 subject : human_sexuality , #q:131, acc: 0.794 subject : international_law , #q:121, acc: 0.835 subject : jurisprudence , #q:108, acc: 0.750 subject : logical_fallacies , #q:163, acc: 0.798 subject : machine_learning , #q:112, acc: 0.580 subject : management , #q:103, acc: 0.816 subject : marketing , #q:234, acc: 0.880 subject : medical_genetics , #q:100, acc: 0.820 subject : miscellaneous , #q:783, acc: 0.831 subject : moral_disputes , #q:346, acc: 0.757 subject : moral_scenarios , #q:895, acc: 0.555 subject : nutrition , #q:306, acc: 0.788 subject : philosophy , #q:311, acc: 0.717 subject : prehistory , #q:324, acc: 0.756 subject : professional_accounting , #q:282, acc: 0.521 subject : professional_law , #q:1534, acc: 0.510 subject : professional_medicine , #q:272, acc: 0.750 subject : professional_psychology , #q:612, acc: 0.721 subject : public_relations , #q:110, acc: 0.691 subject : security_studies , #q:245, acc: 0.727 subject : sociology , #q:201, acc: 0.856 subject : us_foreign_policy , #q:100, acc: 0.860 subject : virology , #q:166, acc: 0.506 subject : world_religions , #q:171, acc: 0.842 Total latency : 64.293 Average accuracy : 0.683 vllm allreduce # env export USE_VLLM_CUSTOM_ALLREDUCE = 1 # gsm8k Accuracy : 0.794 Invalid : 0.000 Latency : 23.143 s Output throughput : 5781.865 token / s # mmlu subject : abstract_algebra , #q:100, acc: 0.350                                                                                                                                 subject: anatomy, #q:135, acc: 0.689                                                                                                                                          subject: astronomy, #q:152, acc: 0.770                                                                                                                                        subject: business_ethics, #q:100, acc: 0.750                                                                                                                                  subject: clinical_knowledge, #q:265, acc: 0.747                                                                                                                               subject: college_biology, #q:144, acc: 0.812                                                                                                                                  subject: college_chemistry, #q:100, acc: 0.480 subject : college_computer_science , #q:100, acc: 0.570 subject : college_mathematics , #q:100, acc: 0.420 subject : college_medicine , #q:173, acc: 0.665 subject : college_physics , #q:102, acc: 0.441 subject : computer_security , #q:100, acc: 0.810 subject : conceptual_physics , #q:235, acc: 0.626 subject : econometrics , #q:114, acc: 0.535 subject : electrical_engineering , #q:145, acc: 0.717 subject : elementary_mathematics , #q:378, acc: 0.503 subject : formal_logic , #q:126, acc: 0.556 subject : global_facts , #q:100, acc: 0.360 subject : high_school_biology , #q:310, acc: 0.810 subject : high_school_chemistry , #q:203, acc: 0.621 subject : high_school_computer_science , #q:100, acc: 0.750 subject : high_school_european_history , #q:165, acc: 0.745 subject : high_school_geography , #q:198, acc: 0.843 subject : high_school_government_and_politics , #q:193, acc: 0.917 subject : high_school_macroeconomics , #q:390, acc: 0.677 subject : high_school_mathematics , #q:270, acc: 0.463 subject : high_school_microeconomics , #q:238, acc: 0.773 subject : high_school_physics , #q:151, acc: 0.470 subject : high_school_psychology , #q:545, acc: 0.864 subject : high_school_statistics , #q:216, acc: 0.597 subject : high_school_us_history , #q:204, acc: 0.838 subject : high_school_world_history , #q:237, acc: 0.848 subject : human_aging , #q:223, acc: 0.686 subject : human_sexuality , #q:131, acc: 0.794 subject : international_law , #q:121, acc: 0.835 subject : jurisprudence , #q:108, acc: 0.750 subject : logical_fallacies , #q:163, acc: 0.798 subject : machine_learning , #q:112, acc: 0.580 subject : management , #q:103, acc: 0.816 subject : marketing , #q:234, acc: 0.872 subject : medical_genetics , #q:100, acc: 0.820 subject : miscellaneous , #q:783, acc: 0.833 subject : moral_disputes , #q:346, acc: 0.757 subject : moral_scenarios , #q:895, acc: 0.554 subject : nutrition , #q:306, acc: 0.794 subject : philosophy , #q:311, acc: 0.720 subject : prehistory , #q:324, acc: 0.756 subject : professional_accounting , #q:282, acc: 0.500 subject : professional_law , #q:1534, acc: 0.512 subject : professional_medicine , #q:272, acc: 0.739 subject : professional_psychology , #q:612, acc: 0.722 subject : public_relations , #q:110, acc: 0.691 subject : security_studies , #q:245, acc: 0.735 subject : sociology , #q:201, acc: 0.851 subject : us_foreign_policy , #q:100, acc: 0.860 subject : virology , #q:166, acc: 0.506 subject : world_religions , #q:171, acc: 0.842 Total latency : 64.397 Average accuracy : 0.684 Checklist Format your code according to the Code Formatting with Pre-Commit . Add unit tests as outlined in the Running Unit Tests . Update documentation / docstrings / example tutorials as needed, according to Writing Documentation . Provide throughput / latency benchmark results and accuracy evaluation results as needed, according to Benchmark and Profiling and Accuracy Results . For reviewers: If you haven't made any contributions to this PR and are only assisting with merging the main branch, please remove yourself as a co-author when merging the PR. Please feel free to join our Slack channel at https://slack.sglang.ai to discuss your PR. Sorry, something went wrong. Uh oh! There was an error while loading. Please reload this page . \ud83d\udc4d 1 merrymercy reacted with thumbs up emoji All reactions \ud83d\udc4d 1 reaction yizhang2077 assigned yizhang2077 and zhyncs Mar 16, 2025 yizhang2077 requested review from zhyncs , ispobock , HandH1998 , BBuf and merrymercy as code owners March 16, 2025 15:26 yizhang2077 removed their assignment Mar 16, 2025 fix custom allreduce performance/accuracy problem 514f331 yizhang2077 force-pushed the fix-allreduce branch\n    from 27ca925 to 514f331 Compare March 16, 2025 16:00 zhyncs approved these changes Mar 16, 2025 View reviewed changes Hide details View details zhyncs merged commit 25e1816 into main Mar 16, 2025 11 checks passed Uh oh! There was an error while loading. Please reload this page . zhyncs deleted the fix-allreduce branch March 16, 2025 19:16 Sign up for free to join this conversation on GitHub .\n    Already have an account? Sign in to comment",
  "timeline_extracted_at": "2025-09-11 18:59:20",
  "has_lm_eval": true,
  "has_performance": true,
  "has_serving": true,
  "has_general_test": true,
  "test_details": "LM_EVAL | PERF | SERVING | TEST",
  "analysis_extracted_at": null,
  "models": [
    "meta-llama/Llama-3.1-8B-Instruct"
  ],
  "lm_eval_commands": [
    "lm_eval --model sglang --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks gsm8k --num_fewshot 8"
  ],
  "perf_command": "python3 -m sglang.bench_serving --backend sglang --dataset-name sharegpt --num-prompts 5000",
  "commit_subject": "fix custom allreduce performance/accuracy problem (#4477)",
  "commit_message": "fix custom allreduce performance/accuracy problem (#4477)",
  "commit_date": "2025-03-16T12:16:30-07:00",
  "files_changed": [
    "sgl-kernel/csrc/allreduce/trt_reduce_internal.cu",
    "sgl-kernel/include/trt_reduce_internal.cuh"
  ],
  "functions_changed": [],
  "stats": {
    "commit_year": 2025,
    "num_edited_lines": 27,
    "num_files": 2,
    "num_hunks": 4,
    "num_non_test_edited_lines": 27,
    "num_non_test_files": 2,
    "num_test_files": 0,
    "only_non_test_files": 1,
    "only_test_files": 0
  },
  "diff_text": "diff --git a/sgl-kernel/csrc/allreduce/trt_reduce_internal.cu b/sgl-kernel/csrc/allreduce/trt_reduce_internal.cu\nindex f1ee5d40e..283e1e8ad 100644\n--- a/sgl-kernel/csrc/allreduce/trt_reduce_internal.cu\n+++ b/sgl-kernel/csrc/allreduce/trt_reduce_internal.cu\n@@ -182,8 +182,9 @@ __inline__ __device__ void block_barrier(\n       }\n     }\n   }\n-\n-  __syncthreads();\n+  if constexpr (start || need_fence) {\n+    __syncthreads();\n+  }\n }\n \n template <typename T, int RANKS_PER_NODE, bool COPY_INPUT = true>\n@@ -262,6 +263,8 @@ static __global__ void __launch_bounds__(512, 1) oneShotAllReduceKernel(AllReduc\n     // Store to the destination buffer.\n     *reinterpret_cast<int4*>(&reinterpret_cast<T*>(params.local_output_buffer_ptr)[iter_offset]) = sums.packed;\n   }\n+  block_barrier<false>(\n+      params.peer_barrier_ptrs_out, params.barrier_flag, params.local_rank, RANKS_PER_NODE, tidx, bidx, grid_size);\n }\n \n template <typename T, int RANKS_PER_NODE, bool COPY_INPUT = true>\n@@ -437,24 +440,8 @@ std::tuple<int, int> kernelLaunchConfig(AllReduceStrategyType algo, AllReducePar\n       assert(params.elts_total % (elts_per_thread * params.ranks_per_node) == 0);\n       size_t const total_threads = roundUp(params.elts_total / (elts_per_thread * params.ranks_per_node), WARP_SIZE);\n \n-      /*\n       threads_per_block = std::min(DEFAULT_BLOCK_SIZE, total_threads);\n-      blocks_per_grid = std::min(static_cast<size_t>(MAX_ALL_REDUCE_BLOCKS), divUp(total_threads, threads_per_block));\n-      */\n-      while (total_threads % blocks_per_grid != 0 || total_threads / blocks_per_grid > DEFAULT_BLOCK_SIZE) {\n-        blocks_per_grid += 1;\n-      }\n-\n-      threads_per_block = total_threads / blocks_per_grid;\n-\n-      // NOTE: need to adjust here\n-      if (blocks_per_grid > MAX_ALL_REDUCE_BLOCKS) {\n-        size_t iter_factor = 1;\n-        while (blocks_per_grid / iter_factor > MAX_ALL_REDUCE_BLOCKS || blocks_per_grid % iter_factor) {\n-          iter_factor += 1;\n-        }\n-        blocks_per_grid /= iter_factor;\n-      }\n+      blocks_per_grid = std::min(static_cast<int>(MAX_ALL_REDUCE_BLOCKS), divUp(total_threads, threads_per_block));\n       params.elts_per_rank = params.elts_total / params.ranks_per_node;\n       params.rank_offset = params.local_rank * params.elts_per_rank;\n       params.elts_per_block = roundUp(divUp(params.elts_per_rank, blocks_per_grid), elts_per_thread);\ndiff --git a/sgl-kernel/include/trt_reduce_internal.cuh b/sgl-kernel/include/trt_reduce_internal.cuh\nindex c670c994d..9fec59b65 100644\n--- a/sgl-kernel/include/trt_reduce_internal.cuh\n+++ b/sgl-kernel/include/trt_reduce_internal.cuh\n@@ -39,7 +39,7 @@ limitations under the License.\n \n namespace trt_llm {\n constexpr size_t WARP_SIZE = 32;\n-constexpr size_t MAX_ALL_REDUCE_BLOCKS = 36;\n+constexpr size_t MAX_ALL_REDUCE_BLOCKS = 32;\n constexpr size_t MAX_RANKS_PER_NODE = 8;\n constexpr size_t DEFAULT_BLOCK_SIZE = 512;",
  "apis": [
    "sgl_kernel.allreduce.init_custom_ar",
    "sgl_kernel.allreduce.all_reduce_reg",
    "sgl_kernel.allreduce.all_reduce"
  ],
  "affected_paths": [
    "/path/to/repos/sglang/sgl-kernel/python/sgl_kernel/allreduce.py"
  ],
  "repo_path": "/path/to/repos/sglang",
  "llm_reason": "The patch modifies two non-test source files (a CUDA source file and its header) and performs non-trivial changes. In block_barrier, it conditionally calls __syncthreads() to possibly avoid unnecessary synchronization, which is a performance tuning measure. In kernelLaunchConfig, it simplifies block/grid calculations by removing a loop that adjusted parameters, favoring a more straightforward computation, and adjusts the MAX_ALL_REDUCE_BLOCKS constant. These changes are aimed at tuning the performance of a custom allreduce operation, as reflected indirectly by the commit message discussing performance/accuracy. Therefore, the commit addresses performance optimization rather than bug fixes, trivial refactoring, or new features.",
  "llm_api_reason": "The commit makes changes in the CUDA kernel code (trt_reduce_internal.cu and its header) that implement the custom allreduce operation. Although the changes are in backend C++/CUDA code, they are called from Python via torch operator calls in the sgl_kernel/allreduce.py module. In particular, the custom allreduce implementations \u2013 such as those wrapped by the Python functions init_custom_ar, all_reduce_reg (for ROCM) and all_reduce (for non-ROCM) \u2013 will now use the updated kernel synchronization (block_barrier) and kernel launch configuration (using the new MAX_ALL_REDUCE_BLOCKS value). These updates affect the high\u2010level Python APIs that users rely on for custom allreduce performance."
}