Traceback (most recent call last):
  File "/tmp/omniperf_test_3tkw55d9.py", line 580, in <module>
    run_test(args.eqcheck, args.reference, args.prefix)
  File "/tmp/omniperf_test_3tkw55d9.py", line 499, in run_test
    data = setup()
           ^^^^^^^
  File "/tmp/omniperf_test_3tkw55d9.py", line 324, in setup
    from vllm.attention.backends.dual_chunk_flash_attn import FlashAttentionMetadata
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, CompilationConfig, ConfigFormat,
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/config.py", line 20, in <module>
    from vllm.model_executor.layers.quantization import (QUANTIZATION_METHODS,
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/model_executor/__init__.py", line 1, in <module>
    from vllm.model_executor.parameter import (BasevLLMParameter,
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/model_executor/parameter.py", line 7, in <module>
    from vllm.distributed import get_tensor_model_parallel_rank
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/distributed/__init__.py", line 1, in <module>
    from .communication_op import *
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/distributed/communication_op.py", line 6, in <module>
    from .parallel_state import get_tp_group
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/distributed/parallel_state.py", line 39, in <module>
    from vllm.platforms import current_platform
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/platforms/__init__.py", line 100, in <module>
    from .cuda import CudaPlatform
  File "/tmp/omniperf_worktree_n2qe01uf/worktree/vllm/platforms/cuda.py", line 14, in <module>
    import vllm._C  # noqa
    ^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'vllm._C'
