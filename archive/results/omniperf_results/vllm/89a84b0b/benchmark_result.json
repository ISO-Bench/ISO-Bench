{
  "instance": {
    "commit_hash": "89a84b0bb7b30706a02836234a94493ea8f780bf",
    "commit_subject": "[Core] Use array to speedup padding (#6779)",
    "repo": "vllm",
    "pr_url": "https://github.com/vllm-project/vllm/pull/6779",
    "files_changed": [
      "vllm/model_executor/layers/sampler.py",
      "vllm/model_executor/sampling_metadata.py",
      "vllm/sequence.py"
    ]
  },
  "result": {
    "status": "success",
    "commit_hash": "89a84b0bb7b30706a02836234a94493ea8f780bf",
    "baseline_ms": 0.5955175000053714,
    "patched_ms": 0.6100658501054568,
    "speedup": 0.9761528200643086,
    "improvement": false,
    "baseline_output": {
      "impl_tag": "child",
      "commit_hash": "89a84b0bb7b30706a02836234a94493ea8f780bf",
      "device": "cpu",
      "dtype": "torch.float16",
      "iters": 20,
      "warmup": 5,
      "avg_ms": 0.5955175000053714,
      "p50_ms": 0.5724789989471901,
      "p95_ms": 0.6045770005584927,
      "eq_level": "numeric",
      "opt_path_hit": true
    },
    "patched_output": {
      "impl_tag": "child",
      "commit_hash": "89a84b0bb7b30706a02836234a94493ea8f780bf",
      "device": "cpu",
      "dtype": "torch.float16",
      "iters": 20,
      "warmup": 5,
      "avg_ms": 0.6100658501054568,
      "p50_ms": 0.5689830013579922,
      "p95_ms": 0.8903559992177179,
      "eq_level": "numeric",
      "opt_path_hit": true
    },
    "error_message": null,
    "stdout": "WARNING 12-24 19:15:56 _custom_ops.py:14] Failed to import from vllm._C with ModuleNotFoundError(\"No module named 'vllm._C'\")\n{\"impl_tag\": \"child\", \"commit_hash\": \"89a84b0bb7b30706a02836234a94493ea8f780bf\", \"device\": \"cpu\", \"dtype\": \"torch.float16\", \"iters\": 20, \"warmup\": 5, \"avg_ms\": 0.5955175000053714, \"p50_ms\": 0.5724789989471901, \"p95_ms\": 0.6045770005584927, \"eq_level\": \"numeric\", \"opt_path_hit\": true}\n\nWARNING 12-24 19:16:01 _custom_ops.py:14] Failed to import from vllm._C with ModuleNotFoundError(\"No module named 'vllm._C'\")\n{\"impl_tag\": \"child\", \"commit_hash\": \"89a84b0bb7b30706a02836234a94493ea8f780bf\", \"device\": \"cpu\", \"dtype\": \"torch.float16\", \"iters\": 20, \"warmup\": 5, \"avg_ms\": 0.6100658501054568, \"p50_ms\": 0.5689830013579922, \"p95_ms\": 0.8903559992177179, \"eq_level\": \"numeric\", \"opt_path_hit\": true}\n",
    "stderr": "/tmp/omniperf_worktree_whq9lmbh/worktree/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\nNo module named 'vllm.commit_id'\n  from vllm.version import __version__ as VLLM_VERSION\n/tmp/omniperf_worktree_whq9lmbh/worktree/vllm/model_executor/sampling_metadata.py:543: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4416.)\n  ).T.contiguous()\n\n/tmp/omniperf_worktree_whq9lmbh/worktree/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\nNo module named 'vllm.commit_id'\n  from vllm.version import __version__ as VLLM_VERSION\n/tmp/omniperf_worktree_whq9lmbh/worktree/vllm/model_executor/sampling_metadata.py:544: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4416.)\n  ).T.contiguous()\n",
    "duration_s": 10.627004861831665,
    "patch_path": "/root/OmniPerf-Bench/perf-agents-bench/state/runs/vllm/claude_code/default/2025-12-23_04-37-32/vllm_core-0041/model_patch.diff",
    "patch_stats": {
      "lines_added": 37,
      "files_changed": 3
    }
  }
}