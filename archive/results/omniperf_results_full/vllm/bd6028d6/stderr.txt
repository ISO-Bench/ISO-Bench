=== BASELINE ===
/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
Traceback (most recent call last):
  File "/ephemeral/benchmark_worktree/benchmarks/benchmark_latency.py", line 186, in <module>
    main(args)
  File "/ephemeral/benchmark_worktree/benchmarks/benchmark_latency.py", line 43, in main
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/utils.py", line 1099, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 248, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/engine/llm_engine.py", line 515, in from_engine_args
    vllm_config = engine_args.create_engine_config(usage_context)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 1154, in create_engine_config
    model_config = self.create_model_config()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 1042, in create_model_config
    return ModelConfig(
           ^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/config.py", line 489, in __init__
    self.multimodal_config = self._init_multimodal_config(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/config.py", line 558, in _init_multimodal_config
    if self.registry.is_multimodal_model(self.architectures):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/registry.py", line 496, in is_multimodal_model
    model_cls, _ = self.inspect_model_cls(architectures)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/registry.py", line 456, in inspect_model_cls
    return self._raise_for_unsupported(architectures)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/registry.py", line 406, in _raise_for_unsupported
    raise ValueError(
ValueError: Model architectures ['Llama4ForConditionalGeneration'] failed to be inspected. Please check the logs for more details.
