=== BASELINE ===
Failed to start vLLM server
b'/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m `rope_scaling`\'s factor field must be a float >= 1, got 40\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m `rope_scaling`\'s beta_fast field must be a float, got 32\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m `rope_scaling`\'s beta_slow field must be a float, got 1\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m `torch_dtype` is deprecated! Use `dtype` instead!\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m `rope_scaling`\'s factor field must be a float >= 1, got 40\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m `rope_scaling`\'s beta_fast field must be a float, got 32\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m `rope_scaling`\'s beta_slow field must be a float, got 1\n/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m Process EngineCore_0:\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m Traceback (most recent call last):\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.run()\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 108, in run\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self._target(*self._args, **self._kwargs)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 671, in run_engine_core\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     raise e\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 658, in run_engine_core\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     engine_core = EngineCoreProc(*args, **kwargs)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 472, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     super().__init__(vllm_config, executor_class, log_stats,\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 77, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.model_executor = executor_class(vllm_config)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 53, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self._init_executor()\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 49, in _init_executor\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.collective_rpc("load_model")\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     answer = run_method(self.driver_worker, method, args, kwargs)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/utils/__init__.py", line 2954, in run_method\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     return func(*args, **kwargs)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 212, in load_model\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1962, in load_model\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.model = model_loader.load_model(\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 44, in load_model\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     model = initialize_model(vllm_config=vllm_config,\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py", line 736, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 183, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py", line 674, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                                                     ^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 640, in make_layers\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py", line 676, in <lambda>\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     lambda prefix: DeepseekV2DecoderLayer(\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py", line 583, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.mlp = DeepseekV2MoE(\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                ^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py", line 149, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.experts = FusedMoE(\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                    ^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 788, in __init__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 283, in create_weights\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     w13_weight = torch.nn.Parameter(torch.empty(\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m                                     ^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m     return func(*args, **kwargs)\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(EngineCore_0 pid=158792)\x1b[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacity of 79.11 GiB of which 2.59 GiB is free. Process 320661 has 76.51 GiB memory in use. Of the allocated memory 75.98 GiB is allocated by PyTorch, and 18.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n[rank0]:[W1226 07:50:23.839258791 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m Traceback (most recent call last):\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "<frozen runpy>", line 198, in _run_module_as_main\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "<frozen runpy>", line 88, in _run_code\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 1881, in <module>\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     uvloop.run(run_server(args))\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/uvloop/__init__.py", line 96, in run\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return __asyncio.run(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/asyncio/runners.py", line 195, in run\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return runner.run(main)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/asyncio/runners.py", line 118, in run\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return self._loop.run_until_complete(task)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/uvloop/__init__.py", line 48, in wrapper\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return await main\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 1813, in run_server\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 1833, in run_server_worker\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     async with build_async_engine_client(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/contextlib.py", line 210, in __aenter__\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return await anext(self.gen)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 165, in build_async_engine_client\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     async with build_async_engine_client_from_engine_args(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/contextlib.py", line 210, in __aenter__\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return await anext(self.gen)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 205, in build_async_engine_client_from_engine_args\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     async_llm = AsyncLLM.from_vllm_config(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/utils/__init__.py", line 1519, in inner\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return fn(*args, **kwargs)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/async_llm.py", line 170, in from_vllm_config\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return cls(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/async_llm.py", line 118, in __init__\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 100, in make_async_mp_client\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     return AsyncMPClient(*client_args)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 731, in __init__\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     super().__init__(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 420, in __init__\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     with launch_core_engines(vllm_config, executor_class,\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/contextlib.py", line 144, in __exit__\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     next(self.gen)\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 697, in launch_core_engines\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     wait_for_engine_startup(\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 750, in wait_for_engine_startup\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m     raise RuntimeError("Engine core initialization failed. "\n\x1b[1;36m(APIServer pid=158670)\x1b[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}\n'