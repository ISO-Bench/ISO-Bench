=== BASELINE ===
Failed to start vLLM server
b'/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\nTraceback (most recent call last):\n  File "<frozen runpy>", line 189, in _run_module_as_main\n  File "<frozen runpy>", line 112, in _get_module_details\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/__init__.py", line 13, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 22, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/config.py", line 43, in <module>\n    from vllm.transformers_utils.config import (\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/transformers_utils/config.py", line 32, in <module>\n    from vllm.transformers_utils.configs import (ChatGLMConfig, Cohere2Config,\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/transformers_utils/configs/__init__.py", line 28, in <module>\n    from vllm.transformers_utils.configs.ovis import OvisConfig\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/transformers_utils/configs/ovis.py", line 76, in <module>\n    AutoConfig.register("aimv2", AIMv2Config)\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1401, in register\n    CONFIG_MAPPING.register(model_type, config, exist_ok=exist_ok)\n  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1081, in register\n    raise ValueError(f"\'{key}\' is already used by a Transformers config, pick another name.")\nValueError: \'aimv2\' is already used by a Transformers config, pick another name.\n'