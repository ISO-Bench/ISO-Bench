=== BASELINE ===
/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!

Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]

Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.32it/s]

Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.32it/s]


Processed prompts:   0%|          | 0/1000 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/1000 [00:04<1:14:37,  4.48s/it, est. speed input: 28.78 toks/s, output: 57.12 toks/s]
Processed prompts:  26%|██▌       | 257/1000 [00:09<00:22, 33.40it/s, est. speed input: 3671.16 toks/s, output: 7285.39 toks/s]
Processed prompts:  51%|█████▏    | 513/1000 [00:13<00:11, 43.79it/s, est. speed input: 4866.31 toks/s, output: 9657.16 toks/s]
Processed prompts:  77%|███████▋  | 769/1000 [00:17<00:04, 49.87it/s, est. speed input: 5546.81 toks/s, output: 11007.62 toks/s]
Processed prompts: 100%|██████████| 1000/1000 [00:17<00:00, 55.91it/s, est. speed input: 7212.07 toks/s, output: 14312.33 toks/s]

=== HUMAN ===
/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!

Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]

Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.32it/s]

Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.32it/s]


Processed prompts:   0%|          | 0/1000 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/1000 [00:04<1:14:55,  4.50s/it, est. speed input: 28.67 toks/s, output: 56.89 toks/s]
Processed prompts:  26%|██▌       | 257/1000 [00:09<00:22, 33.28it/s, est. speed input: 3657.59 toks/s, output: 7258.45 toks/s]
Processed prompts:  51%|█████▏    | 513/1000 [00:13<00:11, 43.69it/s, est. speed input: 4853.28 toks/s, output: 9631.29 toks/s]
Processed prompts:  77%|███████▋  | 769/1000 [00:17<00:04, 49.52it/s, est. speed input: 5516.17 toks/s, output: 10946.82 toks/s]
Processed prompts: 100%|██████████| 1000/1000 [00:17<00:00, 55.60it/s, est. speed input: 7172.27 toks/s, output: 14233.33 toks/s]

=== AGENT ===
/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/ephemeral/benchmark_worktree/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm.commit_id'
  from vllm.version import __version__ as VLLM_VERSION
`torch_dtype` is deprecated! Use `dtype` instead!

Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]

Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.37it/s]

Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.36it/s]

[rank0]: Traceback (most recent call last):
[rank0]:   File "/ephemeral/benchmark_worktree/benchmarks/benchmark_throughput.py", line 460, in <module>
[rank0]:     main(args)
[rank0]:   File "/ephemeral/benchmark_worktree/benchmarks/benchmark_throughput.py", line 233, in main
[rank0]:     elapsed_time = run_vllm(
[rank0]:                    ^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/benchmarks/benchmark_throughput.py", line 92, in run_vllm
[rank0]:     llm = LLM(
[rank0]:           ^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/entrypoints/llm.py", line 177, in __init__
[rank0]:     self.llm_engine = LLMEngine.from_engine_args(
[rank0]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/engine/llm_engine.py", line 532, in from_engine_args
[rank0]:     engine = cls(
[rank0]:              ^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/engine/llm_engine.py", line 314, in __init__
[rank0]:     self._initialize_kv_caches()
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/engine/llm_engine.py", line 442, in _initialize_kv_caches
[rank0]:     self.model_executor.determine_num_available_blocks())
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/executor/gpu_executor.py", line 113, in determine_num_available_blocks
[rank0]:     return self.driver_worker.determine_num_available_blocks()
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/worker/worker.py", line 222, in determine_num_available_blocks
[rank0]:     self.model_runner.profile_run()
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/worker/model_runner.py", line 1124, in profile_run
[rank0]:     self.execute_model(model_input, kv_caches, intermediate_tensors)
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/worker/model_runner.py", line 1446, in execute_model
[rank0]:     hidden_or_intermediate_states = model_executable(
[rank0]:                                     ^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/model_executor/models/gemma.py", line 351, in forward
[rank0]:     hidden_states = self.model(input_ids, positions, kv_caches,
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/model_executor/models/gemma.py", line 289, in forward
[rank0]:     hidden_states, residual = layer(
[rank0]:                               ^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/model_executor/models/gemma.py", line 227, in forward
[rank0]:     hidden_states = self.self_attn(
[rank0]:                     ^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/model_executor/models/gemma.py", line 174, in forward
[rank0]:     q, k = self.rotary_emb(positions, q, k)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/model_executor/custom_op.py", line 14, in forward
[rank0]:     return self._forward_method(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/model_executor/layers/rotary_embedding.py", line 216, in forward_cuda
[rank0]:     ops.rotary_embedding(positions, query, key, self.head_size,
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/_custom_ops.py", line 38, in wrapper
[rank0]:     raise e
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/_custom_ops.py", line 29, in wrapper
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_worktree/vllm/_custom_ops.py", line 139, in rotary_embedding
[rank0]:     torch.ops._C.rotary_embedding(positions, query, key, head_size,
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/torch/_ops.py", line 1170, in __getattr__
[rank0]:     raise AttributeError(
[rank0]: AttributeError: '_OpNamespace' '_C' object has no attribute 'rotary_embedding'
