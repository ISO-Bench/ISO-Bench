{
  "generated_at": "2025-12-25T09:33:05.949246",
  "title": "OmniPerf Native Benchmark Report",
  "summary": {
    "vllm_total": 96,
    "vllm_successful": 18,
    "sglang_total": 74,
    "sglang_successful": 28,
    "total_benchmarks": 170,
    "total_successful": 46
  },
  "vllm": {
    "results": [],
    "stats": {
      "mean_improvement_pct": 0.2899601304820654,
      "improved_count": 1,
      "regressed_count": 0,
      "max_improvement": 0.2899601304820654,
      "min_improvement": 0.2899601304820654
    },
    "total": 96,
    "status_breakdown": {
      "baseline_failed": 77,
      "success": 18,
      "no_patch": 1
    },
    "successful": 18
  },
  "sglang": {
    "results": [],
    "stats": {},
    "total": 74,
    "status_breakdown": {
      "baseline_failed": 46,
      "success": 28
    },
    "successful": 28
  },
  "findings": [
    "1. Wheel-based benchmarking approach validated successfully for commits with available pre-built wheels",
    "2. Most benchmark failures are due to: (a) serving benchmarks requiring server lifecycle management, (b) missing wheels for older commits",
    "3. The single successful 3-way benchmark (ce6bf3a2) showed baseline ~28,327 tok/s throughput with google/gemma-2b model",
    "4. Agent PYTHONPATH overlay approach works only for pure Python changes - C extension modifications require full wheel rebuild",
    "5. vLLM native benchmarks: 18/96 successful (18.8%)",
    "6. SGLang native benchmarks: 28/74 successful (37.8%)"
  ],
  "limitations": [
    "1. Serving benchmarks (benchmark_serving.py) require running vLLM/SGLang server - not implemented",
    "2. Many commits reference local model paths (e.g., /data/users/ktong/llama/) from original PR authors",
    "3. Older commits (pre-0.5.x) lack pre-built wheels on wheels.vllm.ai",
    "4. Agent patches that modify C code (CUDA kernels, etc.) cannot be tested via PYTHONPATH overlay",
    "5. Disk space constraints limit concurrent wheel installations"
  ]
}