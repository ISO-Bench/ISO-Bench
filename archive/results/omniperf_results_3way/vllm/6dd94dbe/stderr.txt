=== BASELINE ===
/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
Traceback (most recent call last):
  File "/ephemeral/benchmark_worktree/benchmarks/benchmark_latency.py", line 150, in <module>
    main(args)
  File "/ephemeral/benchmark_worktree/benchmarks/benchmark_latency.py", line 27, in main
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/utils.py", line 1039, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 239, in __init__
    self.llm_engine = self.engine_class.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/engine/llm_engine.py", line 479, in from_engine_args
    engine_config = engine_args.create_engine_config(usage_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 1050, in create_engine_config
    model_config = self.create_model_config()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 975, in create_model_config
    return ModelConfig(
           ^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/config.py", line 343, in __init__
    self.multimodal_config = self._init_multimodal_config(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/config.py", line 402, in _init_multimodal_config
    if ModelRegistry.is_multimodal_model(architectures):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/registry.py", line 432, in is_multimodal_model
    model_cls, _ = self.inspect_model_cls(architectures)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/registry.py", line 392, in inspect_model_cls
    return self._raise_for_unsupported(architectures)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ephemeral/benchmark_venv/lib/python3.12/site-packages/vllm/model_executor/models/registry.py", line 349, in _raise_for_unsupported
    raise ValueError(
ValueError: Model architectures ['LlamaForCausalLM'] failed to be inspected. Please check the logs for more details.
