=== BASELINE ===
/ephemeral/benchmark_venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
usage: benchmark_serving.py [-h]
                            [--backend {tgi,vllm,lmdeploy,deepspeed-mii,openai,openai-chat,openai-audio,tensorrt-llm,scalellm,sglang,llama.cpp}]
                            [--base-url BASE_URL] [--host HOST] [--port PORT]
                            [--endpoint ENDPOINT]
                            [--dataset-name {sharegpt,burstgpt,sonnet,random,hf,custom}]
                            [--dataset-path DATASET_PATH] [--no-stream]
                            [--max-concurrency MAX_CONCURRENCY] --model MODEL
                            [--tokenizer TOKENIZER] [--use-beam-search]
                            [--num-prompts NUM_PROMPTS] [--logprobs LOGPROBS]
                            [--request-rate REQUEST_RATE]
                            [--burstiness BURSTINESS] [--seed SEED]
                            [--trust-remote-code] [--disable-tqdm] [--profile]
                            [--save-result] [--save-detailed]
                            [--append-result] [--metadata [KEY=VALUE ...]]
                            [--result-dir RESULT_DIR]
                            [--result-filename RESULT_FILENAME] [--ignore-eos]
                            [--percentile-metrics PERCENTILE_METRICS]
                            [--metric-percentiles METRIC_PERCENTILES]
                            [--goodput GOODPUT [GOODPUT ...]]
                            [--custom-output-len CUSTOM_OUTPUT_LEN]
                            [--custom-skip-chat-template]
                            [--sonnet-input-len SONNET_INPUT_LEN]
                            [--sonnet-output-len SONNET_OUTPUT_LEN]
                            [--sonnet-prefix-len SONNET_PREFIX_LEN]
                            [--sharegpt-output-len SHAREGPT_OUTPUT_LEN]
                            [--random-input-len RANDOM_INPUT_LEN]
                            [--random-output-len RANDOM_OUTPUT_LEN]
                            [--random-range-ratio RANDOM_RANGE_RATIO]
                            [--random-prefix-len RANDOM_PREFIX_LEN]
                            [--hf-subset HF_SUBSET] [--hf-split HF_SPLIT]
                            [--hf-output-len HF_OUTPUT_LEN] [--top-p TOP_P]
                            [--top-k TOP_K] [--min-p MIN_P]
                            [--temperature TEMPERATURE]
                            [--tokenizer-mode {auto,slow,mistral,custom}]
                            [--served-model-name SERVED_MODEL_NAME]
                            [--lora-modules LORA_MODULES [LORA_MODULES ...]]
                            [--ramp-up-strategy {linear,exponential}]
                            [--ramp-up-start-rps RAMP_UP_START_RPS]
                            [--ramp-up-end-rps RAMP_UP_END_RPS]
benchmark_serving.py: error: unrecognized arguments: --dtype float16
