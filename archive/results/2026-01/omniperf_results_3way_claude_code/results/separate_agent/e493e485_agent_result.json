{
  "human_commit": "e493e485",
  "human_commit_full": "e493e48524e9e78ab33eafec6461b3940e361189",
  "parent_commit": "4ce64e2df48649c4873f828b8bf71790aa1e56ee",
  "model": "microsoft/phi-1_5",
  "status": "error",
  "error": "Server crashed after applying patch",
  "duration_s": 181.60522317886353,
  "metrics": {},
  "raw_output": "thon with vLLM...\nWARNING 01-10 05:48:01 [__init__.py:221] Platform plugin tpu function's return value is None\nINFO 01-10 05:48:01 [__init__.py:220] Platform plugin cuda loaded.\nWARNING 01-10 05:48:01 [__init__.py:221] Platform plugin cuda function's return value is None\nWARNING 01-10 05:48:01 [__init__.py:221] Platform plugin rocm function's return value is None\nWARNING 01-10 05:48:01 [__init__.py:221] Platform plugin hpu function's return value is None\nWARNING 01-10 05:48:01 [__init__.py:221] Platform plugin xpu function's return value is None\nWARNING 01-10 05:48:01 [__init__.py:221] Platform plugin cpu function's return value is None\nWARNING 01-10 05:48:01 [__init__.py:221] Platform plugin neuron function's return value is None\nINFO 01-10 05:48:01 [__init__.py:246] Automatically detected platform cuda.\nWARNING 01-10 05:48:05 [__init__.py:221] Platform plugin tpu function's return value is None\nINFO 01-10 05:48:05 [__init__.py:220] Platform plugin cuda loaded.\nWARNING 01-10 05:48:05 [__init__.py:221] Platform plugin cuda function's return value is None\nWARNING 01-10 05:48:05 [__init__.py:221] Platform plugin rocm function's return value is None\nWARNING 01-10 05:48:05 [__init__.py:221] Platform plugin hpu function's return value is None\nWARNING 01-10 05:48:05 [__init__.py:221] Platform plugin xpu function's return value is None\nWARNING 01-10 05:48:05 [__init__.py:221] Platform plugin cpu function's return value is None\nWARNING 01-10 05:48:05 [__init__.py:221] Platform plugin neuron function's return value is None\nINFO 01-10 05:48:05 [__init__.py:246] Automatically detected platform cuda.\nWARNING: Could not find Python with vLLM, trying default python3\nWARNING 01-10 05:48:08 [__init__.py:221] Platform plugin tpu function's return value is None\nINFO 01-10 05:48:08 [__init__.py:220] Platform plugin cuda loaded.\nWARNING 01-10 05:48:08 [__init__.py:221] Platform plugin cuda function's return value is None\nWARNING 01-10 05:48:08 [__init__.py:221] Platform plugin rocm function's return value is None\nWARNING 01-10 05:48:08 [__init__.py:221] Platform plugin hpu function's return value is None\nWARNING 01-10 05:48:08 [__init__.py:221] Platform plugin xpu function's return value is None\nWARNING 01-10 05:48:08 [__init__.py:221] Platform plugin cpu function's return value is None\nWARNING 01-10 05:48:08 [__init__.py:221] Platform plugin neuron function's return value is None\nINFO 01-10 05:48:08 [__init__.py:246] Automatically detected platform cuda.\nvLLM import failed\noutlines.fsm OK\nCloning vLLM repo for benchmark scripts...\nCloning into 'vllm_bench'...\n=== Starting vLLM server for AGENT benchmark ===\nWARNING 01-10 05:48:22 [__init__.py:221] Platform plugin tpu function's return value is None\nINFO 01-10 05:48:22 [__init__.py:220] Platform plugin cuda loaded.\nWARNING 01-10 05:48:22 [__init__.py:221] Platform plugin cuda function's return value is None\nWARNING 01-10 05:48:22 [__init__.py:221] Platform plugin rocm function's return value is None\nWARNING 01-10 05:48:22 [__init__.py:221] Platform plugin hpu function's return value is None\nWARNING 01-10 05:48:22 [__init__.py:221] Platform plugin xpu function's return value is None\nWARNING 01-10 05:48:22 [__init__.py:221] Platform plugin cpu function's return value is None\nWARNING 01-10 05:48:22 [__init__.py:221] Platform plugin neuron function's return value is None\nINFO 01-10 05:48:22 [__init__.py:246] Automatically detected platform cuda.\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 189, in _run_module_as_main\n  File \"<frozen runpy>\", line 112, in _get_module_details\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 12, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 20, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n  File \"/opt/vllm_baseline/vllm/config.py\", line 32, in <module>\n    from vllm.model_executor.layers.quantization import (QUANTIZATION_METHODS,\n  File \"/opt/vllm_baseline/vllm/model_executor/__init__.py\", line 3, in <module>\n    from vllm.model_executor.parameter import (BasevLLMParameter,\n  File \"/opt/vllm_baseline/vllm/model_executor/parameter.py\", line 9, in <module>\n    from vllm.distributed import get_tensor_model_parallel_rank\n  File \"/opt/vllm_baseline/vllm/distributed/__init__.py\", line 3, in <module>\n    from .communication_op import *\n  File \"/opt/vllm_baseline/vllm/distributed/communication_op.py\", line 8, in <module>\n    from .parallel_state import get_tp_group\n  File \"/opt/vllm_baseline/vllm/distributed/parallel_state.py\", line 150, in <module>\n    from vllm.platforms import current_platform\n  File \"/opt/vllm_baseline/vllm/platforms/__init__.py\", line 278, in __getattr__\n    _current_platform = resolve_obj_by_qualname(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/utils.py\", line 2189, in resolve_obj_by_qualname\n    module = importlib.import_module(module_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/platforms/cuda.py\", line 14, in <module>\n    import vllm._C  # noqa\n    ^^^^^^^^^^^^^^\nImportError: /opt/vllm_baseline/vllm/_C.abi3.so: undefined symbol: cuTensorMapEncodeTiled\nSERVER_CRASHED\nUnable to find image 'anonymous/vllm-baseline:baseline-4ce64e2df486' locally\nbaseline-4ce64e2df486: Pulling from anonymous/vllm-baseline\n9cb31e2e37ea: Already exists\nb95112eaf283: Already exists\n030ef8250936: Already exists\n72ac9ccfda38: Already exists\n73389fbd088f: Already exists\n0264850675f7: Already exists\nde1d03310308: Already exists\nc1d2af7fad0f: Already exists\n5601308b3ac6: Already exists\n6b2035e8b73e: Already exists\ned71f8f81b33: Already exists\na04181a7ff83: Already exists\nb89dfbaf9e2c: Already exists\ndc1d202b3ed0: Already exists\nad0178e8a361: Already exists\ne4a092a24edb: Already exists\ncd9db290845e: Already exists\nefae73abea6f: Already exists\n00e7621a9cc3: Already exists\n1a270b3605fe: Already exists\nccfda7d8bfa7: Already exists\n04977fb136f9: Already exists\n7fcbac520dff: Already exists\nb5abbd3e01bf: Already exists\n78b25cb932a0: Already exists\n891dbec03ee9: Already exists\n4939c688e3c0: Pulling fs layer\ne857900fbe7f: Pulling fs layer\nf918633b6888: Pulling fs layer\n2bef9cab8039: Pulling fs layer\n5210225062fc: Pulling fs layer\n653decdfec23: Pulling fs layer\nbf68a310bfe6: Pulling fs layer\n9043604ca511: Pulling fs layer\n369b9947b0b4: Pulling fs layer\n8a774528b291: Pulling fs layer\n45b019441493: Pulling fs layer\nbf68a310bfe6: Waiting\n2bef9cab8039: Waiting\n9043604ca511: Waiting\n369b9947b0b4: Waiting\n8a774528b291: Waiting\n45b019441493: Waiting\n5210225062fc: Waiting\n653decdfec23: Waiting\nf918633b6888: Verifying Checksum\nf918633b6888: Download complete\n2bef9cab8039: Verifying Checksum\n2bef9cab8039: Download complete\n5210225062fc: Download complete\n653decdfec23: Verifying Checksum\n653decdfec23: Download complete\n4939c688e3c0: Verifying Checksum\n4939c688e3c0: Download complete\n9043604ca511: Download complete\n369b9947b0b4: Verifying Checksum\n369b9947b0b4: Download complete\n8a774528b291: Verifying Checksum\n8a774528b291: Download complete\n45b019441493: Verifying Checksum\n45b019441493: Download complete\n4939c688e3c0: Pull complete\nbf68a310bfe6: Verifying Checksum\nbf68a310bfe6: Download complete\ne857900fbe7f: Verifying Checksum\ne857900fbe7f: Download complete\ne857900fbe7f: Pull complete\nf918633b6888: Pull complete\n2bef9cab8039: Pull complete\n5210225062fc: Pull complete\n653decdfec23: Pull complete\nbf68a310bfe6: Pull complete\n9043604ca511: Pull complete\n369b9947b0b4: Pull complete\n8a774528b291: Pull complete\n45b019441493: Pull complete\nDigest: sha256:3df6704394356585deaff6927c126ee1981578f17b2311676c5dda34c537b47f\nStatus: Downloaded newer image for anonymous/vllm-baseline:baseline-4ce64e2df486\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 12, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 20, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n  File \"/opt/vllm_baseline/vllm/config.py\", line 32, in <module>\n    from vllm.model_executor.layers.quantization import (QUANTIZATION_METHODS,\n  File \"/opt/vllm_baseline/vllm/model_executor/__init__.py\", line 3, in <module>\n    from vllm.model_executor.parameter import (BasevLLMParameter,\n  File \"/opt/vllm_baseline/vllm/model_executor/parameter.py\", line 9, in <module>\n    from vllm.distributed import get_tensor_model_parallel_rank\n  File \"/opt/vllm_baseline/vllm/distributed/__init__.py\", line 3, in <module>\n    from .communication_op import *\n  File \"/opt/vllm_baseline/vllm/distributed/communication_op.py\", line 8, in <module>\n    from .parallel_state import get_tp_group\n  File \"/opt/vllm_baseline/vllm/distributed/parallel_state.py\", line 150, in <module>\n    from vllm.platforms import current_platform\n  File \"/opt/vllm_baseline/vllm/platforms/__init__.py\", line 278, in __getattr__\n    _current_platform = resolve_obj_by_qualname(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/utils.py\", line 2189, in resolve_obj_by_qualname\n    module = importlib.import_module(module_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/platforms/cuda.py\", line 14, in <module>\n    import vllm._C  # noqa\n    ^^^^^^^^^^^^^^\nImportError: /opt/vllm_baseline/vllm/_C.abi3.so: undefined symbol: cuTensorMapEncodeTiled\n",
  "timestamp": "2026-01-10 13:48:24"
}