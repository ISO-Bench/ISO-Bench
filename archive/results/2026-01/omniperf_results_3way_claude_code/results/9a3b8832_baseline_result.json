{
  "human_commit": "9a3b8832",
  "human_commit_full": "9a3b88328f7e434cac35b90ee463de6689f9a833",
  "parent_commit": "3014c920dae5a2360b9b4141395522cc52b59193",
  "model": "Qwen/Qwen2.5-VL-3B-Instruct",
  "status": "success",
  "error": null,
  "duration_s": 125.8130042552948,
  "metrics": {
    "output_token_throughput_tok_s": 6131.44,
    "ttft_mean_ms": 5300.91,
    "tpot_mean_ms": 23.25,
    "itl_mean_ms": 23.25
  },
  "raw_output": "base_url='http://localhost:8000', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sonnet', dataset_path='/opt/vllm_bench/benchmarks/sonnet.txt', model='Qwen/Qwen2.5-VL-3B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=1000, sharegpt_output_len=None, sonnet_input_len=256, sonnet_output_len=64, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=inf, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, percentile_metrics='ttft,tpot,itl', metric_percentiles='99')\nStarting initial single prompt test run...\nInitial test run completed. Starting main benchmark run...\nTraffic request rate: inf\n\n  0%|          | 0/1000 [00:00<?, ?it/s]\n  0%|          | 1/1000 [00:02<48:47,  2.93s/it]\n  1%|          | 8/1000 [00:03<05:01,  3.29it/s]\n 26%|\u2588\u2588\u258c       | 257/1000 [00:05<00:11, 62.07it/s]\n 26%|\u2588\u2588\u258b       | 264/1000 [00:05<00:12, 58.60it/s]\n 51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 513/1000 [00:08<00:05, 89.10it/s]\n 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 521/1000 [00:08<00:05, 83.09it/s]\n 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 769/1000 [00:10<00:02, 105.36it/s]\n 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 778/1000 [00:10<00:02, 99.96it/s] \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:10<00:00, 95.80it/s]\n============ Serving Benchmark Result ============\nSuccessful requests:                     1000      \nBenchmark duration (s):                  10.44     \nTotal input tokens:                      215000    \nTotal generated tokens:                  64000     \nRequest throughput (req/s):              95.80     \nOutput token throughput (tok/s):         6131.44   \nTotal Token throughput (tok/s):          26729.26  \n---------------Time to First Token----------------\nMean TTFT (ms):                          5300.91   \nMedian TTFT (ms):                        4484.79   \nP99 TTFT (ms):                           8880.55   \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          23.25     \nMedian TPOT (ms):                        23.32     \nP99 TPOT (ms):                           36.26     \n---------------Inter-token Latency----------------\nMean ITL (ms):                           23.25     \nMedian ITL (ms):                         22.29     \nP99 ITL (ms):                            49.67     \n==================================================\nStopping vLLM server...\nBENCHMARK_DONE\n/opt/vllm_bench/benchmarks/benchmark_serving.py:18: SyntaxWarning: invalid escape sequence '\\ '\n  --request-rate <request_rate> \\ # By default <request_rate> is inf\nNamespace(backend='vllm', base_url='http://localhost:8000', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sonnet', dataset_path='/opt/vllm_bench/benchmarks/sonnet.txt', model='Qwen/Qwen2.5-VL-3B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=1000, sharegpt_output_len=None, sonnet_input_len=256, sonnet_output_len=64, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=inf, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, percentile_metrics='ttft,tpot,itl', metric_percentiles='99')\nStarting initial single prompt test run...\nInitial test run completed. Starting main benchmark run...\nTraffic request rate: inf\n\n  0%|          | 0/1000 [00:00<?, ?it/s]\n  0%|          | 1/1000 [00:02<48:47,  2.93s/it]\n  1%|          | 8/1000 [00:03<05:01,  3.29it/s]\n 26%|\u2588\u2588\u258c       | 257/1000 [00:05<00:11, 62.07it/s]\n 26%|\u2588\u2588\u258b       | 264/1000 [00:05<00:12, 58.60it/s]\n 51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 513/1000 [00:08<00:05, 89.10it/s]\n 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 521/1000 [00:08<00:05, 83.09it/s]\n 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 769/1000 [00:10<00:02, 105.36it/s]\n 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 778/1000 [00:10<00:02, 99.96it/s] \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:10<00:00, 95.80it/s]\n============ Serving Benchmark Result ============\nSuccessful requests:                     1000      \nBenchmark duration (s):                  10.44     \nTotal input tokens:                      215000    \nTotal generated tokens:                  64000     \nRequest throughput (req/s):              95.80     \nOutput token throughput (tok/s):         6131.44   \nTotal Token throughput (tok/s):          26729.26  \n---------------Time to First Token----------------\nMean TTFT (ms):                          5300.91   \nMedian TTFT (ms):                        4484.79   \nP99 TTFT (ms):                           8880.55   \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          23.25     \nMedian TPOT (ms):                        23.32     \nP99 TPOT (ms):                           36.26     \n---------------Inter-token Latency----------------\nMean ITL (ms):                           23.25     \nMedian ITL (ms):                         22.29     \nP99 ITL (ms):                            49.67     \n==================================================\n",
  "timestamp": "2026-01-18 14:15:24"
}