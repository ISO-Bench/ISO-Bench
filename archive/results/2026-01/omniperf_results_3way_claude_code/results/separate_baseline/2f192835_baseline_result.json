{
  "human_commit": "2f192835",
  "human_commit_full": "2f1928354903ae0c6edfe76cc90081eb513ead2c",
  "parent_commit": "95baec828f3ee046074dace1d88202a920b7dc15",
  "status": "error",
  "benchmark_type": "serving",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "duration_s": 4.941125869750977,
  "error": "Server crashed during startup",
  "ttft_mean": null,
  "ttft_median": null,
  "ttft_p99": null,
  "tpot_mean": null,
  "tpot_median": null,
  "tpot_p99": null,
  "itl_mean": null,
  "itl_median": null,
  "itl_p99": null,
  "throughput_req_s": null,
  "throughput_tok_s": null,
  "timestamp": "2026-01-09 03:50:20",
  "raw_output": "=== Using cached baseline image (skipping build) ===\n=== Starting vLLM server for BASELINE benchmark ===\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\n    __import__(pkg_name)\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 3, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 6, in <module>\n    from vllm.config import (CacheConfig, DeviceConfig, EngineConfig, LoRAConfig,\n  File \"/opt/vllm_baseline/vllm/config.py\", line 7, in <module>\n    import torch\n  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1477, in <module>\n    from .functional import *  # noqa: F403\n  File \"/usr/local/lib/python3.10/dist-packages/torch/functional.py\", line 9, in <module>\n    import torch.nn.functional as F\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n    from .modules import *  # noqa: F403\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n    from .transformer import TransformerEncoder, TransformerDecoder, \\\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/vllm_baseline/vllm/entrypoints/openai/api_server.py\", line 22, in <module>\n    from vllm.entrypoints.openai.serving_chat import OpenAIServingChat\n  File \"/opt/vllm_baseline/vllm/entrypoints/openai/serving_chat.py\", line 15, in <module>\n    from vllm.model_executor.guided_decoding import (\n  File \"/opt/vllm_baseline/vllm/model_executor/guided_decoding.py\", line 15, in <module>\n    from vllm.model_executor.guided_logits_processors import (CFGLogitsProcessor,\n  File \"/opt/vllm_baseline/vllm/model_executor/guided_logits_processors.py\", line 22, in <module>\n    from outlines.fsm.fsm import CFGFSM, RegexFSM\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/__init__.py\", line 2, in <module>\n    import outlines.generate\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/generate/__init__.py\", line 2, in <module>\n    from .cfg import cfg\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/generate/cfg.py\", line 5, in <module>\n    from outlines.models import OpenAI\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/models/__init__.py\", line 10, in <module>\n    from .azure import AzureOpenAI, azure_openai\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/models/azure.py\", line 7, in <module>\n    from outlines.models.openai import OpenAI, OpenAIConfig\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/models/openai.py\", line 11, in <module>\n    from outlines.base import vectorize\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/base.py\", line 8, in <module>\n    from numpy.lib.function_base import (\nModuleNotFoundError: No module named 'numpy.lib.function_base'\nBASELINE_SERVER_CRASHED\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
}