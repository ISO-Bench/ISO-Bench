{
  "commit": "015069b0",
  "commit_full": "015069b01741e9ecb9e604c7fe87fbdfc306ebe5",
  "parent_commit": "fbefc8a78d22",
  "model": "Qwen/Qwen3-1.7B",
  "model_note": "Corrected from Qwen/Qwen3-7B-Instruct per user",
  "benchmark_type": "serving",
  "dataset": "sharegpt",
  "status": "success",
  "metrics": {
    "successful_requests": 50,
    "benchmark_duration_s": 52.19,
    "total_input_tokens": 12332,
    "total_generated_tokens": 10349,
    "request_throughput_req_s": 0.96,
    "output_token_throughput_tok_s": 198.31,
    "total_token_throughput_tok_s": 434.63,
    "mean_ttft_ms": 10.47,
    "median_ttft_ms": 10.92,
    "p99_ttft_ms": 13.33,
    "mean_tpot_ms": 3.90,
    "median_tpot_ms": 3.88,
    "p99_tpot_ms": 4.08,
    "mean_itl_ms": 3.90,
    "median_itl_ms": 3.90,
    "p99_itl_ms": 4.25
  },
  "docker_image": "anonymous/vllm-baseline:baseline-fbefc8a78d22",
  "benchmark_command": "python3 benchmark_serving.py --backend vllm --model Qwen/Qwen3-1.7B --host localhost --port 8000 --dataset-name sharegpt --dataset-path /data/sharegpt.json --request-rate 1 --num-prompts 50",
  "timestamp": "2026-01-09T05:49:00Z",
  "notes": "Model corrected from Qwen/Qwen3-7B-Instruct to Qwen/Qwen3-1.7B"
}
