{
  "human_commit": "e493e485",
  "human_commit_full": "e493e48524e9e78ab33eafec6461b3940e361189",
  "parent_commit": "4ce64e2df48649c4873f828b8bf71790aa1e56ee",
  "status": "error",
  "benchmark_type": "throughput",
  "model": "microsoft/phi-1_5",
  "duration_s": 2720.3358545303345,
  "error": "No throughput metrics in output",
  "ttft_mean": null,
  "ttft_median": null,
  "ttft_p99": null,
  "tpot_mean": null,
  "tpot_median": null,
  "tpot_p99": null,
  "itl_mean": null,
  "itl_median": null,
  "itl_p99": null,
  "throughput_req_s": null,
  "throughput_tok_s": null,
  "timestamp": "2026-01-08 23:36:51",
  "raw_output": "-no-guided-decoding-disable-any-whitespace]\n                               [--guided-decoding-disable-additional-properties | --no-guided-decoding-disable-additional-properties]\n                               [--enable-reasoning | --no-enable-reasoning]\n                               [--reasoning-parser {deepseek_r1,granite,qwen3}]\n                               [--distributed-executor-backend {external_launcher,mp,ray,uni,None}]\n                               [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]\n                               [--tensor-parallel-size TENSOR_PARALLEL_SIZE]\n                               [--data-parallel-size DATA_PARALLEL_SIZE]\n                               [--data-parallel-size-local DATA_PARALLEL_SIZE_LOCAL]\n                               [--data-parallel-address DATA_PARALLEL_ADDRESS]\n                               [--data-parallel-rpc-port DATA_PARALLEL_RPC_PORT]\n                               [--enable-expert-parallel | --no-enable-expert-parallel]\n                               [--max-parallel-loading-workers MAX_PARALLEL_LOADING_WORKERS]\n                               [--ray-workers-use-nsight | --no-ray-workers-use-nsight]\n                               [--disable-custom-all-reduce | --no-disable-custom-all-reduce]\n                               [--worker-cls WORKER_CLS]\n                               [--worker-extension-cls WORKER_EXTENSION_CLS]\n                               [--block-size {1,8,16,32,64,128}]\n                               [--gpu-memory-utilization GPU_MEMORY_UTILIZATION]\n                               [--swap-space SWAP_SPACE]\n                               [--kv-cache-dtype {auto,fp8,fp8_e4m3,fp8_e5m2}]\n                               [--num-gpu-blocks-override NUM_GPU_BLOCKS_OVERRIDE]\n                               [--enable-prefix-caching | --no-enable-prefix-caching]\n                               [--prefix-caching-hash-algo {builtin,sha256}]\n                               [--cpu-offload-gb CPU_OFFLOAD_GB]\n                               [--calculate-kv-scales | --no-calculate-kv-scales]\n                               [--tokenizer-pool-size TOKENIZER_POOL_SIZE]\n                               [--tokenizer-pool-type TOKENIZER_POOL_TYPE]\n                               [--tokenizer-pool-extra-config TOKENIZER_POOL_EXTRA_CONFIG]\n                               [--limit-mm-per-prompt LIMIT_MM_PER_PROMPT]\n                               [--mm-processor-kwargs MM_PROCESSOR_KWARGS]\n                               [--disable-mm-preprocessor-cache | --no-disable-mm-preprocessor-cache]\n                               [--enable-lora | --no-enable-lora]\n                               [--enable-lora-bias | --no-enable-lora-bias]\n                               [--max-loras MAX_LORAS]\n                               [--max-lora-rank MAX_LORA_RANK]\n                               [--lora-extra-vocab-size LORA_EXTRA_VOCAB_SIZE]\n                               [--lora-dtype {auto,bfloat16,float16}]\n                               [--long-lora-scaling-factors LONG_LORA_SCALING_FACTORS [LONG_LORA_SCALING_FACTORS ...]]\n                               [--max-cpu-loras MAX_CPU_LORAS]\n                               [--fully-sharded-loras | --no-fully-sharded-loras]\n                               [--enable-prompt-adapter | --no-enable-prompt-adapter]\n                               [--max-prompt-adapters MAX_PROMPT_ADAPTERS]\n                               [--max-prompt-adapter-token MAX_PROMPT_ADAPTER_TOKEN]\n                               [--device {auto,cpu,cuda,hpu,neuron,tpu,xpu}]\n                               [--speculative-config SPECULATIVE_CONFIG]\n                               [--show-hidden-metrics-for-version SHOW_HIDDEN_METRICS_FOR_VERSION]\n                               [--otlp-traces-endpoint OTLP_TRACES_ENDPOINT]\n                               [--collect-detailed-traces {all,model,worker,None} [{all,model,worker,None} ...]]\n                               [--max-num-batched-tokens MAX_NUM_BATCHED_TOKENS]\n                               [--max-num-seqs MAX_NUM_SEQS]\n                               [--max-num-partial-prefills MAX_NUM_PARTIAL_PREFILLS]\n                               [--max-long-partial-prefills MAX_LONG_PARTIAL_PREFILLS]\n                               [--cuda-graph-sizes CUDA_GRAPH_SIZES [CUDA_GRAPH_SIZES ...]]\n                               [--long-prefill-token-threshold LONG_PREFILL_TOKEN_THRESHOLD]\n                               [--num-lookahead-slots NUM_LOOKAHEAD_SLOTS]\n                               [--scheduler-delay-factor SCHEDULER_DELAY_FACTOR]\n                               [--preemption-mode {recompute,swap,None}]\n                               [--num-scheduler-steps NUM_SCHEDULER_STEPS]\n                               [--multi-step-stream-outputs | --no-multi-step-stream-outputs]\n                               [--scheduling-policy {fcfs,priority}]\n                               [--enable-chunked-prefill | --no-enable-chunked-prefill]\n                               [--disable-chunked-mm-input | --no-disable-chunked-mm-input]\n                               [--scheduler-cls SCHEDULER_CLS]\n                               [--kv-transfer-config KV_TRANSFER_CONFIG]\n                               [--kv-events-config KV_EVENTS_CONFIG]\n                               [--compilation-config COMPILATION_CONFIG]\n                               [--additional-config ADDITIONAL_CONFIG]\n                               [--use-v2-block-manager] [--disable-log-stats]\n                               [--disable-log-requests]\nbenchmark_throughput.py: error: unrecognized arguments: python benchmarks/benchmark_serving.py\nUnable to find image 'anonymous/vllm-baseline:e493e48524e9e78ab33eafec6461b3940e361189' locally\ne493e48524e9e78ab33eafec6461b3940e361189: Pulling from anonymous/vllm-baseline\n9cb31e2e37ea: Already exists\nb95112eaf283: Already exists\n030ef8250936: Already exists\n72ac9ccfda38: Already exists\n73389fbd088f: Already exists\n0264850675f7: Already exists\nde1d03310308: Already exists\nc1d2af7fad0f: Already exists\n5601308b3ac6: Already exists\n6b2035e8b73e: Already exists\ned71f8f81b33: Already exists\na04181a7ff83: Already exists\nb89dfbaf9e2c: Already exists\ndc1d202b3ed0: Already exists\nad0178e8a361: Already exists\ne4a092a24edb: Already exists\ncd9db290845e: Already exists\nefae73abea6f: Pulling fs layer\n00e7621a9cc3: Pulling fs layer\n1a270b3605fe: Pulling fs layer\nccfda7d8bfa7: Pulling fs layer\n04977fb136f9: Pulling fs layer\n7fcbac520dff: Pulling fs layer\nb5abbd3e01bf: Pulling fs layer\n78b25cb932a0: Pulling fs layer\n891dbec03ee9: Pulling fs layer\n4939c688e3c0: Pulling fs layer\n04977fb136f9: Waiting\n7fcbac520dff: Waiting\nb5abbd3e01bf: Waiting\n78b25cb932a0: Waiting\n891dbec03ee9: Waiting\nccfda7d8bfa7: Waiting\n4939c688e3c0: Waiting\n00e7621a9cc3: Verifying Checksum\n00e7621a9cc3: Download complete\n1a270b3605fe: Verifying Checksum\n1a270b3605fe: Download complete\nccfda7d8bfa7: Verifying Checksum\nccfda7d8bfa7: Download complete\n7fcbac520dff: Verifying Checksum\n7fcbac520dff: Download complete\n04977fb136f9: Verifying Checksum\n04977fb136f9: Download complete\nb5abbd3e01bf: Verifying Checksum\nb5abbd3e01bf: Download complete\n78b25cb932a0: Verifying Checksum\n78b25cb932a0: Download complete\n891dbec03ee9: Verifying Checksum\n891dbec03ee9: Download complete\n4939c688e3c0: Verifying Checksum\n4939c688e3c0: Download complete\nefae73abea6f: Verifying Checksum\nefae73abea6f: Download complete\nefae73abea6f: Pull complete\n00e7621a9cc3: Pull complete\n1a270b3605fe: Pull complete\nccfda7d8bfa7: Pull complete\n04977fb136f9: Pull complete\n7fcbac520dff: Pull complete\nb5abbd3e01bf: Pull complete\n78b25cb932a0: Pull complete\n891dbec03ee9: Pull complete\n4939c688e3c0: Pull complete\nDigest: sha256:2c3f3cd2fca0c66023a86686ed0775a5f6b59c3b3b944e1ce0bdc3520246a720\nStatus: Downloaded newer image for anonymous/vllm-baseline:e493e48524e9e78ab33eafec6461b3940e361189\ndebconf: delaying package configuration, since apt-utils is not installed\nFrom https://github.com/vllm-project/vllm\n * branch            4ce64e2df48649c4873f828b8bf71790aa1e56ee -> FETCH_HEAD\nNote: switching to '4ce64e2df48649c4873f828b8bf71790aa1e56ee'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at 4ce64e2 [Bugfix][Model] Fix baichuan model loader for tp (#18597)\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n\n[notice] A new release of pip is available: 25.2 -> 25.3\n[notice] To update, run: python3.12 -m pip install --upgrade pip\nUsing Python 3.12.11 environment at: /usr\nUninstalled 1 package in 137ms\n - vllm==0.0.0+local (from file:///vllm-workspace/dist/vllm-0.0.0+local-cp38-abi3-linux_x86_64.whl)\nUsing Python 3.12.11 environment at: /usr\nAudited 5 packages in 8ms\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n\n[notice] A new release of pip is available: 25.2 -> 25.3\n[notice] To update, run: python3.12 -m pip install --upgrade pip\n"
}