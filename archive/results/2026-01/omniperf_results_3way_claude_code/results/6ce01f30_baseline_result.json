{
  "human_commit": "6ce01f30",
  "human_commit_full": "6ce01f30667bbae33f112152e07a3b66b841078f",
  "parent_commit": "6a11fdfbb8d6701c7ad38648aead23d8cbe6aac5",
  "model": "meta-llama/Meta-Llama-3-8B",
  "status": "error",
  "error": "No serving metrics in output",
  "duration_s": 322.4627652168274,
  "metrics": {},
  "raw_output": "nflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n\n[notice] A new release of pip is available: 25.2 -> 25.3\n[notice] To update, run: python3 -m pip install --upgrade pip\nInstalling pyairports pycountry...\nRequirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (0.0.1)\nRequirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (24.6.1)\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n\n[notice] A new release of pip is available: 25.2 -> 25.3\n[notice] To update, run: python3 -m pip install --upgrade pip\nDone installing dependencies\nStarted vLLM server with PID 133\nWaiting for server... (5/300)\nWaiting for server... (10/300)\nWaiting for server... (15/300)\nWaiting for server... (20/300)\nWaiting for server... (25/300)\nWaiting for server... (30/300)\nWaiting for server... (35/300)\nWaiting for server... (40/300)\nWaiting for server... (45/300)\nWaiting for server... (50/300)\nWaiting for server... (55/300)\nWaiting for server... (60/300)\nWaiting for server... (65/300)\nWaiting for server... (70/300)\nWaiting for server... (75/300)\nWaiting for server... (80/300)\nWaiting for server... (85/300)\nWaiting for server... (90/300)\nWaiting for server... (95/300)\nWaiting for server... (100/300)\nWaiting for server... (105/300)\nWaiting for server... (110/300)\nWaiting for server... (115/300)\nWaiting for server... (120/300)\nWaiting for server... (125/300)\nWaiting for server... (130/300)\nWaiting for server... (135/300)\nWaiting for server... (140/300)\nWaiting for server... (145/300)\nWaiting for server... (150/300)\nWaiting for server... (155/300)\nWaiting for server... (160/300)\nWaiting for server... (165/300)\nWaiting for server... (170/300)\nWaiting for server... (175/300)\nWaiting for server... (180/300)\nWaiting for server... (185/300)\nWaiting for server... (190/300)\nWaiting for server... (195/300)\nWaiting for server... (200/300)\nWaiting for server... (205/300)\nWaiting for server... (210/300)\nWaiting for server... (215/300)\nWaiting for server... (220/300)\nWaiting for server... (225/300)\nWaiting for server... (230/300)\nWaiting for server... (235/300)\nWaiting for server... (240/300)\nWaiting for server... (245/300)\nWaiting for server... (250/300)\nWaiting for server... (255/300)\nWaiting for server... (260/300)\nWaiting for server... (265/300)\nWaiting for server... (270/300)\nWaiting for server... (275/300)\nWaiting for server... (280/300)\nWaiting for server... (285/300)\nWaiting for server... (290/300)\nWaiting for server... (295/300)\nWaiting for server... (300/300)\nERROR: Server failed to start within 300 seconds\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/vllm_baseline/vllm/entrypoints/openai/api_server.py\", line 23, in <module>\n    from vllm.entrypoints.openai.cli_args import make_arg_parser\n  File \"/opt/vllm_baseline/vllm/entrypoints/openai/cli_args.py\", line 12, in <module>\n    from vllm.entrypoints.openai.serving_engine import (LoRAModulePath,\n  File \"/opt/vllm_baseline/vllm/entrypoints/openai/serving_engine.py\", line 28, in <module>\n    from vllm.model_executor.guided_decoding import (\n  File \"/opt/vllm_baseline/vllm/model_executor/guided_decoding/__init__.py\", line 6, in <module>\n    from vllm.model_executor.guided_decoding.lm_format_enforcer_decoding import (\n  File \"/opt/vllm_baseline/vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py\", line 15, in <module>\n    from vllm.model_executor.guided_decoding.outlines_decoding import (\n  File \"/opt/vllm_baseline/vllm/model_executor/guided_decoding/outlines_decoding.py\", line 13, in <module>\n    from vllm.model_executor.guided_decoding.outlines_logits_processors import (\n  File \"/opt/vllm_baseline/vllm/model_executor/guided_decoding/outlines_logits_processors.py\", line 24, in <module>\n    from outlines.caching import cache\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/__init__.py\", line 5, in <module>\n    import outlines.types\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/types/__init__.py\", line 1, in <module>\n    from . import airports, countries\n  File \"/usr/local/lib/python3.10/dist-packages/outlines/types/airports.py\", line 4, in <module>\n    from pyairports.airports import AIRPORT_LIST\nModuleNotFoundError: No module named 'pyairports'\nSERVER_START_FAILED\n",
  "timestamp": "2026-01-18 16:23:47"
}