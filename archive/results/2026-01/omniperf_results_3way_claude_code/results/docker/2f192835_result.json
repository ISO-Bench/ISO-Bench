{
  "commit_hash": "2f1928354903ae0c6edfe76cc90081eb513ead2c",
  "status": "incompatible",
  "benchmark_type": "serving",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "fix_applied": "numpy<2 downgrade",
  "error": "vLLM 0.4.0.post1 has fundamental model compatibility issues - rope_scaling format and cache engine bugs prevent running with modern models",
  "timestamp": "2026-01-05 17:46:39"
}
