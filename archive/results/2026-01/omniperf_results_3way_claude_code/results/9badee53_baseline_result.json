{
  "human_commit": "9badee53",
  "human_commit_full": "9badee53decb3d432dc805336abfb0eb81dfb48f",
  "parent_commit": "beebf4742af80296d3c3a657c66d512615c550c1",
  "model": "meta-llama/Llama-3.2-1B-Instruct",
  "status": "success",
  "error": null,
  "duration_s": 63.86362957954407,
  "metrics": {
    "output_token_throughput_tok_s": 10588.27,
    "ttft_mean_ms": 2894.68,
    "tpot_mean_ms": 18.21,
    "itl_mean_ms": 18.19
  },
  "raw_output": ":01, 251.88it/s]\n 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 719/1000 [00:05<00:01, 269.93it/s]\n 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 758/1000 [00:05<00:00, 290.57it/s]\n 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 790/1000 [00:05<00:01, 151.58it/s]\n 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 857/1000 [00:05<00:00, 230.93it/s]\n 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 982/1000 [00:06<00:00, 411.70it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:06<00:00, 165.44it/s]\n============ Serving Benchmark Result ============\nSuccessful requests:                     1000      \nBenchmark duration (s):                  6.04      \nTotal input tokens:                      231000    \nTotal generated tokens:                  64000     \nRequest throughput (req/s):              165.44    \nOutput token throughput (tok/s):         10588.27  \nTotal Token throughput (tok/s):          48805.31  \n---------------Time to First Token----------------\nMean TTFT (ms):                          2894.68   \nMedian TTFT (ms):                        2744.14   \nP99 TTFT (ms):                           5268.14   \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          18.21     \nMedian TPOT (ms):                        19.07     \nP99 TPOT (ms):                           19.69     \n---------------Inter-token Latency----------------\nMean ITL (ms):                           18.19     \nMedian ITL (ms):                         14.86     \nP99 ITL (ms):                            31.15     \n==================================================\nStopping vLLM server...\nBENCHMARK_DONE\n/opt/vllm_bench/benchmarks/benchmark_serving.py:18: SyntaxWarning: invalid escape sequence '\\ '\n  --request-rate <request_rate> \\ # By default <request_rate> is inf\nINFO 01-18 06:16:15 [__init__.py:253] Automatically detected platform cuda.\nNamespace(backend='vllm', base_url='http://localhost:8000', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sonnet', dataset_path='/opt/vllm_bench/benchmarks/sonnet.txt', model='meta-llama/Llama-3.2-1B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=1000, sharegpt_output_len=None, sonnet_input_len=256, sonnet_output_len=64, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=inf, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, metadata=None, result_dir=None, result_filename=None, percentile_metrics='ttft,tpot,itl', metric_percentiles='99')\nStarting initial single prompt test run...\nInitial test run completed. Starting main benchmark run...\nTraffic request rate: inf\n\n  0%|          | 0/1000 [00:00<?, ?it/s]\n  0%|          | 1/1000 [00:01<32:56,  1.98s/it]\n  1%|\u258f         | 14/1000 [00:02<01:47,  9.15it/s]\n  6%|\u258c         | 58/1000 [00:02<00:20, 45.80it/s]\n 10%|\u2588         | 101/1000 [00:02<00:10, 85.75it/s]\n 14%|\u2588\u258d        | 143/1000 [00:02<00:06, 126.60it/s]\n 18%|\u2588\u258a        | 183/1000 [00:02<00:04, 163.98it/s]\n 22%|\u2588\u2588\u258f       | 223/1000 [00:02<00:03, 199.39it/s]\n 26%|\u2588\u2588\u258c       | 257/1000 [00:03<00:06, 121.29it/s]\n 28%|\u2588\u2588\u258a       | 281/1000 [00:03<00:05, 130.95it/s]\n 32%|\u2588\u2588\u2588\u258f      | 316/1000 [00:03<00:04, 159.48it/s]\n 36%|\u2588\u2588\u2588\u258c      | 355/1000 [00:03<00:03, 192.23it/s]\n 40%|\u2588\u2588\u2588\u2589      | 395/1000 [00:03<00:02, 210.46it/s]\n 44%|\u2588\u2588\u2588\u2588\u258d     | 442/1000 [00:03<00:02, 254.97it/s]\n 48%|\u2588\u2588\u2588\u2588\u258a     | 481/1000 [00:03<00:01, 272.64it/s]\n 51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 513/1000 [00:04<00:03, 145.14it/s]\n 54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 537/1000 [00:04<00:03, 151.92it/s]\n 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 571/1000 [00:04<00:02, 176.20it/s]\n 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 602/1000 [00:04<00:01, 200.67it/s]\n 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 641/1000 [00:04<00:01, 229.47it/s]\n 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 680/1000 [00:05<00:01, 251.88it/s]\n 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 719/1000 [00:05<00:01, 269.93it/s]\n 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 758/1000 [00:05<00:00, 290.57it/s]\n 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 790/1000 [00:05<00:01, 151.58it/s]\n 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 857/1000 [00:05<00:00, 230.93it/s]\n 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 982/1000 [00:06<00:00, 411.70it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:06<00:00, 165.44it/s]\n============ Serving Benchmark Result ============\nSuccessful requests:                     1000      \nBenchmark duration (s):                  6.04      \nTotal input tokens:                      231000    \nTotal generated tokens:                  64000     \nRequest throughput (req/s):              165.44    \nOutput token throughput (tok/s):         10588.27  \nTotal Token throughput (tok/s):          48805.31  \n---------------Time to First Token----------------\nMean TTFT (ms):                          2894.68   \nMedian TTFT (ms):                        2744.14   \nP99 TTFT (ms):                           5268.14   \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          18.21     \nMedian TPOT (ms):                        19.07     \nP99 TPOT (ms):                           19.69     \n---------------Inter-token Latency----------------\nMean ITL (ms):                           18.19     \nMedian ITL (ms):                         14.86     \nP99 ITL (ms):                            31.15     \n==================================================\n",
  "timestamp": "2026-01-18 14:16:27"
}