{
  "human_commit": "2deb029d",
  "human_commit_full": "2deb029d115dadd012ce5ea70487a207cb025493",
  "parent_commit": "029c71de11bc3bcf84a1b3cf9d91e79ab6949799",
  "model": "RedHatAI/Meta-Llama-3-8B-Instruct-FP8",
  "status": "success",
  "error": null,
  "duration_s": 254.57323551177979,
  "metrics": {
    "input_throughput_tok_s": 16727.7,
    "throughput_tok_s": 5186.87,
    "elapsed_time_s": 3.9213526248931885
  },
  "raw_output": "m up------\n\nProcessed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\nProcessed prompts:   1%|          | 1/100 [00:03<06:16,  3.81s/it, est. speed input: 169.38 toks/s, output: 52.52 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03<00:00, 26.25it/s, est. speed input: 16930.67 toks/s, output: 5249.81 toks/s]\ncost time 3.8798890113830566\n------start generating------\n\nProcessed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\nProcessed prompts:   1%|          | 1/100 [00:03<06:21,  3.85s/it, est. speed input: 167.35 toks/s, output: 51.89 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03<00:00, 25.93it/s, est. speed input: 16727.70 toks/s, output: 5186.87 toks/s]\ncost time 3.9213526248931885\nBENCHMARK_DONE\nINFO 01-19 07:55:54 llm_engine.py:194] Initializing an LLM engine (v0.5.5) with config: model='RedHatAI/Meta-Llama-3-8B-Instruct-FP8', speculative_config=None, tokenizer='RedHatAI/Meta-Llama-3-8B-Instruct-FP8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=RedHatAI/Meta-Llama-3-8B-Instruct-FP8, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=True)\nINFO 01-19 07:55:55 model_runner.py:879] Starting to load model RedHatAI/Meta-Llama-3-8B-Instruct-FP8...\nWARNING 01-19 07:55:55 fp8.py:46] Detected fp8 checkpoint. Please note that the format is experimental and subject to change.\nINFO 01-19 07:55:55 weight_utils.py:236] Using model weights format ['*.safetensors']\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.98it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.52it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.57it/s]\n\nINFO 01-19 07:56:06 model_runner.py:890] Loading model weights took 8.4596 GB\nINFO 01-19 07:56:07 gpu_executor.py:121] # GPU blocks: 31150, # CPU blocks: 2048\nINFO 01-19 07:56:09 block_manager_v1.py:263] Automatic prefix caching is enabled.\nTesting filtered datasets\n------warm up------\n\nProcessed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\nProcessed prompts:   1%|          | 1/100 [00:03<06:16,  3.81s/it, est. speed input: 169.38 toks/s, output: 52.52 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03<00:00, 26.25it/s, est. speed input: 16930.67 toks/s, output: 5249.81 toks/s]\ncost time 3.8798890113830566\n------start generating------\n\nProcessed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\nProcessed prompts:   1%|          | 1/100 [00:03<06:21,  3.85s/it, est. speed input: 167.35 toks/s, output: 51.89 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03<00:00, 25.93it/s, est. speed input: 16727.70 toks/s, output: 5186.87 toks/s]\ncost time 3.9213526248931885\nUnable to find image 'anonymous/vllm-baseline:baseline-029c71de11bc' locally\nbaseline-029c71de11bc: Pulling from anonymous/vllm-baseline\nf838dcd8c06f: Pulling fs layer\na9d2c68a1bc5: Pulling fs layer\n408650cf297c: Pulling fs layer\n1925415c388f: Pulling fs layer\n0e01e0e535dd: Pulling fs layer\n9abcd34352ed: Pulling fs layer\nfd4221a803b7: Pulling fs layer\naae24386184f: Pulling fs layer\ne7d6081f7476: Pulling fs layer\nf0e985ba8be1: Pulling fs layer\n5fb8a651a289: Pulling fs layer\ne39f3f578bc8: Pulling fs layer\ne39f3f578bc8: Download complete\n9abcd34352ed: Download complete\n1925415c388f: Download complete\nf0e985ba8be1: Download complete\naae24386184f: Download complete\nf838dcd8c06f: Download complete\ne7d6081f7476: Download complete\n0e01e0e535dd: Download complete\na9d2c68a1bc5: Download complete\n408650cf297c: Download complete\n5fb8a651a289: Download complete\n5fb8a651a289: Pull complete\n0e01e0e535dd: Pull complete\nfd4221a803b7: Download complete\n408650cf297c: Pull complete\nf838dcd8c06f: Pull complete\nfd4221a803b7: Pull complete\naae24386184f: Pull complete\ne39f3f578bc8: Pull complete\nf0e985ba8be1: Pull complete\ne7d6081f7476: Pull complete\na9d2c68a1bc5: Pull complete\n9abcd34352ed: Pull complete\n1925415c388f: Pull complete\nDigest: sha256:1eb02ee1fadcf0f6c9188bcaca328df7a2d421a3973ac273056bb4da8128f883\nStatus: Downloaded newer image for anonymous/vllm-baseline:baseline-029c71de11bc\n",
  "timestamp": "2026-01-19 15:56:24"
}