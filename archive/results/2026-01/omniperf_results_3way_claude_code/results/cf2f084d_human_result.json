{
  "human_commit": "cf2f084d",
  "human_commit_full": "cf2f084d56a1293cb08da2393984cdc7685ac019",
  "parent_commit": "f721096d48a7e3b98dffcb9b400bf58989cef64d",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "status": "error",
  "error": "Server crashed during startup",
  "duration_s": 219.74393939971924,
  "metrics": {},
  "raw_output": "Applying aimv2 compatibility fix (pre-import)...\nChecking vLLM compatibility...\nvLLM api_server imports OK - no compatibility fixes needed\nDetecting vLLM version...\nFound vLLM at: /workspace/vllm\nFixing rope_scaling compatibility for Llama-3.1 models...\n  Patching: /workspace/vllm/model_executor/layers/rotary_embedding.py\n  Patching: /workspace/vllm/config.py\nSearching for Python with vLLM...\nFound vLLM at: /usr/bin/python3\nvLLM version: 0.3.3 at /workspace/vllm\nvLLM 0.3.3 OK\nFixing outlines.fsm compatibility (fsm.guide missing)...\nFound existing installation: outlines 0.0.34\nUninstalling outlines-0.0.34:\n  Successfully uninstalled outlines-0.0.34\nCollecting outlines==0.0.34\n  Downloading outlines-0.0.34-py3-none-any.whl (76 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 76.5/76.5 KB 4.3 MB/s eta 0:00:00\nInstalling collected packages: outlines\nSuccessfully installed outlines-0.0.34\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWarning: outlines.fsm fix failed - trying alternative approach...\nDownloading benchmark scripts...\nBenchmark scripts downloaded\ntotal 8\ndrwxr-xr-x 2 root root 4096 Jan 19 17:32 .\ndrwxr-xr-x 3 root root 4096 Jan 19 17:32 ..\nCreating sonnet dataset...\n=== Starting vLLM server for HUMAN benchmark ===\n/usr/bin/python3: Error while finding module specification for 'vllm.entrypoints.openai.api_server' (ModuleNotFoundError: No module named 'vllm')\nSERVER_CRASHED\nUnable to find image 'anonymous/vllm-bench:cf2f084d56a1293cb08da2393984cdc7685ac019' locally\ncf2f084d56a1293cb08da2393984cdc7685ac019: Pulling from anonymous/vllm-bench\ne3eef04d9f0a: Pulling fs layer\n86dff5f500e9: Pulling fs layer\na03ec84e77d0: Pulling fs layer\n9800f3929d8c: Pulling fs layer\n06176ad0d495: Pulling fs layer\n8e2b65f8d9d3: Pulling fs layer\ne556129a5305: Pulling fs layer\nc834972e083f: Pulling fs layer\ne556129a5305: Download complete\nc834972e083f: Download complete\ne3eef04d9f0a: Download complete\na03ec84e77d0: Download complete\n06176ad0d495: Download complete\n8e2b65f8d9d3: Download complete\n9800f3929d8c: Download complete\ne556129a5305: Pull complete\nc834972e083f: Pull complete\n9800f3929d8c: Pull complete\n86dff5f500e9: Download complete\n86dff5f500e9: Pull complete\n8e2b65f8d9d3: Pull complete\na03ec84e77d0: Pull complete\ne3eef04d9f0a: Pull complete\n06176ad0d495: Pull complete\nDigest: sha256:c09ac2b5ce9562b3822367c2793f3f5f9333d013248c74654dce1d89d6810390\nStatus: Downloaded newer image for anonymous/vllm-bench:cf2f084d56a1293cb08da2393984cdc7685ac019\n",
  "timestamp": "2026-01-19 17:32:59"
}