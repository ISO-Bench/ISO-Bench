2026-01-03 15:31:51,729 | INFO | ================================================================================
2026-01-03 15:31:51,729 | INFO | HERO BENCHMARK RUN
2026-01-03 15:31:51,729 | INFO | Start time: 2026-01-03T15:31:51.729333
2026-01-03 15:31:51,729 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_153151.log
2026-01-03 15:31:51,729 | INFO | ================================================================================
2026-01-03 15:31:51,729 | INFO | Loaded 59 commits from plan
2026-01-03 15:31:51,729 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
Using the latest cached version of the dataset since ISO-Bench/ISO-Bench couldn't be found on the Hugging Face Hub
2026-01-03 15:32:03,804 | WARNING | Using the latest cached version of the dataset since ISO-Bench/ISO-Bench couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'vllm' at /home/ubuntu/.cache/huggingface/datasets/ISO-Bench___omniperf_v1/vllm/0.0.0/8735bd19aefce609ea1fa7e332d95baa1cd83c2c (last modified on Sat Jan  3 12:15:04 2026).
2026-01-03 15:32:03,805 | WARNING | Found the latest cached dataset configuration 'vllm' at /home/ubuntu/.cache/huggingface/datasets/ISO-Bench___omniperf_v1/vllm/0.0.0/8735bd19aefce609ea1fa7e332d95baa1cd83c2c (last modified on Sat Jan  3 12:15:04 2026).
2026-01-03 15:32:03,871 | INFO | 
*** PARALLEL MODE: 15 concurrent benchmarks ***
2026-01-03 15:32:03,871 | INFO | Spawning Modal containers in parallel...
2026-01-03 15:32:03,872 | INFO | [015069b0] Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 15:32:03,873 | INFO | [0ec82edd] Fixing model name: Qwen/Qwen3-30B-A3B -> Qwen/Qwen3-30B-A3B-Instruct-2507
2026-01-03 15:32:03,876 | INFO | [0d243f2a] Starting benchmark | Model: mistralai/Mixtral-8x7B-Instruct-v0.1 | GPU: H100:2
2026-01-03 15:32:03,876 | INFO | [0ec82edd] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-Instruct-2507 | GPU: H100:2
2026-01-03 15:32:03,877 | INFO | [22d33bac] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:32:03,878 | INFO | [296f927f] Starting benchmark | Model: ibm-ai-platform/Bamba-9B-v2 | GPU: H100:1
2026-01-03 15:32:03,878 | INFO | [22dd9c27] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:32:03,878 | INFO | [21d93c14] Starting benchmark | Model: mistralai/Mixtral-8x7B-v0.1 | GPU: H100:8
2026-01-03 15:32:03,879 | INFO | [015069b0] Starting benchmark | Model: mergekit-community/Qwen3-7B-Instruct | GPU: H100:1
2026-01-03 15:32:03,880 | INFO | [3092375e] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:32:03,881 | INFO | [2a052011] Starting benchmark | Model: nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8 | GPU: H100:2
2026-01-03 15:32:03,882 | INFO | [3476ed08] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:32:03,882 | INFO | [2deb029d] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 15:32:03,882 | INFO | [2f192835] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:32:03,883 | INFO | [379da6dc] Starting benchmark | Model: meta-llama/Llama-3-70B | GPU: H100:4
2026-01-03 15:32:03,883 | INFO | [35fad35a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:32:03,884 | INFO | [3a243095] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:32:04,080 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 15:32:04,080 | INFO |   Baseline wheel: 005ae9be
2026-01-03 15:32:04,080 | INFO |   Human wheel: 0d243f2a
2026-01-03 15:32:04,080 | INFO |   Human wheel: 0ec82edd
2026-01-03 15:32:04,080 | INFO |   GPU config: H100:2
2026-01-03 15:32:04,080 | INFO |   Baseline wheel: b0e96aae
2026-01-03 15:32:04,081 | INFO |   GPU config: H100:2
2026-01-03 15:32:04,081 | INFO |   Baseline wheel: a6d795d5
2026-01-03 15:32:04,081 | INFO |   Baseline wheel: f1c85201
2026-01-03 15:32:04,081 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 15:32:04,081 | INFO |   Baseline wheel: 0032903a
2026-01-03 15:32:04,081 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 15:32:04,081 | INFO |   Baseline wheel: 3cd91dc9
2026-01-03 15:32:04,081 | INFO |   Human wheel: 22d33bac
2026-01-03 15:32:04,081 | INFO |   Baseline wheel: 36fb68f9
2026-01-03 15:32:04,081 | INFO |   Command preview: vllm bench throughput --model Qwen/Qwen3-30B-A3B-Instruct-2507 --load-format dummy --input-len 1000 ...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 15:32:04,081 | INFO |   Baseline wheel: 54600709
2026-01-03 15:32:04,082 | INFO |   Human wheel: 22dd9c27
2026-01-03 15:32:04,082 | INFO |   Baseline wheel: 029c71de
2026-01-03 15:32:04,082 | INFO |   Human wheel: 21d93c14
2026-01-03 15:32:04,082 | INFO |   Baseline wheel: 95baec82
2026-01-03 15:32:04,082 | INFO |   Baseline wheel: ebce310b
2026-01-03 15:32:04,082 | INFO |   Baseline wheel: 733e7c9e
2026-01-03 15:32:04,082 | INFO |   Human wheel: 015069b0
2026-01-03 15:32:04,082 | INFO |   Baseline wheel: 64172a97
2026-01-03 15:32:04,082 | INFO |   Human wheel: 296f927f
2026-01-03 15:32:04,083 | INFO |   Human wheel: 3092375e
2026-01-03 15:32:04,083 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,083 | INFO |   Human wheel: 2a052011
2026-01-03 15:32:04,084 | INFO |   Human wheel: 3476ed08
2026-01-03 15:32:04,084 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,084 | INFO |   Human wheel: 2deb029d
2026-01-03 15:32:04,084 | INFO |   GPU config: H100:8
2026-01-03 15:32:04,084 | INFO |   Human wheel: 2f192835
2026-01-03 15:32:04,084 | INFO |   Human wheel: 379da6dc
2026-01-03 15:32:04,084 | INFO |   Human wheel: 35fad35a
2026-01-03 15:32:04,084 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,084 | INFO |   Human wheel: 3a243095
2026-01-03 15:32:04,084 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,084 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,084 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,085 | INFO |   GPU config: H100:2
2026-01-03 15:32:04,085 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,085 | INFO |   Command preview: VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --mo...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,085 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,085 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model mistralai/Mixtral-8x7B-v0.1 --tensor-parallel-size...
Running 3-way benchmark on Modal with H100:8...
2026-01-03 15:32:04,085 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,085 | INFO |   GPU config: H100:4
2026-01-03 15:32:04,085 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,085 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,085 | INFO |   GPU config: H100:1
2026-01-03 15:32:04,085 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dataset-name sharegpt...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,085 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,086 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 15:32:04,086 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,086 | INFO |   Command preview: python benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --out...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,087 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,087 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-70B --dtype float8 --input-len 100...
Running 3-way benchmark on Modal with H100:4...
2026-01-03 15:32:04,087 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:32:04,087 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
