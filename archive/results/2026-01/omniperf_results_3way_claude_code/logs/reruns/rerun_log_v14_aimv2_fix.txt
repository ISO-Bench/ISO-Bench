2026-01-03 17:41:03,790 | INFO | ================================================================================
2026-01-03 17:41:03,790 | INFO | HERO BENCHMARK RUN
2026-01-03 17:41:03,790 | INFO | Start time: 2026-01-03T17:41:03.790339
2026-01-03 17:41:03,790 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_174103.log
2026-01-03 17:41:03,790 | INFO | ================================================================================
2026-01-03 17:41:03,790 | INFO | Loaded 59 commits from plan
2026-01-03 17:41:03,790 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2026-01-03 17:41:06,417 | INFO | 
*** PARALLEL MODE: 15 concurrent benchmarks ***
2026-01-03 17:41:06,417 | INFO | Spawning Modal containers in parallel...
2026-01-03 17:41:06,417 | INFO | [015069b0] Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 17:41:06,418 | INFO | [0ec82edd] Fixing model name: Qwen/Qwen3-30B-A3B -> Qwen/Qwen3-30B-A3B-Instruct-2507
2026-01-03 17:41:06,421 | INFO | [0d243f2a] Starting benchmark | Model: mistralai/Mixtral-8x7B-Instruct-v0.1 | GPU: H100:2
2026-01-03 17:41:06,421 | INFO | [015069b0] Starting benchmark | Model: mergekit-community/Qwen3-7B-Instruct | GPU: H100:1
2026-01-03 17:41:06,421 | INFO | [0ec82edd] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-Instruct-2507 | GPU: H100:2
2026-01-03 17:41:06,422 | INFO | [21d93c14] Starting benchmark | Model: mistralai/Mixtral-8x7B-v0.1 | GPU: H100:8
2026-01-03 17:41:06,422 | INFO | [22d33bac] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:41:06,423 | INFO | [22dd9c27] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:41:06,423 | INFO | [296f927f] Starting benchmark | Model: ibm-ai-platform/Bamba-9B-v2 | GPU: H100:1
2026-01-03 17:41:06,425 | INFO | [2deb029d] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 17:41:06,425 | INFO | [2a052011] Starting benchmark | Model: nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8 | GPU: H100:2
2026-01-03 17:41:06,427 | INFO | [3092375e] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:41:06,427 | INFO | [2f192835] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:41:06,427 | INFO | [35fad35a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:41:06,428 | INFO | [379da6dc] Starting benchmark | Model: meta-llama/Llama-3-70B | GPU: H100:4
2026-01-03 17:41:06,429 | INFO | [3476ed08] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:41:06,429 | INFO | [3a243095] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:41:06,623 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 17:41:06,623 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 17:41:06,623 | INFO |   Human wheel: 0d243f2a
2026-01-03 17:41:06,623 | INFO |   Human wheel: 015069b0
2026-01-03 17:41:06,623 | INFO |   Baseline wheel: 005ae9be
2026-01-03 17:41:06,623 | INFO |   GPU config: H100:2
2026-01-03 17:41:06,623 | INFO |   Baseline wheel: f1c85201
2026-01-03 17:41:06,623 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: a6d795d5
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: b0e96aae
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: 0032903a
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: 029c71de
2026-01-03 17:41:06,624 | INFO |   Human wheel: 0ec82edd
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: 36fb68f9
2026-01-03 17:41:06,624 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: 3cd91dc9
2026-01-03 17:41:06,624 | INFO |   Human wheel: 21d93c14
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: 95baec82
2026-01-03 17:41:06,624 | INFO |   Baseline wheel: 733e7c9e
2026-01-03 17:41:06,625 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,625 | INFO |   Baseline wheel: ebce310b
2026-01-03 17:41:06,625 | INFO |   Human wheel: 22dd9c27
2026-01-03 17:41:06,625 | INFO |   Baseline wheel: 54600709
2026-01-03 17:41:06,625 | INFO |   Human wheel: 22d33bac
2026-01-03 17:41:06,625 | INFO |   Baseline wheel: 64172a97
2026-01-03 17:41:06,625 | INFO |   Human wheel: 296f927f
2026-01-03 17:41:06,625 | INFO |   Human wheel: 2deb029d
2026-01-03 17:41:06,625 | INFO |   GPU config: H100:2
2026-01-03 17:41:06,625 | INFO |   Human wheel: 2a052011
2026-01-03 17:41:06,626 | INFO |   Human wheel: 3092375e
2026-01-03 17:41:06,626 | INFO |   GPU config: H100:8
2026-01-03 17:41:06,626 | INFO |   Human wheel: 2f192835
2026-01-03 17:41:06,626 | INFO |   Human wheel: 35fad35a
2026-01-03 17:41:06,627 | INFO |   Human wheel: 379da6dc
2026-01-03 17:41:06,627 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,627 | INFO |   Human wheel: 3476ed08
2026-01-03 17:41:06,627 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,627 | INFO |   Human wheel: 3a243095
2026-01-03 17:41:06,627 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,627 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,627 | INFO |   Command preview: vllm bench throughput --model Qwen/Qwen3-30B-A3B-Instruct-2507 --load-format dummy --input-len 1000 ...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:41:06,627 | INFO |   GPU config: H100:2
2026-01-03 17:41:06,628 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,628 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model mistralai/Mixtral-8x7B-v0.1 --tensor-parallel-size...
Running 3-way benchmark on Modal with H100:8...
2026-01-03 17:41:06,628 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,628 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,628 | INFO |   GPU config: H100:4
2026-01-03 17:41:06,628 | INFO |   Command preview: VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --mo...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,628 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,628 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,628 | INFO |   GPU config: H100:1
2026-01-03 17:41:06,628 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dataset-name sharegpt...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,628 | INFO |   Command preview: python benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --out...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,629 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:41:06,629 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,629 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,629 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,629 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-70B --dtype float8 --input-len 100...
Running 3-way benchmark on Modal with H100:4...
2026-01-03 17:41:06,630 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:41:06,630 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 029c71de, will build from source
[URL CHECK] Baseline wheel URL does not exist for ebce310b, will build from source
[URL CHECK] Baseline wheel URL does not exist for 64172a97, will build from source
[URL CHECK] Baseline wheel URL does not exist for 54600709, will build from source
[URL CHECK] Baseline wheel URL does not exist for 36fb68f9, will build from source
[URL CHECK] Baseline wheel URL does not exist for 95baec82, will build from source
[URL CHECK] Baseline wheel URL does not exist for f1c85201, will build from source
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 0d243f2a, will build from source
[CPU PRE-BUILD] Building human 0d243f2a on CPU...
[ENSURE BUILD] Checking/building vLLM 0d243f2a on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 379da6dc, will build from source
[CPU PRE-BUILD] Building baseline ebce310b on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM ebce310b on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 2deb029d, will build from source
[CPU PRE-BUILD] Building baseline 029c71de on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 029c71de on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 2f192835, will build from source
[CPU PRE-BUILD] Building baseline 95baec82 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 95baec82 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 2a052011, will build from source
[CPU PRE-BUILD] Building baseline 36fb68f9 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 36fb68f9 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 3476ed08, will build from source
[CPU PRE-BUILD] Building baseline 54600709 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 54600709 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 3a243095, will build from source
[CPU PRE-BUILD] Building baseline 64172a97 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 64172a97 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 21d93c14, will build from source
[CPU PRE-BUILD] Building baseline f1c85201 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM f1c85201 on CPU-only instance...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Cache HIT: vLLM 0.7.3.dev241+g0d243f2a5.d20220101.cu124 already cached
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=url, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Baseline build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Building human 21d93c14 on CPU...
[ENSURE BUILD] Checking/building vLLM 21d93c14 on CPU-only instance...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Human build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Wheel sources: baseline=None, human=None, agent=None
Using Docker image fallback for 21d93c14
Using Docker image fallback: anonymous/vllm-bench:21d93c140d0a
  Human commit: 21d93c140d0a97af5f0c59e660cf04bd417fd424
  Base commit: f1c8520146031a650404a6ab120ee11e91c10bed
Creating Modal Sandbox with H100 x 8...
Running 3-way benchmark in sandbox...
Writing benchmark script to sandbox (22808 chars)...
Exception traceback: Traceback (most recent call last):
  File "/home/ubuntu/OmniPerf-Bench/src/eval/modal_benchmark.py", line 5588, in run_3way_benchmark_docker_fallback
    f = sb.open(script_path, "w")
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/sandbox.py", line 1108, in open
    return await _FileIO.create(path, mode, self._client, task_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 239, in create
    await self._open_file(path, mode)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 230, in _open_file
    await self._wait(resp.exec_id)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 201, in _wait
    raise data
modal.exception.FilesystemExecutionError: request cancelled due to internal error

2026-01-03 17:42:45,816 | INFO | 
2026-01-03 17:42:45,816 | INFO | ================================================================================
2026-01-03 17:42:45,817 | INFO | [1/59] COMPLETED: 21d93c14
2026-01-03 17:42:45,817 | INFO | Subject: Optimize Mixtral with expert parallelism (#2090)
2026-01-03 17:42:45,817 | ERROR |   ❌ ERROR: Docker fallback failed: request cancelled due to internal error
2026-01-03 17:42:45,817 | INFO |   Progress: 0 success, 1 errors (1/59)
2026-01-03 17:42:45,818 | INFO | [4fb56914] Starting benchmark | Model: deepseek-ai/DeepSeek-V3-0324 | GPU: H100:8
2026-01-03 17:42:45,819 | INFO |   Baseline wheel: 0df4d9b0
2026-01-03 17:42:45,819 | INFO |   Human wheel: 4fb56914
2026-01-03 17:42:45,819 | INFO |   GPU config: H100:8
2026-01-03 17:42:45,819 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V3-0324 --dataset-name sharegpt ...
[BLOCKED] Model deepseek-ai/DeepSeek-V3-0324 is blocked (too large/unstable), skipping benchmark
2026-01-03 17:42:45,819 | INFO | 
2026-01-03 17:42:45,819 | INFO | ================================================================================
2026-01-03 17:42:45,819 | INFO | [2/59] COMPLETED: 4fb56914
2026-01-03 17:42:45,819 | INFO | Subject: [perf] Add fused MLA QKV + strided layernorm (#21116)
2026-01-03 17:42:45,819 | ERROR |   ❌ BLOCKED_MODEL: Model deepseek-ai/DeepSeek-V3-0324 is blocked: too large or unstable for reliable benchmarking
2026-01-03 17:42:45,820 | INFO |   Progress: 0 success, 2 errors (2/59)
2026-01-03 17:42:45,821 | INFO | [526de822] Starting benchmark | Model: MODEL | GPU: H100:1
2026-01-03 17:42:45,821 | INFO |   Baseline wheel: 56fe4c29
2026-01-03 17:42:45,821 | INFO |   Human wheel: 526de822
2026-01-03 17:42:45,821 | INFO |   GPU config: H100:1
2026-01-03 17:42:45,821 | INFO |   Command preview: python benchmarks/benchmark_latency.py --dtype bfloat16 --enable-chunked-prefill False --load-format...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 17:43:08,935 | INFO | 
2026-01-03 17:43:08,935 | INFO | ================================================================================
2026-01-03 17:43:08,935 | INFO | [3/59] COMPLETED: 22dd9c27
2026-01-03 17:43:08,936 | INFO | Subject: [Kernel] Optimize Prefill Attention in Unified Triton Attent
2026-01-03 17:43:08,936 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 17:43:08,936 | INFO |   Progress: 0 success, 3 errors (3/59)
2026-01-03 17:43:08,938 | INFO | [660470e5] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:43:08,938 | INFO |   Baseline wheel: 8d59dbb0
2026-01-03 17:43:08,938 | INFO |   Human wheel: 660470e5
2026-01-03 17:43:08,938 | INFO |   GPU config: H100:1
2026-01-03 17:43:08,938 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --tensor-parallel-si...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 8d59dbb0, will build from source
[URL CHECK] Human wheel URL does not exist for 660470e5, will build from source
[CPU PRE-BUILD] Building baseline 8d59dbb0 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 8d59dbb0 on CPU-only instance...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 17:44:47,197 | INFO | 
2026-01-03 17:44:47,197 | INFO | ================================================================================
2026-01-03 17:44:47,197 | INFO | [4/59] COMPLETED: 526de822
2026-01-03 17:44:47,197 | INFO | Subject: [Kernel][Triton][AMD] Use block size heuristic for avg 2.8x 
2026-01-03 17:44:47,197 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 17:44:47,197 | INFO |   Progress: 0 success, 4 errors (4/59)
2026-01-03 17:44:47,199 | INFO | [67da5720] Starting benchmark | Model: Qwen/Qwen2.5-VL-3B-Instruct | GPU: H100:1
2026-01-03 17:44:47,199 | INFO |   Baseline wheel: 5c04bb8b
2026-01-03 17:44:47,199 | INFO |   Human wheel: 67da5720
2026-01-03 17:44:47,199 | INFO |   GPU config: H100:1
2026-01-03 17:44:47,199 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-VL-3B-Instruct --dataset-name sharegpt -...
