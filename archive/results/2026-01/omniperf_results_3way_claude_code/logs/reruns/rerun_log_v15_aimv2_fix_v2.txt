2026-01-03 17:51:29,333 | INFO | ================================================================================
2026-01-03 17:51:29,333 | INFO | HERO BENCHMARK RUN
2026-01-03 17:51:29,333 | INFO | Start time: 2026-01-03T17:51:29.333402
2026-01-03 17:51:29,333 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_175129.log
2026-01-03 17:51:29,333 | INFO | ================================================================================
2026-01-03 17:51:29,333 | INFO | Loaded 59 commits from plan
2026-01-03 17:51:29,333 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2026-01-03 17:51:32,520 | INFO | 
*** PARALLEL MODE: 15 concurrent benchmarks ***
2026-01-03 17:51:32,520 | INFO | Spawning Modal containers in parallel...
2026-01-03 17:51:32,520 | INFO | [015069b0] Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 17:51:32,521 | INFO | [0ec82edd] Fixing model name: Qwen/Qwen3-30B-A3B -> Qwen/Qwen3-30B-A3B-Instruct-2507
2026-01-03 17:51:32,524 | INFO | [015069b0] Starting benchmark | Model: mergekit-community/Qwen3-7B-Instruct | GPU: H100:1
2026-01-03 17:51:32,524 | INFO | [21d93c14] Starting benchmark | Model: mistralai/Mixtral-8x7B-v0.1 | GPU: H100:8
2026-01-03 17:51:32,525 | INFO | [0ec82edd] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-Instruct-2507 | GPU: H100:2
2026-01-03 17:51:32,525 | INFO | [0d243f2a] Starting benchmark | Model: mistralai/Mixtral-8x7B-Instruct-v0.1 | GPU: H100:2
2026-01-03 17:51:32,526 | INFO | [22dd9c27] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:51:32,526 | INFO | [296f927f] Starting benchmark | Model: ibm-ai-platform/Bamba-9B-v2 | GPU: H100:1
2026-01-03 17:51:32,526 | INFO | [22d33bac] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:51:32,528 | INFO | [2deb029d] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 17:51:32,529 | INFO | [2a052011] Starting benchmark | Model: nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8 | GPU: H100:2
2026-01-03 17:51:32,529 | INFO | [3092375e] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:51:32,529 | INFO | [2f192835] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:51:32,530 | INFO | [3476ed08] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:51:32,531 | INFO | [379da6dc] Starting benchmark | Model: meta-llama/Llama-3-70B | GPU: H100:4
2026-01-03 17:51:32,531 | INFO | [35fad35a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:51:32,532 | INFO | [3a243095] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:51:32,730 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 17:51:32,730 | INFO |   Baseline wheel: f1c85201
2026-01-03 17:51:32,730 | INFO |   Human wheel: 015069b0
2026-01-03 17:51:32,730 | INFO |   Human wheel: 21d93c14
2026-01-03 17:51:32,730 | INFO |   Baseline wheel: 005ae9be
2026-01-03 17:51:32,730 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,730 | INFO |   GPU config: H100:8
2026-01-03 17:51:32,730 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 17:51:32,731 | INFO |   Human wheel: 0ec82edd
2026-01-03 17:51:32,731 | INFO |   Baseline wheel: 0032903a
2026-01-03 17:51:32,731 | INFO |   Baseline wheel: b0e96aae
2026-01-03 17:51:32,731 | INFO |   Baseline wheel: a6d795d5
2026-01-03 17:51:32,731 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,731 | INFO |   Baseline wheel: 029c71de
2026-01-03 17:51:32,731 | INFO |   Baseline wheel: 36fb68f9
2026-01-03 17:51:32,731 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model mistralai/Mixtral-8x7B-v0.1 --tensor-parallel-size...
Running 3-way benchmark on Modal with H100:8...
2026-01-03 17:51:32,731 | INFO |   Baseline wheel: 3cd91dc9
2026-01-03 17:51:32,731 | INFO |   Human wheel: 0d243f2a
2026-01-03 17:51:32,731 | INFO |   Baseline wheel: 95baec82
2026-01-03 17:51:32,732 | INFO |   GPU config: H100:2
2026-01-03 17:51:32,732 | INFO |   Baseline wheel: 54600709
2026-01-03 17:51:32,732 | INFO |   Human wheel: 296f927f
2026-01-03 17:51:32,732 | INFO |   Baseline wheel: ebce310b
2026-01-03 17:51:32,732 | INFO |   Human wheel: 22d33bac
2026-01-03 17:51:32,732 | INFO |   Human wheel: 22dd9c27
2026-01-03 17:51:32,732 | INFO |   Baseline wheel: 733e7c9e
2026-01-03 17:51:32,732 | INFO |   Baseline wheel: 64172a97
2026-01-03 17:51:32,733 | INFO |   Human wheel: 2deb029d
2026-01-03 17:51:32,733 | INFO |   Human wheel: 2a052011
2026-01-03 17:51:32,733 | INFO |   Human wheel: 3092375e
2026-01-03 17:51:32,733 | INFO |   GPU config: H100:2
2026-01-03 17:51:32,734 | INFO |   Human wheel: 2f192835
2026-01-03 17:51:32,734 | INFO |   Command preview: vllm bench throughput --model Qwen/Qwen3-30B-A3B-Instruct-2507 --load-format dummy --input-len 1000 ...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:51:32,734 | INFO |   Human wheel: 3476ed08
2026-01-03 17:51:32,734 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,734 | INFO |   Human wheel: 379da6dc
2026-01-03 17:51:32,734 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,734 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,734 | INFO |   Human wheel: 35fad35a
2026-01-03 17:51:32,734 | INFO |   Human wheel: 3a243095
2026-01-03 17:51:32,734 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,734 | INFO |   GPU config: H100:2
2026-01-03 17:51:32,734 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,734 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:51:32,734 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,735 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,735 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dataset-name sharegpt...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,735 | INFO |   GPU config: H100:4
2026-01-03 17:51:32,735 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,735 | INFO |   Command preview: VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --mo...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,735 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,735 | INFO |   GPU config: H100:1
2026-01-03 17:51:32,735 | INFO |   Command preview: python benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --out...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,736 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:51:32,736 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,736 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,736 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,737 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-70B --dtype float8 --input-len 100...
Running 3-way benchmark on Modal with H100:4...
2026-01-03 17:51:32,737 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:51:32,738 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
