2026-01-03 18:20:41,123 | INFO | ================================================================================
2026-01-03 18:20:41,123 | INFO | HERO BENCHMARK RUN
2026-01-03 18:20:41,123 | INFO | Start time: 2026-01-03T18:20:41.123378
2026-01-03 18:20:41,123 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_182041.log
2026-01-03 18:20:41,123 | INFO | ================================================================================
2026-01-03 18:20:41,123 | INFO | Loaded 59 commits from plan
2026-01-03 18:20:41,123 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2026-01-03 18:20:43,641 | INFO | 
*** PARALLEL MODE: 15 concurrent benchmarks ***
2026-01-03 18:20:43,641 | INFO | Spawning Modal containers in parallel...
2026-01-03 18:20:43,642 | INFO | [015069b0] Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 18:20:43,643 | INFO | [0ec82edd] Fixing model name: Qwen/Qwen3-30B-A3B -> Qwen/Qwen3-30B-A3B-Instruct-2507
2026-01-03 18:20:43,645 | INFO | [0d243f2a] Starting benchmark | Model: mistralai/Mixtral-8x7B-Instruct-v0.1 | GPU: H100:2
2026-01-03 18:20:43,646 | INFO | [0ec82edd] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-Instruct-2507 | GPU: H100:2
2026-01-03 18:20:43,646 | INFO | [21d93c14] Starting benchmark | Model: mistralai/Mixtral-8x7B-v0.1 | GPU: H100:8
2026-01-03 18:20:43,647 | INFO | [015069b0] Starting benchmark | Model: mergekit-community/Qwen3-7B-Instruct | GPU: H100:1
2026-01-03 18:20:43,647 | INFO | [22dd9c27] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:20:43,647 | INFO | [22d33bac] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:20:43,648 | INFO | [296f927f] Starting benchmark | Model: ibm-ai-platform/Bamba-9B-v2 | GPU: H100:1
2026-01-03 18:20:43,649 | INFO | [2deb029d] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 18:20:43,650 | INFO | [2a052011] Starting benchmark | Model: nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8 | GPU: H100:2
2026-01-03 18:20:43,650 | INFO | [2f192835] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:20:43,651 | INFO | [3092375e] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:20:43,652 | INFO | [35fad35a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:20:43,653 | INFO | [3476ed08] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:20:43,654 | INFO | [379da6dc] Starting benchmark | Model: meta-llama/Llama-3-70B | GPU: H100:4
2026-01-03 18:20:43,654 | INFO | [3a243095] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:20:43,851 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 18:20:43,852 | INFO |   Baseline wheel: 005ae9be
2026-01-03 18:20:43,852 | INFO |   Human wheel: 0d243f2a
2026-01-03 18:20:43,852 | INFO |   Human wheel: 0ec82edd
2026-01-03 18:20:43,852 | INFO |   GPU config: H100:2
2026-01-03 18:20:43,852 | INFO |   GPU config: H100:2
2026-01-03 18:20:43,852 | INFO |   Baseline wheel: f1c85201
2026-01-03 18:20:43,852 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 18:20:43,852 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 18:20:43,852 | INFO |   Command preview: vllm bench throughput --model Qwen/Qwen3-30B-A3B-Instruct-2507 --load-format dummy --input-len 1000 ...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 18:20:43,852 | INFO |   Baseline wheel: a6d795d5
2026-01-03 18:20:43,853 | INFO |   Human wheel: 21d93c14
2026-01-03 18:20:43,853 | INFO |   Baseline wheel: b0e96aae
2026-01-03 18:20:43,853 | INFO |   Baseline wheel: 0032903a
2026-01-03 18:20:43,853 | INFO |   Baseline wheel: 029c71de
2026-01-03 18:20:43,853 | INFO |   Human wheel: 015069b0
2026-01-03 18:20:43,854 | INFO |   Baseline wheel: 36fb68f9
2026-01-03 18:20:43,854 | INFO |   Baseline wheel: 95baec82
2026-01-03 18:20:43,854 | INFO |   Baseline wheel: 3cd91dc9
2026-01-03 18:20:43,854 | INFO |   Human wheel: 22dd9c27
2026-01-03 18:20:43,855 | INFO |   Baseline wheel: 733e7c9e
2026-01-03 18:20:43,855 | INFO |   GPU config: H100:8
2026-01-03 18:20:43,855 | INFO |   Baseline wheel: 54600709
2026-01-03 18:20:43,855 | INFO |   Baseline wheel: ebce310b
2026-01-03 18:20:43,855 | INFO |   Human wheel: 22d33bac
2026-01-03 18:20:43,855 | INFO |   Baseline wheel: 64172a97
2026-01-03 18:20:43,855 | INFO |   Human wheel: 296f927f
2026-01-03 18:20:43,855 | INFO |   Human wheel: 2deb029d
2026-01-03 18:20:43,855 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,856 | INFO |   Human wheel: 2a052011
2026-01-03 18:20:43,856 | INFO |   Human wheel: 2f192835
2026-01-03 18:20:43,856 | INFO |   Human wheel: 3092375e
2026-01-03 18:20:43,856 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,856 | INFO |   Human wheel: 35fad35a
2026-01-03 18:20:43,856 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model mistralai/Mixtral-8x7B-v0.1 --tensor-parallel-size...
Running 3-way benchmark on Modal with H100:8...
2026-01-03 18:20:43,856 | INFO |   Human wheel: 3476ed08
2026-01-03 18:20:43,856 | INFO |   Human wheel: 379da6dc
2026-01-03 18:20:43,856 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,857 | INFO |   Human wheel: 3a243095
2026-01-03 18:20:43,857 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,857 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,857 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,857 | INFO |   GPU config: H100:2
2026-01-03 18:20:43,857 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,857 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,857 | INFO |   Command preview: VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --mo...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,857 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,858 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,858 | INFO |   GPU config: H100:4
2026-01-03 18:20:43,858 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,858 | INFO |   GPU config: H100:1
2026-01-03 18:20:43,858 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dataset-name sharegpt...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,858 | INFO |   Command preview: python benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --out...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,859 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 18:20:43,859 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,859 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,860 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,860 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:20:43,860 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-70B --dtype float8 --input-len 100...
Running 3-way benchmark on Modal with H100:4...
2026-01-03 18:20:43,860 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for f1c85201, will build from source
[URL CHECK] Baseline wheel URL does not exist for 95baec82, will build from source
[URL CHECK] Baseline wheel URL does not exist for 54600709, will build from source
[URL CHECK] Baseline wheel URL does not exist for 36fb68f9, will build from source
[URL CHECK] Baseline wheel URL does not exist for 029c71de, will build from source
[URL CHECK] Baseline wheel URL does not exist for 64172a97, will build from source
[URL CHECK] Baseline wheel URL does not exist for ebce310b, will build from source
[URL CHECK] Human wheel URL does not exist for 21d93c14, will build from source
[CPU PRE-BUILD] Building baseline f1c85201 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM f1c85201 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 0d243f2a, will build from source
[CPU PRE-BUILD] Building human 0d243f2a on CPU...
[ENSURE BUILD] Checking/building vLLM 0d243f2a on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 379da6dc, will build from source
[CPU PRE-BUILD] Building baseline ebce310b on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM ebce310b on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 3a243095, will build from source
[CPU PRE-BUILD] Building baseline 64172a97 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 64172a97 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 3476ed08, will build from source
[CPU PRE-BUILD] Building baseline 54600709 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 54600709 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 2f192835, will build from source
[CPU PRE-BUILD] Building baseline 95baec82 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 95baec82 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 2a052011, will build from source
[CPU PRE-BUILD] Building baseline 36fb68f9 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 36fb68f9 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 2deb029d, will build from source
[CPU PRE-BUILD] Building baseline 029c71de on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 029c71de on CPU-only instance...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Cache HIT: vLLM 0.7.3.dev241+g0d243f2a5.d20220101.cu124 already cached
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=url, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Baseline build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Building human 21d93c14 on CPU...
[ENSURE BUILD] Checking/building vLLM 21d93c14 on CPU-only instance...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Human build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Wheel sources: baseline=None, human=None, agent=None
Using Docker image fallback for 21d93c14
Using Docker image fallback: anonymous/vllm-bench:21d93c140d0a
  Human commit: 21d93c140d0a97af5f0c59e660cf04bd417fd424
  Base commit: f1c8520146031a650404a6ab120ee11e91c10bed
Creating Modal Sandbox with H100 x 8...
Running 3-way benchmark in sandbox...
Writing benchmark script to sandbox (22808 chars)...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 3a243095 on CPU...
[ENSURE BUILD] Checking/building vLLM 3a243095 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.0.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 2f192835 on CPU...
[ENSURE BUILD] Checking/building vLLM 2f192835 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 379da6dc on CPU...
[ENSURE BUILD] Checking/building vLLM 379da6dc on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 2a052011 on CPU...
[ENSURE BUILD] Checking/building vLLM 2a052011 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.4.0.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:4...
[PARALLEL] Starting 3-way parallel benchmark with H100:4...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 3476ed08 on CPU...
[ENSURE BUILD] Checking/building vLLM 3476ed08 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
Exception traceback: Traceback (most recent call last):
  File "/home/ubuntu/OmniPerf-Bench/src/eval/modal_benchmark.py", line 5678, in run_3way_benchmark_docker_fallback
    f = sb.open(script_path, "w")
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/sandbox.py", line 1108, in open
    return await _FileIO.create(path, mode, self._client, task_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 239, in create
    await self._open_file(path, mode)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 230, in _open_file
    await self._wait(resp.exec_id)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 201, in _wait
    raise data
modal.exception.FilesystemExecutionError: request cancelled due to internal error

2026-01-03 18:39:22,681 | INFO | 
2026-01-03 18:39:22,681 | INFO | ================================================================================
2026-01-03 18:39:22,681 | INFO | [1/59] COMPLETED: 21d93c14
2026-01-03 18:39:22,681 | INFO | Subject: Optimize Mixtral with expert parallelism (#2090)
2026-01-03 18:39:22,681 | ERROR |   ❌ ERROR: Docker fallback failed: request cancelled due to internal error
2026-01-03 18:39:22,682 | INFO |   Progress: 0 success, 1 errors (1/59)
2026-01-03 18:39:22,683 | INFO | [4fb56914] Starting benchmark | Model: deepseek-ai/DeepSeek-V3-0324 | GPU: H100:8
2026-01-03 18:39:22,683 | INFO |   Baseline wheel: 0df4d9b0
2026-01-03 18:39:22,683 | INFO |   Human wheel: 4fb56914
2026-01-03 18:39:22,683 | INFO |   GPU config: H100:8
2026-01-03 18:39:22,683 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V3-0324 --dataset-name sharegpt ...
[BLOCKED] Model deepseek-ai/DeepSeek-V3-0324 is blocked (too large/unstable), skipping benchmark
2026-01-03 18:39:22,683 | INFO | 
2026-01-03 18:39:22,683 | INFO | ================================================================================
2026-01-03 18:39:22,683 | INFO | [2/59] COMPLETED: 4fb56914
2026-01-03 18:39:22,684 | INFO | Subject: [perf] Add fused MLA QKV + strided layernorm (#21116)
2026-01-03 18:39:22,684 | ERROR |   ❌ BLOCKED_MODEL: Model deepseek-ai/DeepSeek-V3-0324 is blocked: too large or unstable for reliable benchmarking
2026-01-03 18:39:22,684 | INFO |   Progress: 0 success, 2 errors (2/59)
2026-01-03 18:39:22,685 | INFO | [526de822] Starting benchmark | Model: MODEL | GPU: H100:1
2026-01-03 18:39:22,685 | INFO |   Baseline wheel: 56fe4c29
2026-01-03 18:39:22,685 | INFO |   Human wheel: 526de822
2026-01-03 18:39:22,685 | INFO |   GPU config: H100:1
2026-01-03 18:39:22,685 | INFO |   Command preview: python benchmarks/benchmark_latency.py --dtype bfloat16 --enable-chunked-prefill False --load-format...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 18:47:29,997 | INFO | 
2026-01-03 18:47:29,998 | INFO | ================================================================================
2026-01-03 18:47:29,998 | INFO | [3/59] COMPLETED: 2a052011
2026-01-03 18:47:29,998 | INFO | Subject: [Kernel] Support MoE Fp8 Checkpoints for Mixtral (Static Wei
2026-01-03 18:47:29,998 | ERROR |   ❌ BASELINE_FAILED: baseline: No metrics; human: No metrics
2026-01-03 18:47:29,998 | INFO |   Progress: 0 success, 3 errors (3/59)
2026-01-03 18:47:30,000 | INFO | [660470e5] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:47:30,000 | INFO |   Baseline wheel: 8d59dbb0
2026-01-03 18:47:30,000 | INFO |   Human wheel: 660470e5
2026-01-03 18:47:30,000 | INFO |   GPU config: H100:1
2026-01-03 18:47:30,000 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --tensor-parallel-si...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 8d59dbb0, will build from source
[URL CHECK] Human wheel URL does not exist for 660470e5, will build from source
[CPU PRE-BUILD] Building baseline 8d59dbb0 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 8d59dbb0 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=success
[PARALLEL] Waiting for human...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 18:56:39,823 | INFO | 
2026-01-03 18:56:39,823 | INFO | ================================================================================
2026-01-03 18:56:39,823 | INFO | [4/59] COMPLETED: 22dd9c27
2026-01-03 18:56:39,823 | INFO | Subject: [Kernel] Optimize Prefill Attention in Unified Triton Attent
2026-01-03 18:56:39,823 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 18:56:39,824 | INFO |   Progress: 0 success, 4 errors (4/59)
2026-01-03 18:56:39,825 | INFO | [67da5720] Starting benchmark | Model: Qwen/Qwen2.5-VL-3B-Instruct | GPU: H100:1
2026-01-03 18:56:39,825 | INFO |   Baseline wheel: 5c04bb8b
2026-01-03 18:56:39,825 | INFO |   Human wheel: 67da5720
2026-01-03 18:56:39,825 | INFO |   GPU config: H100:1
2026-01-03 18:56:39,825 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-VL-3B-Instruct --dataset-name sharegpt -...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 18:58:04,998 | INFO | 
2026-01-03 18:58:04,998 | INFO | ================================================================================
2026-01-03 18:58:04,998 | INFO | [5/59] COMPLETED: 526de822
2026-01-03 18:58:04,998 | INFO | Subject: [Kernel][Triton][AMD] Use block size heuristic for avg 2.8x 
2026-01-03 18:58:04,998 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 18:58:04,999 | INFO |   Progress: 0 success, 5 errors (5/59)
2026-01-03 18:58:05,001 | INFO | [6ce01f30] Starting benchmark | Model: meta-llama/Llama-3-8B | GPU: H100:1
2026-01-03 18:58:05,001 | INFO |   Baseline wheel: 6a11fdfb
2026-01-03 18:58:05,001 | INFO |   Human wheel: 6ce01f30
2026-01-03 18:58:05,001 | INFO |   GPU config: H100:1
2026-01-03 18:58:05,001 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-8B --backend vllm --num-prompts 10...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 6a11fdfb, will build from source
[URL CHECK] Human wheel URL does not exist for 6ce01f30, will build from source
[CPU PRE-BUILD] Building baseline 6a11fdfb on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 6a11fdfb on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.4+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 660470e5 on CPU...
[ENSURE BUILD] Checking/building vLLM 660470e5 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.3.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 6ce01f30 on CPU...
[ENSURE BUILD] Checking/building vLLM 6ce01f30 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.4+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.3.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 19:40:43,266 | INFO | 
2026-01-03 19:40:43,266 | INFO | ================================================================================
2026-01-03 19:40:43,266 | INFO | [6/59] COMPLETED: 379da6dc
2026-01-03 19:40:43,266 | INFO | Subject: [Kernel] [FP8] Improve FP8 linear layer performance (#4691)
2026-01-03 19:40:43,266 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed; human: Server failed
2026-01-03 19:40:43,267 | INFO |   Progress: 0 success, 6 errors (6/59)
2026-01-03 19:40:43,269 | INFO | [6d646d08] Starting benchmark | Model: meta-llama/Llama-3-8B | GPU: H100:1
2026-01-03 19:40:43,269 | INFO |   Baseline wheel: 95a178f8
2026-01-03 19:40:43,269 | INFO |   Human wheel: 6d646d08
2026-01-03 19:40:43,269 | INFO |   GPU config: H100:1
2026-01-03 19:40:43,269 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-8B --dataset-name sharegpt --multi...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 95a178f8, will build from source
[URL CHECK] Human wheel URL does not exist for 6d646d08, will build from source
[CPU PRE-BUILD] Building baseline 95a178f8 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 95a178f8 on CPU-only instance...
[PARALLEL] human completed: status=error
2026-01-03 19:46:07,050 | INFO | 
2026-01-03 19:46:07,050 | INFO | ================================================================================
2026-01-03 19:46:07,050 | INFO | [7/59] COMPLETED: 0d243f2a
2026-01-03 19:46:07,050 | INFO | Subject: [ROCm][MoE] mi300 mixtral8x7B perf for specific BS
2026-01-03 19:46:07,050 | ERROR |   ❌ HUMAN_FAILED: human: Server failed to start
2026-01-03 19:46:07,050 | INFO |   Progress: 0 success, 7 errors (7/59)
2026-01-03 19:46:07,052 | INFO | [6e36f4fa] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 19:46:07,052 | INFO |   Baseline wheel: dd2a6a82
2026-01-03 19:46:07,052 | INFO |   Human wheel: 6e36f4fa
2026-01-03 19:46:07,052 | INFO |   GPU config: H100:1
2026-01-03 19:46:07,052 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for dd2a6a82, will build from source
[URL CHECK] Human wheel URL does not exist for 6e36f4fa, will build from source
[CPU PRE-BUILD] Building baseline dd2a6a82 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM dd2a6a82 on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 19:46:21,489 | INFO | 
2026-01-03 19:46:21,489 | INFO | ================================================================================
2026-01-03 19:46:21,489 | INFO | [8/59] COMPLETED: 0ec82edd
2026-01-03 19:46:21,489 | INFO | Subject: [perf] Speed up align sum kernels (#21079)
2026-01-03 19:46:21,489 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start; human: Server failed to start
2026-01-03 19:46:21,490 | INFO |   Progress: 0 success, 8 errors (8/59)
2026-01-03 19:46:21,492 | INFO | [7c01f706] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 19:46:21,492 | INFO |   Baseline wheel: 51e971d3
2026-01-03 19:46:21,492 | INFO |   Human wheel: 7c01f706
2026-01-03 19:46:21,492 | INFO |   GPU config: H100:1
2026-01-03 19:46:21,492 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 51e971d3, will build from source
[URL CHECK] Human wheel URL does not exist for 7c01f706, will build from source
[CPU PRE-BUILD] Building baseline 51e971d3 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 51e971d3 on CPU-only instance...
[ENSURE BUILD] Exception: Task's current input in-01KE2HE8QKKAZPX3JX8TYC3S9Q:1767464444665-0 hit its timeout of 5400s
[ENSURE BUILD] Traceback:
Traceback (most recent call last):
  File "/home/ubuntu/OmniPerf-Bench/src/eval/modal_benchmark.py", line 4130, in ensure_vllm_build_cached
    result = fn.remote(commit_hash, force_build_dir=force_build_dir)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/_object.py", line 340, in wrapped
    return await method(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/_functions.py", line 1766, in remote
    return await self._call_function(args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/_functions.py", line 1710, in _call_function
    return await invocation.run_function()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/_functions.py", line 293, in run_function
    return await _process_result(item.result, item.data_format, self.stub, self.client)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/_utils/function_utils.py", line 491, in _process_result
    raise FunctionTimeoutError(result.exception)
modal.exception.FunctionTimeoutError: Task's current input in-01KE2HE8QKKAZPX3JX8TYC3S9Q:1767464444665-0 hit its timeout of 5400s

[CPU PRE-BUILD] WARNING: Baseline build failed: Task's current input in-01KE2HE8QKKAZPX3JX8TYC3S9Q:1767464444665-0 hit its timeout of 5400s
[CPU PRE-BUILD] Building human 2deb029d on CPU...
[ENSURE BUILD] Checking/building vLLM 2deb029d on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 19:55:47,199 | INFO | 
2026-01-03 19:55:47,200 | INFO | ================================================================================
2026-01-03 19:55:47,200 | INFO | [9/59] COMPLETED: 3a243095
2026-01-03 19:55:47,200 | INFO | Subject: Optimize `_get_ranks` in Sampler (#3623)
2026-01-03 19:55:47,200 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 19:55:47,200 | INFO |   Progress: 0 success, 9 errors (9/59)
2026-01-03 19:55:47,202 | INFO | [80aa7e91] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 19:55:47,202 | INFO |   Baseline wheel: bd439735
2026-01-03 19:55:47,202 | INFO |   Human wheel: 80aa7e91
2026-01-03 19:55:47,202 | INFO |   GPU config: H100:1
2026-01-03 19:55:47,202 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for bd439735, will build from source
[URL CHECK] Human wheel URL does not exist for 80aa7e91, will build from source
[CPU PRE-BUILD] Building baseline bd439735 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM bd439735 on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 19:55:52,749 | INFO | 
2026-01-03 19:55:52,749 | INFO | ================================================================================
2026-01-03 19:55:52,749 | INFO | [10/59] COMPLETED: 35fad35a
2026-01-03 19:55:52,749 | INFO | Subject: [V1][Sampler] Faster top-k only implementation (#1
2026-01-03 19:55:52,749 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 19:55:52,750 | INFO |   Progress: 0 success, 10 errors (10/59)
2026-01-03 19:55:52,751 | INFO | [83450458] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 19:55:52,751 | INFO |   Baseline wheel: 5b8a1fde
2026-01-03 19:55:52,751 | INFO |   Human wheel: 83450458
2026-01-03 19:55:52,751 | INFO |   GPU config: H100:1
2026-01-03 19:55:52,751 | INFO |   Command preview: python benchmarks/benchmark_latency.py --model meta-llama/Llama-3.1-8B-Instruct --speculative-model ...
Running 3-way benchmark on Modal with H100:1...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 19:55:52,772 | INFO | 
2026-01-03 19:55:52,772 | INFO | ================================================================================
2026-01-03 19:55:52,772 | INFO | [11/59] COMPLETED: 22d33bac
2026-01-03 19:55:52,772 | INFO | Subject: [FrontEnd][Perf] `merge_async_iterators` fast-path
2026-01-03 19:55:52,772 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 19:55:52,773 | INFO |   Progress: 0 success, 11 errors (11/59)
2026-01-03 19:55:52,774 | INFO | [89a84b0b] Starting benchmark | Model: Qwen/Qwen1.5-0.5B | GPU: H100:1
2026-01-03 19:55:52,774 | INFO |   Baseline wheel: 084a01fd
2026-01-03 19:55:52,774 | INFO |   Human wheel: 89a84b0b
2026-01-03 19:55:52,774 | INFO |   GPU config: H100:1
2026-01-03 19:55:52,774 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen1.5-0.5B --backend vllm --num-prompts 2048 -...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 084a01fd, will build from source
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 89a84b0b, will build from source
[CPU PRE-BUILD] Building baseline 084a01fd on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 084a01fd on CPU-only instance...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] human completed: status=error
2026-01-03 19:55:54,394 | INFO | 
2026-01-03 19:55:54,394 | INFO | ================================================================================
2026-01-03 19:55:54,394 | INFO | [12/59] COMPLETED: 296f927f
2026-01-03 19:55:54,394 | INFO | Subject: [Model] RE: Mamba2 Prefill Performance Tweaks: Fix
2026-01-03 19:55:54,394 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 19:55:54,395 | INFO |   Progress: 0 success, 12 errors (12/59)
2026-01-03 19:55:54,396 | INFO | [8bc68e19] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 19:55:54,396 | INFO |   Baseline wheel: 0fca3cdc
2026-01-03 19:55:54,396 | INFO |   Human wheel: 8bc68e19
2026-01-03 19:55:54,396 | INFO |   GPU config: H100:1
2026-01-03 19:55:54,396 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 0fca3cdc, will build from source
[URL CHECK] Human wheel URL does not exist for 8bc68e19, will build from source
[CPU PRE-BUILD] Building baseline 0fca3cdc on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 0fca3cdc on CPU-only instance...
[PARALLEL] human completed: status=error
2026-01-03 19:55:57,985 | INFO | 
2026-01-03 19:55:57,985 | INFO | ================================================================================
2026-01-03 19:55:57,985 | INFO | [13/59] COMPLETED: 2f192835
2026-01-03 19:55:57,985 | INFO | Subject: [Core] latency optimization (#3890)
2026-01-03 19:55:57,985 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 19:55:57,985 | INFO |   Progress: 0 success, 13 errors (13/59)
2026-01-03 19:55:57,987 | INFO | [8d75fe48] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 19:55:57,987 | INFO |   Baseline wheel: 388596c9
2026-01-03 19:55:57,987 | INFO |   Human wheel: 8d75fe48
2026-01-03 19:55:57,987 | INFO |   GPU config: H100:1
2026-01-03 19:55:57,987 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --dataset-na...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 388596c9, will build from source
[URL CHECK] Human wheel URL does not exist for 8d75fe48, will build from source
[CPU PRE-BUILD] Building baseline 388596c9 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 388596c9 on CPU-only instance...
[PARALLEL] human completed: status=error
2026-01-03 19:56:03,645 | INFO | 
2026-01-03 19:56:03,645 | INFO | ================================================================================
2026-01-03 19:56:03,645 | INFO | [14/59] COMPLETED: 3092375e
2026-01-03 19:56:03,645 | INFO | Subject: [V1][Performance] Implement custom serializaton fo
2026-01-03 19:56:03,645 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 19:56:03,645 | INFO |   Progress: 0 success, 14 errors (14/59)
2026-01-03 19:56:03,646 | INFO | [93e5f3c5] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 19:56:03,646 | INFO |   Baseline wheel: 70363bcc
2026-01-03 19:56:03,646 | INFO |   Human wheel: 93e5f3c5
2026-01-03 19:56:03,647 | INFO |   GPU config: H100:1
2026-01-03 19:56:03,647 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 6d646d08 on CPU...
[ENSURE BUILD] Checking/building vLLM 6d646d08 on CPU-only instance...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 19:57:01,930 | INFO | 
2026-01-03 19:57:01,930 | INFO | ================================================================================
2026-01-03 19:57:01,930 | INFO | [15/59] COMPLETED: 83450458
2026-01-03 19:57:01,930 | INFO | Subject: [Performance][Spec Decode] Optimize ngram lookup performance
2026-01-03 19:57:01,930 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 19:57:01,931 | INFO |   Progress: 0 success, 15 errors (15/59)
2026-01-03 19:57:01,932 | INFO | [9474e89b] Starting benchmark | Model: huggyllama/llama-7b | GPU: H100:1
2026-01-03 19:57:01,932 | INFO |   Baseline wheel: 20478c4d
2026-01-03 19:57:01,932 | INFO |   Human wheel: 9474e89b
2026-01-03 19:57:01,932 | INFO |   GPU config: H100:1
2026-01-03 19:57:01,933 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model huggyllama/llama-7b --dataset-name sharegpt --num-...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 20478c4d, will build from source
[URL CHECK] Human wheel URL does not exist for 9474e89b, will build from source
[CPU PRE-BUILD] Building baseline 20478c4d on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 20478c4d on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 19:58:00,280 | INFO | 
2026-01-03 19:58:00,280 | INFO | ================================================================================
2026-01-03 19:58:00,280 | INFO | [16/59] COMPLETED: 3476ed08
2026-01-03 19:58:00,280 | INFO | Subject: [Core] Optimize block_manager_v2 vs block_manager_v1 (to mak
2026-01-03 19:58:00,280 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 19:58:00,281 | INFO |   Progress: 0 success, 16 errors (16/59)
2026-01-03 19:58:00,282 | INFO | [99abb8b6] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 19:58:00,282 | INFO |   Baseline wheel: 3a1e6481
2026-01-03 19:58:00,283 | INFO |   Human wheel: 99abb8b6
2026-01-03 19:58:00,283 | INFO |   GPU config: H100:1
2026-01-03 19:58:00,283 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --speculative-model ...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 7c01f706 on CPU...
[ENSURE BUILD] Checking/building vLLM 7c01f706 on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 20:01:07,595 | INFO | 
2026-01-03 20:01:07,595 | INFO | ================================================================================
2026-01-03 20:01:07,595 | INFO | [17/59] COMPLETED: 015069b0
2026-01-03 20:01:07,595 | INFO | Subject: [Misc] Optimize the Qwen3_ReasoningParser extract_
2026-01-03 20:01:07,595 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 20:01:07,596 | INFO |   Progress: 0 success, 17 errors (17/59)
2026-01-03 20:01:07,597 | INFO | [9a3b8832] Starting benchmark | Model: Qwen/Qwen2.5-VL-3B-Instruct | GPU: H100:1
2026-01-03 20:01:07,597 | INFO |   Baseline wheel: 3014c920
2026-01-03 20:01:07,597 | INFO |   Human wheel: 9a3b8832
2026-01-03 20:01:07,597 | INFO |   GPU config: H100:1
2026-01-03 20:01:07,597 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-VL-3B-Instruct...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] human completed: status=error
2026-01-03 20:01:16,852 | INFO | 
2026-01-03 20:01:16,852 | INFO | ================================================================================
2026-01-03 20:01:16,852 | INFO | [18/59] COMPLETED: 67da5720
2026-01-03 20:01:16,852 | INFO | Subject: [PERF] Speed up Qwen2.5-VL model by speed up rotar
2026-01-03 20:01:16,852 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 20:01:16,853 | INFO |   Progress: 0 success, 18 errors (18/59)
2026-01-03 20:01:16,854 | INFO | [9badee53] Starting benchmark | Model: meta-llama/Llama-3.2-1B-Instruct | GPU: H100:1
2026-01-03 20:01:16,854 | INFO |   Baseline wheel: beebf474
2026-01-03 20:01:16,854 | INFO |   Human wheel: 9badee53
2026-01-03 20:01:16,854 | INFO |   GPU config: H100:1
2026-01-03 20:01:16,854 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.2-1B-Instruct --dataset-path Share...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 9474e89b on CPU...
[ENSURE BUILD] Checking/building vLLM 9474e89b on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 8bc68e19 on CPU...
[ENSURE BUILD] Checking/building vLLM 8bc68e19 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 6e36f4fa on CPU...
[ENSURE BUILD] Checking/building vLLM 6e36f4fa on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=None, human=volume, agent=None
Using Docker image fallback for 2deb029d
Using Docker image fallback: anonymous/vllm-bench:2deb029d115d
  Human commit: 2deb029d115dadd012ce5ea70487a207cb025493
  Base commit: 029c71de11bc3bcf84a1b3cf9d91e79ab6949799
Creating Modal Sandbox with H100 x 1...
Running 3-way benchmark in sandbox...
Writing benchmark script to sandbox (22854 chars)...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 20:04:32,850 | INFO | 
2026-01-03 20:04:32,850 | INFO | ================================================================================
2026-01-03 20:04:32,850 | INFO | [19/59] COMPLETED: 9badee53
2026-01-03 20:04:32,850 | INFO | Subject: Fix performance when `--generation-config` is not 
2026-01-03 20:04:32,850 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 20:04:32,851 | INFO |   Progress: 0 success, 19 errors (19/59)
2026-01-03 20:04:32,852 | INFO | [9d72daf4] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 20:04:32,852 | INFO |   Baseline wheel: 6dd55af6
2026-01-03 20:04:32,852 | INFO |   Human wheel: 9d72daf4
2026-01-03 20:04:32,852 | INFO |   GPU config: H100:1
2026-01-03 20:04:32,852 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
Exception traceback: Traceback (most recent call last):
  File "/home/ubuntu/OmniPerf-Bench/src/eval/modal_benchmark.py", line 5678, in run_3way_benchmark_docker_fallback
    f = sb.open(script_path, "w")
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/sandbox.py", line 1108, in open
    return await _FileIO.create(path, mode, self._client, task_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 239, in create
    await self._open_file(path, mode)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 230, in _open_file
    await self._wait(resp.exec_id)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 201, in _wait
    raise data
modal.exception.FilesystemExecutionError: request cancelled due to internal error

2026-01-03 20:04:35,745 | INFO | 
2026-01-03 20:04:35,745 | INFO | ================================================================================
2026-01-03 20:04:35,745 | INFO | [20/59] COMPLETED: 2deb029d
2026-01-03 20:04:35,745 | INFO | Subject: [Performance][BlockManagerV2] Mark prefix cache block as com
2026-01-03 20:04:35,745 | ERROR |   ❌ ERROR: Docker fallback failed: request cancelled due to internal error
2026-01-03 20:04:35,746 | INFO |   Progress: 0 success, 20 errors (20/59)
2026-01-03 20:04:35,747 | INFO | [9ed82e70] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 20:04:35,747 | INFO |   Baseline wheel: 51f8aa90
2026-01-03 20:04:35,748 | INFO |   Human wheel: 9ed82e70
2026-01-03 20:04:35,748 | INFO |   GPU config: H100:1
2026-01-03 20:04:35,748 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 51f8aa90, will build from source
[URL CHECK] Human wheel URL does not exist for 9ed82e70, will build from source
[CPU PRE-BUILD] Building baseline 51f8aa90 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 51f8aa90 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.0+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 80aa7e91 on CPU...
[ENSURE BUILD] Checking/building vLLM 80aa7e91 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 20:08:04,675 | INFO | 
2026-01-03 20:08:04,676 | INFO | ================================================================================
2026-01-03 20:08:04,676 | INFO | [21/59] COMPLETED: 9474e89b
2026-01-03 20:08:04,676 | INFO | Subject: [PREFIX CACHING FOLLOW UP] A bunch of fixes to block allocat
2026-01-03 20:08:04,676 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 20:08:04,676 | INFO |   Progress: 0 success, 21 errors (21/59)
2026-01-03 20:08:04,678 | INFO | [ac45c44d] Starting benchmark | Model: deepseek-ai/DeepSeek-V2 | GPU: H100:4
2026-01-03 20:08:04,678 | INFO |   Baseline wheel: d6664664
2026-01-03 20:08:04,678 | INFO |   Human wheel: ac45c44d
2026-01-03 20:08:04,678 | INFO |   GPU config: H100:4
2026-01-03 20:08:04,678 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V2 --dataset-name sharegpt --num...
Running 3-way benchmark on Modal with H100:4...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:4...
[PARALLEL] Starting 3-way parallel benchmark with H100:4...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.4.3+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 8d75fe48 on CPU...
[ENSURE BUILD] Checking/building vLLM 8d75fe48 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.3.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 89a84b0b on CPU...
[ENSURE BUILD] Checking/building vLLM 89a84b0b on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.2+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 9ed82e70 on CPU...
[ENSURE BUILD] Checking/building vLLM 9ed82e70 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.0+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[ENSURE BUILD] Built and cached: vLLM 0.4.3+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.2+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.3.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 20:27:30,545 | INFO | 
2026-01-03 20:27:30,546 | INFO | ================================================================================
2026-01-03 20:27:30,546 | INFO | [22/59] COMPLETED: 6e36f4fa
2026-01-03 20:27:30,546 | INFO | Subject: improve chunked prefill performance
2026-01-03 20:27:30,546 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 20:27:30,547 | INFO |   Progress: 0 success, 22 errors (22/59)
2026-01-03 20:27:30,548 | INFO | [ad8d696a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 20:27:30,548 | INFO |   Baseline wheel: 3d925165
2026-01-03 20:27:30,548 | INFO |   Human wheel: ad8d696a
2026-01-03 20:27:30,548 | INFO |   GPU config: H100:1
2026-01-03 20:27:30,548 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 3d925165, will build from source
[URL CHECK] Human wheel URL does not exist for ad8d696a, will build from source
[CPU PRE-BUILD] Building baseline 3d925165 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 3d925165 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human ad8d696a on CPU...
[ENSURE BUILD] Checking/building vLLM ad8d696a on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] human completed: status=error
2026-01-03 20:41:55,597 | INFO | 
2026-01-03 20:41:55,597 | INFO | ================================================================================
2026-01-03 20:41:55,597 | INFO | [23/59] COMPLETED: 660470e5
2026-01-03 20:41:55,597 | INFO | Subject: [Core] Optimize evictor-v2 performance (#7193)
2026-01-03 20:41:55,597 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 20:41:55,598 | INFO |   Progress: 0 success, 23 errors (23/59)
2026-01-03 20:41:55,599 | INFO | [aea94362] Starting benchmark | Model: meta-llama/Llama-3.2-1B-Instruct | GPU: H100:1
2026-01-03 20:41:55,599 | INFO |   Baseline wheel: 7206ce4c
2026-01-03 20:41:55,599 | INFO |   Human wheel: aea94362
2026-01-03 20:41:55,599 | INFO |   GPU config: H100:1
2026-01-03 20:41:55,599 | INFO |   Command preview: python benchmarks/benchmark_serving.py --backend vllm --model meta-llama/Llama-3.2-1B-Instruct --dat...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 20:42:17,323 | INFO | 
2026-01-03 20:42:17,323 | INFO | ================================================================================
2026-01-03 20:42:17,323 | INFO | [24/59] COMPLETED: 6ce01f30
2026-01-03 20:42:17,323 | INFO | Subject: [Performance] Optimize `get_seqs` (#7051)
2026-01-03 20:42:17,323 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 20:42:17,324 | INFO |   Progress: 0 success, 24 errors (24/59)
2026-01-03 20:42:17,326 | INFO | [b10e5198] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 20:42:17,326 | INFO |   Baseline wheel: 9bde5ba1
2026-01-03 20:42:17,326 | INFO |   Human wheel: b10e5198
2026-01-03 20:42:17,326 | INFO |   GPU config: H100:1
2026-01-03 20:42:17,326 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 20:45:51,046 | INFO | 
2026-01-03 20:45:51,046 | INFO | ================================================================================
2026-01-03 20:45:51,046 | INFO | [25/59] COMPLETED: aea94362
2026-01-03 20:45:51,046 | INFO | Subject: [Frontend][V1] Online serving performance improvements (#122
2026-01-03 20:45:51,046 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 20:45:51,047 | INFO |   Progress: 0 success, 25 errors (25/59)
2026-01-03 20:45:51,048 | INFO | [b6d10354] Starting benchmark | Model: meta-llama/Llama-2-70b-hf | GPU: H100:4
2026-01-03 20:45:51,048 | INFO |   Baseline wheel: 51c31bc1
2026-01-03 20:45:51,048 | INFO |   Human wheel: b6d10354
2026-01-03 20:45:51,048 | INFO |   GPU config: H100:4
2026-01-03 20:45:51,048 | INFO |   Command preview: python benchmarks/benchmark_latency.py --model meta-llama/Llama-2-70b-hf --dtype float16 --tensor-pa...
Running 3-way benchmark on Modal with H100:4...
[URL CHECK] Baseline wheel URL does not exist for 51c31bc1, will build from source
[URL CHECK] Human wheel URL does not exist for b6d10354, will build from source
[CPU PRE-BUILD] Building baseline 51c31bc1 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 51c31bc1 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.0+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human b6d10354 on CPU...
[ENSURE BUILD] Checking/building vLLM b6d10354 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.0+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:4...
[PARALLEL] Starting 3-way parallel benchmark with H100:4...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 20:57:02,355 | INFO | 
2026-01-03 20:57:02,356 | INFO | ================================================================================
2026-01-03 20:57:02,356 | INFO | [26/59] COMPLETED: b6d10354
2026-01-03 20:57:02,356 | INFO | Subject: [Kernel] Layernorm performance optimization (#3662)
2026-01-03 20:57:02,356 | ERROR |   ❌ BASELINE_FAILED: baseline: None; human: None
2026-01-03 20:57:02,356 | INFO |   Progress: 0 success, 26 errors (26/59)
2026-01-03 20:57:02,357 | INFO | [baeded25] Starting benchmark | Model: deepseek-ai/DeepSeek-V3 | GPU: H100:8
2026-01-03 20:57:02,357 | INFO |   Baseline wheel: 3e1c76cf
2026-01-03 20:57:02,357 | INFO |   Human wheel: baeded25
2026-01-03 20:57:02,357 | INFO |   GPU config: H100:8
2026-01-03 20:57:02,358 | INFO |   Command preview: python benchmarks/benchmark_latency.py --model deepseek-ai/DeepSeek-V3 --batch-size 32 --input-len 5...
[BLOCKED] Model deepseek-ai/DeepSeek-V3 is blocked (too large/unstable), skipping benchmark
2026-01-03 20:57:02,358 | INFO | 
2026-01-03 20:57:02,358 | INFO | ================================================================================
2026-01-03 20:57:02,358 | INFO | [27/59] COMPLETED: baeded25
2026-01-03 20:57:02,358 | INFO | Subject: [Attention] Deepseek v3 MLA support with FP8 compute (#12601
2026-01-03 20:57:02,358 | ERROR |   ❌ BLOCKED_MODEL: Model deepseek-ai/DeepSeek-V3 is blocked: too large or unstable for reliable benchmarking
2026-01-03 20:57:02,359 | INFO |   Progress: 0 success, 27 errors (27/59)
2026-01-03 20:57:02,360 | INFO | [bfdb1ba5] Starting benchmark | Model: meta-llama/Llama-2-7b-chat-hf | GPU: H100:1
2026-01-03 20:57:02,360 | INFO |   Baseline wheel: cf2f084d
2026-01-03 20:57:02,360 | INFO |   Human wheel: bfdb1ba5
2026-01-03 20:57:02,360 | INFO |   GPU config: H100:1
2026-01-03 20:57:02,360 | INFO |   Command preview: python /home/ray/default/vllm_public/benchmarks/benchmark_latency.py --model meta-llama/Llama-2-7b-c...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for cf2f084d, will build from source
[URL CHECK] Human wheel URL does not exist for bfdb1ba5, will build from source
[CPU PRE-BUILD] Building baseline cf2f084d on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM cf2f084d on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 20:57:43,469 | INFO | 
2026-01-03 20:57:43,469 | INFO | ================================================================================
2026-01-03 20:57:43,470 | INFO | [28/59] COMPLETED: 93e5f3c5
2026-01-03 20:57:43,470 | INFO | Subject: [Perf] Optimize Preparing Inputs for GPU Model Run
2026-01-03 20:57:43,470 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 20:57:43,471 | INFO |   Progress: 0 success, 28 errors (28/59)
2026-01-03 20:57:43,471 | INFO | [c0569dbc] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-FP8 | GPU: H100:2
2026-01-03 20:57:43,471 | INFO |   Baseline wheel: 8bb43b9c
2026-01-03 20:57:43,471 | INFO |   Human wheel: c0569dbc
2026-01-03 20:57:43,471 | INFO |   GPU config: H100:2
2026-01-03 20:57:43,472 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen3-30B-A3B-FP8 --dataset-name sharegpt --num-...
Running 3-way benchmark on Modal with H100:2...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 20:59:17,203 | INFO | 
2026-01-03 20:59:17,203 | INFO | ================================================================================
2026-01-03 20:59:17,204 | INFO | [29/59] COMPLETED: 99abb8b6
2026-01-03 20:59:17,204 | INFO | Subject: [V1][Spec Decode] Optimize Rejection Sampler with 
2026-01-03 20:59:17,204 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 20:59:17,205 | INFO |   Progress: 0 success, 29 errors (29/59)
2026-01-03 20:59:17,205 | INFO | [c45f3c3a] Starting benchmark | Model: facebook/opt-13b | GPU: H100:1
2026-01-03 20:59:17,205 | INFO |   Baseline wheel: 7a7929ab
2026-01-03 20:59:17,206 | INFO |   Human wheel: c45f3c3a
2026-01-03 20:59:17,206 | INFO |   GPU config: H100:1
2026-01-03 20:59:17,206 | INFO |   Command preview: python benchmark/benchmark_latency.py --model facebook/opt-13b...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 7a7929ab, will build from source
[URL CHECK] Human wheel URL does not exist for c45f3c3a, will build from source
[CPU PRE-BUILD] Building baseline 7a7929ab on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 7a7929ab on CPU-only instance...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Baseline build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Building human c45f3c3a on CPU...
[ENSURE BUILD] Checking/building vLLM c45f3c3a on CPU-only instance...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Human build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Wheel sources: baseline=None, human=None, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 20:59:57,696 | INFO | 
2026-01-03 20:59:57,696 | INFO | ================================================================================
2026-01-03 20:59:57,697 | INFO | [30/59] COMPLETED: c45f3c3a
2026-01-03 20:59:57,697 | INFO | Subject: Optimize tensor parallel execution speed (#17)
2026-01-03 20:59:57,697 | ERROR |   ❌ BASELINE_FAILED: baseline: No wheel source provided for baseline; human: No wheel source provided for human
2026-01-03 20:59:57,698 | INFO |   Progress: 0 success, 30 errors (30/59)
2026-01-03 20:59:57,698 | INFO | [ca7a2d5f] Starting benchmark | Model: deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct | GPU: H100:1
2026-01-03 20:59:57,698 | INFO |   Baseline wheel: 33368140
2026-01-03 20:59:57,699 | INFO |   Human wheel: ca7a2d5f
2026-01-03 20:59:57,699 | INFO |   GPU config: H100:1
2026-01-03 20:59:57,699 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct --dataset...
