2026-01-03 15:40:02,966 | INFO | ================================================================================
2026-01-03 15:40:02,966 | INFO | HERO BENCHMARK RUN
2026-01-03 15:40:02,966 | INFO | Start time: 2026-01-03T15:40:02.966327
2026-01-03 15:40:02,966 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_154002.log
2026-01-03 15:40:02,966 | INFO | ================================================================================
2026-01-03 15:40:02,966 | INFO | Loaded 59 commits from plan
2026-01-03 15:40:02,966 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2026-01-03 15:40:09,227 | INFO | 
*** PARALLEL MODE: 15 concurrent benchmarks ***
2026-01-03 15:40:09,227 | INFO | Spawning Modal containers in parallel...
2026-01-03 15:40:09,227 | INFO | [015069b0] Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 15:40:09,228 | INFO | [0ec82edd] Fixing model name: Qwen/Qwen3-30B-A3B -> Qwen/Qwen3-30B-A3B-Instruct-2507
2026-01-03 15:40:09,231 | INFO | [0d243f2a] Starting benchmark | Model: mistralai/Mixtral-8x7B-Instruct-v0.1 | GPU: H100:2
2026-01-03 15:40:09,232 | INFO | [21d93c14] Starting benchmark | Model: mistralai/Mixtral-8x7B-v0.1 | GPU: H100:8
2026-01-03 15:40:09,232 | INFO | [22d33bac] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:40:09,233 | INFO | [015069b0] Starting benchmark | Model: mergekit-community/Qwen3-7B-Instruct | GPU: H100:1
2026-01-03 15:40:09,233 | INFO | [0ec82edd] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-Instruct-2507 | GPU: H100:2
2026-01-03 15:40:09,233 | INFO | [22dd9c27] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:40:09,234 | INFO | [296f927f] Starting benchmark | Model: ibm-ai-platform/Bamba-9B-v2 | GPU: H100:1
2026-01-03 15:40:09,234 | INFO | [2deb029d] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 15:40:09,236 | INFO | [2f192835] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:40:09,236 | INFO | [2a052011] Starting benchmark | Model: nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8 | GPU: H100:2
2026-01-03 15:40:09,237 | INFO | [3092375e] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:40:09,238 | INFO | [35fad35a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:40:09,238 | INFO | [379da6dc] Starting benchmark | Model: meta-llama/Llama-3-70B | GPU: H100:4
2026-01-03 15:40:09,238 | INFO | [3476ed08] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:40:09,239 | INFO | [3a243095] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:40:09,443 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 15:40:09,443 | INFO |   Baseline wheel: f1c85201
2026-01-03 15:40:09,443 | INFO |   Human wheel: 0d243f2a
2026-01-03 15:40:09,443 | INFO |   Human wheel: 21d93c14
2026-01-03 15:40:09,443 | INFO |   Baseline wheel: b0e96aae
2026-01-03 15:40:09,443 | INFO |   GPU config: H100:2
2026-01-03 15:40:09,443 | INFO |   GPU config: H100:8
2026-01-03 15:40:09,443 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 15:40:09,444 | INFO |   Human wheel: 22d33bac
2026-01-03 15:40:09,444 | INFO |   Baseline wheel: 005ae9be
2026-01-03 15:40:09,444 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 15:40:09,444 | INFO |   Baseline wheel: a6d795d5
2026-01-03 15:40:09,444 | INFO |   Baseline wheel: 0032903a
2026-01-03 15:40:09,444 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model mistralai/Mixtral-8x7B-v0.1 --tensor-parallel-size...
Running 3-way benchmark on Modal with H100:8...
2026-01-03 15:40:09,444 | INFO |   Baseline wheel: 029c71de
2026-01-03 15:40:09,444 | INFO |   Human wheel: 015069b0
2026-01-03 15:40:09,444 | INFO |   Baseline wheel: 95baec82
2026-01-03 15:40:09,445 | INFO |   Baseline wheel: 36fb68f9
2026-01-03 15:40:09,445 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,445 | INFO |   Baseline wheel: 3cd91dc9
2026-01-03 15:40:09,445 | INFO |   Baseline wheel: 733e7c9e
2026-01-03 15:40:09,445 | INFO |   Baseline wheel: ebce310b
2026-01-03 15:40:09,445 | INFO |   Baseline wheel: 54600709
2026-01-03 15:40:09,445 | INFO |   Baseline wheel: 64172a97
2026-01-03 15:40:09,445 | INFO |   Human wheel: 0ec82edd
2026-01-03 15:40:09,446 | INFO |   Human wheel: 22dd9c27
2026-01-03 15:40:09,446 | INFO |   Human wheel: 296f927f
2026-01-03 15:40:09,446 | INFO |   Human wheel: 2deb029d
2026-01-03 15:40:09,446 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,446 | INFO |   Human wheel: 2f192835
2026-01-03 15:40:09,446 | INFO |   Human wheel: 2a052011
2026-01-03 15:40:09,447 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,447 | INFO |   Human wheel: 3092375e
2026-01-03 15:40:09,447 | INFO |   Human wheel: 35fad35a
2026-01-03 15:40:09,447 | INFO |   Human wheel: 379da6dc
2026-01-03 15:40:09,448 | INFO |   GPU config: H100:4
2026-01-03 15:40:09,447 | INFO |   Human wheel: 3a243095
2026-01-03 15:40:09,447 | INFO |   GPU config: H100:2
2026-01-03 15:40:09,447 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,447 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,447 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,447 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,447 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,447 | INFO |   GPU config: H100:2
2026-01-03 15:40:09,448 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,448 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,447 | INFO |   Human wheel: 3476ed08
2026-01-03 15:40:09,448 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-70B --dtype float8 --input-len 100...
Running 3-way benchmark on Modal with H100:4...
2026-01-03 15:40:09,448 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,448 | INFO |   Command preview: vllm bench throughput --model Qwen/Qwen3-30B-A3B-Instruct-2507 --load-format dummy --input-len 1000 ...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 15:40:09,448 | INFO |   Command preview: VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --mo...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,448 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dataset-name sharegpt...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,448 | INFO |   Command preview: python benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --out...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,449 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,449 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 15:40:09,449 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,449 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,449 | INFO |   GPU config: H100:1
2026-01-03 15:40:09,449 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 15:40:09,452 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for f1c85201, will build from source
[URL CHECK] Baseline wheel URL does not exist for 95baec82, will build from source
[URL CHECK] Baseline wheel URL does not exist for 54600709, will build from source
[URL CHECK] Baseline wheel URL does not exist for 64172a97, will build from source
[URL CHECK] Baseline wheel URL does not exist for 029c71de, will build from source
[URL CHECK] Baseline wheel URL does not exist for ebce310b, will build from source
[URL CHECK] Baseline wheel URL does not exist for 36fb68f9, will build from source
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 0d243f2a, will build from source
[CPU PRE-BUILD] Building human 0d243f2a on CPU...
[ENSURE BUILD] Checking/building vLLM 0d243f2a on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 21d93c14, will build from source
[CPU PRE-BUILD] Building baseline f1c85201 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM f1c85201 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 2f192835, will build from source
[CPU PRE-BUILD] Building baseline 95baec82 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 95baec82 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 3476ed08, will build from source
[CPU PRE-BUILD] Building baseline 54600709 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 54600709 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 3a243095, will build from source
[CPU PRE-BUILD] Building baseline 64172a97 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 64172a97 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 379da6dc, will build from source
[CPU PRE-BUILD] Building baseline ebce310b on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM ebce310b on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 2deb029d, will build from source
[CPU PRE-BUILD] Building baseline 029c71de on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 029c71de on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 2a052011, will build from source
[CPU PRE-BUILD] Building baseline 36fb68f9 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 36fb68f9 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Cache HIT: vLLM 0.7.3.dev241+g0d243f2a5.d20220101.cu124 already cached
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=url, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Baseline build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Building human 21d93c14 on CPU...
[ENSURE BUILD] Checking/building vLLM 21d93c14 on CPU-only instance...
[ENSURE BUILD] FAILED: Wheel build failed with return code 1
[CPU PRE-BUILD] WARNING: Human build failed: Wheel build failed with return code 1
[CPU PRE-BUILD] Wheel sources: baseline=None, human=None, agent=None
Using Docker image fallback for 21d93c14
Using Docker image fallback: anonymous/vllm-bench:21d93c140d0a
  Human commit: 21d93c140d0a97af5f0c59e660cf04bd417fd424
  Base commit: f1c8520146031a650404a6ab120ee11e91c10bed
Creating Modal Sandbox with H100 x 8...
Running 3-way benchmark in sandbox...
Writing benchmark script to sandbox (22808 chars)...
Exception traceback: Traceback (most recent call last):
  File "/home/ubuntu/OmniPerf-Bench/src/eval/modal_benchmark.py", line 5486, in run_3way_benchmark_docker_fallback
    f = sb.open(script_path, "w")
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/sandbox.py", line 1108, in open
    return await _FileIO.create(path, mode, self._client, task_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 239, in create
    await self._open_file(path, mode)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 230, in _open_file
    await self._wait(resp.exec_id)
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/modal/file_io.py", line 201, in _wait
    raise data
modal.exception.FilesystemExecutionError: request cancelled due to internal error

2026-01-03 15:41:32,857 | INFO | 
2026-01-03 15:41:32,857 | INFO | ================================================================================
2026-01-03 15:41:32,857 | INFO | [1/59] COMPLETED: 21d93c14
2026-01-03 15:41:32,857 | INFO | Subject: Optimize Mixtral with expert parallelism (#2090)
2026-01-03 15:41:32,857 | ERROR |   ❌ ERROR: Docker fallback failed: request cancelled due to internal error
2026-01-03 15:41:32,857 | INFO |   Progress: 0 success, 1 errors (1/59)
2026-01-03 15:41:32,859 | INFO | [4fb56914] Starting benchmark | Model: deepseek-ai/DeepSeek-V3-0324 | GPU: H100:8
2026-01-03 15:41:32,859 | INFO |   Baseline wheel: 0df4d9b0
2026-01-03 15:41:32,859 | INFO |   Human wheel: 4fb56914
2026-01-03 15:41:32,859 | INFO |   GPU config: H100:8
2026-01-03 15:41:32,859 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V3-0324 --dataset-name sharegpt ...
[BLOCKED] Model deepseek-ai/DeepSeek-V3-0324 is blocked (too large/unstable), skipping benchmark
2026-01-03 15:41:32,860 | INFO | 
2026-01-03 15:41:32,860 | INFO | ================================================================================
2026-01-03 15:41:32,860 | INFO | [2/59] COMPLETED: 4fb56914
2026-01-03 15:41:32,860 | INFO | Subject: [perf] Add fused MLA QKV + strided layernorm (#21116)
2026-01-03 15:41:32,860 | ERROR |   ❌ BLOCKED_MODEL: Model deepseek-ai/DeepSeek-V3-0324 is blocked: too large or unstable for reliable benchmarking
2026-01-03 15:41:32,860 | INFO |   Progress: 0 success, 2 errors (2/59)
2026-01-03 15:41:32,862 | INFO | [526de822] Starting benchmark | Model: MODEL | GPU: H100:1
2026-01-03 15:41:32,862 | INFO |   Baseline wheel: 56fe4c29
2026-01-03 15:41:32,862 | INFO |   Human wheel: 526de822
2026-01-03 15:41:32,862 | INFO |   GPU config: H100:1
2026-01-03 15:41:32,862 | INFO |   Command preview: python benchmarks/benchmark_latency.py --dtype bfloat16 --enable-chunked-prefill False --load-format...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 15:42:02,977 | INFO | 
2026-01-03 15:42:02,977 | INFO | ================================================================================
2026-01-03 15:42:02,977 | INFO | [3/59] COMPLETED: 22dd9c27
2026-01-03 15:42:02,977 | INFO | Subject: [Kernel] Optimize Prefill Attention in Unified Triton Attent
2026-01-03 15:42:02,977 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 15:42:02,977 | INFO |   Progress: 0 success, 3 errors (3/59)
2026-01-03 15:42:02,979 | INFO | [660470e5] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 15:42:02,979 | INFO |   Baseline wheel: 8d59dbb0
2026-01-03 15:42:02,979 | INFO |   Human wheel: 660470e5
2026-01-03 15:42:02,979 | INFO |   GPU config: H100:1
2026-01-03 15:42:02,979 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --tensor-parallel-si...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 8d59dbb0, will build from source
[URL CHECK] Human wheel URL does not exist for 660470e5, will build from source
[CPU PRE-BUILD] Building baseline 8d59dbb0 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 8d59dbb0 on CPU-only instance...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 15:43:26,677 | INFO | 
2026-01-03 15:43:26,678 | INFO | ================================================================================
2026-01-03 15:43:26,678 | INFO | [4/59] COMPLETED: 526de822
2026-01-03 15:43:26,678 | INFO | Subject: [Kernel][Triton][AMD] Use block size heuristic for avg 2.8x 
2026-01-03 15:43:26,678 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 15:43:26,679 | INFO |   Progress: 0 success, 4 errors (4/59)
2026-01-03 15:43:26,680 | INFO | [67da5720] Starting benchmark | Model: Qwen/Qwen2.5-VL-3B-Instruct | GPU: H100:1
2026-01-03 15:43:26,680 | INFO |   Baseline wheel: 5c04bb8b
2026-01-03 15:43:26,680 | INFO |   Human wheel: 67da5720
2026-01-03 15:43:26,680 | INFO |   GPU config: H100:1
2026-01-03 15:43:26,680 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-VL-3B-Instruct --dataset-name sharegpt -...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.4.0.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 2f192835 on CPU...
[ENSURE BUILD] Checking/building vLLM 2f192835 on CPU-only instance...
[PARALLEL] baseline completed: status=success
[PARALLEL] Waiting for human...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 3a243095 on CPU...
[ENSURE BUILD] Checking/building vLLM 3a243095 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 2a052011 on CPU...
[ENSURE BUILD] Checking/building vLLM 2a052011 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 379da6dc on CPU...
[ENSURE BUILD] Checking/building vLLM 379da6dc on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 3476ed08 on CPU...
[ENSURE BUILD] Checking/building vLLM 3476ed08 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 2deb029d on CPU...
[ENSURE BUILD] Checking/building vLLM 2deb029d on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.4+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 660470e5 on CPU...
[ENSURE BUILD] Checking/building vLLM 660470e5 on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 15:54:43,120 | INFO | 
2026-01-03 15:54:43,121 | INFO | ================================================================================
2026-01-03 15:54:43,121 | INFO | [5/59] COMPLETED: 2a052011
2026-01-03 15:54:43,121 | INFO | Subject: [Kernel] Support MoE Fp8 Checkpoints for Mixtral (Static Wei
2026-01-03 15:54:43,121 | ERROR |   ❌ BASELINE_FAILED: baseline: No metrics; human: No metrics
2026-01-03 15:54:43,121 | INFO |   Progress: 0 success, 5 errors (5/59)
2026-01-03 15:54:43,122 | INFO | [6ce01f30] Starting benchmark | Model: meta-llama/Llama-3-8B | GPU: H100:1
2026-01-03 15:54:43,122 | INFO |   Baseline wheel: 6a11fdfb
2026-01-03 15:54:43,122 | INFO |   Human wheel: 6ce01f30
2026-01-03 15:54:43,123 | INFO |   GPU config: H100:1
2026-01-03 15:54:43,123 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-8B --backend vllm --num-prompts 10...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 6a11fdfb, will build from source
[URL CHECK] Human wheel URL does not exist for 6ce01f30, will build from source
[CPU PRE-BUILD] Building baseline 6a11fdfb on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 6a11fdfb on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:4...
[PARALLEL] Starting 3-way parallel benchmark with H100:4...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.4.0.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.4+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.3.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 6ce01f30 on CPU...
[ENSURE BUILD] Checking/building vLLM 6ce01f30 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 16:13:15,945 | INFO | 
2026-01-03 16:13:15,945 | INFO | ================================================================================
2026-01-03 16:13:15,945 | INFO | [6/59] COMPLETED: 2deb029d
2026-01-03 16:13:15,945 | INFO | Subject: [Performance][BlockManagerV2] Mark prefix cache block as com
2026-01-03 16:13:15,945 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 16:13:15,946 | INFO |   Progress: 0 success, 6 errors (6/59)
2026-01-03 16:13:15,947 | INFO | [6d646d08] Starting benchmark | Model: meta-llama/Llama-3-8B | GPU: H100:1
2026-01-03 16:13:15,947 | INFO |   Baseline wheel: 95a178f8
2026-01-03 16:13:15,947 | INFO |   Human wheel: 6d646d08
2026-01-03 16:13:15,947 | INFO |   GPU config: H100:1
2026-01-03 16:13:15,947 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-8B --dataset-name sharegpt --multi...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 95a178f8, will build from source
[URL CHECK] Human wheel URL does not exist for 6d646d08, will build from source
[CPU PRE-BUILD] Building baseline 95a178f8 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 95a178f8 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.3.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 6d646d08 on CPU...
[ENSURE BUILD] Checking/building vLLM 6d646d08 on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 16:41:42,637 | INFO | 
2026-01-03 16:41:42,637 | INFO | ================================================================================
2026-01-03 16:41:42,637 | INFO | [7/59] COMPLETED: 35fad35a
2026-01-03 16:41:42,637 | INFO | Subject: [V1][Sampler] Faster top-k only implementation (#1
2026-01-03 16:41:42,637 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 16:41:42,637 | INFO |   Progress: 0 success, 7 errors (7/59)
2026-01-03 16:41:42,638 | INFO | [6e36f4fa] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 16:41:42,638 | INFO |   Baseline wheel: dd2a6a82
2026-01-03 16:41:42,638 | INFO |   Human wheel: 6e36f4fa
2026-01-03 16:41:42,639 | INFO |   GPU config: H100:1
2026-01-03 16:41:42,639 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[URL CHECK] Baseline wheel URL does not exist for dd2a6a82, will build from source
[PARALLEL] human completed: status=error
2026-01-03 16:41:42,876 | INFO | 
2026-01-03 16:41:42,876 | INFO | ================================================================================
2026-01-03 16:41:42,876 | INFO | [8/59] COMPLETED: 22d33bac
2026-01-03 16:41:42,876 | INFO | Subject: [FrontEnd][Perf] `merge_async_iterators` fast-path
2026-01-03 16:41:42,876 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 16:41:42,877 | INFO |   Progress: 0 success, 8 errors (8/59)
2026-01-03 16:41:42,878 | INFO | [7c01f706] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 16:41:42,878 | INFO |   Baseline wheel: 51e971d3
2026-01-03 16:41:42,878 | INFO |   Human wheel: 7c01f706
2026-01-03 16:41:42,878 | INFO |   GPU config: H100:1
2026-01-03 16:41:42,878 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Human wheel URL does not exist for 6e36f4fa, will build from source
[CPU PRE-BUILD] Building baseline dd2a6a82 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM dd2a6a82 on CPU-only instance...
[URL CHECK] Baseline wheel URL does not exist for 51e971d3, will build from source
[URL CHECK] Human wheel URL does not exist for 7c01f706, will build from source
[CPU PRE-BUILD] Building baseline 51e971d3 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 51e971d3 on CPU-only instance...
[PARALLEL] human completed: status=error
2026-01-03 16:41:50,846 | INFO | 
2026-01-03 16:41:50,846 | INFO | ================================================================================
2026-01-03 16:41:50,846 | INFO | [9/59] COMPLETED: 296f927f
2026-01-03 16:41:50,846 | INFO | Subject: [Model] RE: Mamba2 Prefill Performance Tweaks: Fix
2026-01-03 16:41:50,846 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 16:41:50,846 | INFO |   Progress: 0 success, 9 errors (9/59)
2026-01-03 16:41:50,848 | INFO | [80aa7e91] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 16:41:50,848 | INFO |   Baseline wheel: bd439735
2026-01-03 16:41:50,848 | INFO |   Human wheel: 80aa7e91
2026-01-03 16:41:50,848 | INFO |   GPU config: H100:1
2026-01-03 16:41:50,848 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for bd439735, will build from source
[URL CHECK] Human wheel URL does not exist for 80aa7e91, will build from source
[CPU PRE-BUILD] Building baseline bd439735 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM bd439735 on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 16:41:52,937 | INFO | 
2026-01-03 16:41:52,937 | INFO | ================================================================================
2026-01-03 16:41:52,937 | INFO | [10/59] COMPLETED: 015069b0
2026-01-03 16:41:52,937 | INFO | Subject: [Misc] Optimize the Qwen3_ReasoningParser extract_
2026-01-03 16:41:52,937 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 16:41:52,938 | INFO |   Progress: 0 success, 10 errors (10/59)
2026-01-03 16:41:52,939 | INFO | [83450458] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 16:41:52,939 | INFO |   Baseline wheel: 5b8a1fde
2026-01-03 16:41:52,939 | INFO |   Human wheel: 83450458
2026-01-03 16:41:52,939 | INFO |   GPU config: H100:1
2026-01-03 16:41:52,939 | INFO |   Command preview: python benchmarks/benchmark_latency.py --model meta-llama/Llama-3.1-8B-Instruct --speculative-model ...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 16:41:53,954 | INFO | 
2026-01-03 16:41:53,954 | INFO | ================================================================================
2026-01-03 16:41:53,954 | INFO | [11/59] COMPLETED: 3092375e
2026-01-03 16:41:53,954 | INFO | Subject: [V1][Performance] Implement custom serializaton fo
2026-01-03 16:41:53,954 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 16:41:53,955 | INFO |   Progress: 0 success, 11 errors (11/59)
2026-01-03 16:41:53,956 | INFO | [89a84b0b] Starting benchmark | Model: Qwen/Qwen1.5-0.5B | GPU: H100:1
2026-01-03 16:41:53,956 | INFO |   Baseline wheel: 084a01fd
2026-01-03 16:41:53,956 | INFO |   Human wheel: 89a84b0b
2026-01-03 16:41:53,956 | INFO |   GPU config: H100:1
2026-01-03 16:41:53,956 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen1.5-0.5B --backend vllm --num-prompts 2048 -...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 084a01fd, will build from source
[URL CHECK] Human wheel URL does not exist for 89a84b0b, will build from source
[CPU PRE-BUILD] Building baseline 084a01fd on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 084a01fd on CPU-only instance...
[PARALLEL] human completed: status=error
2026-01-03 16:42:02,227 | INFO | 
2026-01-03 16:42:02,227 | INFO | ================================================================================
2026-01-03 16:42:02,227 | INFO | [12/59] COMPLETED: 0d243f2a
2026-01-03 16:42:02,227 | INFO | Subject: [ROCm][MoE] mi300 mixtral8x7B perf for specific BS
2026-01-03 16:42:02,228 | ERROR |   ❌ HUMAN_FAILED: human: Server failed to start
2026-01-03 16:42:02,228 | INFO |   Progress: 0 success, 12 errors (12/59)
2026-01-03 16:42:02,229 | INFO | [8bc68e19] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 16:42:02,230 | INFO |   Baseline wheel: 0fca3cdc
2026-01-03 16:42:02,230 | INFO |   Human wheel: 8bc68e19
2026-01-03 16:42:02,230 | INFO |   GPU config: H100:1
2026-01-03 16:42:02,230 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 0fca3cdc, will build from source
[URL CHECK] Human wheel URL does not exist for 8bc68e19, will build from source
[CPU PRE-BUILD] Building baseline 0fca3cdc on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 0fca3cdc on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 16:42:09,718 | INFO | 
2026-01-03 16:42:09,718 | INFO | ================================================================================
2026-01-03 16:42:09,718 | INFO | [13/59] COMPLETED: 0ec82edd
2026-01-03 16:42:09,718 | INFO | Subject: [perf] Speed up align sum kernels (#21079)
2026-01-03 16:42:09,719 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start; human: Server failed to start
2026-01-03 16:42:09,719 | INFO |   Progress: 0 success, 13 errors (13/59)
2026-01-03 16:42:09,720 | INFO | [8d75fe48] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 16:42:09,720 | INFO |   Baseline wheel: 388596c9
2026-01-03 16:42:09,720 | INFO |   Human wheel: 8d75fe48
2026-01-03 16:42:09,720 | INFO |   GPU config: H100:1
2026-01-03 16:42:09,720 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --dataset-na...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 388596c9, will build from source
[URL CHECK] Human wheel URL does not exist for 8d75fe48, will build from source
[CPU PRE-BUILD] Building baseline 388596c9 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 388596c9 on CPU-only instance...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 16:43:19,686 | INFO | 
2026-01-03 16:43:19,686 | INFO | ================================================================================
2026-01-03 16:43:19,686 | INFO | [14/59] COMPLETED: 83450458
2026-01-03 16:43:19,686 | INFO | Subject: [Performance][Spec Decode] Optimize ngram lookup performance
2026-01-03 16:43:19,686 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 16:43:19,687 | INFO |   Progress: 0 success, 14 errors (14/59)
2026-01-03 16:43:19,687 | INFO | [93e5f3c5] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 16:43:19,688 | INFO |   Baseline wheel: 70363bcc
2026-01-03 16:43:19,688 | INFO |   Human wheel: 93e5f3c5
2026-01-03 16:43:19,688 | INFO |   GPU config: H100:1
2026-01-03 16:43:19,688 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 16:44:09,345 | INFO | 
2026-01-03 16:44:09,345 | INFO | ================================================================================
2026-01-03 16:44:09,345 | INFO | [15/59] COMPLETED: 67da5720
2026-01-03 16:44:09,345 | INFO | Subject: [PERF] Speed up Qwen2.5-VL model by speed up rotar
2026-01-03 16:44:09,345 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 16:44:09,346 | INFO |   Progress: 0 success, 15 errors (15/59)
2026-01-03 16:44:09,347 | INFO | [9474e89b] Starting benchmark | Model: huggyllama/llama-7b | GPU: H100:1
2026-01-03 16:44:09,347 | INFO |   Baseline wheel: 20478c4d
2026-01-03 16:44:09,347 | INFO |   Human wheel: 9474e89b
2026-01-03 16:44:09,347 | INFO |   GPU config: H100:1
2026-01-03 16:44:09,347 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model huggyllama/llama-7b --dataset-name sharegpt --num-...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 20478c4d, will build from source
[URL CHECK] Human wheel URL does not exist for 9474e89b, will build from source
[CPU PRE-BUILD] Building baseline 20478c4d on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 20478c4d on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 8bc68e19 on CPU...
[ENSURE BUILD] Checking/building vLLM 8bc68e19 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 9474e89b on CPU...
[ENSURE BUILD] Checking/building vLLM 9474e89b on CPU-only instance...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 16:50:52,554 | INFO | 
2026-01-03 16:50:52,554 | INFO | ================================================================================
2026-01-03 16:50:52,554 | INFO | [16/59] COMPLETED: 3a243095
2026-01-03 16:50:52,554 | INFO | Subject: Optimize `_get_ranks` in Sampler (#3623)
2026-01-03 16:50:52,554 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 16:50:52,555 | INFO |   Progress: 0 success, 16 errors (16/59)
2026-01-03 16:50:52,556 | INFO | [99abb8b6] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 16:50:52,556 | INFO |   Baseline wheel: 3a1e6481
2026-01-03 16:50:52,556 | INFO |   Human wheel: 99abb8b6
2026-01-03 16:50:52,556 | INFO |   GPU config: H100:1
2026-01-03 16:50:52,556 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --speculative-model ...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 7c01f706 on CPU...
[ENSURE BUILD] Checking/building vLLM 7c01f706 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.4.2+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.3.3+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.3.post1+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 89a84b0b on CPU...
[ENSURE BUILD] Checking/building vLLM 89a84b0b on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.0+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 80aa7e91 on CPU...
[ENSURE BUILD] Checking/building vLLM 80aa7e91 on CPU-only instance...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 16:56:23,456 | INFO | 
2026-01-03 16:56:23,457 | INFO | ================================================================================
2026-01-03 16:56:23,457 | INFO | [17/59] COMPLETED: 9474e89b
2026-01-03 16:56:23,457 | INFO | Subject: [PREFIX CACHING FOLLOW UP] A bunch of fixes to block allocat
2026-01-03 16:56:23,457 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 16:56:23,457 | INFO |   Progress: 0 success, 17 errors (17/59)
2026-01-03 16:56:23,458 | INFO | [9a3b8832] Starting benchmark | Model: Qwen/Qwen2.5-VL-3B-Instruct | GPU: H100:1
2026-01-03 16:56:23,458 | INFO |   Baseline wheel: 3014c920
2026-01-03 16:56:23,459 | INFO |   Human wheel: 9a3b8832
2026-01-03 16:56:23,459 | INFO |   GPU config: H100:1
2026-01-03 16:56:23,459 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model Qwen/Qwen2.5-VL-3B-Instruct...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 16:58:38,998 | INFO | 
2026-01-03 16:58:38,998 | INFO | ================================================================================
2026-01-03 16:58:38,998 | INFO | [18/59] COMPLETED: 379da6dc
2026-01-03 16:58:38,998 | INFO | Subject: [Kernel] [FP8] Improve FP8 linear layer performance (#4691)
2026-01-03 16:58:38,998 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed; human: Server failed
2026-01-03 16:58:38,999 | INFO |   Progress: 0 success, 18 errors (18/59)
2026-01-03 16:58:38,999 | INFO | [9badee53] Starting benchmark | Model: meta-llama/Llama-3.2-1B-Instruct | GPU: H100:1
2026-01-03 16:58:38,999 | INFO |   Baseline wheel: beebf474
2026-01-03 16:58:39,000 | INFO |   Human wheel: 9badee53
2026-01-03 16:58:39,000 | INFO |   GPU config: H100:1
2026-01-03 16:58:39,000 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.2-1B-Instruct --dataset-path Share...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 17:01:38,694 | INFO | 
2026-01-03 17:01:38,694 | INFO | ================================================================================
2026-01-03 17:01:38,694 | INFO | [19/59] COMPLETED: 2f192835
2026-01-03 17:01:38,694 | INFO | Subject: [Core] latency optimization (#3890)
2026-01-03 17:01:38,694 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 17:01:38,695 | INFO |   Progress: 0 success, 19 errors (19/59)
2026-01-03 17:01:38,696 | INFO | [9d72daf4] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:01:38,697 | INFO |   Baseline wheel: 6dd55af6
2026-01-03 17:01:38,697 | INFO |   Human wheel: 9d72daf4
2026-01-03 17:01:38,697 | INFO |   GPU config: H100:1
2026-01-03 17:01:38,697 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] human completed: status=no_metrics
2026-01-03 17:01:50,494 | INFO | 
2026-01-03 17:01:50,494 | INFO | ================================================================================
2026-01-03 17:01:50,494 | INFO | [20/59] COMPLETED: 9badee53
2026-01-03 17:01:50,494 | INFO | Subject: Fix performance when `--generation-config` is not 
2026-01-03 17:01:50,494 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 17:01:50,495 | INFO |   Progress: 0 success, 20 errors (20/59)
2026-01-03 17:01:50,496 | INFO | [9ed82e70] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:01:50,496 | INFO |   Baseline wheel: 51f8aa90
2026-01-03 17:01:50,496 | INFO |   Human wheel: 9ed82e70
2026-01-03 17:01:50,496 | INFO |   GPU config: H100:1
2026-01-03 17:01:50,496 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 51f8aa90, will build from source
[URL CHECK] Human wheel URL does not exist for 9ed82e70, will build from source
[CPU PRE-BUILD] Building baseline 51f8aa90 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 51f8aa90 on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.5+cu124
[CPU PRE-BUILD] Baseline build ready (wheel: volume)
[CPU PRE-BUILD] Building human 6e36f4fa on CPU...
[ENSURE BUILD] Checking/building vLLM 6e36f4fa on CPU-only instance...
[ENSURE BUILD] Built and cached: vLLM 0.5.0.post1+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 17:03:06,320 | INFO | 
2026-01-03 17:03:06,320 | INFO | ================================================================================
2026-01-03 17:03:06,320 | INFO | [21/59] COMPLETED: 3476ed08
2026-01-03 17:03:06,320 | INFO | Subject: [Core] Optimize block_manager_v2 vs block_manager_v1 (to mak
2026-01-03 17:03:06,321 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 17:03:06,321 | INFO |   Progress: 0 success, 21 errors (21/59)
2026-01-03 17:03:06,322 | INFO | [ac45c44d] Starting benchmark | Model: deepseek-ai/DeepSeek-V2 | GPU: H100:4
2026-01-03 17:03:06,322 | INFO |   Baseline wheel: d6664664
2026-01-03 17:03:06,322 | INFO |   Human wheel: ac45c44d
2026-01-03 17:03:06,322 | INFO |   GPU config: H100:4
2026-01-03 17:03:06,322 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V2 --dataset-name sharegpt --num...
Running 3-way benchmark on Modal with H100:4...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:4...
[PARALLEL] Starting 3-way parallel benchmark with H100:4...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Built and cached: vLLM 0.5.0+cu124
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=volume, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=error
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=error
2026-01-03 17:06:48,909 | INFO | 
2026-01-03 17:06:48,910 | INFO | ================================================================================
2026-01-03 17:06:48,910 | INFO | [22/59] COMPLETED: 660470e5
2026-01-03 17:06:48,910 | INFO | Subject: [Core] Optimize evictor-v2 performance (#7193)
2026-01-03 17:06:48,910 | ERROR |   ❌ BASELINE_FAILED: baseline: Server failed to start. Logs: No server logs available; human: Server failed to start. Logs: No server logs available
2026-01-03 17:06:48,911 | INFO |   Progress: 0 success, 22 errors (22/59)
2026-01-03 17:06:48,912 | INFO | [ad8d696a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:06:48,912 | INFO |   Baseline wheel: 3d925165
2026-01-03 17:06:48,912 | INFO |   Human wheel: ad8d696a
2026-01-03 17:06:48,912 | INFO |   GPU config: H100:1
2026-01-03 17:06:48,912 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
