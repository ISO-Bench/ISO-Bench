2026-01-03 14:19:48,385 | INFO | ================================================================================
2026-01-03 14:19:48,385 | INFO | HERO BENCHMARK RUN
2026-01-03 14:19:48,385 | INFO | Start time: 2026-01-03T14:19:48.385159
2026-01-03 14:19:48,385 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_141948.log
2026-01-03 14:19:48,385 | INFO | ================================================================================
2026-01-03 14:19:48,385 | INFO | Loaded 59 commits from plan
2026-01-03 14:19:48,385 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2026-01-03 14:19:51,002 | INFO | 
================================================================================
2026-01-03 14:19:51,002 | INFO | [1/59] BENCHMARK: 015069b0
2026-01-03 14:19:51,002 | INFO | Subject: [Misc] Optimize the Qwen3_ReasoningParser extract_
2026-01-03 14:19:51,002 | INFO | Model: Qwen/Qwen3-7B-Instruct
2026-01-03 14:19:51,002 | INFO | ================================================================================
2026-01-03 14:19:51,002 | INFO |   Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 14:19:51,203 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 14:19:51,203 | INFO |   Human wheel: 015069b0
2026-01-03 14:19:51,203 | INFO |   GPU config: H100:1
2026-01-03 14:19:51,203 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
2026-01-03 14:31:47,501 | ERROR |   ‚ùå ERROR: BASELINE server failed to start. Logs: )
  File "/usr/local/lib/python3.11/site-packages/uvloop/__init__.py", line 92, in run
    return runner.run(wrapper())
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/usr/local/lib/python3.11/site-packages/uvloop/__init__.py", line 48, in wrapper
    return await main
           ^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/vllm/entrypoints/openai/api_server.py", line 1078, in run_server
    async with build_async_engine_client(args) as engine_client:
  File "/usr/local/lib/python3.11/contextlib.py", line 204, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/vllm/entrypoints/openai/api_server.py", line 146, in build_async_engine_client
    async with build_async_engine_client_from_engine_args(
  File "/usr/local/lib/python3.11/contextlib.py", line 204, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/vllm/entrypoints/openai/api_server.py", line 175, in build_async_engine_client_from_engine_args
    from vllm.v1.engine.async_llm import AsyncLLM
  File "/usr/local/lib/python3.11/site-packages/vllm/v1/engine/async_llm.py", line 30, in <module>
    from vllm.v1.engine.output_processor import (OutputProcessor,
  File "/usr/local/lib/python3.11/site-packages/vllm/v1/engine/output_processor.py", line 13, in <module>
    from vllm.v1.engine.detokenizer import IncrementalDetokenizer
  File "/usr/local/lib/python3.11/site-packages/vllm/v1/engine/detokenizer.py", line 8, in <module>
    from tokenizers.decoders import DecodeStream
ImportError: cannot import name 'DecodeStream' from 'tokenizers.decoders' (/usr/local/lib/python3.11/site-packages/tokenizers/decoders/__init__.py)

2026-01-03 14:31:47,501 | INFO |   Progress: 0 success, 1 errors (1/59)
2026-01-03 14:31:47,501 | INFO | 
================================================================================
2026-01-03 14:31:47,501 | INFO | [2/59] BENCHMARK: 0d243f2a
2026-01-03 14:31:47,501 | INFO | Subject: [ROCm][MoE] mi300 mixtral8x7B perf for specific BS
2026-01-03 14:31:47,501 | INFO | Model: mistralai/Mixtral-8x7B-Instruct-v0.1
2026-01-03 14:31:47,501 | INFO | ================================================================================
2026-01-03 14:31:47,503 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 14:31:47,503 | INFO |   Human wheel: 0d243f2a
2026-01-03 14:31:47,503 | INFO |   GPU config: H100:2
2026-01-03 14:31:47,504 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
