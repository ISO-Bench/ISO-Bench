2026-01-03 18:05:44,379 | INFO | ================================================================================
2026-01-03 18:05:44,380 | INFO | HERO BENCHMARK RUN
2026-01-03 18:05:44,380 | INFO | Start time: 2026-01-03T18:05:44.380092
2026-01-03 18:05:44,380 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_180544.log
2026-01-03 18:05:44,380 | INFO | ================================================================================
2026-01-03 18:05:44,380 | INFO | Loaded 59 commits from plan
2026-01-03 18:05:44,380 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2026-01-03 18:05:46,900 | INFO | 
*** PARALLEL MODE: 15 concurrent benchmarks ***
2026-01-03 18:05:46,900 | INFO | Spawning Modal containers in parallel...
2026-01-03 18:05:46,901 | INFO | [015069b0] Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 18:05:46,901 | INFO | [0ec82edd] Fixing model name: Qwen/Qwen3-30B-A3B -> Qwen/Qwen3-30B-A3B-Instruct-2507
2026-01-03 18:05:46,903 | INFO | [015069b0] Starting benchmark | Model: mergekit-community/Qwen3-7B-Instruct | GPU: H100:1
2026-01-03 18:05:46,904 | INFO | [0d243f2a] Starting benchmark | Model: mistralai/Mixtral-8x7B-Instruct-v0.1 | GPU: H100:2
2026-01-03 18:05:46,905 | INFO | [22dd9c27] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:05:46,906 | INFO | [21d93c14] Starting benchmark | Model: mistralai/Mixtral-8x7B-v0.1 | GPU: H100:8
2026-01-03 18:05:46,907 | INFO | [296f927f] Starting benchmark | Model: ibm-ai-platform/Bamba-9B-v2 | GPU: H100:1
2026-01-03 18:05:46,907 | INFO | [22d33bac] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:05:46,908 | INFO | [0ec82edd] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-Instruct-2507 | GPU: H100:2
2026-01-03 18:05:46,909 | INFO | [2f192835] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:05:46,909 | INFO | [2a052011] Starting benchmark | Model: nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8 | GPU: H100:2
2026-01-03 18:05:46,910 | INFO | [3092375e] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:05:46,910 | INFO | [2deb029d] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 18:05:46,910 | INFO | [3476ed08] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:05:46,911 | INFO | [35fad35a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:05:46,917 | INFO | [379da6dc] Starting benchmark | Model: meta-llama/Llama-3-70B | GPU: H100:4
2026-01-03 18:05:46,917 | INFO | [3a243095] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 18:05:47,112 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 18:05:47,112 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 18:05:47,112 | INFO |   Human wheel: 015069b0
2026-01-03 18:05:47,112 | INFO |   Human wheel: 0d243f2a
2026-01-03 18:05:47,112 | INFO |   Baseline wheel: a6d795d5
2026-01-03 18:05:47,112 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,112 | INFO |   GPU config: H100:2
2026-01-03 18:05:47,112 | INFO |   Baseline wheel: f1c85201
2026-01-03 18:05:47,113 | INFO |   Human wheel: 22dd9c27
2026-01-03 18:05:47,113 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,113 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 18:05:47,113 | INFO |   Baseline wheel: 0032903a
2026-01-03 18:05:47,113 | INFO |   Human wheel: 21d93c14
2026-01-03 18:05:47,113 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,114 | INFO |   Baseline wheel: b0e96aae
2026-01-03 18:05:47,114 | INFO |   Human wheel: 296f927f
2026-01-03 18:05:47,114 | INFO |   Baseline wheel: 005ae9be
2026-01-03 18:05:47,115 | INFO |   Baseline wheel: 95baec82
2026-01-03 18:05:47,115 | INFO |   GPU config: H100:8
2026-01-03 18:05:47,115 | INFO |   Command preview: VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --mo...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,115 | INFO |   Baseline wheel: 36fb68f9
2026-01-03 18:05:47,115 | INFO |   Human wheel: 22d33bac
2026-01-03 18:05:47,115 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,115 | INFO |   Baseline wheel: 3cd91dc9
2026-01-03 18:05:47,115 | INFO |   Human wheel: 0ec82edd
2026-01-03 18:05:47,115 | INFO |   Human wheel: 2f192835
2026-01-03 18:05:47,115 | INFO |   Baseline wheel: 029c71de
2026-01-03 18:05:47,115 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model mistralai/Mixtral-8x7B-v0.1 --tensor-parallel-size...
Running 3-way benchmark on Modal with H100:8...
2026-01-03 18:05:47,115 | INFO |   Baseline wheel: 54600709
2026-01-03 18:05:47,116 | INFO |   Baseline wheel: 733e7c9e
2026-01-03 18:05:47,116 | INFO |   Human wheel: 2a052011
2026-01-03 18:05:47,116 | INFO |   Baseline wheel: ebce310b
2026-01-03 18:05:47,117 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,117 | INFO |   Baseline wheel: 64172a97
2026-01-03 18:05:47,117 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dataset-name sharegpt...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,117 | INFO |   Human wheel: 3092375e
2026-01-03 18:05:47,117 | INFO |   GPU config: H100:2
2026-01-03 18:05:47,117 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,117 | INFO |   Human wheel: 2deb029d
2026-01-03 18:05:47,117 | INFO |   Human wheel: 3476ed08
2026-01-03 18:05:47,117 | INFO |   Human wheel: 35fad35a
2026-01-03 18:05:47,117 | INFO |   GPU config: H100:2
2026-01-03 18:05:47,118 | INFO |   Human wheel: 379da6dc
2026-01-03 18:05:47,118 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,118 | INFO |   Human wheel: 3a243095
2026-01-03 18:05:47,118 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,118 | INFO |   Command preview: vllm bench throughput --model Qwen/Qwen3-30B-A3B-Instruct-2507 --load-format dummy --input-len 1000 ...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 18:05:47,118 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,118 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,118 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,118 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,119 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 18:05:47,119 | INFO |   GPU config: H100:4
2026-01-03 18:05:47,119 | INFO |   GPU config: H100:1
2026-01-03 18:05:47,119 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,120 | INFO |   Command preview: python benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --out...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,120 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,120 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 18:05:47,121 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-70B --dtype float8 --input-len 100...
Running 3-way benchmark on Modal with H100:4...
2026-01-03 18:05:47,121 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
