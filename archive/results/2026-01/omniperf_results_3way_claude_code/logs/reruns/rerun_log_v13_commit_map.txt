2026-01-03 17:36:12,465 | INFO | ================================================================================
2026-01-03 17:36:12,465 | INFO | HERO BENCHMARK RUN
2026-01-03 17:36:12,465 | INFO | Start time: 2026-01-03T17:36:12.465583
2026-01-03 17:36:12,465 | INFO | Log file: omniperf_results/hero_run_logs/hero_run_20260103_173612.log
2026-01-03 17:36:12,465 | INFO | ================================================================================
2026-01-03 17:36:12,465 | INFO | Loaded 59 commits from plan
2026-01-03 17:36:12,465 | INFO | 
Loading HuggingFace dataset...
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2026-01-03 17:36:15,787 | INFO | 
*** PARALLEL MODE: 15 concurrent benchmarks ***
2026-01-03 17:36:15,787 | INFO | Spawning Modal containers in parallel...
2026-01-03 17:36:15,788 | INFO | [015069b0] Fixing model name: Qwen/Qwen3-7B-Instruct -> mergekit-community/Qwen3-7B-Instruct
2026-01-03 17:36:15,788 | INFO | [0ec82edd] Fixing model name: Qwen/Qwen3-30B-A3B -> Qwen/Qwen3-30B-A3B-Instruct-2507
2026-01-03 17:36:15,791 | INFO | [015069b0] Starting benchmark | Model: mergekit-community/Qwen3-7B-Instruct | GPU: H100:1
2026-01-03 17:36:15,791 | INFO | [0d243f2a] Starting benchmark | Model: mistralai/Mixtral-8x7B-Instruct-v0.1 | GPU: H100:2
2026-01-03 17:36:15,792 | INFO | [22d33bac] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:36:15,793 | INFO | [21d93c14] Starting benchmark | Model: mistralai/Mixtral-8x7B-v0.1 | GPU: H100:8
2026-01-03 17:36:15,793 | INFO | [296f927f] Starting benchmark | Model: ibm-ai-platform/Bamba-9B-v2 | GPU: H100:1
2026-01-03 17:36:15,793 | INFO | [2a052011] Starting benchmark | Model: nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8 | GPU: H100:2
2026-01-03 17:36:15,793 | INFO | [0ec82edd] Starting benchmark | Model: Qwen/Qwen3-30B-A3B-Instruct-2507 | GPU: H100:2
2026-01-03 17:36:15,794 | INFO | [22dd9c27] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:36:15,795 | INFO | [2deb029d] Starting benchmark | Model: neuralmagic/Meta-Llama-3-8B-Instruct-FP8 | GPU: H100:1
2026-01-03 17:36:15,797 | INFO | [2f192835] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:36:15,798 | INFO | [3476ed08] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:36:15,798 | INFO | [3092375e] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:36:15,798 | INFO | [379da6dc] Starting benchmark | Model: meta-llama/Llama-3-70B | GPU: H100:4
2026-01-03 17:36:15,799 | INFO | [3a243095] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:36:15,799 | INFO | [35fad35a] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:36:15,996 | INFO |   Baseline wheel: fbefc8a7
2026-01-03 17:36:15,996 | INFO |   Baseline wheel: 88f6ba32
2026-01-03 17:36:15,996 | INFO |   Human wheel: 015069b0
2026-01-03 17:36:15,996 | INFO |   Human wheel: 0d243f2a
2026-01-03 17:36:15,996 | INFO |   Baseline wheel: b0e96aae
2026-01-03 17:36:15,996 | INFO |   GPU config: H100:1
2026-01-03 17:36:15,996 | INFO |   GPU config: H100:2
2026-01-03 17:36:15,996 | INFO |   Baseline wheel: f1c85201
2026-01-03 17:36:15,997 | INFO |   Human wheel: 22d33bac
2026-01-03 17:36:15,997 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mergekit-community/Qwen3-7B-Instruct --dataset-name s...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:15,997 | INFO |   Baseline wheel: 36fb68f9
2026-01-03 17:36:15,997 | INFO |   Baseline wheel: 005ae9be
2026-01-03 17:36:15,997 | INFO |   Baseline wheel: 0032903a
2026-01-03 17:36:15,997 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model mistralai/Mixtral-8x7B-Instruct-v0.1...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:36:15,997 | INFO |   Baseline wheel: a6d795d5
2026-01-03 17:36:15,998 | INFO |   Human wheel: 21d93c14
2026-01-03 17:36:15,998 | INFO |   GPU config: H100:1
2026-01-03 17:36:15,998 | INFO |   Baseline wheel: 029c71de
2026-01-03 17:36:15,998 | INFO |   Baseline wheel: 95baec82
2026-01-03 17:36:15,998 | INFO |   Human wheel: 2a052011
2026-01-03 17:36:15,999 | INFO |   Human wheel: 0ec82edd
2026-01-03 17:36:15,999 | INFO |   Baseline wheel: 54600709
2026-01-03 17:36:15,999 | INFO |   Baseline wheel: 3cd91dc9
2026-01-03 17:36:15,999 | INFO |   Human wheel: 296f927f
2026-01-03 17:36:15,999 | INFO |   Baseline wheel: ebce310b
2026-01-03 17:36:15,999 | INFO |   Baseline wheel: 64172a97
2026-01-03 17:36:15,999 | INFO |   Baseline wheel: 733e7c9e
2026-01-03 17:36:16,000 | INFO |   Human wheel: 22dd9c27
2026-01-03 17:36:16,000 | INFO |   GPU config: H100:8
2026-01-03 17:36:16,000 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,000 | INFO |   Human wheel: 2deb029d
2026-01-03 17:36:16,000 | INFO |   Human wheel: 2f192835
2026-01-03 17:36:16,000 | INFO |   GPU config: H100:2
2026-01-03 17:36:16,000 | INFO |   GPU config: H100:2
2026-01-03 17:36:16,000 | INFO |   Human wheel: 3476ed08
2026-01-03 17:36:16,000 | INFO |   Human wheel: 3092375e
2026-01-03 17:36:16,000 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,000 | INFO |   Human wheel: 379da6dc
2026-01-03 17:36:16,000 | INFO |   Human wheel: 3a243095
2026-01-03 17:36:16,001 | INFO |   Human wheel: 35fad35a
2026-01-03 17:36:16,001 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,001 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model mistralai/Mixtral-8x7B-v0.1 --tensor-parallel-size...
Running 3-way benchmark on Modal with H100:8...
2026-01-03 17:36:16,001 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,001 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,001 | INFO |   Command preview: python benchmarks/benchmark_throughput.py --model nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:36:16,001 | INFO |   Command preview: vllm bench throughput --model Qwen/Qwen3-30B-A3B-Instruct-2507 --load-format dummy --input-len 1000 ...
Running 3-way benchmark on Modal with H100:2...
2026-01-03 17:36:16,001 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,001 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,001 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model ibm-ai-platform/Bamba-9B-v2 --dataset-name sharegpt...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,002 | INFO |   GPU config: H100:4
2026-01-03 17:36:16,002 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,002 | INFO |   GPU config: H100:1
2026-01-03 17:36:16,002 | INFO |   Command preview: VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 VLLM_USE_V1=1 python benchmarks/benchmark_latency.py --mo...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,002 | INFO |   Command preview: python benchmarks/benchmark_prefix_caching.py --model neuralmagic/Meta-Llama-3-8B-Instruct-FP8 --out...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,002 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,003 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --dtype float16 --nu...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,003 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,004 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3-70B --dtype float8 --input-len 100...
Running 3-way benchmark on Modal with H100:4...
2026-01-03 17:36:16,004 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm --num...
Running 3-way benchmark on Modal with H100:1...
2026-01-03 17:36:16,004 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --backend vllm...
Running 3-way benchmark on Modal with H100:1...
[URL CHECK] Baseline wheel URL does not exist for 95baec82, will build from source
[URL CHECK] Baseline wheel URL does not exist for ebce310b, will build from source
[URL CHECK] Baseline wheel URL does not exist for f1c85201, will build from source
[URL CHECK] Baseline wheel URL does not exist for 64172a97, will build from source
[URL CHECK] Baseline wheel URL does not exist for 029c71de, will build from source
[URL CHECK] Baseline wheel URL does not exist for 36fb68f9, will build from source
[URL CHECK] Baseline wheel URL does not exist for 54600709, will build from source
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 2f192835, will build from source
[CPU PRE-BUILD] Building baseline 95baec82 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 95baec82 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 379da6dc, will build from source
[CPU PRE-BUILD] Building baseline ebce310b on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM ebce310b on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 2deb029d, will build from source
[CPU PRE-BUILD] Building baseline 029c71de on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 029c71de on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 21d93c14, will build from source
[CPU PRE-BUILD] Building baseline f1c85201 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM f1c85201 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 0d243f2a, will build from source
[CPU PRE-BUILD] Building human 0d243f2a on CPU...
[ENSURE BUILD] Checking/building vLLM 0d243f2a on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 3476ed08, will build from source
[CPU PRE-BUILD] Building baseline 54600709 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 54600709 on CPU-only instance...
[URL CHECK] Human wheel URL does not exist for 2a052011, will build from source
[CPU PRE-BUILD] Building baseline 36fb68f9 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 36fb68f9 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[URL CHECK] Human wheel URL does not exist for 3a243095, will build from source
[CPU PRE-BUILD] Building baseline 64172a97 on CPU (no S3 wheel)...
[ENSURE BUILD] Checking/building vLLM 64172a97 on CPU-only instance...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[ENSURE BUILD] Cache HIT: vLLM 0.7.3.dev241+g0d243f2a5.d20220101.cu124 already cached
[CPU PRE-BUILD] Human wheel ready in volume
[CPU PRE-BUILD] Wheel sources: baseline=url, human=volume, agent=None
[PARALLEL MODE] Using parallel execution for H100:2...
[PARALLEL] Starting 3-way parallel benchmark with H100:2...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 17:38:26,807 | INFO | 
2026-01-03 17:38:26,807 | INFO | ================================================================================
2026-01-03 17:38:26,807 | INFO | [1/59] COMPLETED: 22dd9c27
2026-01-03 17:38:26,807 | INFO | Subject: [Kernel] Optimize Prefill Attention in Unified Triton Attent
2026-01-03 17:38:26,807 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 17:38:26,808 | INFO |   Progress: 0 success, 1 errors (1/59)
2026-01-03 17:38:26,809 | INFO | [4fb56914] Starting benchmark | Model: deepseek-ai/DeepSeek-V3-0324 | GPU: H100:8
2026-01-03 17:38:26,809 | INFO |   Baseline wheel: 0df4d9b0
2026-01-03 17:38:26,809 | INFO |   Human wheel: 4fb56914
2026-01-03 17:38:26,809 | INFO |   GPU config: H100:8
2026-01-03 17:38:26,809 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V3-0324 --dataset-name sharegpt ...
[BLOCKED] Model deepseek-ai/DeepSeek-V3-0324 is blocked (too large/unstable), skipping benchmark
2026-01-03 17:38:26,810 | INFO | 
2026-01-03 17:38:26,810 | INFO | ================================================================================
2026-01-03 17:38:26,810 | INFO | [2/59] COMPLETED: 4fb56914
2026-01-03 17:38:26,810 | INFO | Subject: [perf] Add fused MLA QKV + strided layernorm (#21116)
2026-01-03 17:38:26,810 | ERROR |   ❌ BLOCKED_MODEL: Model deepseek-ai/DeepSeek-V3-0324 is blocked: too large or unstable for reliable benchmarking
2026-01-03 17:38:26,810 | INFO |   Progress: 0 success, 2 errors (2/59)
2026-01-03 17:38:26,812 | INFO | [526de822] Starting benchmark | Model: MODEL | GPU: H100:1
2026-01-03 17:38:26,812 | INFO |   Baseline wheel: 56fe4c29
2026-01-03 17:38:26,812 | INFO |   Human wheel: 526de822
2026-01-03 17:38:26,812 | INFO |   GPU config: H100:1
2026-01-03 17:38:26,812 | INFO |   Command preview: python benchmarks/benchmark_latency.py --dtype bfloat16 --enable-chunked-prefill False --load-format...
Running 3-way benchmark on Modal with H100:1...
[CPU PRE-BUILD] Wheel sources: baseline=url, human=url, agent=None
[PARALLEL MODE] Using parallel execution for H100:1...
[PARALLEL] Starting 3-way parallel benchmark with H100:1...
[PARALLEL] Spawning baseline, human in parallel...
[PARALLEL] Waiting for all phases to complete...
[PARALLEL] Waiting for baseline...
[PARALLEL] baseline completed: status=no_metrics
[PARALLEL] Waiting for human...
[PARALLEL] human completed: status=no_metrics
2026-01-03 17:40:26,041 | INFO | 
2026-01-03 17:40:26,041 | INFO | ================================================================================
2026-01-03 17:40:26,041 | INFO | [3/59] COMPLETED: 526de822
2026-01-03 17:40:26,041 | INFO | Subject: [Kernel][Triton][AMD] Use block size heuristic for avg 2.8x 
2026-01-03 17:40:26,041 | ERROR |   ❌ BASELINE_FAILED: baseline: Benchmark produced no metrics; human: Benchmark produced no metrics
2026-01-03 17:40:26,042 | INFO |   Progress: 0 success, 3 errors (3/59)
2026-01-03 17:40:26,044 | INFO | [660470e5] Starting benchmark | Model: meta-llama/Llama-3.1-8B-Instruct | GPU: H100:1
2026-01-03 17:40:26,044 | INFO |   Baseline wheel: 8d59dbb0
2026-01-03 17:40:26,044 | INFO |   Human wheel: 660470e5
2026-01-03 17:40:26,044 | INFO |   GPU config: H100:1
2026-01-03 17:40:26,044 | INFO |   Command preview: python benchmarks/benchmark_serving.py --model meta-llama/Llama-3.1-8B-Instruct --tensor-parallel-si...
