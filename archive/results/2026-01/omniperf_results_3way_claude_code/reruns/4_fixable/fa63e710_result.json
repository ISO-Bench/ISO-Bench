{
  "commit_short": "fa63e710",
  "commit_full": "fa63e710c7fbaae3a445f669d3b5ba6b9a4ef412",
  "parent_hash": "2a0309a646b1ed83a0c40974e08c8dc628726d3c",
  "task_id": "vllm_core-0091",
  "model": "meta-llama/Meta-Llama-3-8B",
  "benchmark_type": "latency",
  "description": "Reduce scheduling overhead after cuda sync",
  "issue": "Effect size (-0.5%) within noise",
  "fix": "Add --num-iters 100, run 3 trials",
  "timestamp": "2026-01-17 07:51:32",
  "baseline_command": "python3 benchmarks/benchmark_latency.py --model meta-llama/Meta-Llama-3-8B --batch-size 32 --input-len 1000 --output-len 128 --num-iters 100",
  "test_command": "python3 benchmarks/benchmark_latency.py --model meta-llama/Meta-Llama-3-8B --batch-size 32 --input-len 1000 --output-len 128 --num-iters 100",
  "is_asymmetric": false,
  "num_trials": 1,
  "baseline": {
    "status": "success",
    "metrics": {
      "latency_avg_ms": 3203.0584950697084,
      "throughput_tok_s": 12797.0
    },
    "duration_s": 400.6794686317444,
    "raw_output": "12 metrics.py:453] Avg prompt throughput: 11184.4 tokens/s, Avg generation throughput: 1193.5 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 82/100 [04:22<00:57,  3.20s/it]\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 83/100 [04:25<00:54,  3.20s/it]INFO 01-16 23:57:17 metrics.py:453] Avg prompt throughput: 10759.3 tokens/s, Avg generation throughput: 1215.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 84/100 [04:28<00:51,  3.19s/it]INFO 01-16 23:57:22 metrics.py:453] Avg prompt throughput: 7976.7 tokens/s, Avg generation throughput: 1456.5 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 85/100 [04:32<00:47,  3.19s/it]\nProfiling iterations:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 86/100 [04:35<00:44,  3.19s/it]INFO 01-16 23:57:27 metrics.py:453] Avg prompt throughput: 12771.5 tokens/s, Avg generation throughput: 1060.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 87/100 [04:38<00:41,  3.19s/it]\nProfiling iterations:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 88/100 [04:41<00:38,  3.19s/it]INFO 01-16 23:57:32 metrics.py:453] Avg prompt throughput: 7538.0 tokens/s, Avg generation throughput: 1479.0 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 16 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 89/100 [04:44<00:35,  3.19s/it]INFO 01-16 23:57:37 metrics.py:453] Avg prompt throughput: 11178.2 tokens/s, Avg generation throughput: 1192.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 90/100 [04:48<00:31,  3.20s/it]\nProfiling iterations:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 91/100 [04:51<00:28,  3.20s/it]INFO 01-16 23:57:43 metrics.py:453] Avg prompt throughput: 10734.9 tokens/s, Avg generation throughput: 1213.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 92/100 [04:54<00:25,  3.20s/it]INFO 01-16 23:57:48 metrics.py:453] Avg prompt throughput: 7988.0 tokens/s, Avg generation throughput: 1452.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.9%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 93/100 [04:57<00:22,  3.20s/it]\nProfiling iterations:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 94/100 [05:01<00:19,  3.27s/it]INFO 01-16 23:57:53 metrics.py:453] Avg prompt throughput: 12452.5 tokens/s, Avg generation throughput: 977.5 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 95/100 [05:04<00:16,  3.25s/it]INFO 01-16 23:57:58 metrics.py:453] Avg prompt throughput: 6398.3 tokens/s, Avg generation throughput: 1574.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 96/100 [05:07<00:12,  3.23s/it]\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 97/100 [05:10<00:09,  3.22s/it]INFO 01-16 23:58:03 metrics.py:453] Avg prompt throughput: 12784.0 tokens/s, Avg generation throughput: 1054.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 98/100 [05:13<00:06,  3.22s/it]\nProfiling iterations:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 99/100 [05:17<00:03,  3.21s/it]INFO 01-16 23:58:08 metrics.py:453] Avg prompt throughput: 7906.9 tokens/s, Avg generation throughput: 1443.8 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 16 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [05:20<00:00,  3.21s/it]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [05:20<00:00,  3.20s/it]\nAvg latency: 3.2030584950697083 seconds\n10% percentile latency: 3.1849410579918187 seconds\n25% percentile latency: 3.190244905748841 seconds\n50% percentile latency: 3.1933818319957936 seconds\n75% percentile latency: 3.1967503052546817 seconds\n90% percentile latency: 3.199761089005915 seconds\n99% percentile latency: 3.45286326954636 seconds\n[rank0]:[W116 23:58:11.918417731 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nBENCHMARK_COMPLETE\n"
  },
  "human": {
    "status": "success",
    "metrics": {
      "latency_avg_ms": 3202.9847665406123,
      "throughput_tok_s": 12775.4
    },
    "duration_s": 400.957683801651,
    "raw_output": "rations:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 82/100 [04:22<00:57,  3.20s/it]INFO 01-17 00:03:55 metrics.py:453] Avg prompt throughput: 9237.6 tokens/s, Avg generation throughput: 1345.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 8 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 83/100 [04:25<00:54,  3.19s/it]INFO 01-17 00:04:00 metrics.py:453] Avg prompt throughput: 9583.1 tokens/s, Avg generation throughput: 1319.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 84/100 [04:28<00:51,  3.19s/it]\nProfiling iterations:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 85/100 [04:32<00:47,  3.19s/it]INFO 01-17 00:04:05 metrics.py:453] Avg prompt throughput: 12308.0 tokens/s, Avg generation throughput: 1095.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 86/100 [04:35<00:44,  3.19s/it]INFO 01-17 00:04:10 metrics.py:453] Avg prompt throughput: 6381.1 tokens/s, Avg generation throughput: 1576.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 87/100 [04:38<00:41,  3.20s/it]\nProfiling iterations:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 88/100 [04:41<00:38,  3.20s/it]INFO 01-17 00:04:15 metrics.py:453] Avg prompt throughput: 12767.8 tokens/s, Avg generation throughput: 1059.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 89/100 [04:44<00:35,  3.19s/it]\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 90/100 [04:48<00:31,  3.19s/it]INFO 01-17 00:04:20 metrics.py:453] Avg prompt throughput: 7975.4 tokens/s, Avg generation throughput: 1443.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 16 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 91/100 [04:51<00:28,  3.20s/it]INFO 01-17 00:04:25 metrics.py:453] Avg prompt throughput: 11190.8 tokens/s, Avg generation throughput: 1187.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 92/100 [04:54<00:25,  3.20s/it]\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 93/100 [04:57<00:22,  3.19s/it]INFO 01-17 00:04:30 metrics.py:453] Avg prompt throughput: 10714.0 tokens/s, Avg generation throughput: 1216.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 94/100 [05:01<00:19,  3.27s/it]INFO 01-17 00:04:35 metrics.py:453] Avg prompt throughput: 7977.2 tokens/s, Avg generation throughput: 1348.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 95/100 [05:04<00:16,  3.25s/it]\nProfiling iterations:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 96/100 [05:07<00:12,  3.23s/it]INFO 01-17 00:04:40 metrics.py:453] Avg prompt throughput: 12510.8 tokens/s, Avg generation throughput: 1082.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 97/100 [05:10<00:09,  3.22s/it]INFO 01-17 00:04:45 metrics.py:453] Avg prompt throughput: 6398.3 tokens/s, Avg generation throughput: 1567.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 98/100 [05:13<00:06,  3.22s/it]\nProfiling iterations:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 99/100 [05:17<00:03,  3.21s/it]INFO 01-17 00:04:50 metrics.py:453] Avg prompt throughput: 12771.9 tokens/s, Avg generation throughput: 1060.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [05:20<00:00,  3.21s/it]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [05:20<00:00,  3.20s/it]\nAvg latency: 3.202984766540612 seconds\n10% percentile latency: 3.18529166089138 seconds\n25% percentile latency: 3.1897089065023465 seconds\n50% percentile latency: 3.192415211502521 seconds\n75% percentile latency: 3.1963362830065307 seconds\n90% percentile latency: 3.200895095009764 seconds\n99% percentile latency: 3.459299391570967 seconds\n[rank0]:[W117 00:04:52.979260739 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nBENCHMARK_COMPLETE\n"
  },
  "agent": {
    "status": "success",
    "metrics": {
      "latency_avg_ms": 3201.863324361184,
      "throughput_tok_s": 12773.1
    },
    "duration_s": 400.1946611404419,
    "raw_output": "ions:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 82/100 [04:22<00:57,  3.19s/it]INFO 01-17 00:10:35 metrics.py:453] Avg prompt throughput: 9244.0 tokens/s, Avg generation throughput: 1346.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 8 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 83/100 [04:25<00:54,  3.19s/it]INFO 01-17 00:10:40 metrics.py:453] Avg prompt throughput: 9597.4 tokens/s, Avg generation throughput: 1321.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 84/100 [04:28<00:51,  3.19s/it]\nProfiling iterations:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 85/100 [04:32<00:47,  3.19s/it]INFO 01-17 00:10:45 metrics.py:453] Avg prompt throughput: 12315.6 tokens/s, Avg generation throughput: 1096.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 86/100 [04:35<00:44,  3.19s/it]INFO 01-17 00:10:50 metrics.py:453] Avg prompt throughput: 6389.6 tokens/s, Avg generation throughput: 1578.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 87/100 [04:38<00:41,  3.19s/it]\nProfiling iterations:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 88/100 [04:41<00:38,  3.19s/it]INFO 01-17 00:10:55 metrics.py:453] Avg prompt throughput: 12766.8 tokens/s, Avg generation throughput: 1059.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 89/100 [04:44<00:35,  3.19s/it]\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 90/100 [04:47<00:31,  3.19s/it]INFO 01-17 00:11:00 metrics.py:453] Avg prompt throughput: 7979.7 tokens/s, Avg generation throughput: 1444.3 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 16 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 91/100 [04:51<00:28,  3.19s/it]INFO 01-17 00:11:05 metrics.py:453] Avg prompt throughput: 11183.2 tokens/s, Avg generation throughput: 1193.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 92/100 [04:54<00:25,  3.19s/it]\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 93/100 [04:57<00:22,  3.19s/it]INFO 01-17 00:11:10 metrics.py:453] Avg prompt throughput: 10752.9 tokens/s, Avg generation throughput: 1215.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 94/100 [05:01<00:19,  3.27s/it]INFO 01-17 00:11:15 metrics.py:453] Avg prompt throughput: 7995.8 tokens/s, Avg generation throughput: 1351.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 95/100 [05:04<00:16,  3.25s/it]\nProfiling iterations:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 96/100 [05:07<00:12,  3.23s/it]INFO 01-17 00:11:20 metrics.py:453] Avg prompt throughput: 12512.9 tokens/s, Avg generation throughput: 1082.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 97/100 [05:10<00:09,  3.22s/it]INFO 01-17 00:11:25 metrics.py:453] Avg prompt throughput: 6398.2 tokens/s, Avg generation throughput: 1574.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.0%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 98/100 [05:13<00:06,  3.21s/it]\nProfiling iterations:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 99/100 [05:16<00:03,  3.21s/it]INFO 01-17 00:11:30 metrics.py:453] Avg prompt throughput: 12777.2 tokens/s, Avg generation throughput: 1054.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [05:20<00:00,  3.21s/it]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [05:20<00:00,  3.20s/it]\nAvg latency: 3.201863324361184 seconds\n10% percentile latency: 3.186104549297306 seconds\n25% percentile latency: 3.1879719514945464 seconds\n50% percentile latency: 3.1912640480004484 seconds\n75% percentile latency: 3.1945296165031323 seconds\n90% percentile latency: 3.199293983489042 seconds\n99% percentile latency: 3.4493520464088943 seconds\n[rank0]:[W117 00:11:32.140616811 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nBENCHMARK_COMPLETE\n"
  },
  "analysis": {
    "primary_metric": "latency_avg_ms",
    "baseline_value": 3203.0584950697084,
    "human_value": 3202.9847665406123,
    "agent_value": 3201.863324361184,
    "human_improvement_pct": 0.0,
    "agent_improvement_pct": 0.04
  }
}