{
  "commit_short": "3476ed08",
  "commit_full": "3476ed0809ec91a3457da0cb90543133a4f4b519",
  "parent_hash": "54600709b6d419fb243ce718a48ab7d40f5c3eb7",
  "task_id": "vllm_core-0017",
  "model": "facebook/opt-125m",
  "benchmark_type": "latency",
  "description": "Optimize block_manager_v2 vs v1",
  "issue": "Same command for baseline/test",
  "fix": "Asymmetric: baseline=no flag, test=--use-v2-block-manager",
  "timestamp": "2026-01-16 13:02:23",
  "baseline_command": "python benchmarks/benchmark_latency.py --model facebook/opt-125m --input-len 1536 --output-len 50 --batch-size 8",
  "test_command": "python benchmarks/benchmark_latency.py --model facebook/opt-125m --input-len 1536 --output-len 50 --batch-size 8 --use-v2-block-manager",
  "is_asymmetric": true,
  "num_trials": 1,
  "baseline": {
    "status": "success",
    "metrics": {
      "latency_avg_ms": 169.1986189332662
    },
    "duration_s": 45.92584800720215,
    "raw_output": "py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nINFO 01-16 13:02:49 weight_utils.py:218] Using model weights format ['*.bin']\nINFO 01-16 13:02:49 model_runner.py:234] Loading model weights took 0.2389 GB\nINFO 01-16 13:02:50 gpu_executor.py:83] # GPU blocks: 128016, # CPU blocks: 7281\nINFO 01-16 13:02:53 model_runner.py:864] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\nINFO 01-16 13:02:53 model_runner.py:868] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 01-16 13:02:59 model_runner.py:1022] Graph capturing finished in 6 secs.\nSamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=50, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None)\nWarming up...\n\nWarmup iterations:   0%|          | 0/10 [00:00<?, ?it/s]\nWarmup iterations:  10%|\u2588         | 1/10 [00:00<00:01,  5.65it/s]\nWarmup iterations:  20%|\u2588\u2588        | 2/10 [00:00<00:01,  5.78it/s]\nWarmup iterations:  30%|\u2588\u2588\u2588       | 3/10 [00:00<00:01,  5.82it/s]\nWarmup iterations:  40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:01,  5.85it/s]\nWarmup iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00<00:00,  5.86it/s]\nWarmup iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:01<00:00,  5.83it/s]\nWarmup iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:01<00:00,  5.84it/s]\nWarmup iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:01<00:00,  5.86it/s]\nWarmup iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:01<00:00,  5.88it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  5.89it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  5.85it/s]\n\nProfiling iterations:   0%|          | 0/30 [00:00<?, ?it/s]\nProfiling iterations:   3%|\u258e         | 1/30 [00:00<00:04,  5.82it/s]\nProfiling iterations:   7%|\u258b         | 2/30 [00:00<00:04,  5.87it/s]\nProfiling iterations:  10%|\u2588         | 3/30 [00:00<00:04,  5.88it/s]\nProfiling iterations:  13%|\u2588\u258e        | 4/30 [00:00<00:04,  5.90it/s]\nProfiling iterations:  17%|\u2588\u258b        | 5/30 [00:00<00:04,  5.89it/s]\nProfiling iterations:  20%|\u2588\u2588        | 6/30 [00:01<00:04,  5.89it/s]\nProfiling iterations:  23%|\u2588\u2588\u258e       | 7/30 [00:01<00:03,  5.88it/s]\nProfiling iterations:  27%|\u2588\u2588\u258b       | 8/30 [00:01<00:03,  5.88it/s]\nProfiling iterations:  30%|\u2588\u2588\u2588       | 9/30 [00:01<00:03,  5.88it/s]\nProfiling iterations:  33%|\u2588\u2588\u2588\u258e      | 10/30 [00:01<00:03,  5.89it/s]\nProfiling iterations:  37%|\u2588\u2588\u2588\u258b      | 11/30 [00:01<00:03,  5.91it/s]\nProfiling iterations:  40%|\u2588\u2588\u2588\u2588      | 12/30 [00:02<00:03,  5.91it/s]\nProfiling iterations:  43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:02<00:02,  5.88it/s]\nProfiling iterations:  47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:02<00:02,  5.90it/s]\nProfiling iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:02<00:02,  5.91it/s]\nProfiling iterations:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:02<00:02,  5.91it/s]\nProfiling iterations:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:02<00:02,  5.92it/s]\nProfiling iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:03<00:02,  5.91it/s]\nProfiling iterations:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:03<00:01,  5.92it/s]\nProfiling iterations:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:03<00:01,  5.93it/s]\nProfiling iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:03<00:01,  5.93it/s]\nProfiling iterations:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:03<00:01,  5.90it/s]\nProfiling iterations:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:03<00:01,  5.90it/s]\nProfiling iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:04<00:01,  5.90it/s]\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:04<00:00,  5.91it/s]\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:04<00:00,  5.91it/s]\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:04<00:00,  5.93it/s]\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:04<00:00,  5.92it/s]\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:04<00:00,  5.93it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:05<00:00,  5.92it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:05<00:00,  5.90it/s]\nAvg latency: 0.1691986189332662 seconds\n10% percentile latency: 0.16786239770017347 seconds\n25% percentile latency: 0.1683596200005013 seconds\n50% percentile latency: 0.16895367499955682 seconds\n75% percentile latency: 0.1698795610000161 seconds\n90% percentile latency: 0.17052149300043312 seconds\n99% percentile latency: 0.17177463489039838 seconds\n\nBENCHMARK_COMPLETE\n"
  },
  "human": {
    "status": "success",
    "metrics": {
      "latency_avg_ms": 175.43653616676238
    },
    "duration_s": 97.9230968952179,
    "raw_output": "dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nINFO 01-16 13:04:23 weight_utils.py:218] Using model weights format ['*.bin']\nINFO 01-16 13:04:24 model_runner.py:234] Loading model weights took 0.2389 GB\nINFO 01-16 13:04:24 gpu_executor.py:83] # GPU blocks: 128016, # CPU blocks: 7281\nINFO 01-16 13:04:28 model_runner.py:864] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\nINFO 01-16 13:04:28 model_runner.py:868] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 01-16 13:04:35 model_runner.py:1022] Graph capturing finished in 7 secs.\nSamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=50, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None)\nWarming up...\n\nWarmup iterations:   0%|          | 0/10 [00:00<?, ?it/s]\nWarmup iterations:  10%|\u2588         | 1/10 [00:00<00:01,  5.55it/s]\nWarmup iterations:  20%|\u2588\u2588        | 2/10 [00:00<00:01,  5.66it/s]\nWarmup iterations:  30%|\u2588\u2588\u2588       | 3/10 [00:00<00:01,  5.71it/s]\nWarmup iterations:  40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:01,  5.72it/s]\nWarmup iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00<00:00,  5.72it/s]\nWarmup iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:01<00:00,  5.73it/s]\nWarmup iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:01<00:00,  5.74it/s]\nWarmup iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:01<00:00,  5.75it/s]\nWarmup iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:01<00:00,  5.76it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  5.74it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  5.73it/s]\n\nProfiling iterations:   0%|          | 0/30 [00:00<?, ?it/s]\nProfiling iterations:   3%|\u258e         | 1/30 [00:00<00:05,  5.69it/s]\nProfiling iterations:   7%|\u258b         | 2/30 [00:00<00:04,  5.64it/s]\nProfiling iterations:  10%|\u2588         | 3/30 [00:00<00:04,  5.63it/s]\nProfiling iterations:  13%|\u2588\u258e        | 4/30 [00:00<00:04,  5.62it/s]\nProfiling iterations:  17%|\u2588\u258b        | 5/30 [00:00<00:04,  5.64it/s]\nProfiling iterations:  20%|\u2588\u2588        | 6/30 [00:01<00:04,  5.65it/s]\nProfiling iterations:  23%|\u2588\u2588\u258e       | 7/30 [00:01<00:04,  5.67it/s]\nProfiling iterations:  27%|\u2588\u2588\u258b       | 8/30 [00:01<00:03,  5.68it/s]\nProfiling iterations:  30%|\u2588\u2588\u2588       | 9/30 [00:01<00:03,  5.70it/s]\nProfiling iterations:  33%|\u2588\u2588\u2588\u258e      | 10/30 [00:01<00:03,  5.71it/s]\nProfiling iterations:  37%|\u2588\u2588\u2588\u258b      | 11/30 [00:01<00:03,  5.71it/s]\nProfiling iterations:  40%|\u2588\u2588\u2588\u2588      | 12/30 [00:02<00:03,  5.72it/s]\nProfiling iterations:  43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:02<00:02,  5.75it/s]\nProfiling iterations:  47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:02<00:02,  5.74it/s]\nProfiling iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:02<00:02,  5.71it/s]\nProfiling iterations:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:02<00:02,  5.72it/s]\nProfiling iterations:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:02<00:02,  5.72it/s]\nProfiling iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:03<00:02,  5.69it/s]\nProfiling iterations:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:03<00:01,  5.70it/s]\nProfiling iterations:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:03<00:01,  5.70it/s]\nProfiling iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:03<00:01,  5.70it/s]\nProfiling iterations:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:03<00:01,  5.71it/s]\nProfiling iterations:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:04<00:01,  5.70it/s]\nProfiling iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:04<00:01,  5.69it/s]\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:04<00:00,  5.70it/s]\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:04<00:00,  5.69it/s]\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:04<00:00,  5.70it/s]\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:04<00:00,  5.69it/s]\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:05<00:00,  5.70it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:05<00:00,  5.69it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:05<00:00,  5.69it/s]\nAvg latency: 0.17543653616676239 seconds\n10% percentile latency: 0.17421639530030006 seconds\n25% percentile latency: 0.17458072649992573 seconds\n50% percentile latency: 0.17507054050020088 seconds\n75% percentile latency: 0.1760678955001822 seconds\n90% percentile latency: 0.1779423474997202 seconds\n\nBENCHMARK_COMPLETE\n"
  },
  "agent": {
    "status": "success",
    "metrics": {
      "latency_avg_ms": 184.16436470006374
    },
    "duration_s": 68.88001608848572,
    "raw_output": "py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nINFO 01-16 13:05:35 weight_utils.py:218] Using model weights format ['*.bin']\nINFO 01-16 13:05:35 model_runner.py:234] Loading model weights took 0.2389 GB\nINFO 01-16 13:05:35 gpu_executor.py:83] # GPU blocks: 128016, # CPU blocks: 7281\nINFO 01-16 13:05:39 model_runner.py:864] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\nINFO 01-16 13:05:39 model_runner.py:868] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 01-16 13:05:45 model_runner.py:1022] Graph capturing finished in 6 secs.\nSamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=50, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None)\nWarming up...\n\nWarmup iterations:   0%|          | 0/10 [00:00<?, ?it/s]\nWarmup iterations:  10%|\u2588         | 1/10 [00:00<00:01,  5.29it/s]\nWarmup iterations:  20%|\u2588\u2588        | 2/10 [00:00<00:01,  5.33it/s]\nWarmup iterations:  30%|\u2588\u2588\u2588       | 3/10 [00:00<00:01,  5.37it/s]\nWarmup iterations:  40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:01,  5.38it/s]\nWarmup iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00<00:00,  5.32it/s]\nWarmup iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:01<00:00,  5.22it/s]\nWarmup iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:01<00:00,  5.25it/s]\nWarmup iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:01<00:00,  5.27it/s]\nWarmup iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:01<00:00,  5.31it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  5.34it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  5.31it/s]\n\nProfiling iterations:   0%|          | 0/30 [00:00<?, ?it/s]\nProfiling iterations:   3%|\u258e         | 1/30 [00:00<00:05,  5.45it/s]\nProfiling iterations:   7%|\u258b         | 2/30 [00:00<00:05,  5.43it/s]\nProfiling iterations:  10%|\u2588         | 3/30 [00:00<00:04,  5.43it/s]\nProfiling iterations:  13%|\u2588\u258e        | 4/30 [00:00<00:04,  5.42it/s]\nProfiling iterations:  17%|\u2588\u258b        | 5/30 [00:00<00:04,  5.41it/s]\nProfiling iterations:  20%|\u2588\u2588        | 6/30 [00:01<00:04,  5.41it/s]\nProfiling iterations:  23%|\u2588\u2588\u258e       | 7/30 [00:01<00:04,  5.41it/s]\nProfiling iterations:  27%|\u2588\u2588\u258b       | 8/30 [00:01<00:04,  5.41it/s]\nProfiling iterations:  30%|\u2588\u2588\u2588       | 9/30 [00:01<00:03,  5.39it/s]\nProfiling iterations:  33%|\u2588\u2588\u2588\u258e      | 10/30 [00:01<00:03,  5.39it/s]\nProfiling iterations:  37%|\u2588\u2588\u2588\u258b      | 11/30 [00:02<00:03,  5.41it/s]\nProfiling iterations:  40%|\u2588\u2588\u2588\u2588      | 12/30 [00:02<00:03,  5.41it/s]\nProfiling iterations:  43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:02<00:03,  5.41it/s]\nProfiling iterations:  47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:02<00:02,  5.42it/s]\nProfiling iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:02<00:02,  5.44it/s]\nProfiling iterations:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:02<00:02,  5.43it/s]\nProfiling iterations:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:03<00:02,  5.41it/s]\nProfiling iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:03<00:02,  5.41it/s]\nProfiling iterations:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:03<00:02,  5.43it/s]\nProfiling iterations:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:03<00:01,  5.43it/s]\nProfiling iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:03<00:01,  5.44it/s]\nProfiling iterations:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:04<00:01,  5.44it/s]\nProfiling iterations:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:04<00:01,  5.45it/s]\nProfiling iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:04<00:01,  5.45it/s]\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:04<00:00,  5.45it/s]\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:04<00:00,  5.43it/s]\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:04<00:00,  5.44it/s]\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:05<00:00,  5.43it/s]\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:05<00:00,  5.44it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:05<00:00,  5.44it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:05<00:00,  5.43it/s]\nAvg latency: 0.18416436470006375 seconds\n10% percentile latency: 0.18291490460014756 seconds\n25% percentile latency: 0.1832797660003962 seconds\n50% percentile latency: 0.18416823650022707 seconds\n75% percentile latency: 0.1849323657502282 seconds\n90% percentile latency: 0.1854262188998291 seconds\n99% percentile latency: 0.18634155841986286 seconds\n\nBENCHMARK_COMPLETE\n"
  },
  "analysis": {
    "primary_metric": "latency_avg_ms",
    "baseline_value": 169.1986189332662,
    "human_value": 175.43653616676238,
    "agent_value": 184.16436470006374,
    "human_improvement_pct": -3.69,
    "agent_improvement_pct": -8.85
  }
}