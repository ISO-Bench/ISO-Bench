{
  "human_commit": "35fad35a",
  "human_commit_full": "35fad35a485eac9195c510731ba4a9d297dfd963",
  "parent_commit": "733e7c9e95f5b066ac420b00701eef7ea164a79e",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "status": "error",
  "error": "Server crashed after applying patch",
  "duration_s": 156.30971097946167,
  "metrics": {},
  "raw_output": "=== Applying agent patch to baseline vLLM ===\nvLLM uses mllama - checking transformers version...\nvLLM found at: /opt/vllm_baseline\nApplying patch...\nchecking file tests/v1/sample/test_topk_topp_sampler.py\nchecking file vllm/v1/sample/ops/topk_topp_sampler.py\nchecking file vllm/v1/sample/sampler.py\npatching file tests/v1/sample/test_topk_topp_sampler.py\npatching file vllm/v1/sample/ops/topk_topp_sampler.py\npatching file vllm/v1/sample/sampler.py\nAGENT_PATCH_APPLIED\nFixing rope_scaling compatibility for Llama-3.1 models...\n  Patching: /opt/vllm_baseline/vllm/transformers_utils/config.py\nSearching for Python with vLLM...\nINFO 01-14 18:49:30 [__init__.py:239] Automatically detected platform cuda.\nINFO 01-14 18:49:34 [__init__.py:239] Automatically detected platform cuda.\nWARNING: Could not find Python with vLLM, trying default python3\nINFO 01-14 18:49:39 [__init__.py:239] Automatically detected platform cuda.\nvLLM import failed\noutlines.fsm OK\n=== Starting vLLM server for AGENT benchmark ===\nINFO 01-14 18:49:48 [__init__.py:239] Automatically detected platform cuda.\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 189, in _run_module_as_main\n  File \"<frozen runpy>\", line 112, in _get_module_details\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 11, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 22, in <module>\n    from vllm.executor.executor_base import ExecutorBase\n  File \"/opt/vllm_baseline/vllm/executor/executor_base.py\", line 16, in <module>\n    from vllm.model_executor.layers.sampler import SamplerOutput\n  File \"/opt/vllm_baseline/vllm/model_executor/layers/sampler.py\", line 23, in <module>\n    from vllm.spec_decode.metrics import SpecDecodeWorkerMetrics\n  File \"/opt/vllm_baseline/vllm/spec_decode/metrics.py\", line 9, in <module>\n    from vllm.model_executor.layers.spec_decode_base_sampler import (\n  File \"/opt/vllm_baseline/vllm/model_executor/layers/spec_decode_base_sampler.py\", line 10, in <module>\n    from vllm.platforms import current_platform\n  File \"/opt/vllm_baseline/vllm/platforms/__init__.py\", line 271, in __getattr__\n    _current_platform = resolve_obj_by_qualname(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/utils.py\", line 1905, in resolve_obj_by_qualname\n    module = importlib.import_module(module_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/platforms/cuda.py\", line 15, in <module>\n    import vllm._C  # noqa\n    ^^^^^^^^^^^^^^\nImportError: /opt/vllm_baseline/vllm/_C.abi3.so: undefined symbol: cuTensorMapEncodeTiled\nSERVER_CRASHED\nUnable to find image 'anonymous/vllm-baseline:baseline-733e7c9e95f5' locally\nbaseline-733e7c9e95f5: Pulling from anonymous/vllm-baseline\n3c645031de29: Already exists\n0d6448aff889: Already exists\n0a7674e3e8fe: Already exists\nb71b637b97c5: Already exists\n56dc85502937: Already exists\nec6d5f6c9ed9: Already exists\n47b8539d532f: Already exists\nfd9cc1ad8dee: Already exists\n83525caeeb35: Already exists\n8e79813a7b9d: Already exists\n312a542960e3: Already exists\n949691b47390: Pulling fs layer\n7cbb09265719: Pulling fs layer\ncb7c80b8c4f1: Pulling fs layer\nf4d72f8f1249: Pulling fs layer\n5b7bacc7057e: Pulling fs layer\ne64afe835865: Pulling fs layer\n4a82fee13bb2: Pulling fs layer\nddcf5b5e4ab8: Pulling fs layer\n2e599e44546d: Pulling fs layer\nc893f5559028: Pulling fs layer\nb063a4ec7879: Pulling fs layer\ne1e445bb7d30: Pulling fs layer\nbdaaf7070025: Pulling fs layer\n7c4e441f5131: Pulling fs layer\n4a82fee13bb2: Waiting\n3698e6c58385: Pulling fs layer\n2e599e44546d: Waiting\nddcf5b5e4ab8: Waiting\nc893f5559028: Waiting\nb063a4ec7879: Waiting\n56bbf6be42b2: Pulling fs layer\ne1e445bb7d30: Waiting\n11b2f7621245: Pulling fs layer\n7c4e441f5131: Waiting\n6724dfa13c29: Pulling fs layer\nf4d72f8f1249: Waiting\nd933ff4bb70a: Pulling fs layer\n3698e6c58385: Waiting\n5b7bacc7057e: Waiting\n56bbf6be42b2: Waiting\n93c0344e74b4: Pulling fs layer\nbdaaf7070025: Waiting\n11b2f7621245: Waiting\n53d40c5f05cc: Pulling fs layer\n6724dfa13c29: Waiting\ne64afe835865: Waiting\nd933ff4bb70a: Waiting\n93c0344e74b4: Waiting\n0a4db432cfb7: Pulling fs layer\n53d40c5f05cc: Waiting\n0a4db432cfb7: Waiting\n7cbb09265719: Download complete\n949691b47390: Verifying Checksum\n949691b47390: Download complete\n949691b47390: Pull complete\n7cbb09265719: Pull complete\n5b7bacc7057e: Verifying Checksum\n5b7bacc7057e: Download complete\ne64afe835865: Verifying Checksum\ne64afe835865: Download complete\nf4d72f8f1249: Verifying Checksum\nf4d72f8f1249: Download complete\ncb7c80b8c4f1: Verifying Checksum\ncb7c80b8c4f1: Download complete\n2e599e44546d: Verifying Checksum\n2e599e44546d: Download complete\nc893f5559028: Download complete\nb063a4ec7879: Verifying Checksum\nb063a4ec7879: Download complete\nddcf5b5e4ab8: Verifying Checksum\nddcf5b5e4ab8: Download complete\ne1e445bb7d30: Verifying Checksum\ne1e445bb7d30: Download complete\n7c4e441f5131: Verifying Checksum\n7c4e441f5131: Download complete\nbdaaf7070025: Verifying Checksum\nbdaaf7070025: Download complete\n3698e6c58385: Verifying Checksum\n3698e6c58385: Download complete\n11b2f7621245: Verifying Checksum\n11b2f7621245: Download complete\n56bbf6be42b2: Download complete\n6724dfa13c29: Verifying Checksum\n6724dfa13c29: Download complete\n93c0344e74b4: Download complete\n53d40c5f05cc: Download complete\n0a4db432cfb7: Download complete\ncb7c80b8c4f1: Pull complete\nf4d72f8f1249: Pull complete\n5b7bacc7057e: Pull complete\ne64afe835865: Pull complete\nd933ff4bb70a: Verifying Checksum\nd933ff4bb70a: Download complete\n4a82fee13bb2: Verifying Checksum\n4a82fee13bb2: Download complete\n4a82fee13bb2: Pull complete\nddcf5b5e4ab8: Pull complete\n2e599e44546d: Pull complete\nc893f5559028: Pull complete\nb063a4ec7879: Pull complete\ne1e445bb7d30: Pull complete\nbdaaf7070025: Pull complete\n7c4e441f5131: Pull complete\n3698e6c58385: Pull complete\n56bbf6be42b2: Pull complete\n11b2f7621245: Pull complete\n6724dfa13c29: Pull complete\nd933ff4bb70a: Pull complete\n93c0344e74b4: Pull complete\n53d40c5f05cc: Pull complete\n0a4db432cfb7: Pull complete\nDigest: sha256:69eae218134488ddbb30c1e436cddaef352080b917c88a527b7f20793a615bfe\nStatus: Downloaded newer image for anonymous/vllm-baseline:baseline-733e7c9e95f5\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 11, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 22, in <module>\n    from vllm.executor.executor_base import ExecutorBase\n  File \"/opt/vllm_baseline/vllm/executor/executor_base.py\", line 16, in <module>\n    from vllm.model_executor.layers.sampler import SamplerOutput\n  File \"/opt/vllm_baseline/vllm/model_executor/layers/sampler.py\", line 23, in <module>\n    from vllm.spec_decode.metrics import SpecDecodeWorkerMetrics\n  File \"/opt/vllm_baseline/vllm/spec_decode/metrics.py\", line 9, in <module>\n    from vllm.model_executor.layers.spec_decode_base_sampler import (\n  File \"/opt/vllm_baseline/vllm/model_executor/layers/spec_decode_base_sampler.py\", line 10, in <module>\n    from vllm.platforms import current_platform\n  File \"/opt/vllm_baseline/vllm/platforms/__init__.py\", line 271, in __getattr__\n    _current_platform = resolve_obj_by_qualname(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/utils.py\", line 1905, in resolve_obj_by_qualname\n    module = importlib.import_module(module_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/platforms/cuda.py\", line 15, in <module>\n    import vllm._C  # noqa\n    ^^^^^^^^^^^^^^\nImportError: /opt/vllm_baseline/vllm/_C.abi3.so: undefined symbol: cuTensorMapEncodeTiled\n",
  "timestamp": "2026-01-15 02:49:49"
}