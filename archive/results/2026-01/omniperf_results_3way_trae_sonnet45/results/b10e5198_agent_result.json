{
  "human_commit": "b10e5198",
  "human_commit_full": "b10e51989551cd80dd74079429ccf91f0807bd92",
  "parent_commit": "9bde5ba12709ea0fe9e1a1eeee1e8d7b4c7ea668",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "status": "error",
  "error": "Server crashed after applying patch",
  "duration_s": 158.27031755447388,
  "metrics": {},
  "raw_output": "ed decoding modules patched\n=== Starting vLLM server for AGENT benchmark ===\nINFO 01-14 15:51:49 [__init__.py:239] Automatically detected platform cuda.\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 189, in _run_module_as_main\n  File \"<frozen runpy>\", line 112, in _get_module_details\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 12, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 15, in <module>\n    from vllm.config import (CacheConfig, CompilationConfig, ConfigFormat,\n  File \"/opt/vllm_baseline/vllm/config.py\", line 29, in <module>\n    from vllm.model_executor.layers.quantization import (QUANTIZATION_METHODS,\n  File \"/opt/vllm_baseline/vllm/model_executor/__init__.py\", line 3, in <module>\n    from vllm.model_executor.parameter import (BasevLLMParameter,\n  File \"/opt/vllm_baseline/vllm/model_executor/parameter.py\", line 9, in <module>\n    from vllm.distributed import get_tensor_model_parallel_rank\n  File \"/opt/vllm_baseline/vllm/distributed/__init__.py\", line 3, in <module>\n    from .communication_op import *\n  File \"/opt/vllm_baseline/vllm/distributed/communication_op.py\", line 8, in <module>\n    from .parallel_state import get_tp_group\n  File \"/opt/vllm_baseline/vllm/distributed/parallel_state.py\", line 122, in <module>\n    from vllm.platforms import current_platform\n  File \"/opt/vllm_baseline/vllm/platforms/__init__.py\", line 271, in __getattr__\n    _current_platform = resolve_obj_by_qualname(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/utils.py\", line 1993, in resolve_obj_by_qualname\n    module = importlib.import_module(module_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/platforms/cuda.py\", line 15, in <module>\n    import vllm._C  # noqa\n    ^^^^^^^^^^^^^^\nImportError: /opt/vllm_baseline/vllm/_C.abi3.so: undefined symbol: cuTensorMapEncodeTiled\nSERVER_CRASHED\nUnable to find image 'anonymous/vllm-baseline:baseline-9bde5ba12709' locally\nbaseline-9bde5ba12709: Pulling from anonymous/vllm-baseline\n3c645031de29: Pulling fs layer\n0d6448aff889: Pulling fs layer\n0a7674e3e8fe: Pulling fs layer\nb71b637b97c5: Pulling fs layer\n56dc85502937: Pulling fs layer\nec6d5f6c9ed9: Pulling fs layer\n47b8539d532f: Pulling fs layer\nfd9cc1ad8dee: Pulling fs layer\n83525caeeb35: Pulling fs layer\n8e79813a7b9d: Pulling fs layer\n312a542960e3: Pulling fs layer\n949691b47390: Pulling fs layer\n7cbb09265719: Pulling fs layer\nec6d5f6c9ed9: Waiting\n47b8539d532f: Waiting\ncb7c80b8c4f1: Pulling fs layer\n312a542960e3: Waiting\nf4d72f8f1249: Pulling fs layer\nb71b637b97c5: Waiting\n949691b47390: Waiting\nfd9cc1ad8dee: Waiting\n7cbb09265719: Waiting\n5b7bacc7057e: Pulling fs layer\n83525caeeb35: Waiting\n56dc85502937: Waiting\ncb7c80b8c4f1: Waiting\ne64afe835865: Pulling fs layer\n8e79813a7b9d: Waiting\na9ef39bb0261: Pulling fs layer\nf4d72f8f1249: Waiting\n5b7bacc7057e: Waiting\ne64afe835865: Waiting\n0c1a2638bbbe: Pulling fs layer\n7f4e1283eab4: Pulling fs layer\n715419302b25: Pulling fs layer\n3bccf4fdeb66: Pulling fs layer\n14b412d881d7: Pulling fs layer\n715419302b25: Waiting\ncaa1f4a81734: Pulling fs layer\na9ef39bb0261: Waiting\n7f4e1283eab4: Waiting\n3bccf4fdeb66: Waiting\n0c1a2638bbbe: Waiting\n14b412d881d7: Waiting\n65ff25b871ed: Pulling fs layer\ncaa1f4a81734: Waiting\n728ccc969967: Pulling fs layer\n28f825683c00: Pulling fs layer\n2d57c7273716: Pulling fs layer\n65ff25b871ed: Waiting\n28f825683c00: Waiting\n96885283b346: Pulling fs layer\n728ccc969967: Waiting\n2d57c7273716: Waiting\n6e227bd4d8a8: Pulling fs layer\n93f118f0976c: Pulling fs layer\n78fbf8dc062e: Pulling fs layer\ne6e081eb798e: Pulling fs layer\n38056a1d24d2: Pulling fs layer\n6e227bd4d8a8: Waiting\n96885283b346: Waiting\n93f118f0976c: Waiting\n78fbf8dc062e: Waiting\ne6e081eb798e: Waiting\n38056a1d24d2: Waiting\n0d6448aff889: Verifying Checksum\n0d6448aff889: Download complete\n3c645031de29: Verifying Checksum\n3c645031de29: Download complete\nb71b637b97c5: Verifying Checksum\nb71b637b97c5: Download complete\n0a7674e3e8fe: Verifying Checksum\n0a7674e3e8fe: Download complete\n56dc85502937: Verifying Checksum\n56dc85502937: Download complete\n47b8539d532f: Verifying Checksum\n47b8539d532f: Download complete\nfd9cc1ad8dee: Download complete\n83525caeeb35: Download complete\n312a542960e3: Verifying Checksum\n312a542960e3: Download complete\n949691b47390: Download complete\n7cbb09265719: Download complete\n3c645031de29: Pull complete\n0d6448aff889: Pull complete\n0a7674e3e8fe: Pull complete\nb71b637b97c5: Pull complete\n56dc85502937: Pull complete\ncb7c80b8c4f1: Verifying Checksum\ncb7c80b8c4f1: Download complete\nf4d72f8f1249: Verifying Checksum\nf4d72f8f1249: Download complete\n5b7bacc7057e: Verifying Checksum\n5b7bacc7057e: Download complete\ne64afe835865: Verifying Checksum\ne64afe835865: Download complete\nec6d5f6c9ed9: Download complete\n0c1a2638bbbe: Verifying Checksum\n0c1a2638bbbe: Download complete\n7f4e1283eab4: Verifying Checksum\n7f4e1283eab4: Download complete\n715419302b25: Verifying Checksum\n715419302b25: Download complete\n3bccf4fdeb66: Verifying Checksum\n3bccf4fdeb66: Download complete\n14b412d881d7: Verifying Checksum\n14b412d881d7: Download complete\ncaa1f4a81734: Verifying Checksum\ncaa1f4a81734: Download complete\n8e79813a7b9d: Verifying Checksum\n8e79813a7b9d: Download complete\n728ccc969967: Verifying Checksum\n728ccc969967: Download complete\nec6d5f6c9ed9: Pull complete\n47b8539d532f: Pull complete\nfd9cc1ad8dee: Pull complete\n83525caeeb35: Pull complete\n28f825683c00: Verifying Checksum\n28f825683c00: Download complete\n2d57c7273716: Verifying Checksum\n2d57c7273716: Download complete\n96885283b346: Verifying Checksum\n96885283b346: Download complete\n6e227bd4d8a8: Download complete\n65ff25b871ed: Verifying Checksum\n65ff25b871ed: Download complete\n78fbf8dc062e: Verifying Checksum\n78fbf8dc062e: Download complete\ne6e081eb798e: Verifying Checksum\ne6e081eb798e: Download complete\n38056a1d24d2: Verifying Checksum\n38056a1d24d2: Download complete\n93f118f0976c: Verifying Checksum\n93f118f0976c: Download complete\na9ef39bb0261: Verifying Checksum\na9ef39bb0261: Download complete\n8e79813a7b9d: Pull complete\n312a542960e3: Pull complete\n949691b47390: Pull complete\n7cbb09265719: Pull complete\ncb7c80b8c4f1: Pull complete\nf4d72f8f1249: Pull complete\n5b7bacc7057e: Pull complete\ne64afe835865: Pull complete\na9ef39bb0261: Pull complete\n0c1a2638bbbe: Pull complete\n7f4e1283eab4: Pull complete\n715419302b25: Pull complete\n3bccf4fdeb66: Pull complete\n14b412d881d7: Pull complete\ncaa1f4a81734: Pull complete\n65ff25b871ed: Pull complete\n728ccc969967: Pull complete\n28f825683c00: Pull complete\n2d57c7273716: Pull complete\n96885283b346: Pull complete\n6e227bd4d8a8: Pull complete\n93f118f0976c: Pull complete\n78fbf8dc062e: Pull complete\ne6e081eb798e: Pull complete\n38056a1d24d2: Pull complete\nDigest: sha256:2ebf273cf22a2c6f8b23d84b3f6e5168ddd4973cd45394b67aa7dffa9df1c7a6\nStatus: Downloaded newer image for anonymous/vllm-baseline:baseline-9bde5ba12709\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 10, in <module>\n    import vllm.env_override  # isort:skip  # noqa: F401\n    ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/env_override.py\", line 4, in <module>\n    import torch\n  File \"/usr/local/lib/python3.12/dist-packages/torch/__init__.py\", line 2108, in <module>\n    from torch import _VF as _VF, functional as functional  # usort: skip\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/functional.py\", line 7, in <module>\n    import torch.nn.functional as F\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\", line 8, in <module>\n    from torch.nn.modules import *  # usort: skip # noqa: F403\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\", line 1, in <module>\n    from .module import Module  # usort: skip\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 29, in <module>\n    from torch.utils._python_dispatch import is_traceable_wrapper_subclass\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/__init__.py\", line 8, in <module>\n    from torch.utils import (\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/__init__.py\", line 1, in <module>\n    from torch.utils.data.dataloader import (\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 21, in <module>\n    import torch.utils.data.graph_settings\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/graph_settings.py\", line 8, in <module>\n    from torch.utils.data.datapipes.iter.sharding import (\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/datapipes/__init__.py\", line 1, in <module>\n    from torch.utils.data.datapipes import dataframe as dataframe, iter as iter, map as map\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/datapipes/iter/__init__.py\", line 1, in <module>\n    from torch.utils.data.datapipes.iter.callable import (\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/datapipes/iter/callable.py\", line 6, in <module>\n    from torch.utils.data._utils.collate import default_collate\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/__init__.py\", line 54, in <module>\n    from . import collate, fetch, pin_memory, signal_handling, worker\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\", line 327, in <module>\n    default_collate_fn_map[np.ndarray] = collate_numpy_array_fn\n                           ^^^^^^^^^^\nAttributeError: module 'numpy' has no attribute 'ndarray'\n",
  "timestamp": "2026-01-14 23:51:50"
}