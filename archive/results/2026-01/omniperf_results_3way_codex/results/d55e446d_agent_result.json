{
  "human_commit": "d55e446d",
  "human_commit_full": "d55e446d1320d0f5f22bc3584f81f18d7924f166",
  "parent_commit": "ec82c3e388b962a30a02fa376c222cef787b3c14",
  "model": "meta-llama/Meta-Llama-3-8B",
  "status": "error",
  "error": "Server crashed after applying patch",
  "duration_s": 201.07188296318054,
  "metrics": {},
  "raw_output": "ue is None\nINFO 01-14 11:43:39 [__init__.py:220] Platform plugin cuda loaded.\nWARNING 01-14 11:43:39 [__init__.py:221] Platform plugin cuda function's return value is None\nWARNING 01-14 11:43:39 [__init__.py:221] Platform plugin rocm function's return value is None\nWARNING 01-14 11:43:39 [__init__.py:221] Platform plugin hpu function's return value is None\nWARNING 01-14 11:43:39 [__init__.py:221] Platform plugin xpu function's return value is None\nWARNING 01-14 11:43:39 [__init__.py:221] Platform plugin cpu function's return value is None\nWARNING 01-14 11:43:39 [__init__.py:221] Platform plugin neuron function's return value is None\nINFO 01-14 11:43:39 [__init__.py:246] Automatically detected platform cuda.\nvLLM import failed\noutlines.fsm OK\n=== Starting vLLM server for AGENT benchmark ===\nWARNING 01-14 11:43:48 [__init__.py:221] Platform plugin tpu function's return value is None\nINFO 01-14 11:43:48 [__init__.py:220] Platform plugin cuda loaded.\nWARNING 01-14 11:43:48 [__init__.py:221] Platform plugin cuda function's return value is None\nWARNING 01-14 11:43:48 [__init__.py:221] Platform plugin rocm function's return value is None\nWARNING 01-14 11:43:48 [__init__.py:221] Platform plugin hpu function's return value is None\nWARNING 01-14 11:43:48 [__init__.py:221] Platform plugin xpu function's return value is None\nWARNING 01-14 11:43:48 [__init__.py:221] Platform plugin cpu function's return value is None\nWARNING 01-14 11:43:48 [__init__.py:221] Platform plugin neuron function's return value is None\nINFO 01-14 11:43:48 [__init__.py:246] Automatically detected platform cuda.\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 189, in _run_module_as_main\n  File \"<frozen runpy>\", line 112, in _get_module_details\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 12, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 20, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n  File \"/opt/vllm_baseline/vllm/config.py\", line 32, in <module>\n    from vllm.model_executor.layers.quantization import (QUANTIZATION_METHODS,\n  File \"/opt/vllm_baseline/vllm/model_executor/__init__.py\", line 3, in <module>\n    from vllm.model_executor.parameter import (BasevLLMParameter,\n  File \"/opt/vllm_baseline/vllm/model_executor/parameter.py\", line 9, in <module>\n    from vllm.distributed import get_tensor_model_parallel_rank\n  File \"/opt/vllm_baseline/vllm/distributed/__init__.py\", line 3, in <module>\n    from .communication_op import *\n  File \"/opt/vllm_baseline/vllm/distributed/communication_op.py\", line 8, in <module>\n    from .parallel_state import get_tp_group\n  File \"/opt/vllm_baseline/vllm/distributed/parallel_state.py\", line 149, in <module>\n    from vllm.platforms import current_platform\n  File \"/opt/vllm_baseline/vllm/platforms/__init__.py\", line 278, in __getattr__\n    _current_platform = resolve_obj_by_qualname(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/utils.py\", line 2189, in resolve_obj_by_qualname\n    module = importlib.import_module(module_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/platforms/cuda.py\", line 14, in <module>\n    import vllm._C  # noqa\n    ^^^^^^^^^^^^^^\nImportError: /opt/vllm_baseline/vllm/_C.abi3.so: undefined symbol: cuTensorMapEncodeTiled\nSERVER_CRASHED\nUnable to find image 'anonymous/vllm-baseline:baseline-ec82c3e388b9' locally\nbaseline-ec82c3e388b9: Pulling from anonymous/vllm-baseline\n9cb31e2e37ea: Already exists\nb95112eaf283: Already exists\n030ef8250936: Already exists\n72ac9ccfda38: Already exists\n73389fbd088f: Already exists\n0264850675f7: Already exists\nde1d03310308: Already exists\nc1d2af7fad0f: Already exists\n5601308b3ac6: Already exists\n6b2035e8b73e: Already exists\ned71f8f81b33: Already exists\na04181a7ff83: Pulling fs layer\nb89dfbaf9e2c: Pulling fs layer\ndc1d202b3ed0: Pulling fs layer\nad0178e8a361: Pulling fs layer\ne4a092a24edb: Pulling fs layer\ncd9db290845e: Pulling fs layer\ndffec7fbf4dd: Pulling fs layer\na8be18ab8904: Pulling fs layer\n0b9c9172e472: Pulling fs layer\ne4a092a24edb: Waiting\ncd9db290845e: Waiting\nec85484421a8: Pulling fs layer\nc05e22123773: Pulling fs layer\n7fcbac520dff: Pulling fs layer\nad0178e8a361: Waiting\n3e3534bc8c88: Pulling fs layer\ndffec7fbf4dd: Waiting\n0b9c9172e472: Waiting\na8be18ab8904: Waiting\n6091d971ea6c: Pulling fs layer\nc05e22123773: Waiting\nec85484421a8: Waiting\n7fcbac520dff: Waiting\n3e3534bc8c88: Waiting\ne6972b3eaa65: Pulling fs layer\n6091d971ea6c: Waiting\n81ed9c91ac45: Pulling fs layer\ne6972b3eaa65: Waiting\nf5d389d07992: Pulling fs layer\n81ed9c91ac45: Waiting\nc540300311d3: Pulling fs layer\nf5d389d07992: Waiting\na1516179e6cc: Pulling fs layer\ne84d76ceac9a: Pulling fs layer\nc540300311d3: Waiting\na1516179e6cc: Waiting\nd8aa6c38e09c: Pulling fs layer\ne84d76ceac9a: Waiting\n490e293976ba: Pulling fs layer\n9c23f5e972d8: Pulling fs layer\n490e293976ba: Waiting\n673d7703b565: Pulling fs layer\nd8aa6c38e09c: Waiting\n9c23f5e972d8: Waiting\n5d396d76920e: Pulling fs layer\n673d7703b565: Waiting\n3e07d9ec2394: Pulling fs layer\n5d396d76920e: Waiting\n33f5af67a8ce: Pulling fs layer\n3e07d9ec2394: Waiting\n33f5af67a8ce: Waiting\nb89dfbaf9e2c: Download complete\na04181a7ff83: Download complete\na04181a7ff83: Pull complete\nb89dfbaf9e2c: Pull complete\ne4a092a24edb: Verifying Checksum\ne4a092a24edb: Download complete\ncd9db290845e: Verifying Checksum\ncd9db290845e: Download complete\nad0178e8a361: Verifying Checksum\nad0178e8a361: Download complete\ndc1d202b3ed0: Verifying Checksum\ndc1d202b3ed0: Download complete\n0b9c9172e472: Verifying Checksum\n0b9c9172e472: Download complete\nec85484421a8: Download complete\nc05e22123773: Verifying Checksum\nc05e22123773: Download complete\n7fcbac520dff: Verifying Checksum\n7fcbac520dff: Download complete\n3e3534bc8c88: Verifying Checksum\n3e3534bc8c88: Download complete\n6091d971ea6c: Verifying Checksum\n6091d971ea6c: Download complete\ne6972b3eaa65: Verifying Checksum\ne6972b3eaa65: Download complete\na8be18ab8904: Verifying Checksum\na8be18ab8904: Download complete\n81ed9c91ac45: Verifying Checksum\n81ed9c91ac45: Download complete\nc540300311d3: Verifying Checksum\nc540300311d3: Download complete\na1516179e6cc: Verifying Checksum\na1516179e6cc: Download complete\ne84d76ceac9a: Verifying Checksum\ne84d76ceac9a: Download complete\ndc1d202b3ed0: Pull complete\nd8aa6c38e09c: Verifying Checksum\nd8aa6c38e09c: Download complete\nad0178e8a361: Pull complete\ne4a092a24edb: Pull complete\ncd9db290845e: Pull complete\n490e293976ba: Verifying Checksum\n490e293976ba: Download complete\n9c23f5e972d8: Verifying Checksum\n9c23f5e972d8: Download complete\n673d7703b565: Download complete\n5d396d76920e: Verifying Checksum\n5d396d76920e: Download complete\n3e07d9ec2394: Verifying Checksum\n3e07d9ec2394: Download complete\n33f5af67a8ce: Verifying Checksum\n33f5af67a8ce: Download complete\nf5d389d07992: Verifying Checksum\nf5d389d07992: Download complete\ndffec7fbf4dd: Verifying Checksum\ndffec7fbf4dd: Download complete\ndffec7fbf4dd: Pull complete\na8be18ab8904: Pull complete\n0b9c9172e472: Pull complete\nec85484421a8: Pull complete\nc05e22123773: Pull complete\n7fcbac520dff: Pull complete\n3e3534bc8c88: Pull complete\n6091d971ea6c: Pull complete\ne6972b3eaa65: Pull complete\n81ed9c91ac45: Pull complete\nf5d389d07992: Pull complete\nc540300311d3: Pull complete\na1516179e6cc: Pull complete\ne84d76ceac9a: Pull complete\nd8aa6c38e09c: Pull complete\n490e293976ba: Pull complete\n9c23f5e972d8: Pull complete\n673d7703b565: Pull complete\n5d396d76920e: Pull complete\n3e07d9ec2394: Pull complete\n33f5af67a8ce: Pull complete\nDigest: sha256:9468d942ccec2c4a10b6fbe0973a8a9740e414a529761ddc999941a1c9c2f9e8\nStatus: Downloaded newer image for anonymous/vllm-baseline:baseline-ec82c3e388b9\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 12, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 20, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n  File \"/opt/vllm_baseline/vllm/config.py\", line 32, in <module>\n    from vllm.model_executor.layers.quantization import (QUANTIZATION_METHODS,\n  File \"/opt/vllm_baseline/vllm/model_executor/__init__.py\", line 3, in <module>\n    from vllm.model_executor.parameter import (BasevLLMParameter,\n  File \"/opt/vllm_baseline/vllm/model_executor/parameter.py\", line 9, in <module>\n    from vllm.distributed import get_tensor_model_parallel_rank\n  File \"/opt/vllm_baseline/vllm/distributed/__init__.py\", line 3, in <module>\n    from .communication_op import *\n  File \"/opt/vllm_baseline/vllm/distributed/communication_op.py\", line 8, in <module>\n    from .parallel_state import get_tp_group\n  File \"/opt/vllm_baseline/vllm/distributed/parallel_state.py\", line 149, in <module>\n    from vllm.platforms import current_platform\n  File \"/opt/vllm_baseline/vllm/platforms/__init__.py\", line 278, in __getattr__\n    _current_platform = resolve_obj_by_qualname(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/utils.py\", line 2189, in resolve_obj_by_qualname\n    module = importlib.import_module(module_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/vllm_baseline/vllm/platforms/cuda.py\", line 14, in <module>\n    import vllm._C  # noqa\n    ^^^^^^^^^^^^^^\nImportError: /opt/vllm_baseline/vllm/_C.abi3.so: undefined symbol: cuTensorMapEncodeTiled\n",
  "timestamp": "2026-01-14 19:43:50"
}