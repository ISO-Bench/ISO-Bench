{
  "human_commit": "b690e348",
  "human_commit_full": "b690e34824fd5a5c4054a0c0468ebfb6aa1dd215",
  "parent_commit": "25373b6c6cc2068e3914fa906d3240088f7af157",
  "model": "ibm-ai-platform/Bamba-9B-v2",
  "status": "error",
  "error": "Server crashed after applying patch",
  "duration_s": 204.73421907424927,
  "metrics": {},
  "raw_output": "ry.py:414]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"/opt/vllm_baseline/vllm/model_executor/models/bamba.py\", line 27, in <module>\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]     from vllm.model_executor.layers.mamba.mamba_mixer2 import MambaMixer2\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"/opt/vllm_baseline/vllm/model_executor/layers/mamba/mamba_mixer2.py\", line 28, in <module>\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]     from vllm.model_executor.layers.mamba.ops.mamba_ssm import (\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]   File \"/opt/vllm_baseline/vllm/model_executor/layers/mamba/ops/mamba_ssm.py\", line 209, in <module>\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]     out: Optional[torch.Tensor] = None):\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414]          ^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414] NameError: name 'Optional' is not defined\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m ERROR 01-14 12:09:51 [registry.py:414] \n\u001b[1;36m(APIServer pid=996)\u001b[0;0m Traceback (most recent call last):\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"<frozen runpy>\", line 198, in _run_module_as_main\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"<frozen runpy>\", line 88, in _run_code\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/opt/vllm_baseline/vllm/entrypoints/openai/api_server.py\", line 1884, in <module>\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     uvloop.run(run_server(args))\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py\", line 109, in run\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     return __asyncio.run(\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m            ^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     return runner.run(main)\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m            ^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     return self._loop.run_until_complete(task)\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py\", line 61, in wrapper\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     return await main\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m            ^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/opt/vllm_baseline/vllm/entrypoints/openai/api_server.py\", line 1816, in run_server\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/opt/vllm_baseline/vllm/entrypoints/openai/api_server.py\", line 1836, in run_server_worker\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     async with build_async_engine_client(\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     return await anext(self.gen)\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m            ^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/opt/vllm_baseline/vllm/entrypoints/openai/api_server.py\", line 165, in build_async_engine_client\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     async with build_async_engine_client_from_engine_args(\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     return await anext(self.gen)\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m            ^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/opt/vllm_baseline/vllm/entrypoints/openai/api_server.py\", line 191, in build_async_engine_client_from_engine_args\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     vllm_config = engine_args.create_engine_config(usage_context=usage_context)\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 1043, in create_engine_config\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     model_config = self.create_model_config()\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 889, in create_model_config\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     return ModelConfig(\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m            ^^^^^^^^^^^^\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   File \"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_dataclasses.py\", line 123, in __init__\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     s.__pydantic_validator__.validate_python(ArgsKwargs(args, kwargs), self_instance=s)\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m pydantic_core._pydantic_core.ValidationError: 1 validation error for ModelConfig\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m   Value error, Model architectures ['BambaForCausalLM'] failed to be inspected. Please check the logs for more details. [type=value_error, input_value=ArgsKwargs((), {'model': ...attention_dtype': None}), input_type=ArgsKwargs]\n\u001b[1;36m(APIServer pid=996)\u001b[0;0m     For further information visit https://errors.pydantic.dev/2.11/v/value_error\nSERVER_CRASHED\nUnable to find image 'anonymous/vllm-baseline:baseline-25373b6c6cc2' locally\nbaseline-25373b6c6cc2: Pulling from anonymous/vllm-baseline\n9cb31e2e37ea: Already exists\nb95112eaf283: Already exists\n030ef8250936: Already exists\n72ac9ccfda38: Already exists\n73389fbd088f: Already exists\n0264850675f7: Already exists\nde1d03310308: Already exists\nc1d2af7fad0f: Already exists\n5601308b3ac6: Already exists\n6b2035e8b73e: Already exists\ned71f8f81b33: Already exists\n6a2306edc128: Already exists\nbb5ee2f41954: Already exists\nae1cc335b65b: Already exists\n2fb01f5ad376: Already exists\nb7dfd152a1fd: Already exists\n2987a32afa11: Already exists\n06ba41083b8d: Pulling fs layer\n3a13c90b0c49: Pulling fs layer\n63db0879e352: Pulling fs layer\nce4b1c2c1a4b: Pulling fs layer\n5605d3eadacd: Pulling fs layer\n969f07e447c8: Pulling fs layer\nd1013c4b4f44: Pulling fs layer\nd76f357a7fd3: Pulling fs layer\n371b8738953d: Pulling fs layer\n5605d3eadacd: Waiting\n3cf45a90fadf: Pulling fs layer\n9af66e82fea9: Pulling fs layer\n969f07e447c8: Waiting\ncb14bfd96623: Pulling fs layer\nd1013c4b4f44: Waiting\n386ac1592b6a: Pulling fs layer\n963fda8b9aa0: Pulling fs layer\n27b005b3f2b3: Pulling fs layer\nd76f357a7fd3: Waiting\nd8c7cc086f6f: Pulling fs layer\n371b8738953d: Waiting\n3cf45a90fadf: Waiting\n945afabce0bd: Pulling fs layer\n310e3f2c7a2a: Pulling fs layer\n386ac1592b6a: Waiting\n27b005b3f2b3: Waiting\n9af66e82fea9: Waiting\n963fda8b9aa0: Waiting\nce4b1c2c1a4b: Waiting\n49124192b7fe: Pulling fs layer\ncb14bfd96623: Waiting\nd8c7cc086f6f: Waiting\n945afabce0bd: Waiting\n310e3f2c7a2a: Waiting\n49124192b7fe: Waiting\n63db0879e352: Verifying Checksum\n63db0879e352: Download complete\n3a13c90b0c49: Verifying Checksum\n3a13c90b0c49: Download complete\nce4b1c2c1a4b: Verifying Checksum\n969f07e447c8: Download complete\nd1013c4b4f44: Verifying Checksum\nd1013c4b4f44: Download complete\nd76f357a7fd3: Verifying Checksum\nd76f357a7fd3: Download complete\n371b8738953d: Verifying Checksum\n371b8738953d: Download complete\n3cf45a90fadf: Verifying Checksum\n3cf45a90fadf: Download complete\n5605d3eadacd: Download complete\n9af66e82fea9: Verifying Checksum\n9af66e82fea9: Download complete\n386ac1592b6a: Verifying Checksum\n386ac1592b6a: Download complete\n963fda8b9aa0: Verifying Checksum\n963fda8b9aa0: Download complete\n27b005b3f2b3: Verifying Checksum\n27b005b3f2b3: Download complete\nd8c7cc086f6f: Verifying Checksum\nd8c7cc086f6f: Download complete\n945afabce0bd: Verifying Checksum\n945afabce0bd: Download complete\n310e3f2c7a2a: Verifying Checksum\n310e3f2c7a2a: Download complete\n49124192b7fe: Verifying Checksum\n49124192b7fe: Download complete\ncb14bfd96623: Verifying Checksum\ncb14bfd96623: Download complete\n06ba41083b8d: Verifying Checksum\n06ba41083b8d: Download complete\n06ba41083b8d: Pull complete\n3a13c90b0c49: Pull complete\n63db0879e352: Pull complete\nce4b1c2c1a4b: Pull complete\n5605d3eadacd: Pull complete\n969f07e447c8: Pull complete\nd1013c4b4f44: Pull complete\nd76f357a7fd3: Pull complete\n371b8738953d: Pull complete\n3cf45a90fadf: Pull complete\n9af66e82fea9: Pull complete\ncb14bfd96623: Pull complete\n386ac1592b6a: Pull complete\n963fda8b9aa0: Pull complete\n27b005b3f2b3: Pull complete\nd8c7cc086f6f: Pull complete\n945afabce0bd: Pull complete\n310e3f2c7a2a: Pull complete\n49124192b7fe: Pull complete\nDigest: sha256:208e2784bc3b289cb2d9f3fc7b61b9c271d0fbc0528d0584ac6027b98921f3c8\nStatus: Downloaded newer image for anonymous/vllm-baseline:baseline-25373b6c6cc2\n",
  "timestamp": "2026-01-14 20:09:53"
}