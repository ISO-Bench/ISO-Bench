{
  "human_commit": "bc7c4d20",
  "human_commit_full": "bc7c4d206bbfb56b06d218b6c2971e8ca191db36",
  "parent_commit": "f67e9e9f221e9791733b827585d6eb6dbc23133c",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "status": "success",
  "error": null,
  "duration_s": 576.9064674377441,
  "metrics": {
    "ttft_mean_ms": 844.89,
    "ttft_median_ms": 913.84,
    "ttft_p99_ms": 1348.76,
    "tpot_mean_ms": 58.19,
    "tpot_median_ms": 37.2,
    "tpot_p99_ms": 753.56,
    "itl_mean_ms": 38.42,
    "itl_median_ms": 22.42,
    "itl_p99_ms": 896.1,
    "request_throughput_req_s": 29.99,
    "output_token_throughput_tok_s": 1857.29,
    "total_token_throughput_tok_s": 9533.51
  },
  "raw_output": "9it/s]\n============ Serving Benchmark Result ============\nSuccessful requests:                     100       \nBenchmark duration (s):                  3.33      \nTotal input tokens:                      25600     \nTotal generated tokens:                  6194      \nRequest throughput (req/s):              29.99     \nOutput token throughput (tok/s):         1857.29   \nTotal Token throughput (tok/s):          9533.51   \n---------------Time to First Token----------------\nMean TTFT (ms):                          844.89    \nMedian TTFT (ms):                        913.84    \nP99 TTFT (ms):                           1348.76   \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          58.19     \nMedian TPOT (ms):                        37.20     \nP99 TPOT (ms):                           753.56    \n---------------Inter-token Latency----------------\nMean ITL (ms):                           38.42     \nMedian ITL (ms):                         22.42     \nP99 ITL (ms):                            896.10    \n==================================================\nBENCHMARK_DONE\nNamespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='meta-llama/Llama-3.1-8B-Instruct', tokenizer=None, use_beam_search=False, num_prompts=100, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, save_detailed=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=256, random_output_len=64, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)\nStarting initial single prompt test run...\nInitial test run completed. Starting main benchmark run...\nTraffic request rate: inf\nBurstiness factor: 1.0 (Poisson process)\nMaximum request concurrency: None\n\n  0%|          | 0/100 [00:00<?, ?it/s]\n  1%|          | 1/100 [00:01<03:07,  1.90s/it]\n  4%|\u258d         | 4/100 [00:02<00:58,  1.63it/s]\n  5%|\u258c         | 5/100 [00:03<00:52,  1.82it/s]\n 27%|\u2588\u2588\u258b       | 27/100 [00:03<00:04, 16.58it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03<00:00, 29.99it/s]\n============ Serving Benchmark Result ============\nSuccessful requests:                     100       \nBenchmark duration (s):                  3.33      \nTotal input tokens:                      25600     \nTotal generated tokens:                  6194      \nRequest throughput (req/s):              29.99     \nOutput token throughput (tok/s):         1857.29   \nTotal Token throughput (tok/s):          9533.51   \n---------------Time to First Token----------------\nMean TTFT (ms):                          844.89    \nMedian TTFT (ms):                        913.84    \nP99 TTFT (ms):                           1348.76   \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          58.19     \nMedian TPOT (ms):                        37.20     \nP99 TPOT (ms):                           753.56    \n---------------Inter-token Latency----------------\nMean ITL (ms):                           38.42     \nMedian ITL (ms):                         22.42     \nP99 ITL (ms):                            896.10    \n==================================================\nUnable to find image 'vllm/vllm-openai:v0.6.0' locally\nv0.6.0: Pulling from vllm/vllm-openai\n43cfb69dbb46: Already exists\nfbcd35dc5bc3: Already exists\nc7232af9ae05: Already exists\ndb6cdef1932a: Already exists\n56dc85502937: Already exists\n9f61b3db38d6: Pulling fs layer\n0bd39d0469a8: Pulling fs layer\nd22ff5f4aac6: Pulling fs layer\nd866993704f5: Pulling fs layer\nb4918d864665: Pulling fs layer\ne93cc01aab8b: Pulling fs layer\nfd30840e514d: Pulling fs layer\n0bd39d0469a8: Waiting\nd22ff5f4aac6: Waiting\nd866993704f5: Waiting\nb4918d864665: Waiting\ne93cc01aab8b: Waiting\nfd30840e514d: Waiting\n9f61b3db38d6: Waiting\n9f61b3db38d6: Verifying Checksum\n9f61b3db38d6: Download complete\n0bd39d0469a8: Verifying Checksum\n0bd39d0469a8: Download complete\n9f61b3db38d6: Pull complete\n0bd39d0469a8: Pull complete\nd22ff5f4aac6: Verifying Checksum\nd22ff5f4aac6: Download complete\nd866993704f5: Verifying Checksum\nd866993704f5: Download complete\nd22ff5f4aac6: Pull complete\nd866993704f5: Pull complete\ne93cc01aab8b: Verifying Checksum\ne93cc01aab8b: Download complete\nfd30840e514d: Verifying Checksum\nfd30840e514d: Download complete\nb4918d864665: Verifying Checksum\nb4918d864665: Download complete\nb4918d864665: Pull complete\ne93cc01aab8b: Pull complete\nfd30840e514d: Pull complete\nDigest: sha256:072427aa6f95c74782a9bc3fe1d1fcd1e1aa3fe47b317584ea2181c549ad2de8\nStatus: Downloaded newer image for vllm/vllm-openai:v0.6.0\n",
  "timestamp": "2026-01-24 09:06:31"
}