{
  "status": "error",
  "gpu_config": "H100:8",
  "baseline_metrics": {},
  "human_metrics": {},
  "agent_metrics": null,
  "human_improvement": {},
  "agent_improvement": null,
  "agent_vs_human": null,
  "error": "Human server failed to start. Logs: /python/sglang/srt/utils/hf_transformers_utils.py\", line 273, in get_config\n    config = AutoConfig.from_pretrained(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 1332, in from_pretrained\n    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 662, in get_config_dict\n    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 744, in _get_config_dict\n    raise OSError(\nOSError: Can't load the configuration of '/home/model/DeepSeek-R1'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/model/DeepSeek-R1' is the correct path to a directory containing a config.json file\n",
  "duration_s": 435.91157126426697,
  "perf_command": "python -m sglang.launch_server --model-path /home/model/DeepSeek-R1 --dist-init-addr 127.0.0.1 --nnodes 2 --node-rank 0 --trust-remote-code --attention-backend fa3 --tp 16 --cuda-graph-max-bs 40 --enable-dp-attention --dp 4 --enable-dp-lm-head",
  "install_method": "docker",
  "baseline_raw": "",
  "human_raw": "",
  "agent_raw": "",
  "commit": "25c83fff",
  "full_commit": "25c83fff6a80d9e3d2749f2ead122f96fdc127e9",
  "parent_commit": "9f2c9568f071bd45edd98d51cc7f1ebbb4ed5e73",
  "model": "/home/model/DeepSeek-R1",
  "subject": "Performing Vocabulary Parallelism for LM Head across Attention TP Groups (#5558)",
  "has_agent_patch": true
}