{
  "status": "error",
  "gpu_config": "H100:1",
  "baseline_metrics": {},
  "human_metrics": {},
  "agent_metrics": null,
  "human_improvement": {},
  "agent_improvement": null,
  "agent_vs_human": null,
  "error": "Human server failed to start. Logs: File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/launch_server.py\", line 7, in <module>\n    from sglang.srt.server_args import prepare_server_args\n  File \"/sgl-workspace/sglang/python/sglang/srt/server_args.py\", line 29, in <module>\n    from sglang.srt.connector import ConnectorType\n  File \"/sgl-workspace/sglang/python/sglang/srt/connector/__init__.py\", line 6, in <module>\n    from sglang.srt.connector.base_connector import (\n  File \"/sgl-workspace/sglang/python/sglang/srt/connector/base_connector.py\", line 10, in <module>\n    import torch\n  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 427, in <module>\n    from torch._C import *  # noqa: F403\nImportError: /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommWindowRegister\n",
  "duration_s": 416.70782470703125,
  "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100",
  "install_method": "docker",
  "baseline_raw": "",
  "human_raw": "",
  "agent_raw": "",
  "baseline_server_logs": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/launch_server.py\", line 6, in <module>\n    from sglang.srt.entrypoints.http_server import launch_server\n  File \"/sgl-workspace/sglang/python/sglang/srt/entrypoints/http_server.py\", line 45, in <module>\n    from sglang.srt.disaggregation.utils import FakeBootstrapHost\n  File \"/sgl-workspace/sglang/python/sglang/srt/disaggregation/utils.py\", line 8, in <module>\n    import torch\n  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 427, in <module>\n    from torch._C import *  # noqa: F403\nImportError: /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommWindowRegister\n",
  "baseline_skip_reason": "Server failed - incompatible overlay",
  "human_server_logs": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/launch_server.py\", line 7, in <module>\n    from sglang.srt.server_args import prepare_server_args\n  File \"/sgl-workspace/sglang/python/sglang/srt/server_args.py\", line 29, in <module>\n    from sglang.srt.connector import ConnectorType\n  File \"/sgl-workspace/sglang/python/sglang/srt/connector/__init__.py\", line 6, in <module>\n    from sglang.srt.connector.base_connector import (\n  File \"/sgl-workspace/sglang/python/sglang/srt/connector/base_connector.py\", line 10, in <module>\n    import torch\n  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 427, in <module>\n    from torch._C import *  # noqa: F403\nImportError: /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommWindowRegister\n",
  "commit": "1acca3a2",
  "full_commit": "1acca3a2c685221cdb181c2abda4f635e1ead435",
  "parent_commit": "6ea1e6ac6e2fa949cebd1b4338f9bfb7036d14fe",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "subject": "FA3 speed up: skip len operation and get batch size directly from forward batch (#5969)",
  "has_agent_patch": true
}