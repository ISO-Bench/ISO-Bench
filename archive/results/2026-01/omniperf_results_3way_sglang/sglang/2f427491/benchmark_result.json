{
  "status": "error",
  "gpu_config": "H100:8",
  "baseline_metrics": {},
  "human_metrics": {},
  "agent_metrics": null,
  "human_improvement": {},
  "agent_improvement": null,
  "agent_vs_human": null,
  "error": "Human server failed to start. Logs: line 323, in _init_model_runner\n    self._model_runner = ModelRunner(\n  File \"/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py\", line 363, in __init__\n    min_per_gpu_memory = self.init_torch_distributed()\n  File \"/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py\", line 704, in init_torch_distributed\n    torch.get_device_module(self.device).set_device(self.gpu_id)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 567, in set_device\n    torch._C._cuda_setDevice(device)\ntorch.AcceleratorError: CUDA error: invalid device ordinal\nGPU device may be out of range, do you have enough GPUs?\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n\n[2026-01-02 21:05:53] Received sigquit from a child process. It usually means the child failed.\n",
  "duration_s": 434.1018557548523,
  "perf_command": "python benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-V3 --tp 16",
  "install_method": "docker",
  "baseline_raw": "",
  "human_raw": "",
  "agent_raw": "",
  "commit": "2f427491",
  "full_commit": "2f42749184ca3679d2bb0361903f46632408f9a2",
  "parent_commit": "d8189660a9bbd4b5b5fe2526424d42c8ffcf7195",
  "model": "deepseek-ai/DeepSeek-V3",
  "subject": "Fix topk inference performance reduce (#6474)",
  "has_agent_patch": true
}