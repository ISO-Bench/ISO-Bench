{
  "status": "success",
  "gpu_config": "H100:1",
  "baseline_metrics": {},
  "human_metrics": {
    "request_throughput": 8.08,
    "output_throughput": 1718.23,
    "input_throughput": 2711.6,
    "total_throughput": 4429.83,
    "ttft_mean": 536.42,
    "ttft_median": 531.97,
    "ttft_p99": 848.83,
    "tpot_mean": 24.47,
    "tpot_median": 10.01,
    "tpot_p99": 182.18,
    "itl_mean": 9.34,
    "itl_median": 7.8,
    "itl_p95": 9.89,
    "itl_p99": 11.26,
    "e2e_latency_mean": 2513.67,
    "e2e_latency_median": 1969.46,
    "e2e_latency_p99": 6709.44,
    "total_input_tokens": 33559.0,
    "total_output_tokens": 21265.0
  },
  "agent_metrics": null,
  "human_improvement": {},
  "agent_improvement": null,
  "agent_vs_human": null,
  "error": null,
  "duration_s": 433.93140602111816,
  "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100",
  "install_method": "docker",
  "baseline_raw": "",
  "human_raw": "",
  "agent_raw": "",
  "commit": "6e2da515",
  "full_commit": "6e2da5156176ed2d7fe2445b7c7316bc1650b20a",
  "parent_commit": "e9a47f4cb58a5a2fedd7843211684b8e4db3c0c5",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "subject": "Replace time.time() to time.perf_counter() for benchmarking. (#6178)",
  "has_agent_patch": true
}