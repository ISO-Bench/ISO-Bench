{
  "status": "success",
  "gpu_config": "H100:1",
  "baseline_metrics": {},
  "human_metrics": {},
  "agent_metrics": {},
  "human_improvement": {},
  "agent_improvement": null,
  "agent_vs_human": null,
  "error": null,
  "duration_s": 539.1313698291779,
  "perf_command": "python3 -m sglang.bench_one_batch_server --model-path /data/Llama-2-7b-hf --mem-fraction-static 0.3 --batch-size 48 --disable-overlap-schedule",
  "install_method": "docker",
  "baseline_raw": "\n/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/bench_one_batch_server.py\", line 25, in <module>\n    from sglang.srt.server import launch_server\n  File \"/sgl-workspace/sglang/python/sglang/srt/server.py\", line 50, in <module>\n    from sglang.srt.managers.data_parallel_controller import (\n  File \"/sgl-workspace/sglang/python/sglang/srt/managers/data_parallel_controller.py\", line 26, in <module>\n    from sglang.srt.layers.dp_attention import compute_dp_attention_world_info\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/dp_attention.py\", line 3, in <module>\n    from sglang.srt.distributed import GroupCoordinator, get_tp_group\n  File \"/sgl-workspace/sglang/python/sglang/srt/distributed/__init__.py\", line 1, in <module>\n    from .communication_op import *\n  File \"/sgl-workspace/sglang/python/sglang/srt/distributed/communication_op.py\", line 7, in <module>\n    from .parallel_state import get_tp_group\n  File \"/sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py\", line 41, in <module>\n    from sglang.srt.utils import (\nImportError: cannot import name 'supports_custom_op' from 'sglang.srt.utils' (/sgl-workspace/sglang/python/sglang/srt/utils/__init__.py)\n",
  "human_raw": "\n/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/bench_one_batch_server.py\", line 38, in <module>\n    from sglang.srt.entrypoints.http_server import launch_server\n  File \"/sgl-workspace/sglang/python/sglang/srt/entrypoints/http_server.py\", line 55, in <module>\n    from sglang.srt.entrypoints.engine import (\n  File \"/sgl-workspace/sglang/python/sglang/srt/entrypoints/engine.py\", line 40, in <module>\n    from sglang.srt.managers.data_parallel_controller import (\n  File \"/sgl-workspace/sglang/python/sglang/srt/managers/data_parallel_controller.py\", line 32, in <module>\n    from sglang.srt.managers.io_struct import (\n  File \"/sgl-workspace/sglang/python/sglang/srt/managers/io_struct.py\", line 31, in <module>\n    from sglang.srt.managers.schedule_batch import BaseFinishReason\n  File \"/sgl-workspace/sglang/python/sglang/srt/managers/schedule_batch.py\", line 5, in <module>\n    from sglang.srt.dllm.config import DllmConfig\n  File \"/sgl-workspace/sglang/python/sglang/srt/dllm/config.py\", line 3, in <module>\n    from sglang.srt.configs.model_config import ModelConfig\n  File \"/sgl-workspace/sglang/python/sglang/srt/configs/model_config.py\", line 26, in <module>\n    from sglang.srt.layers.quantization import QUANTIZATION_METHODS\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/__init__.py\", line 19, in <module>\n    from sglang.srt.layers.quantization.auto_round import AutoRoundConfig\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/auto_round.py\", line 12, in <module>\n    from sglang.srt.layers.quantization.utils import get_scalar_types\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/utils.py\", line 13, in <module>\n    from sglang.srt.layers.quantization.fp8_kernel import scaled_fp8_quant\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/fp8_kernel.py\", line 45, in <module>\n    from sgl_kernel import sgl_per_tensor_quant_fp8, sgl_per_token_quant_fp8\n  File \"/opt/conda/lib/python3.10/site-packages/sgl_kernel/__init__.py\", line 5, in <module>\n    common_ops = _load_architecture_specific_ops()\n  File \"/opt/conda/lib/python3.10/site-packages/sgl_kernel/load_utils.py\", line 188, in _load_architecture_specific_ops\n    raise ImportError(error_msg)\nImportError: \n[sgl_kernel] CRITICAL: Could not load any common_ops library!\n\nAttempted locations:\n1. Architecture-specific pattern: /opt/conda/lib/python3.10/site-packages/sgl_kernel/sm90/common_ops.* - found files: ['/opt/conda/lib/python3.10/site-packages/sgl_kernel/sm90/common_ops.abi3.so']\n2. Fallback pattern: /opt/conda/lib/python3.10/site-packages/sgl_kernel/common_ops.* - found files: []\n3. Standard Python import: common_ops - failed\n\nGPU Info:\n- Compute capability: 90\n- Expected variant: SM90 (Hopper/H100 with fast math optimization)\n\nPlease ensure sgl_kernel is properly installed with:\npip install --upgrade sgl_kernel\n\nError details from previous import attempts:\n- ImportError: libnuma.so.1: cannot open shared object file: No such file or directory\n- ModuleNotFoundError: No module named 'common_ops'\n\n",
  "agent_raw": "\n/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/bench_one_batch_server.py\", line 25, in <module>\n    from sglang.srt.server import launch_server\n  File \"/sgl-workspace/sglang/python/sglang/srt/server.py\", line 50, in <module>\n    from sglang.srt.managers.data_parallel_controller import (\n  File \"/sgl-workspace/sglang/python/sglang/srt/managers/data_parallel_controller.py\", line 26, in <module>\n    from sglang.srt.layers.dp_attention import compute_dp_attention_world_info\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/dp_attention.py\", line 3, in <module>\n    from sglang.srt.distributed import GroupCoordinator, get_tp_group\n  File \"/sgl-workspace/sglang/python/sglang/srt/distributed/__init__.py\", line 1, in <module>\n    from .communication_op import *\n  File \"/sgl-workspace/sglang/python/sglang/srt/distributed/communication_op.py\", line 7, in <module>\n    from .parallel_state import get_tp_group\n  File \"/sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py\", line 41, in <module>\n    from sglang.srt.utils import (\nImportError: cannot import name 'supports_custom_op' from 'sglang.srt.utils' (/sgl-workspace/sglang/python/sglang/srt/utils/__init__.py)\n",
  "commit": "2bd18e2d",
  "full_commit": "2bd18e2d767e3a0f8afb5aff427bc8e6e4d297c0",
  "parent_commit": "83452dbb4a19c6a2461e972eb2b64a2df9a466b8",
  "model": "meta-llama/Llama-2-7b-hf",
  "subject": "Memory pool: Minor optimize to avoid to (#2901)",
  "has_agent_patch": true
}