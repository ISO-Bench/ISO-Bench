{
  "status": "error",
  "gpu_config": "H100:1",
  "baseline_metrics": {},
  "human_metrics": {},
  "agent_metrics": null,
  "human_improvement": {},
  "agent_improvement": null,
  "agent_vs_human": null,
  "error": "Human server failed to start. Logs: chitecture_specific_ops()\n  File \"/opt/conda/lib/python3.10/site-packages/sgl_kernel/load_utils.py\", line 188, in _load_architecture_specific_ops\n    raise ImportError(error_msg)\nImportError: \n[sgl_kernel] CRITICAL: Could not load any common_ops library!\n\nAttempted locations:\n1. Architecture-specific pattern: /opt/conda/lib/python3.10/site-packages/sgl_kernel/sm90/common_ops.* - found files: ['/opt/conda/lib/python3.10/site-packages/sgl_kernel/sm90/common_ops.abi3.so']\n2. Fallback pattern: /opt/conda/lib/python3.10/site-packages/sgl_kernel/common_ops.* - found files: []\n3. Standard Python import: common_ops - failed\n\nGPU Info:\n- Compute capability: 90\n- Expected variant: SM90 (Hopper/H100 with fast math optimization)\n\nPlease ensure sgl_kernel is properly installed with:\npip install --upgrade sgl_kernel\n\nError details from previous import attempts:\n- ImportError: libnuma.so.1: cannot open shared object file: No such file or directory\n- ModuleNotFoundError: No module named 'common_ops'\n\n",
  "duration_s": 567.7609338760376,
  "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100",
  "install_method": "docker",
  "baseline_raw": "",
  "human_raw": "",
  "agent_raw": "",
  "baseline_server_logs": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/launch_server.py\", line 6, in <module>\n    from sglang.srt.server import launch_server\n  File \"/sgl-workspace/sglang/python/sglang/srt/server.py\", line 44, in <module>\n    from sglang.srt.constrained import disable_cache\n  File \"/sgl-workspace/sglang/python/sglang/srt/constrained/__init__.py\", line 27, in <module>\n    from outlines.fsm.regex import FSMInfo, make_byte_level_fsm, make_deterministic_fsm\nModuleNotFoundError: No module named 'outlines.fsm.regex'\n\nError: No module named 'outlines.fsm.regex'. Please install a new version of outlines by `pip install \"outlines>=0.0.44\"`\n\n",
  "baseline_skip_reason": "Server failed - incompatible overlay",
  "human_server_logs": "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/sgl-workspace/sglang/python/sglang/launch_server.py\", line 29, in <module>\n    server_args = prepare_server_args(sys.argv[1:])\n  File \"/sgl-workspace/sglang/python/sglang/srt/server_args.py\", line 5014, in prepare_server_args\n    return ServerArgs.from_cli_args(raw_args)\n  File \"/sgl-workspace/sglang/python/sglang/srt/server_args.py\", line 4516, in from_cli_args\n    return cls(**{attr: getattr(args, attr) for attr in attrs})\n  File \"<string>\", line 314, in __init__\n  File \"/sgl-workspace/sglang/python/sglang/srt/server_args.py\", line 672, in __post_init__\n    self._handle_gpu_memory_settings(gpu_mem)\n  File \"/sgl-workspace/sglang/python/sglang/srt/server_args.py\", line 985, in _handle_gpu_memory_settings\n    model_config = self.get_model_config()\n  File \"/sgl-workspace/sglang/python/sglang/srt/server_args.py\", line 4526, in get_model_config\n    from sglang.srt.configs.model_config import ModelConfig\n  File \"/sgl-workspace/sglang/python/sglang/srt/configs/model_config.py\", line 26, in <module>\n    from sglang.srt.layers.quantization import QUANTIZATION_METHODS\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/__init__.py\", line 19, in <module>\n    from sglang.srt.layers.quantization.auto_round import AutoRoundConfig\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/auto_round.py\", line 12, in <module>\n    from sglang.srt.layers.quantization.utils import get_scalar_types\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/utils.py\", line 13, in <module>\n    from sglang.srt.layers.quantization.fp8_kernel import scaled_fp8_quant\n  File \"/sgl-workspace/sglang/python/sglang/srt/layers/quantization/fp8_kernel.py\", line 45, in <module>\n    from sgl_kernel import sgl_per_tensor_quant_fp8, sgl_per_token_quant_fp8\n  File \"/opt/conda/lib/python3.10/site-packages/sgl_kernel/__init__.py\", line 5, in <module>\n    common_ops = _load_architecture_specific_ops()\n  File \"/opt/conda/lib/python3.10/site-packages/sgl_kernel/load_utils.py\", line 188, in _load_architecture_specific_ops\n    raise ImportError(error_msg)\nImportError: \n[sgl_kernel] CRITICAL: Could not load any common_ops library!\n\nAttempted locations:\n1. Architecture-specific pattern: /opt/conda/lib/python3.10/site-packages/sgl_kernel/sm90/common_ops.* - found files: ['/opt/conda/lib/python3.10/site-packages/sgl_kernel/sm90/common_ops.abi3.so']\n2. Fallback pattern: /opt/conda/lib/python3.10/site-packages/sgl_kernel/common_ops.* - found files: []\n3. Standard Python import: common_ops - failed\n\nGPU Info:\n- Compute capability: 90\n- Expected variant: SM90 (Hopper/H100 with fast math optimization)\n\nPlease ensure sgl_kernel is properly installed with:\npip install --upgrade sgl_kernel\n\nError details from previous import attempts:\n- ImportError: libnuma.so.1: cannot open shared object file: No such file or directory\n- ModuleNotFoundError: No module named 'common_ops'\n\n",
  "commit": "2854a5ea",
  "full_commit": "2854a5ea9fbb31165936f633ab99915dec760f8d",
  "parent_commit": "42a2d82ba71dc86ca3b6342c978db450658b750c",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "subject": "Fix the overhead due to penalizer in bench_latency (#1496)",
  "has_agent_patch": true
}