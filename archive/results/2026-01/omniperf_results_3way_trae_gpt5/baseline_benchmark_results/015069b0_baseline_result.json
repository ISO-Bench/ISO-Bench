{
  "human_commit": "015069b0",
  "human_commit_full": "015069b01741e9ecb9e604c7fe87fbdfc306ebe5",
  "parent_commit": "fbefc8a78d22b20eac042c586805c7dcbfc66b1c",
  "status": "error",
  "benchmark_type": "serving",
  "model": "Qwen/Qwen3-1.7B",
  "duration_s": 25.368113040924072,
  "error": "Server crashed during startup",
  "ttft_mean": null,
  "ttft_median": null,
  "ttft_p99": null,
  "tpot_mean": null,
  "tpot_median": null,
  "tpot_p99": null,
  "itl_mean": null,
  "itl_median": null,
  "itl_p99": null,
  "throughput_req_s": null,
  "throughput_tok_s": null,
  "timestamp": "2026-01-14 13:12:10",
  "raw_output": "=== Using cached baseline image (skipping build) ===\nApplying compatibility fixes...\nFixing transformers compatibility (LogitsWarper missing)...\nFixing rope_scaling compatibility...\n=== Starting vLLM server for BASELINE benchmark ===\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 189, in _run_module_as_main\n  File \"<frozen runpy>\", line 112, in _get_module_details\n  File \"/opt/vllm_baseline/vllm/__init__.py\", line 12, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/opt/vllm_baseline/vllm/engine/arg_utils.py\", line 18, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n  File \"/opt/vllm_baseline/vllm/config.py\", line 25, in <module>\n    from transformers import PretrainedConfig\nImportError: cannot import name 'PretrainedConfig' from 'transformers' (unknown location)\nBASELINE_SERVER_CRASHED\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n\n[notice] A new release of pip is available: 25.2 -> 25.3\n[notice] To update, run: python3.12 -m pip install --upgrade pip\n"
}