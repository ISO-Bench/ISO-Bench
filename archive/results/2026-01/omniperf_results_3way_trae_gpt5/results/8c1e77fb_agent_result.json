{
  "human_commit": "8c1e77fb",
  "human_commit_full": "8c1e77fb585c4f42783a3d88c1efc7c9e15fd89f",
  "parent_commit": "5fc5ce0fe45f974fc8840175e8321652238400f0",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "status": "success",
  "error": null,
  "duration_s": 146.56675934791565,
  "metrics": {
    "latency_avg_ms": 2437.845266600319,
    "throughput_tok_s": 7342.2
  },
  "raw_output": ":  27%|\u2588\u2588\u258b       | 8/30 [00:19<00:53,  2.43s/it]INFO 01-14 07:48:38 metrics.py:460] Avg prompt throughput: 6549.8 tokens/s, Avg generation throughput: 1707.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  30%|\u2588\u2588\u2588       | 9/30 [00:21<00:50,  2.43s/it]\nProfiling iterations:  33%|\u2588\u2588\u2588\u258e      | 10/30 [00:24<00:48,  2.43s/it]INFO 01-14 07:48:43 metrics.py:460] Avg prompt throughput: 6543.4 tokens/s, Avg generation throughput: 1699.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  37%|\u2588\u2588\u2588\u258b      | 11/30 [00:26<00:46,  2.43s/it]\nProfiling iterations:  40%|\u2588\u2588\u2588\u2588      | 12/30 [00:29<00:43,  2.43s/it]INFO 01-14 07:48:48 metrics.py:460] Avg prompt throughput: 6543.8 tokens/s, Avg generation throughput: 1699.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:31<00:41,  2.43s/it]\nProfiling iterations:  47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:34<00:38,  2.43s/it]INFO 01-14 07:48:53 metrics.py:460] Avg prompt throughput: 6534.9 tokens/s, Avg generation throughput: 1703.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:36<00:36,  2.43s/it]\nProfiling iterations:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:38<00:34,  2.43s/it]INFO 01-14 07:48:58 metrics.py:460] Avg prompt throughput: 6539.3 tokens/s, Avg generation throughput: 1698.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:41<00:31,  2.43s/it]\nProfiling iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:43<00:29,  2.43s/it]INFO 01-14 07:49:03 metrics.py:460] Avg prompt throughput: 6548.4 tokens/s, Avg generation throughput: 1701.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:46<00:26,  2.43s/it]\nProfiling iterations:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:48<00:25,  2.51s/it]INFO 01-14 07:49:08 metrics.py:460] Avg prompt throughput: 6545.2 tokens/s, Avg generation throughput: 1591.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:51<00:22,  2.48s/it]\nProfiling iterations:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:53<00:19,  2.46s/it]INFO 01-14 07:49:13 metrics.py:460] Avg prompt throughput: 6542.2 tokens/s, Avg generation throughput: 1712.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:56<00:17,  2.45s/it]\nProfiling iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:58<00:14,  2.44s/it]INFO 01-14 07:49:18 metrics.py:460] Avg prompt throughput: 6538.7 tokens/s, Avg generation throughput: 1711.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [01:00<00:12,  2.44s/it]\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [01:03<00:09,  2.43s/it]\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [01:05<00:07,  2.43s/it]INFO 01-14 07:49:23 metrics.py:460] Avg prompt throughput: 6838.1 tokens/s, Avg generation throughput: 1645.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 24 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [01:08<00:04,  2.44s/it]\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [01:10<00:02,  2.44s/it]INFO 01-14 07:49:28 metrics.py:460] Avg prompt throughput: 7313.9 tokens/s, Avg generation throughput: 1629.4 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 16 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.\n\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:13<00:00,  2.43s/it]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:13<00:00,  2.44s/it]\nAvg latency: 2.437845266600319 seconds\n10% percentile latency: 2.4226360424014275 seconds\n25% percentile latency: 2.4240828637503 seconds\n50% percentile latency: 2.4300075945011486 seconds\n75% percentile latency: 2.4348108147505627 seconds\n90% percentile latency: 2.4385891670986894 seconds\n99% percentile latency: 2.607320313131022 seconds\n[rank0]:[W114 07:49:31.991583833 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
  "timestamp": "2026-01-14 15:49:33"
}