{
  "human_commit": "3b61cb45",
  "human_commit_full": "3b61cb450d899dc423feb264c297d4d18d701678",
  "parent_commit": "edc4fa31888b4a41060acb7b16250540f051ad59",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "status": "success",
  "error": null,
  "duration_s": 172.49663376808167,
  "metrics": {
    "latency_avg_ms": 2436.4294297665765,
    "throughput_tok_s": 7663.4
  },
  "raw_output": " 27%|\u2588\u2588\u258b       | 8/30 [00:19<00:53,  2.44s/it]INFO 01-14 07:11:21 metrics.py:460] Avg prompt throughput: 6552.3 tokens/s, Avg generation throughput: 1682.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  30%|\u2588\u2588\u2588       | 9/30 [00:21<00:51,  2.44s/it]\nProfiling iterations:  33%|\u2588\u2588\u2588\u258e      | 10/30 [00:24<00:48,  2.44s/it]INFO 01-14 07:11:26 metrics.py:460] Avg prompt throughput: 6544.7 tokens/s, Avg generation throughput: 1700.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  37%|\u2588\u2588\u2588\u258b      | 11/30 [00:26<00:46,  2.43s/it]\nProfiling iterations:  40%|\u2588\u2588\u2588\u2588      | 12/30 [00:29<00:43,  2.43s/it]INFO 01-14 07:11:31 metrics.py:460] Avg prompt throughput: 6541.6 tokens/s, Avg generation throughput: 1705.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:31<00:41,  2.43s/it]\nProfiling iterations:  47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:34<00:39,  2.46s/it]INFO 01-14 07:11:36 metrics.py:460] Avg prompt throughput: 6543.0 tokens/s, Avg generation throughput: 1661.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:36<00:36,  2.45s/it]\nProfiling iterations:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:38<00:34,  2.43s/it]INFO 01-14 07:11:41 metrics.py:460] Avg prompt throughput: 6541.9 tokens/s, Avg generation throughput: 1724.9 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:41<00:31,  2.43s/it]\nProfiling iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:43<00:29,  2.42s/it]INFO 01-14 07:11:46 metrics.py:460] Avg prompt throughput: 6546.7 tokens/s, Avg generation throughput: 1617.5 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:46<00:27,  2.49s/it]\nProfiling iterations:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:48<00:24,  2.47s/it]INFO 01-14 07:11:51 metrics.py:460] Avg prompt throughput: 6547.0 tokens/s, Avg generation throughput: 1675.1 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:51<00:22,  2.48s/it]\nProfiling iterations:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:53<00:19,  2.47s/it]INFO 01-14 07:11:56 metrics.py:460] Avg prompt throughput: 6538.9 tokens/s, Avg generation throughput: 1705.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:56<00:17,  2.46s/it]\nProfiling iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:58<00:14,  2.44s/it]INFO 01-14 07:12:01 metrics.py:460] Avg prompt throughput: 6547.5 tokens/s, Avg generation throughput: 1713.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [01:01<00:12,  2.43s/it]\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [01:03<00:09,  2.43s/it]\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [01:05<00:07,  2.42s/it]INFO 01-14 07:12:06 metrics.py:460] Avg prompt throughput: 6920.4 tokens/s, Avg generation throughput: 1659.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 24 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [01:08<00:04,  2.42s/it]\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [01:10<00:02,  2.42s/it]INFO 01-14 07:12:11 metrics.py:460] Avg prompt throughput: 7347.5 tokens/s, Avg generation throughput: 1636.9 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 16 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%.\n\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:13<00:00,  2.42s/it]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:13<00:00,  2.44s/it]\nAvg latency: 2.4364294297665765 seconds\n10% percentile latency: 2.407591700101693 seconds\n25% percentile latency: 2.4133908787498513 seconds\n50% percentile latency: 2.4214178064994485 seconds\n75% percentile latency: 2.433467623499382 seconds\n90% percentile latency: 2.468779812498542 seconds\n99% percentile latency: 2.6103911301702465 seconds\n[rank0]:[W114 07:12:14.002023847 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
  "timestamp": "2026-01-14 15:12:16"
}