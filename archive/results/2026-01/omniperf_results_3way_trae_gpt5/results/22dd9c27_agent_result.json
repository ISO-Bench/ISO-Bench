{
  "human_commit": "22dd9c27",
  "human_commit_full": "22dd9c2730dc1124b9d0ac15fff223d0b8d9020b",
  "parent_commit": "a6d795d593046abd490b16349bcd9b40feedd334",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "status": "success",
  "error": null,
  "duration_s": 97.65687036514282,
  "metrics": {
    "latency_avg_ms": 827.658669499821,
    "throughput_tok_s": 19561.3
  },
  "raw_output": "ecoding=None, extra_args=None)\nWarming up...\n\nWarmup iterations:   0%|          | 0/10 [00:00<?, ?it/s]\nWarmup iterations:  10%|\u2588         | 1/10 [00:00<00:07,  1.22it/s]\nWarmup iterations:  20%|\u2588\u2588        | 2/10 [00:01<00:06,  1.22it/s]\nWarmup iterations:  30%|\u2588\u2588\u2588       | 3/10 [00:02<00:05,  1.22it/s]\nWarmup iterations:  40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03<00:04,  1.22it/s]\nWarmup iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:04<00:04,  1.22it/s]\nWarmup iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04<00:03,  1.22it/s]INFO 01-14 09:07:22 [metrics.py:417] Avg prompt throughput: 19561.3 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nWarmup iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:05<00:02,  1.22it/s]\nWarmup iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:06<00:01,  1.22it/s]\nWarmup iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:07<00:00,  1.22it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08<00:00,  1.22it/s]\nWarmup iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08<00:00,  1.22it/s]\n\nProfiling iterations:   0%|          | 0/30 [00:00<?, ?it/s]\nProfiling iterations:   3%|\u258e         | 1/30 [00:00<00:23,  1.22it/s]\nProfiling iterations:   7%|\u258b         | 2/30 [00:01<00:23,  1.22it/s]INFO 01-14 09:07:27 [metrics.py:417] Avg prompt throughput: 19530.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  10%|\u2588         | 3/30 [00:02<00:22,  1.22it/s]\nProfiling iterations:  13%|\u2588\u258e        | 4/30 [00:03<00:21,  1.21it/s]\nProfiling iterations:  17%|\u2588\u258b        | 5/30 [00:04<00:20,  1.21it/s]\nProfiling iterations:  20%|\u2588\u2588        | 6/30 [00:04<00:19,  1.21it/s]\nProfiling iterations:  23%|\u2588\u2588\u258e       | 7/30 [00:05<00:18,  1.21it/s]\nProfiling iterations:  27%|\u2588\u2588\u258b       | 8/30 [00:06<00:18,  1.21it/s]INFO 01-14 09:07:32 [metrics.py:417] Avg prompt throughput: 19457.4 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  30%|\u2588\u2588\u2588       | 9/30 [00:07<00:17,  1.21it/s]\nProfiling iterations:  33%|\u2588\u2588\u2588\u258e      | 10/30 [00:08<00:16,  1.21it/s]\nProfiling iterations:  37%|\u2588\u2588\u2588\u258b      | 11/30 [00:09<00:15,  1.21it/s]\nProfiling iterations:  40%|\u2588\u2588\u2588\u2588      | 12/30 [00:09<00:14,  1.21it/s]\nProfiling iterations:  43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:10<00:14,  1.21it/s]\nProfiling iterations:  47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:11<00:13,  1.21it/s]INFO 01-14 09:07:37 [metrics.py:417] Avg prompt throughput: 19396.3 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:12<00:12,  1.21it/s]\nProfiling iterations:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:13<00:11,  1.21it/s]\nProfiling iterations:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:14<00:10,  1.21it/s]\nProfiling iterations:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:14<00:09,  1.21it/s]\nProfiling iterations:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:15<00:09,  1.21it/s]\nProfiling iterations:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:16<00:08,  1.21it/s]INFO 01-14 09:07:42 [metrics.py:417] Avg prompt throughput: 19301.2 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:17<00:07,  1.21it/s]\nProfiling iterations:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:18<00:06,  1.21it/s]\nProfiling iterations:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:19<00:05,  1.21it/s]\nProfiling iterations:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:19<00:04,  1.21it/s]\nProfiling iterations:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:20<00:04,  1.20it/s]\nProfiling iterations:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:21<00:03,  1.20it/s]INFO 01-14 09:07:47 [metrics.py:417] Avg prompt throughput: 19249.1 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.\n\nProfiling iterations:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:22<00:02,  1.20it/s]\nProfiling iterations:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:23<00:01,  1.20it/s]\nProfiling iterations:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:24<00:00,  1.20it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:24<00:00,  1.20it/s]\nProfiling iterations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:24<00:00,  1.21it/s]\nAvg latency: 0.827658669499821 seconds\n10% percentile latency: 0.822804430200631 seconds\n25% percentile latency: 0.8256892547478856 seconds\n50% percentile latency: 0.8280035899988434 seconds\n75% percentile latency: 0.8303405157521411 seconds\n90% percentile latency: 0.831304028798695 seconds\n99% percentile latency: 0.8325406446002671 seconds\n[rank0]:[W114 09:07:50.844109178 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
  "timestamp": "2026-01-14 17:07:53"
}