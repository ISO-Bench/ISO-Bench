{
  "instance": {
    "commit_hash": "eefbf4a68b7b0a5b8364a59647906be1b7f043e2",
    "commit_subject": "[Perf] Optimize `reshape_and_cache_flash` CUDA Kernel (#22036)",
    "repo": "vllm",
    "pr_url": "https://github.com/vllm-project/vllm/pull/22036",
    "files_changed": [
      "benchmarks/kernels/benchmark_reshape_and_cache_flash.py",
      "csrc/cache_kernels.cu"
    ]
  },
  "result": {
    "status": "success",
    "commit_hash": "eefbf4a68b7b0a5b8364a59647906be1b7f043e2",
    "baseline_ms": 0.18832895994186402,
    "patched_ms": 0.18845119953155517,
    "speedup": 0.9993513461840784,
    "improvement": false,
    "baseline_output": {
      "impl_tag": "child",
      "commit_hash": "eefbf4a68b7b0a5b8364a59647906be1b7f043e2",
      "device": "cuda",
      "dtype": "torch.float16",
      "iters": 50,
      "warmup": 5,
      "avg_ms": 0.18832895994186402,
      "p50_ms": 0.18614399433135986,
      "p95_ms": 0.19017599523067474,
      "eq_level": "numeric",
      "opt_path_hit": true
    },
    "patched_output": {
      "impl_tag": "child",
      "commit_hash": "eefbf4a68b7b0a5b8364a59647906be1b7f043e2",
      "device": "cuda",
      "dtype": "torch.float16",
      "iters": 50,
      "warmup": 5,
      "avg_ms": 0.18845119953155517,
      "p50_ms": 0.18595199286937714,
      "p95_ms": 0.19040000438690186,
      "eq_level": "numeric",
      "opt_path_hit": true
    },
    "error_message": null,
    "stdout": "INFO 12-24 20:09:57 [__init__.py:241] Automatically detected platform cuda.\n{\"impl_tag\": \"child\", \"commit_hash\": \"eefbf4a68b7b0a5b8364a59647906be1b7f043e2\", \"device\": \"cuda\", \"dtype\": \"torch.float16\", \"iters\": 50, \"warmup\": 5, \"avg_ms\": 0.18832895994186402, \"p50_ms\": 0.18614399433135986, \"p95_ms\": 0.19017599523067474, \"eq_level\": \"numeric\", \"opt_path_hit\": true}\n\nINFO 12-24 20:10:01 [__init__.py:241] Automatically detected platform cuda.\n{\"impl_tag\": \"child\", \"commit_hash\": \"eefbf4a68b7b0a5b8364a59647906be1b7f043e2\", \"device\": \"cuda\", \"dtype\": \"torch.float16\", \"iters\": 50, \"warmup\": 5, \"avg_ms\": 0.18845119953155517, \"p50_ms\": 0.18595199286937714, \"p95_ms\": 0.19040000438690186, \"eq_level\": \"numeric\", \"opt_path_hit\": true}\n",
    "stderr": "\n",
    "duration_s": 28.878714084625244,
    "patch_path": "/root/OmniPerf-Bench/perf-agents-bench/state/runs/vllm/claude_code/default/2025-12-22_21-40-38/vllm_core-0088/model_patch.diff",
    "patch_stats": null,
    "used_wheel": true,
    "used_compilation": false
  }
}