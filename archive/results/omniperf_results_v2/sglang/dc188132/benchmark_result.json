{
  "instance": {
    "commit_hash": "dc1881326f61734a4160620b6e12a5542b756066",
    "commit_subject": "Fix perf regression on small batch sizes (#3008)",
    "repo": "sglang",
    "pr_url": "https://github.com/sgl-project/sglang/pull/3008",
    "files_changed": [
      "python/sglang/srt/layers/radix_attention.py",
      "python/sglang/srt/mem_cache/memory_pool.py"
    ]
  },
  "result": {
    "status": "baseline_failed",
    "commit_hash": "dc1881326f61734a4160620b6e12a5542b756066",
    "baseline_ms": null,
    "patched_ms": null,
    "speedup": null,
    "improvement": false,
    "baseline_output": null,
    "patched_output": null,
    "error_message": "Baseline test failed to produce JSON output",
    "stdout": "",
    "stderr": "/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/vllm/__init__.py:5: RuntimeWarning: Failed to read commit hash:\nNo module named 'vllm._version'\n  from .version import __version__, __version_tuple__  # isort:skip\nTraceback (most recent call last):\n  File \"/tmp/omniperf_test_jmfilbgp.py\", line 115, in setup\n    from sglang.srt.mem_cache.memory_pool import MHATokenToKVPool\n  File \"/tmp/omniperf_worktree_89z9vp41/worktree/python/sglang/srt/mem_cache/memory_pool.py\", line 36, in <module>\n    from sglang.srt.layers.radix_attention import RadixAttention\n  File \"/tmp/omniperf_worktree_89z9vp41/worktree/python/sglang/srt/layers/radix_attention.py\", line 18, in <module>\n    from sglang.srt.model_executor.forward_batch_info import ForwardBatch\n  File \"/tmp/omniperf_worktree_89z9vp41/worktree/python/sglang/srt/model_executor/forward_batch_info.py\", line 40, in <module>\n    from sglang.srt.layers.rotary_embedding import MRotaryEmbedding\n  File \"/tmp/omniperf_worktree_89z9vp41/worktree/python/sglang/srt/layers/rotary_embedding.py\", line 9, in <module>\n    from vllm.model_executor.custom_op import CustomOp\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/vllm/__init__.py\", line 11, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/vllm/engine/arg_utils.py\", line 13, in <module>\n    from vllm.config import (CacheConfig, CompilationConfig, ConfigFormat,\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/vllm/config.py\", line 19, in <module>\n    from transformers import PretrainedConfig\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/transformers/__init__.py\", line 27, in <module>\n    from . import dependency_versions_check\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 57, in <module>\n    require_version_core(deps[pkg])\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/transformers/utils/versions.py\", line 117, in require_version_core\n    return require_version(requirement, hint)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/transformers/utils/versions.py\", line 111, in require_version\n    _compare_versions(op, got_ver, want_ver, requirement, pkg, hint)\n  File \"/root/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/transformers/utils/versions.py\", line 44, in _compare_versions\n    raise ImportError(\nImportError: huggingface-hub>=0.34.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.2.3.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/omniperf_test_jmfilbgp.py\", line 389, in <module>\n    run_test(args.eqcheck, args.reference, args.prefix)\n  File \"/tmp/omniperf_test_jmfilbgp.py\", line 320, in run_test\n    data = setup()\n           ^^^^^^^\n  File \"/tmp/omniperf_test_jmfilbgp.py\", line 158, in setup\n    pool = MockPool()\n           ^^^^^^^^^^\n  File \"/tmp/omniperf_test_jmfilbgp.py\", line 137, in __init__\n    self.k_buffer = [torch.zeros(total_tokens, num_heads, head_dim, device=device, dtype=dtype) \n                                 ^^^^^^^^^^^^\nNameError: cannot access free variable 'total_tokens' where it is not associated with a value in enclosing scope\n",
    "duration_s": 2.230471134185791,
    "patch_path": "/root/OmniPerf-Bench/perf-agents-bench/state/runs/sglang/claude_code/default/2025-12-23_06-28-44/sglang_066_dc188132/model_patch.diff",
    "patch_stats": null
  }
}