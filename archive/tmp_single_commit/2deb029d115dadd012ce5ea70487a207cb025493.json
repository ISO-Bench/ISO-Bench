{
    "commit_hash": "2deb029d115dadd012ce5ea70487a207cb025493",
    "subject": "[Performance][BlockManagerV2] Mark prefix cache block as computed after schedule (#7822)",
    "message": "[Performance][BlockManagerV2] Mark prefix cache block as computed after schedule (#7822)",
    "date": "2024-08-26T11:24:53-07:00",
    "files_changed": [
      "tests/core/block/test_prefix_caching_block.py",
      "vllm/core/block/prefix_caching_block.py",
      "vllm/core/block_manager_v2.py"
    ],
    "functions_changed": [],
    "stats": {
      "num_test_files": 1,
      "num_non_test_files": 2,
      "only_test_files": 0,
      "only_non_test_files": 0,
      "num_files": 3,
      "num_hunks": 6,
      "num_edited_lines": 63,
      "num_non_test_edited_lines": 32,
      "commit_year": 2024
    },
    "affected_paths": [
      "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/core/block/prefix_caching_block.py",
      "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm/vllm/core/block_manager.py"
    ],
    "apis": [
      "PrefixCachingBlockAllocator.mark_blocks_as_computed",
      "BlockSpaceManagerV2.mark_blocks_as_computed"
    ],
    "diff_text": "diff --git a/tests/core/block/test_prefix_caching_block.py b/tests/core/block/test_prefix_caching_block.py\nindex c2226870c..25be2dd13 100644\n--- a/tests/core/block/test_prefix_caching_block.py\n+++ b/tests/core/block/test_prefix_caching_block.py\n@@ -708,6 +708,37 @@ class TestPrefixCachingBlockAllocator:\n                                                token_ids=token_ids)\n         assert allocator.get_prefix_cache_hit_rate() > 0.99\n \n+    # Test case for marking cache hit blocks as computed right after\n+    # a batch of prefill sequences are scheduled.\n+    @staticmethod\n+    def test_touch_block():\n+        block_size = 16\n+        common_blocks = 4\n+        allocator = PrefixCachingBlockAllocator(num_blocks=8,\n+                                                block_size=block_size)\n+\n+        common_token_ids = list(range(block_size * common_blocks))\n+\n+        # Mimic the behavior of allocating the same block chain\n+        # (i.e., common prefix) for a batch of 3 different prefill sequences.\n+        for _ in range(3):\n+            blocks = TestPrefixCachingBlockAllocator.create_immutable_chain(\n+                block_size=block_size,\n+                token_ids=common_token_ids,\n+                allocator=allocator,\n+            )\n+            block_ids = [block.block_id for block in blocks]\n+            # The allocated blocks should  be marked as touched\n+            # but not computed.\n+            computed_block_ids = allocator.get_computed_block_ids(\n+                [], block_ids, skip_last_block_id=False)\n+            assert len(computed_block_ids) == 0\n+\n+        allocator.mark_blocks_as_computed([])\n+        computed_block_ids = allocator.get_computed_block_ids(\n+            [], block_ids, skip_last_block_id=False)\n+        assert len(computed_block_ids) == common_blocks\n+\n     @staticmethod\n     def create_immutable_chain(\n         block_size: int,\ndiff --git a/vllm/core/block/prefix_caching_block.py b/vllm/core/block/prefix_caching_block.py\nindex 432a6651a..a87e814cf 100644\n--- a/vllm/core/block/prefix_caching_block.py\n+++ b/vllm/core/block/prefix_caching_block.py\n@@ -1,6 +1,6 @@\n \"\"\"Token blocks.\"\"\"\n from os.path import commonprefix\n-from typing import Dict, FrozenSet, Iterable, List, Optional, Tuple\n+from typing import Dict, FrozenSet, Iterable, List, Optional, Set, Tuple\n \n from vllm.core.block.common import (CacheMetricData, CopyOnWriteTracker,\n                                     get_all_blocks_recursively)\n@@ -73,6 +73,11 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         # prefix hash will be in this dict, even if they have refcount 0.\n         self._cached_blocks: Dict[PrefixHash, BlockId] = {}\n \n+        # A list of immutable block IDs that have been touched by scheduler\n+        # and should be marked as computed after an entire batch of sequences\n+        # are scheduled.\n+        self._touched_blocks: Set[BlockId] = set()\n+\n         # Used to track status of each physical block id\n         self._block_tracker: Dict[BlockId, BlockTracker] = {}\n         for block_id in block_ids:\n@@ -438,10 +443,14 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         assert self._refcounter.get(block.block_id) > 0\n \n         if block.content_hash not in self._cached_blocks:\n-            # No cached content hash => Set this block as cached\n-            # (Note that this block is not computed yet =>\n-            #  Will be computed after free())\n+            # No cached content hash => Set this block as cached.\n+            # Note that this block cannot be marked as computed yet\n+            # because other sequences in the same batch cannot reuse\n+            # this block.\n             self._cached_blocks[block.content_hash] = block.block_id\n+            # Mark this block as touched so that it can be marked as\n+            # computed after the entire batch of sequences are scheduled.\n+            self._touched_blocks.add(block.block_id)\n             return block.block_id\n \n         # Reuse the cached content hash\n@@ -507,7 +516,10 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n                     \"Mark block as accessed which is not belonged to GPU\")\n \n     def mark_blocks_as_computed(self, block_ids: List[int]) -> None:\n-        raise NotImplementedError(\"Marking as computed is incremental\")\n+        # Mark all touched blocks as computed.\n+        for block_id in self._touched_blocks:\n+            self._block_tracker[block_id].computed = True\n+        self._touched_blocks.clear()\n \n     def _track_block_id(self, block_id: Optional[BlockId],\n                         computed: bool) -> None:\ndiff --git a/vllm/core/block_manager_v2.py b/vllm/core/block_manager_v2.py\nindex b7d9451f1..7d4919a0d 100644\n--- a/vllm/core/block_manager_v2.py\n+++ b/vllm/core/block_manager_v2.py\n@@ -287,11 +287,11 @@ class BlockSpaceManagerV2(BlockSpaceManager):\n                 seq.seq_id, now)\n \n     def mark_blocks_as_computed(self, seq_group: SequenceGroup):\n-        # The only need for mark block as computed is for prefix caching,\n-        # while currently we could determine whether one block is computed\n-        # or not by check whether it has content hash.\n-        # So this function is useless for block_v2.\n-        pass\n+        # If prefix caching is enabled, mark immutable blocks as computed\n+        # right after they have been scheduled (for prefill). This assumes\n+        # the scheduler is synchronous so blocks are actually computed when\n+        # scheduling the next batch.\n+        self.block_allocator.mark_blocks_as_computed([])\n \n     def get_common_computed_block_ids(\n             self, seqs: List[Sequence]) -> GenericSequence[int]:",
    "llm_reason": "The commit modifies both production code (in vllm/core/block/prefix_caching_block.py and vllm/core/block_manager_v2.py) and tests (in tests/core/block/test_prefix_caching_block.py). The changes include implementing logic to mark blocks as computed based on a touched blocks set, which streamlines the caching mechanism after scheduling, thus likely reducing redundant computation. Although the commit message mentions \"[Performance]\", our analysis confirms that the changes adjust internal handling to improve caching efficiency—a fundamental performance optimization. The modifications impact core APIs and address CPU-based performance improvements. Therefore, it satisfies the conditions for a performance-related commit.",
    "llm_api_reason": "The commit adds a new implementation for marking blocks as computed right after scheduling a batch of prefill sequences. In PrefixCachingBlockAllocator, the method mark_blocks_as_computed is now implemented to iterate over the touched blocks, mark them computed, and clear the touched blocks list. Meanwhile, in BlockSpaceManagerV2 the previously empty mark_blocks_as_computed method is updated to call the allocator’s new implementation. These changes affect the respective publicly exposed APIs.",
    "repo_path": "/Users/fortuna/buckets/gso_bucket/analysis/repos/vllm"
}