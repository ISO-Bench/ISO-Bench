{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-0fca3cd", "model_patch": "diff --git a/model_patch.diff b/model_patch.diff\nnew file mode 100644\nindex 0000000..e69de29\ndiff --git a/vllm/model_executor/model_loader/loader.py b/vllm/model_executor/model_loader/loader.py\nindex 748fb9d..ff2bf77 100644\n--- a/vllm/model_executor/model_loader/loader.py\n+++ b/vllm/model_executor/model_loader/loader.py\n@@ -222,9 +222,10 @@ class DefaultModelLoader(BaseModelLoader):\n                    cache_config: CacheConfig) -> nn.Module:\n         with set_default_torch_dtype(model_config.dtype):\n             with torch.device(device_config.device):\n-                model = _initialize_model(model_config, self.load_config,\n-                                          lora_config, vision_language_config,\n-                                          cache_config)\n+                with torch.no_grad():\n+                    model = _initialize_model(model_config, self.load_config,\n+                                              lora_config, vision_language_config,\n+                                              cache_config)\n             with torch.no_grad():\n                 model.load_weights(\n                     self._get_weights_iterator(model_config.model,\n@@ -344,8 +345,9 @@ class TensorizerLoader(BaseModelLoader):\n                 tensorizer_config.hf_config = model_config.hf_config\n                 tensorizer_config.dtype = model_config.dtype\n \n-                model = load_with_tensorizer(tensorizer_config, **extra_kwargs)\n-        return model.eval()\n+                with torch.no_grad():\n+                    model = load_with_tensorizer(tensorizer_config, **extra_kwargs)\n+            return model.eval()\n \n     def load_model(self, *, model_config: ModelConfig,\n                    device_config: DeviceConfig,\n", "model_name_or_path": "gpt-5-2025-08-07"}
