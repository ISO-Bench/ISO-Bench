diff --git a/tests/v1/sample/test_rejection_sampler.py b/tests/v1/sample/test_rejection_sampler.py
index 84139a4..0f56f70 100644
--- a/tests/v1/sample/test_rejection_sampler.py
+++ b/tests/v1/sample/test_rejection_sampler.py
@@ -345,8 +345,8 @@ def estimate_rejection_sampling_pdf(
                                             num_samples, k)
 
     # Bonus tokens not used but required.
-    bonus_token_ids = torch.zeros((1, 1), dtype=torch.int64,
-                                  device=DEVICE).repeat(num_samples, 1)
+    bonus_token_ids = torch.zeros((num_samples, 1), dtype=torch.int64,
+                                  device=DEVICE)
 
     sampling_metadata = create_sampling_metadata(all_greedy=False)
     output_token_ids = sampler(draft_token_ids.tolist(), draft_probs,
diff --git a/vllm/v1/outputs.py b/vllm/v1/outputs.py
index edae654..b75b487 100644
--- a/vllm/v1/outputs.py
+++ b/vllm/v1/outputs.py
@@ -40,7 +40,7 @@ class LogprobsTensors(NamedTuple):
         )
 
 
-@dataclass
+@dataclass(slots=True)
 class SamplerOutput:
 
     # [num_reqs, max_num_generated_tokens]
@@ -53,7 +53,7 @@ class SamplerOutput:
 
 # ModelRunnerOutput is serialized and sent to the scheduler process.
 # This is expensive for torch.Tensor so prefer to use list instead.
-@dataclass
+@dataclass(slots=True)
 class ModelRunnerOutput:
 
     # [num_reqs]
