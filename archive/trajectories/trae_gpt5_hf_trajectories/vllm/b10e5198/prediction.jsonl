{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-9bde5ba", "model_patch": "diff --git a/vllm/v1/core/block_pool.py b/vllm/v1/core/block_pool.py\nindex f7cebb1..786b946 100644\n--- a/vllm/v1/core/block_pool.py\n+++ b/vllm/v1/core/block_pool.py\n@@ -166,15 +166,13 @@ class BlockPool:\n         enable_caching = self.enable_caching\n \n         ret: list[KVCacheBlock] = [None] * num_blocks  # type: ignore\n-        idx = 0\n-        while idx < num_blocks:\n+        for idx in range(num_blocks):\n             curr_block = popleft()\n             assert curr_block.ref_cnt == 0\n             if enable_caching:\n                 maybe_evict(curr_block)\n             incr_ref(curr_block)\n             ret[idx] = curr_block\n-            idx += 1\n \n         return ret\n \n@@ -230,7 +228,8 @@ class BlockPool:\n         decr_ref = KVCacheBlock.decr_ref\n         for block in ordered_blocks:\n             decr_ref(block)\n-            if block.ref_cnt == 0 and block is not null_block:\n+            new_ref = block.ref_cnt\n+            if new_ref == 0 and block is not null_block:\n                 append_free(block)\n \n     def reset_prefix_cache(self) -> bool:\n", "model_name_or_path": "gpt-5-2025-08-07"}
