id: "chunked_local_attn_opt"
name: "Chunked Local Attention Hybrid KV Toggle"
description: "Optimize scheduler config behavior when chunked local attention is enabled"
repo:
  url: "https://github.com/vllm-project/vllm.git"
  human_commit: "8aa1485fcff7be3e42300c0615ee0f3f3cbce9a8"
runner:
  requires_gpu: false
  allow_network_during_prepare: true
env_build:
  allowed_strategies: ["dockerfile", "requirements"]
  params:
    dockerfile_path: null
    requirements_file: null
optimization_contract:
  strict_targets: false
  target_files:
    - "vllm/config.py"
    - "vllm/envs.py"
  constraints:
    - "No public API breakage"
    - "Maintain functional equivalence"
    - "Focus on performance optimization"
testpack:
  entrypoint: "../vlm-bench-generic"
metrics: []
scoring:
  primary: "functional_equivalence"
  tie_breaker: "functional_equivalence"
