id: "vllm_core"
name: "vLLM core performance"
description: "Run vLLM performance checks with Dockerfile-based env"

repo:
  url: "https://github.com/vllm-project/vllm.git"
  human_commit: "f092153fbe349a9a1742940e3703bfcff6aa0a6d"
  # pre_commit omitted â†’ defaults to the first parent of human_commit

runner:
  requires_gpu: false
  cuda_version: null
  python_version: null
  platform: "linux/amd64"
  allow_network_during_prepare: true
  allowed_env: []

env_build:
  allowed_strategies:
    - "dockerfile"
    - "requirements"
  params:
    dockerfile_path: null
    requirements_file: null

optimization_contract:
  strict_targets: false
  target_files: []
  constraints:
    - "No public API breakage"
    - "All TestPack checks must pass"

# OpenHands CLI configuration (uvx-based CLI per docs)
# See: https://docs.all-hands.dev/usage/how-to/cli-mode
agents:
  openhands:
    args:
      subcommand: ["--python", "3.12", "--from", "openhands-ai", "python", "-m", "openhands.core.main"]

testpack:
  entrypoint: "../vlm-bench-generic"
  version_constraint: ">=0.1.0"

metrics:
  - name: "throughput_img_per_s"
    using: "runtime:throughput"
    args:
      cmd: "python -c \"print(1.0)\""
      warmups: 1
      trials: 3
      duration_s: 1
  - name: "functional_match"
    using: "quality:hash_match"
    args:
      ref: "human.json"
      candidate: "{candidate}.json"

scoring:
  primary: "functional_match"
  tie_breaker: "throughput_img_per_s"

