{
  "metadata": {
    "run_id": "sglang/claude_code/default/2025-12-23_06-28-44",
    "item_id": "sglang_052_ac971ff6",
    "task_id": "sglang_core",
    "human_commit": "ac971ff633de330de3ded7f7475caaf7cd5bbdcd",
    "pre_commit": "e1792cca2491af86f29782a3b83533a6566ac75b",
    "agent_status": "success",
    "patch_path": "/home/ubuntu/OmniPerf-Bench/perf-agents-bench/state/runs/sglang/claude_code/default/2025-12-23_06-28-44/sglang_052_ac971ff6/model_patch.diff",
    "test_script_path": "/home/ubuntu/OmniPerf-Bench/hf_cache/test-generation-scripts/repo/generated_test_generators_v4/ac971ff6_test_case_generator.py",
    "repo": "sglang",
    "agent": "claude_code",
    "model": "default",
    "timestamp": "2025-12-23_06-28-44",
    "source_dir": "/home/ubuntu/OmniPerf-Bench/perf-agents-bench/state/runs/sglang/claude_code/default/2025-12-23_06-28-44/sglang_052_ac971ff6"
  },
  "result": {
    "status": "error",
    "baseline_ms": null,
    "patched_ms": null,
    "speedup": null,
    "improvement": false,
    "baseline_output": null,
    "patched_output": null,
    "error_message": "Baseline test failed to produce output",
    "stdout": "\n",
    "stderr": "Traceback (most recent call last):\n  File \"/tmp/eval_worktree_lsbxa2zv/test_script.py\", line 354, in <module>\n    run_test(args.eqcheck, args.reference, args.prefix)\n  File \"/tmp/eval_worktree_lsbxa2zv/test_script.py\", line 292, in run_test\n    result, timing_stats = time_gpu(lambda: experiment(data), warmup=warmup, iterations=iters)\n  File \"/tmp/eval_worktree_lsbxa2zv/test_script.py\", line 247, in time_gpu\n    _ = func()\n  File \"/tmp/eval_worktree_lsbxa2zv/test_script.py\", line 292, in <lambda>\n    result, timing_stats = time_gpu(lambda: experiment(data), warmup=warmup, iterations=iters)\n  File \"/tmp/eval_worktree_lsbxa2zv/test_script.py\", line 138, in experiment\n    server_args = target()\nTypeError: ServerArgs.__init__() missing 1 required positional argument: 'model_path'\n\n",
    "duration_s": 5.41303277015686
  }
}