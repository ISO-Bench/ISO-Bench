{
  "metadata": {
    "run_id": "sglang/trae/gpt-5/2025-11-14_21-05-32",
    "item_id": "sglang_040_915140fd",
    "task_id": "sglang_core",
    "human_commit": "915140fd18c9ff4193e994e6d756ea762a52240a",
    "pre_commit": "36fc9260a276be963c098a1a0c2402b9a4008922",
    "agent_status": "error",
    "patch_path": null,
    "test_script_path": "/home/ubuntu/OmniPerf-Bench/hf_cache/test-generation-scripts/repo/generated_test_generators_v4/915140fd_test_case_generator.py",
    "repo": "sglang",
    "agent": "trae",
    "model": "gpt-5",
    "timestamp": "2025-11-14_21-05-32",
    "source_dir": "/home/ubuntu/OmniPerf-Bench/perf-agents-bench/state/runs/sglang/trae/gpt-5/2025-11-14_21-05-32/sglang_040_915140fd"
  },
  "result": {
    "status": "error",
    "baseline_ms": null,
    "patched_ms": null,
    "speedup": null,
    "improvement": false,
    "baseline_output": null,
    "patched_output": null,
    "error_message": "Baseline test failed to produce output",
    "stdout": "\n",
    "stderr": "Traceback (most recent call last):\n  File \"/tmp/eval_worktree_ri2cgmdc/test_script.py\", line 439, in <module>\n    run_test(args.eqcheck, args.reference, args.prefix)\n  File \"/tmp/eval_worktree_ri2cgmdc/test_script.py\", line 377, in run_test\n    data = setup()\n  File \"/tmp/eval_worktree_ri2cgmdc/test_script.py\", line 147, in setup\n    w13_weight_scale = torch.randn(num_local_experts, 2 * intermediate_size, hidden_size // 16,\nRuntimeError: \"normal_kernel_cuda\" not implemented for 'Float8_e4m3fn'\n\n",
    "duration_s": 3.143188953399658
  }
}