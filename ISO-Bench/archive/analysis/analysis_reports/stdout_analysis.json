[
  {
    "run_id": "vllm_core-3368ff88",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10226,
        "output_tokens": 1629,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 551258
      }
    ]
  },
  {
    "run_id": "vllm_core-34aabdf0",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      }
    ]
  },
  {
    "run_id": "vllm_core-39bd9d7d",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      }
    ]
  },
  {
    "run_id": "vllm_core-49197c86",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 3406,
        "output_tokens": 240,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 383855
      }
    ]
  },
  {
    "run_id": "vllm_core-4be69dfd",
    "items": [
      {
        "item_id": "vllm_core-0001",
        "input_tokens": 8614,
        "output_tokens": 120,
        "gpt5_errors": 21,
        "max_step": 6,
        "completed": true,
        "stdout_size": 79977
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": 2751,
        "output_tokens": 267,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 477540
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": 4104,
        "output_tokens": 154,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 193039
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": 3919,
        "output_tokens": 150,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 235506
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": 4018,
        "output_tokens": 158,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 227420
      },
      {
        "item_id": "vllm_core-0007",
        "input_tokens": 4076,
        "output_tokens": 140,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 892223
      },
      {
        "item_id": "vllm_core-0008",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 67089
      }
    ]
  },
  {
    "run_id": "vllm_core-4f52631f",
    "items": [
      {
        "item_id": "vllm_core-0001",
        "input_tokens": 4307,
        "output_tokens": 144,
        "gpt5_errors": 19,
        "max_step": 9,
        "completed": true,
        "stdout_size": 292375
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": 4126,
        "output_tokens": 180,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 93271
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": 4104,
        "output_tokens": 154,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 161064
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": 3919,
        "output_tokens": 150,
        "gpt5_errors": 0,
        "max_step": 6,
        "completed": true,
        "stdout_size": 87123
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": 4018,
        "output_tokens": 158,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 88220
      }
    ]
  },
  {
    "run_id": "vllm_core-5b1cefb4",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10226,
        "output_tokens": 1537,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 541389
      }
    ]
  },
  {
    "run_id": "vllm_core-6274bd5e",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10226,
        "output_tokens": 1326,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 320902
      }
    ]
  },
  {
    "run_id": "vllm_core-6520a271",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10381,
        "output_tokens": 1443,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 401446
      }
    ]
  },
  {
    "run_id": "vllm_core-73442e7b",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 3406,
        "output_tokens": 240,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 161811
      }
    ]
  },
  {
    "run_id": "vllm_core-74a18447",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 3406,
        "output_tokens": 240,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 216326
      }
    ]
  },
  {
    "run_id": "vllm_core-755e50f9",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10226,
        "output_tokens": 1348,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 416400
      }
    ]
  },
  {
    "run_id": "vllm_core-7e93f61e",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      }
    ]
  },
  {
    "run_id": "vllm_core-84ca0ad4",
    "items": [
      {
        "item_id": "vllm_core-0001",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0007",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0008",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0042",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0044",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0045",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0046",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0047",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0048",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0049",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0050",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0051",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0052",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0053",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0054",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0055",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0056",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0057",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0058",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0059",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0060",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0061",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0062",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0063",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0064",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0065",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0066",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0067",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0068",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0069",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0070",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0071",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0072",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0073",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0074",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0075",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0076",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0077",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      },
      {
        "item_id": "vllm_core-0078",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 105
      }
    ]
  },
  {
    "run_id": "vllm_core-8e54a51a",
    "items": [
      {
        "item_id": "vllm_core-0001",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0007",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0008",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0042",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0044",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0045",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0046",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0047",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0048",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0049",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0050",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0051",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0052",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0053",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0054",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0055",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0056",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0057",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0058",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0059",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0060",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0061",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0062",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0063",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0064",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0065",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0066",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0067",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": true,
        "stdout_size": 37357
      }
    ]
  },
  {
    "run_id": "vllm_core-9641716f",
    "items": [
      {
        "item_id": "vllm_core-0001",
        "input_tokens": 8619,
        "output_tokens": 1758,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 524660
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": 8258,
        "output_tokens": 1539,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 468684
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": 8213,
        "output_tokens": 881,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 540817
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": 7843,
        "output_tokens": 891,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 608435
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": 8042,
        "output_tokens": 1503,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 487976
      },
      {
        "item_id": "vllm_core-0007",
        "input_tokens": 8157,
        "output_tokens": 1109,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 301279
      },
      {
        "item_id": "vllm_core-0008",
        "input_tokens": 8113,
        "output_tokens": 750,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 255163
      },
      {
        "item_id": "vllm_core-0042",
        "input_tokens": 9254,
        "output_tokens": 1384,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 725778
      },
      {
        "item_id": "vllm_core-0044",
        "input_tokens": 8341,
        "output_tokens": 1552,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 667346
      },
      {
        "item_id": "vllm_core-0045",
        "input_tokens": 7892,
        "output_tokens": 1777,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 310374
      },
      {
        "item_id": "vllm_core-0046",
        "input_tokens": 8280,
        "output_tokens": 669,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 392627
      },
      {
        "item_id": "vllm_core-0047",
        "input_tokens": 8404,
        "output_tokens": 1179,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 531523
      },
      {
        "item_id": "vllm_core-0048",
        "input_tokens": 8070,
        "output_tokens": 620,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 440966
      },
      {
        "item_id": "vllm_core-0049",
        "input_tokens": 8369,
        "output_tokens": 491,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 439537
      },
      {
        "item_id": "vllm_core-0050",
        "input_tokens": 8099,
        "output_tokens": 678,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 276919
      },
      {
        "item_id": "vllm_core-0051",
        "input_tokens": 8216,
        "output_tokens": 742,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 947837
      },
      {
        "item_id": "vllm_core-0052",
        "input_tokens": 8055,
        "output_tokens": 877,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 1089282
      },
      {
        "item_id": "vllm_core-0053",
        "input_tokens": 8196,
        "output_tokens": 692,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 842983
      },
      {
        "item_id": "vllm_core-0054",
        "input_tokens": 8146,
        "output_tokens": 815,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 972325
      },
      {
        "item_id": "vllm_core-0055",
        "input_tokens": 8457,
        "output_tokens": 1103,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 848214
      },
      {
        "item_id": "vllm_core-0056",
        "input_tokens": 8103,
        "output_tokens": 724,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 457631
      },
      {
        "item_id": "vllm_core-0057",
        "input_tokens": 8002,
        "output_tokens": 848,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 279170
      },
      {
        "item_id": "vllm_core-0058",
        "input_tokens": 8292,
        "output_tokens": 1386,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 482836
      },
      {
        "item_id": "vllm_core-0059",
        "input_tokens": 8064,
        "output_tokens": 616,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 941200
      },
      {
        "item_id": "vllm_core-0060",
        "input_tokens": 8176,
        "output_tokens": 1255,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 687079
      },
      {
        "item_id": "vllm_core-0061",
        "input_tokens": 8143,
        "output_tokens": 1278,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 527864
      },
      {
        "item_id": "vllm_core-0062",
        "input_tokens": 7882,
        "output_tokens": 997,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 478844
      },
      {
        "item_id": "vllm_core-0063",
        "input_tokens": 8141,
        "output_tokens": 767,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 501408
      },
      {
        "item_id": "vllm_core-0064",
        "input_tokens": 8411,
        "output_tokens": 1207,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 906980
      },
      {
        "item_id": "vllm_core-0065",
        "input_tokens": 8108,
        "output_tokens": 800,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 538685
      },
      {
        "item_id": "vllm_core-0066",
        "input_tokens": 8492,
        "output_tokens": 689,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 667606
      },
      {
        "item_id": "vllm_core-0067",
        "input_tokens": 8560,
        "output_tokens": 1174,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 430647
      },
      {
        "item_id": "vllm_core-0068",
        "input_tokens": 8159,
        "output_tokens": 1239,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 612632
      },
      {
        "item_id": "vllm_core-0069",
        "input_tokens": 8186,
        "output_tokens": 675,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 428141
      },
      {
        "item_id": "vllm_core-0070",
        "input_tokens": 8778,
        "output_tokens": 1002,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 675507
      },
      {
        "item_id": "vllm_core-0071",
        "input_tokens": 8000,
        "output_tokens": 941,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 487192
      },
      {
        "item_id": "vllm_core-0072",
        "input_tokens": 8182,
        "output_tokens": 573,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 394598
      },
      {
        "item_id": "vllm_core-0073",
        "input_tokens": 8046,
        "output_tokens": 1183,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 287244
      },
      {
        "item_id": "vllm_core-0074",
        "input_tokens": 8421,
        "output_tokens": 1208,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 566831
      },
      {
        "item_id": "vllm_core-0075",
        "input_tokens": 8077,
        "output_tokens": 1121,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 723844
      },
      {
        "item_id": "vllm_core-0076",
        "input_tokens": 7919,
        "output_tokens": 873,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 270433
      },
      {
        "item_id": "vllm_core-0077",
        "input_tokens": 8181,
        "output_tokens": 675,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 807025
      },
      {
        "item_id": "vllm_core-0078",
        "input_tokens": 8057,
        "output_tokens": 1002,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 693173
      },
      {
        "item_id": "vllm_core-0079",
        "input_tokens": 8214,
        "output_tokens": 870,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 499686
      },
      {
        "item_id": "vllm_core-0080",
        "input_tokens": 8295,
        "output_tokens": 1005,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 370409
      },
      {
        "item_id": "vllm_core-0081",
        "input_tokens": 8024,
        "output_tokens": 791,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 245084
      },
      {
        "item_id": "vllm_core-0082",
        "input_tokens": 8444,
        "output_tokens": 927,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 726665
      },
      {
        "item_id": "vllm_core-0083",
        "input_tokens": 8187,
        "output_tokens": 879,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 379539
      },
      {
        "item_id": "vllm_core-0084",
        "input_tokens": 8065,
        "output_tokens": 800,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 246850
      },
      {
        "item_id": "vllm_core-0085",
        "input_tokens": 8449,
        "output_tokens": 1658,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 834089
      },
      {
        "item_id": "vllm_core-0086",
        "input_tokens": 8010,
        "output_tokens": 638,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 212290
      },
      {
        "item_id": "vllm_core-0087",
        "input_tokens": 8421,
        "output_tokens": 821,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 564211
      },
      {
        "item_id": "vllm_core-0088",
        "input_tokens": 7994,
        "output_tokens": 1463,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 451696
      },
      {
        "item_id": "vllm_core-0089",
        "input_tokens": 8119,
        "output_tokens": 665,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 352170
      },
      {
        "item_id": "vllm_core-0090",
        "input_tokens": 8027,
        "output_tokens": 989,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 302836
      },
      {
        "item_id": "vllm_core-0091",
        "input_tokens": 8146,
        "output_tokens": 813,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 668751
      },
      {
        "item_id": "vllm_core-0092",
        "input_tokens": 8101,
        "output_tokens": 1078,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 393825
      },
      {
        "item_id": "vllm_core-0093",
        "input_tokens": 8174,
        "output_tokens": 812,
        "gpt5_errors": 0,
        "max_step": 4,
        "completed": true,
        "stdout_size": 141424
      },
      {
        "item_id": "vllm_core-0094",
        "input_tokens": 8313,
        "output_tokens": 1116,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 527834
      },
      {
        "item_id": "vllm_core-0095",
        "input_tokens": 8070,
        "output_tokens": 1031,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 321236
      }
    ]
  },
  {
    "run_id": "vllm_core-a19481e2",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10458,
        "output_tokens": 1520,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 473509
      }
    ]
  },
  {
    "run_id": "vllm_core-a40b2039",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 53755
      },
      {
        "item_id": "vllm_core-0001",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 63149
      },
      {
        "item_id": "vllm_core-0002",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 58126
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 56995
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 56022
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 49868
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 52946
      },
      {
        "item_id": "vllm_core-0007",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 53107
      },
      {
        "item_id": "vllm_core-0008",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 53916
      },
      {
        "item_id": "vllm_core-0009",
        "input_tokens": 10337,
        "output_tokens": 1341,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 126039
      },
      {
        "item_id": "vllm_core-0010",
        "input_tokens": 10721,
        "output_tokens": 1243,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 301089
      },
      {
        "item_id": "vllm_core-0011",
        "input_tokens": 10603,
        "output_tokens": 1078,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 624810
      },
      {
        "item_id": "vllm_core-0012",
        "input_tokens": 10271,
        "output_tokens": 1005,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 312110
      },
      {
        "item_id": "vllm_core-0013",
        "input_tokens": 10661,
        "output_tokens": 472,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 385381
      },
      {
        "item_id": "vllm_core-0014",
        "input_tokens": 10291,
        "output_tokens": 760,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 228186
      },
      {
        "item_id": "vllm_core-0015",
        "input_tokens": 10411,
        "output_tokens": 1440,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 391891
      },
      {
        "item_id": "vllm_core-0016",
        "input_tokens": 10264,
        "output_tokens": 3067,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 107860
      },
      {
        "item_id": "vllm_core-0017",
        "input_tokens": 11044,
        "output_tokens": 1001,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 385817
      },
      {
        "item_id": "vllm_core-0018",
        "input_tokens": 10320,
        "output_tokens": 918,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 108961
      },
      {
        "item_id": "vllm_core-0019",
        "input_tokens": 10636,
        "output_tokens": 1027,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 145675
      },
      {
        "item_id": "vllm_core-0020",
        "input_tokens": 10250,
        "output_tokens": 1174,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 238192
      },
      {
        "item_id": "vllm_core-0021",
        "input_tokens": 10454,
        "output_tokens": 1696,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 200634
      },
      {
        "item_id": "vllm_core-0022",
        "input_tokens": 10285,
        "output_tokens": 604,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 230219
      },
      {
        "item_id": "vllm_core-0023",
        "input_tokens": 10626,
        "output_tokens": 1639,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 312308
      },
      {
        "item_id": "vllm_core-0024",
        "input_tokens": 10419,
        "output_tokens": 1139,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 164631
      },
      {
        "item_id": "vllm_core-0025",
        "input_tokens": 10109,
        "output_tokens": 1137,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 122930
      },
      {
        "item_id": "vllm_core-0026",
        "input_tokens": 10461,
        "output_tokens": 1210,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 428448
      },
      {
        "item_id": "vllm_core-0027",
        "input_tokens": 10259,
        "output_tokens": 816,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 102192
      },
      {
        "item_id": "vllm_core-0028",
        "input_tokens": 10372,
        "output_tokens": 1209,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 202896
      },
      {
        "item_id": "vllm_core-0029",
        "input_tokens": 10177,
        "output_tokens": 1669,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 170055
      },
      {
        "item_id": "vllm_core-0030",
        "input_tokens": 10580,
        "output_tokens": 1169,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 478722
      },
      {
        "item_id": "vllm_core-0031",
        "input_tokens": 10856,
        "output_tokens": 964,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 489981
      },
      {
        "item_id": "vllm_core-0032",
        "input_tokens": 10531,
        "output_tokens": 1128,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 329398
      },
      {
        "item_id": "vllm_core-0033",
        "input_tokens": 10209,
        "output_tokens": 888,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 448297
      },
      {
        "item_id": "vllm_core-0034",
        "input_tokens": 10345,
        "output_tokens": 1027,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 568320
      },
      {
        "item_id": "vllm_core-0035",
        "input_tokens": 10434,
        "output_tokens": 1282,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 454930
      },
      {
        "item_id": "vllm_core-0036",
        "input_tokens": 10292,
        "output_tokens": 1061,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 363539
      },
      {
        "item_id": "vllm_core-0037",
        "input_tokens": 10111,
        "output_tokens": 1061,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 237107
      },
      {
        "item_id": "vllm_core-0038",
        "input_tokens": 10396,
        "output_tokens": 2146,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 271268
      },
      {
        "item_id": "vllm_core-0039",
        "input_tokens": 10217,
        "output_tokens": 1242,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 464295
      },
      {
        "item_id": "vllm_core-0040",
        "input_tokens": 10143,
        "output_tokens": 847,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 213236
      },
      {
        "item_id": "vllm_core-0041",
        "input_tokens": 10222,
        "output_tokens": 1389,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 517643
      },
      {
        "item_id": "vllm_core-0042",
        "input_tokens": 11388,
        "output_tokens": 1660,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 426690
      },
      {
        "item_id": "vllm_core-0043",
        "input_tokens": 10301,
        "output_tokens": 785,
        "gpt5_errors": 0,
        "max_step": 4,
        "completed": true,
        "stdout_size": 218619
      },
      {
        "item_id": "vllm_core-0044",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 56658
      },
      {
        "item_id": "vllm_core-0045",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 50016
      },
      {
        "item_id": "vllm_core-0046",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 54876
      },
      {
        "item_id": "vllm_core-0047",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 56982
      },
      {
        "item_id": "vllm_core-0048",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": true,
        "stdout_size": 38111
      }
    ]
  },
  {
    "run_id": "vllm_core-aab87872",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10226,
        "output_tokens": 1942,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 761277
      }
    ]
  },
  {
    "run_id": "vllm_core-aed20220",
    "items": [
      {
        "item_id": "vllm_core-0001",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0007",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0008",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0042",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0044",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0045",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0046",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0047",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0048",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0049",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0050",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0051",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0052",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0053",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0054",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0055",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0056",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0057",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0058",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0059",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0060",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0061",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0062",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0063",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0064",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0065",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      },
      {
        "item_id": "vllm_core-0066",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      }
    ]
  },
  {
    "run_id": "vllm_core-b6e02aed",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 3406,
        "output_tokens": 240,
        "gpt5_errors": 21,
        "max_step": 99,
        "completed": true,
        "stdout_size": 839218
      }
    ]
  },
  {
    "run_id": "vllm_core-beffe4cd",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 51326
      },
      {
        "item_id": "vllm_core-0001",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 60397
      },
      {
        "item_id": "vllm_core-0002",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 55699
      },
      {
        "item_id": "vllm_core-0003",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 54566
      },
      {
        "item_id": "vllm_core-0004",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 52944
      },
      {
        "item_id": "vllm_core-0005",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 48408
      },
      {
        "item_id": "vllm_core-0006",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 50351
      },
      {
        "item_id": "vllm_core-0007",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 51487
      },
      {
        "item_id": "vllm_core-0008",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 51326
      },
      {
        "item_id": "vllm_core-0009",
        "input_tokens": 10181,
        "output_tokens": 911,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 124711
      },
      {
        "item_id": "vllm_core-0010",
        "input_tokens": 10595,
        "output_tokens": 2087,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 303163
      },
      {
        "item_id": "vllm_core-0011",
        "input_tokens": 10458,
        "output_tokens": 936,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 670612
      },
      {
        "item_id": "vllm_core-0012",
        "input_tokens": 10198,
        "output_tokens": 1239,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 337291
      },
      {
        "item_id": "vllm_core-0013",
        "input_tokens": 10542,
        "output_tokens": 1477,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 434404
      },
      {
        "item_id": "vllm_core-0014",
        "input_tokens": 10207,
        "output_tokens": 1008,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 227772
      },
      {
        "item_id": "vllm_core-0015",
        "input_tokens": 10255,
        "output_tokens": 1314,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 747145
      },
      {
        "item_id": "vllm_core-0016",
        "input_tokens": 10196,
        "output_tokens": 4096,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 149679
      },
      {
        "item_id": "vllm_core-0017",
        "input_tokens": 10882,
        "output_tokens": 752,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 257517
      },
      {
        "item_id": "vllm_core-0018",
        "input_tokens": 10184,
        "output_tokens": 877,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 195278
      },
      {
        "item_id": "vllm_core-0019",
        "input_tokens": 10481,
        "output_tokens": 986,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 196890
      },
      {
        "item_id": "vllm_core-0020",
        "input_tokens": 10156,
        "output_tokens": 1385,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 178778
      },
      {
        "item_id": "vllm_core-0021",
        "input_tokens": 10358,
        "output_tokens": 926,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 182645
      },
      {
        "item_id": "vllm_core-0022",
        "input_tokens": 10187,
        "output_tokens": 884,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 156291
      },
      {
        "item_id": "vllm_core-0023",
        "input_tokens": 10463,
        "output_tokens": 840,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 309656
      },
      {
        "item_id": "vllm_core-0024",
        "input_tokens": 10280,
        "output_tokens": 1159,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 134974
      },
      {
        "item_id": "vllm_core-0025",
        "input_tokens": 10031,
        "output_tokens": 1089,
        "gpt5_errors": 0,
        "max_step": 3,
        "completed": true,
        "stdout_size": 77058
      },
      {
        "item_id": "vllm_core-0026",
        "input_tokens": 10296,
        "output_tokens": 824,
        "gpt5_errors": 0,
        "max_step": 6,
        "completed": true,
        "stdout_size": 184070
      },
      {
        "item_id": "vllm_core-0027",
        "input_tokens": 10137,
        "output_tokens": 1441,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 118667
      },
      {
        "item_id": "vllm_core-0028",
        "input_tokens": 10205,
        "output_tokens": 900,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 298841
      },
      {
        "item_id": "vllm_core-0029",
        "input_tokens": 10094,
        "output_tokens": 1119,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 224065
      },
      {
        "item_id": "vllm_core-0030",
        "input_tokens": 10471,
        "output_tokens": 1306,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 372002
      },
      {
        "item_id": "vllm_core-0031",
        "input_tokens": 10656,
        "output_tokens": 1615,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 395374
      },
      {
        "item_id": "vllm_core-0032",
        "input_tokens": 10389,
        "output_tokens": 1830,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 471644
      },
      {
        "item_id": "vllm_core-0033",
        "input_tokens": 10091,
        "output_tokens": 1516,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 221793
      },
      {
        "item_id": "vllm_core-0034",
        "input_tokens": 10258,
        "output_tokens": 1693,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 325311
      },
      {
        "item_id": "vllm_core-0035",
        "input_tokens": 10283,
        "output_tokens": 688,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 436836
      },
      {
        "item_id": "vllm_core-0036",
        "input_tokens": 10234,
        "output_tokens": 897,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 481276
      },
      {
        "item_id": "vllm_core-0037",
        "input_tokens": 10098,
        "output_tokens": 1714,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 210362
      },
      {
        "item_id": "vllm_core-0038",
        "input_tokens": 10383,
        "output_tokens": 927,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 228264
      },
      {
        "item_id": "vllm_core-0039",
        "input_tokens": 10204,
        "output_tokens": 785,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 265334
      },
      {
        "item_id": "vllm_core-0040",
        "input_tokens": 10130,
        "output_tokens": 814,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 105478
      },
      {
        "item_id": "vllm_core-0041",
        "input_tokens": 10209,
        "output_tokens": 1114,
        "gpt5_errors": 21,
        "max_step": 9,
        "completed": true,
        "stdout_size": 649870
      },
      {
        "item_id": "vllm_core-0042",
        "input_tokens": 11375,
        "output_tokens": 1072,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 487645
      },
      {
        "item_id": "vllm_core-0043",
        "input_tokens": 10226,
        "output_tokens": 1697,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 460922
      },
      {
        "item_id": "vllm_core-0044",
        "input_tokens": 10462,
        "output_tokens": 1809,
        "gpt5_errors": 0,
        "max_step": 4,
        "completed": true,
        "stdout_size": 172833
      },
      {
        "item_id": "vllm_core-0045",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 49695
      },
      {
        "item_id": "vllm_core-0046",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 54555
      },
      {
        "item_id": "vllm_core-0047",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 56658
      },
      {
        "item_id": "vllm_core-0048",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 1,
        "completed": true,
        "stdout_size": 51475
      }
    ]
  },
  {
    "run_id": "vllm_core-c16e7d24",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10381,
        "output_tokens": 639,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 407600
      }
    ]
  },
  {
    "run_id": "vllm_core-cd4bc029",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      }
    ]
  },
  {
    "run_id": "vllm_core-d22fa127",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10226,
        "output_tokens": 1234,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 344317
      }
    ]
  },
  {
    "run_id": "vllm_core-dbf30c3c",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": null,
        "output_tokens": null,
        "gpt5_errors": 0,
        "max_step": 0,
        "completed": false,
        "stdout_size": 0
      }
    ]
  },
  {
    "run_id": "vllm_core-e615cb42",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 3406,
        "output_tokens": 240,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 93309
      }
    ]
  },
  {
    "run_id": "vllm_core-f8009ca8",
    "items": [
      {
        "item_id": "vllm_core-0000",
        "input_tokens": 10226,
        "output_tokens": 1993,
        "gpt5_errors": 0,
        "max_step": 9,
        "completed": true,
        "stdout_size": 650353
      }
    ]
  }
]