{
  "changed": [
    ".buildkite/nightly-benchmarks/scripts/nightly-annotate.sh",
    ".buildkite/nightly-benchmarks/scripts/run-nightly-benchmarks.sh",
    ".buildkite/nightly-benchmarks/tests/genai-perf-tests.json",
    ".buildkite/run-cpu-test.sh",
    ".buildkite/run-gh200-test.sh",
    ".buildkite/run-hpu-test.sh",
    ".buildkite/run-neuron-test.sh",
    ".buildkite/run-openvino-test.sh",
    ".buildkite/run-tpu-test.sh",
    ".buildkite/run-xpu-test.sh",
    ".buildkite/test-pipeline.yaml",
    ".github/workflows/actionlint.yml",
    ".github/workflows/clang-format.yml",
    ".github/workflows/codespell.yml",
    ".github/workflows/matchers/ruff.json",
    ".github/workflows/mypy.yaml",
    ".github/workflows/png-lint.yml",
    ".github/workflows/pre-commit.yml",
    ".github/workflows/ruff.yml",
    ".github/workflows/shellcheck.yml",
    ".github/workflows/sphinx-lint.yml",
    ".github/workflows/yapf.yml",
    ".pre-commit-config.yaml",
    "Dockerfile.cpu",
    "Dockerfile.hpu",
    "Dockerfile.rocm",
    "README.md",
    "SECURITY.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_latency.py",
    "benchmarks/benchmark_long_document_qa_throughput.py",
    "benchmarks/benchmark_prefix_caching.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/kernels/benchmark_lora.py",
    "benchmarks/kernels/benchmark_moe.py",
    "benchmarks/kernels/utils.py",
    "cmake/utils.cmake",
    "csrc/activation_kernels.cu",
    "csrc/core/scalar_type.hpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/cpu_types_arm.hpp",
    "csrc/cpu/cpu_types_vsx.hpp",
    "csrc/cpu/cpu_types_x86.hpp",
    "csrc/cutlass_extensions/common.hpp",
    "csrc/ops.h",
    "csrc/prepare_inputs/advance_step.cu",
    "csrc/torch_bindings.cpp",
    "docs/README.md",
    "docs/requirements-docs.txt",
    "docs/source/api/inference_params.md",
    "docs/source/api/model/adapters.md",
    "docs/source/api/model/index.md",
    "docs/source/api/model/interfaces.md",
    "docs/source/api/model/interfaces_base.md",
    "docs/source/api/multimodal/index.md",
    "docs/source/api/multimodal/inputs.md",
    "docs/source/community/sponsors.md",
    "docs/source/conf.py",
    "docs/source/contributing/model/basic.md",
    "docs/source/contributing/model/index.md",
    "docs/source/contributing/model/multimodal.md",
    "docs/source/contributing/model/registration.md",
    "docs/source/contributing/model/tests.md",
    "docs/source/contributing/overview.md",
    "docs/source/contributing/profiling/profiling_index.md",
    "docs/source/deployment/docker.md",
    "docs/source/deployment/frameworks/bentoml.md",
    "docs/source/deployment/frameworks/cerebrium.md",
    "docs/source/deployment/frameworks/dstack.md",
    "docs/source/deployment/frameworks/index.md",
    "docs/source/deployment/frameworks/modal.md",
    "docs/source/deployment/frameworks/skypilot.md",
    "docs/source/deployment/integrations/llamastack.md",
    "docs/source/deployment/k8s.md",
    "docs/source/design/automatic_prefix_caching.md",
    "docs/source/design/input_processing/input_processing_pipeline.md",
    "docs/source/design/input_processing/model_inputs_index.md",
    "docs/source/design/mm_processing.md",
    "docs/source/features/compatibility_matrix.md",
    "docs/source/features/quantization/auto_awq.md",
    "docs/source/features/quantization/bnb.md",
    "docs/source/features/quantization/fp8.md",
    "docs/source/features/quantization/fp8_e4m3_kvcache.md",
    "docs/source/features/quantization/gguf.md",
    "docs/source/features/quantization/int8.md",
    "docs/source/features/quantization/supported_hardware.md",
    "docs/source/features/spec_decode.md",
    "docs/source/features/structured_outputs.md",
    "docs/source/features/tool_calling.md",
    "docs/source/getting_started/faq.md",
    "docs/source/getting_started/installation/ai_accelerator/hpu-gaudi.inc.md",
    "docs/source/getting_started/installation/ai_accelerator/index.md",
    "docs/source/getting_started/installation/ai_accelerator/neuron.inc.md",
    "docs/source/getting_started/installation/ai_accelerator/openvino.inc.md",
    "docs/source/getting_started/installation/ai_accelerator/tpu.inc.md",
    "docs/source/getting_started/installation/cpu-arm.md",
    "docs/source/getting_started/installation/cpu/apple.inc.md",
    "docs/source/getting_started/installation/cpu/arm.inc.md",
    "docs/source/getting_started/installation/cpu/build.inc.md",
    "docs/source/getting_started/installation/cpu/index.md",
    "docs/source/getting_started/installation/cpu/x86.inc.md",
    "docs/source/getting_started/installation/device.template.md",
    "docs/source/getting_started/installation/gpu-rocm.md",
    "docs/source/getting_started/installation/gpu/cuda.inc.md",
    "docs/source/getting_started/installation/gpu/index.md",
    "docs/source/getting_started/installation/gpu/rocm.inc.md",
    "docs/source/getting_started/installation/gpu/xpu.inc.md",
    "docs/source/getting_started/installation/index.md",
    "docs/source/getting_started/installation/python_env_setup.inc.md",
    "docs/source/getting_started/quickstart.md",
    "docs/source/getting_started/troubleshooting.md",
    "docs/source/index.md",
    "docs/source/models/extensions/runai_model_streamer.md",
    "docs/source/models/generative_models.md",
    "docs/source/models/pooling_models.md",
    "docs/source/models/supported_models.md",
    "docs/source/performance/optimization.md",
    "docs/source/serving/distributed_serving.md",
    "docs/source/serving/integrations/langchain.md",
    "docs/source/serving/integrations/llamaindex.md",
    "docs/source/serving/metrics.md",
    "docs/source/serving/multimodal_inputs.md",
    "docs/source/serving/offline_inference.md",
    "docs/source/serving/openai_compatible_server.md",
    "examples/offline_inference/arctic.py",
    "examples/offline_inference/audio_language.py",
    "examples/offline_inference/basic.py",
    "examples/offline_inference/basic_with_model_default_sampling.py",
    "examples/offline_inference/chat.py",
    "examples/offline_inference/chat_with_tools.py",
    "examples/offline_inference/classification.py",
    "examples/offline_inference/cli.py",
    "examples/offline_inference/distributed.py",
    "examples/offline_inference/embedding.py",
    "examples/offline_inference/encoder_decoder.py",
    "examples/offline_inference/florence2_inference.py",
    "examples/offline_inference/gguf_inference.py",
    "examples/offline_inference/mlpspeculator.py",
    "examples/offline_inference/neuron.py",
    "examples/offline_inference/neuron_int8_quantization.py",
    "examples/offline_inference/openai/openai_batch.md",
    "examples/offline_inference/openai/openai_example_batch.jsonl",
    "examples/offline_inference/pixtral.py",
    "examples/offline_inference/prefix_caching.py",
    "examples/offline_inference/profiling.py",
    "examples/offline_inference/rlhf.py",
    "examples/offline_inference/scoring.py",
    "examples/offline_inference/simple_profiling.py",
    "examples/offline_inference/structured_outputs.py",
    "examples/offline_inference/torchrun_example.py",
    "examples/offline_inference/tpu.py",
    "examples/offline_inference/vision_language.py",
    "examples/offline_inference/vision_language_embedding.py",
    "examples/offline_inference/vision_language_multi_image.py",
    "examples/offline_inference/whisper.py",
    "examples/online_serving/disaggregated_prefill.sh",
    "examples/online_serving/openai_chat_completion_client_for_multimodal.py",
    "examples/template_deepseek_vl2.jinja",
    "examples/template_pixtral_hf.jinja",
    "format.sh",
    "pyproject.toml",
    "requirements-lint.txt",
    "requirements-test.in",
    "requirements-test.txt",
    "setup.py",
    "tests/conftest.py",
    "tests/distributed/test_torchrun_example.py",
    "tests/engine/test_custom_executor.py",
    "tests/engine/test_multiproc_workers.py",
    "tests/entrypoints/llm/test_collective_rpc.py",
    "tests/entrypoints/llm/test_encode.py",
    "tests/entrypoints/openai/test_lora_adapters.py",
    "tests/entrypoints/openai/test_lora_lineage.py",
    "tests/entrypoints/openai/test_score.py",
    "tests/entrypoints/openai/test_serving_chat.py",
    "tests/entrypoints/openai/test_serving_models.py",
    "tests/entrypoints/openai/test_shutdown.py",
    "tests/entrypoints/test_chat_utils.py",
    "tests/kernels/test_activation.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_attention_selector.py",
    "tests/kernels/test_encoder_decoder_attn.py",
    "tests/kernels/test_moe.py",
    "tests/kv_transfer/test_send_recv.py",
    "tests/lora/conftest.py",
    "tests/lora/test_layers.py",
    "tests/lora/test_lora_checkpoints.py",
    "tests/lora/test_lora_huggingface.py",
    "tests/lora/test_lora_manager.py",
    "tests/lora/test_mixtral.py",
    "tests/lora/test_peft_helper.py",
    "tests/lora/test_punica_ops_sizes.py",
    "tests/lora/test_punica_ops_variation.py",
    "tests/lora/test_quant_model.py",
    "tests/lora/utils.py",
    "tests/model_executor/test_model_load_with_params.py",
    "tests/models/decoder_only/audio_language/test_ultravox.py",
    "tests/models/decoder_only/language/test_gguf.py",
    "tests/models/decoder_only/language/test_jamba.py",
    "tests/models/decoder_only/language/test_mamba.py",
    "tests/models/decoder_only/language/test_models.py",
    "tests/models/decoder_only/vision_language/test_models.py",
    "tests/models/decoder_only/vision_language/test_qwen2_vl.py",
    "tests/models/decoder_only/vision_language/vlm_utils/model_utils.py",
    "tests/models/embedding/language/test_cls_models.py",
    "tests/models/embedding/language/test_embedding.py",
    "tests/models/multimodal/__init__.py",
    "tests/models/multimodal/processing/__init__.py",
    "tests/models/multimodal/processing/test_common.py",
    "tests/models/multimodal/processing/test_idefics3.py",
    "tests/models/multimodal/processing/test_internvl.py",
    "tests/models/multimodal/processing/test_llava_next.py",
    "tests/models/multimodal/processing/test_llava_onevision.py",
    "tests/models/multimodal/processing/test_phi3v.py",
    "tests/models/multimodal/processing/test_qwen.py",
    "tests/models/multimodal/processing/test_qwen2_vl.py",
    "tests/models/registry.py",
    "tests/models/test_initialization.py",
    "tests/multi_step/test_correctness_async_llm.py",
    "tests/multi_step/test_correctness_llm.py",
    "tests/multimodal/test_processing.py",
    "tests/multimodal/utils.py",
    "tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_attention_backend.py",
    "tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_platform.py",
    "tests/plugins_tests/test_platform_plugins.py",
    "tests/quantization/test_compressed_tensors.py",
    "tests/quantization/test_fp8.py",
    "tests/quantization/test_lm_head.py",
    "tests/quantization/test_quark.py",
    "tests/quantization/test_register_quantization_config.py",
    "tests/spec_decode/e2e/test_integration_dist_tp4.py",
    "tests/tensorizer_loader/test_tensorizer.py",
    "tests/test_utils.py",
    "tests/utils.py",
    "tests/v1/core/test_prefix_caching.py",
    "tests/v1/engine/test_async_llm.py",
    "tests/v1/engine/test_engine_core.py",
    "tests/v1/engine/test_engine_core_client.py",
    "tests/v1/engine/test_output_processor.py",
    "tests/v1/test_utils.py",
    "tests/weight_loading/models.txt",
    "tests/weight_loading/test_weight_loading.py",
    "tools/actionlint.sh",
    "tools/profiler/print_layerwise_table.py",
    "tools/profiler/visualize_layerwise_profile.py",
    "tools/shellcheck.sh",
    "tools/sphinx-lint.sh",
    "vllm/__init__.py",
    "vllm/_custom_ops.py",
    "vllm/attention/backends/abstract.py",
    "vllm/attention/backends/blocksparse_attn.py",
    "vllm/attention/backends/flash_attn.py",
    "vllm/attention/backends/flashinfer.py",
    "vllm/attention/layer.py",
    "vllm/attention/selector.py",
    "vllm/compilation/backends.py",
    "vllm/compilation/decorators.py",
    "vllm/config.py",
    "vllm/connections.py",
    "vllm/distributed/device_communicators/pynccl.py",
    "vllm/distributed/kv_transfer/kv_connector/simple_connector.py",
    "vllm/distributed/parallel_state.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/async_llm_engine.py",
    "vllm/engine/llm_engine.py",
    "vllm/engine/multiprocessing/__init__.py",
    "vllm/engine/multiprocessing/client.py",
    "vllm/engine/multiprocessing/engine.py",
    "vllm/engine/output_processor/single_step.py",
    "vllm/engine/protocol.py",
    "vllm/entrypoints/chat_utils.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/api_server.py",
    "vllm/entrypoints/openai/cli_args.py",
    "vllm/entrypoints/openai/run_batch.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/entrypoints/openai/serving_models.py",
    "vllm/entrypoints/openai/serving_score.py",
    "vllm/envs.py",
    "vllm/executor/cpu_executor.py",
    "vllm/executor/distributed_gpu_executor.py",
    "vllm/executor/executor_base.py",
    "vllm/executor/gpu_executor.py",
    "vllm/executor/hpu_executor.py",
    "vllm/executor/mp_distributed_executor.py",
    "vllm/executor/multiproc_worker_utils.py",
    "vllm/executor/multiproc_xpu_executor.py",
    "vllm/executor/neuron_executor.py",
    "vllm/executor/openvino_executor.py",
    "vllm/executor/ray_distributed_executor.py",
    "vllm/executor/ray_hpu_executor.py",
    "vllm/executor/ray_tpu_executor.py",
    "vllm/executor/ray_utils.py",
    "vllm/executor/ray_xpu_executor.py",
    "vllm/executor/tpu_executor.py",
    "vllm/executor/uniproc_executor.py",
    "vllm/executor/xpu_executor.py",
    "vllm/forward_context.py",
    "vllm/inputs/__init__.py",
    "vllm/inputs/data.py",
    "vllm/inputs/preprocess.py",
    "vllm/inputs/registry.py",
    "vllm/lora/layers.py",
    "vllm/lora/models.py",
    "vllm/lora/ops/torch_ops/__init__.py",
    "vllm/lora/ops/torch_ops/lora_ops.py",
    "vllm/lora/ops/triton_ops/__init__.py",
    "vllm/lora/ops/triton_ops/bgmv_expand.py",
    "vllm/lora/ops/triton_ops/bgmv_expand_slice.py",
    "vllm/lora/ops/triton_ops/bgmv_shrink.py",
    "vllm/lora/ops/triton_ops/sgmv_expand.py",
    "vllm/lora/ops/triton_ops/sgmv_shrink.py",
    "vllm/lora/ops/triton_ops/utils.py",
    "vllm/lora/peft_helper.py",
    "vllm/lora/punica_wrapper/punica_cpu.py",
    "vllm/lora/punica_wrapper/punica_gpu.py",
    "vllm/lora/punica_wrapper/punica_selector.py",
    "vllm/lora/worker_manager.py",
    "vllm/model_executor/custom_op.py",
    "vllm/model_executor/guided_decoding/xgrammar_decoding.py",
    "vllm/model_executor/layers/activation.py",
    "vllm/model_executor/layers/fused_moe/fused_moe.py",
    "vllm/model_executor/layers/fused_moe/layer.py",
    "vllm/model_executor/layers/fused_moe/moe_torch_iterative.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/logits_processor.py",
    "vllm/model_executor/layers/quantization/__init__.py",
    "vllm/model_executor/layers/quantization/base_config.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/utils.py",
    "vllm/model_executor/layers/quantization/fp8.py",
    "vllm/model_executor/layers/quantization/quark/__init__.py",
    "vllm/model_executor/layers/quantization/quark/quark.py",
    "vllm/model_executor/layers/quantization/quark/quark_moe.py",
    "vllm/model_executor/layers/quantization/quark/schemes/__init__.py",
    "vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py",
    "vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py",
    "vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py",
    "vllm/model_executor/layers/quantization/quark/utils.py",
    "vllm/model_executor/layers/quantization/utils/fp8_utils.py",
    "vllm/model_executor/layers/rejection_sampler.py",
    "vllm/model_executor/layers/rotary_embedding.py",
    "vllm/model_executor/layers/vocab_parallel_embedding.py",
    "vllm/model_executor/model_loader/loader.py",
    "vllm/model_executor/model_loader/tensorizer.py",
    "vllm/model_executor/model_loader/utils.py",
    "vllm/model_executor/model_loader/weight_utils.py",
    "vllm/model_executor/models/aria.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/blip2.py",
    "vllm/model_executor/models/chameleon.py",
    "vllm/model_executor/models/chatglm.py",
    "vllm/model_executor/models/commandr.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/deepseek_v2.py",
    "vllm/model_executor/models/deepseek_v3.py",
    "vllm/model_executor/models/deepseek_vl2.py",
    "vllm/model_executor/models/eagle.py",
    "vllm/model_executor/models/exaone.py",
    "vllm/model_executor/models/fairseq2_llama.py",
    "vllm/model_executor/models/falcon.py",
    "vllm/model_executor/models/fuyu.py",
    "vllm/model_executor/models/gemma.py",
    "vllm/model_executor/models/gemma2.py",
    "vllm/model_executor/models/glm4_vision_encoder.py",
    "vllm/model_executor/models/gpt2.py",
    "vllm/model_executor/models/gpt_j.py",
    "vllm/model_executor/models/granite.py",
    "vllm/model_executor/models/idefics3.py",
    "vllm/model_executor/models/interfaces.py",
    "vllm/model_executor/models/interfaces_base.py",
    "vllm/model_executor/models/intern_vit.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/llava_onevision.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/minicpm3.py",
    "vllm/model_executor/models/minicpmv.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mllama.py",
    "vllm/model_executor/models/molmo.py",
    "vllm/model_executor/models/nemotron.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/phi.py",
    "vllm/model_executor/models/phi3.py",
    "vllm/model_executor/models/phi3_small.py",
    "vllm/model_executor/models/phi3v.py",
    "vllm/model_executor/models/phimoe.py",
    "vllm/model_executor/models/qwen.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_audio.py",
    "vllm/model_executor/models/qwen2_rm.py",
    "vllm/model_executor/models/qwen2_vl.py",
    "vllm/model_executor/models/registry.py",
    "vllm/model_executor/models/roberta.py",
    "vllm/model_executor/models/solar.py",
    "vllm/model_executor/models/stablelm.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/ultravox.py",
    "vllm/model_executor/parameter.py",
    "vllm/multimodal/__init__.py",
    "vllm/multimodal/base.py",
    "vllm/multimodal/inputs.py",
    "vllm/multimodal/processing.py",
    "vllm/multimodal/profiling.py",
    "vllm/multimodal/registry.py",
    "vllm/platforms/__init__.py",
    "vllm/platforms/cpu.py",
    "vllm/platforms/cuda.py",
    "vllm/platforms/hpu.py",
    "vllm/platforms/interface.py",
    "vllm/platforms/neuron.py",
    "vllm/platforms/openvino.py",
    "vllm/platforms/rocm.py",
    "vllm/platforms/tpu.py",
    "vllm/platforms/xpu.py",
    "vllm/plugins/__init__.py",
    "vllm/profiler/layerwise_profile.py",
    "vllm/spec_decode/medusa_worker.py",
    "vllm/spec_decode/multi_step_worker.py",
    "vllm/spec_decode/ngram_worker.py",
    "vllm/spec_decode/smaller_tp_proposer_worker.py",
    "vllm/spec_decode/spec_decode_worker.py",
    "vllm/transformers_utils/config.py",
    "vllm/transformers_utils/configs/__init__.py",
    "vllm/transformers_utils/configs/aria.py",
    "vllm/transformers_utils/configs/deepseek_vl2.py",
    "vllm/transformers_utils/processors/__init__.py",
    "vllm/transformers_utils/processors/deepseek_vl2.py",
    "vllm/transformers_utils/tokenizer.py",
    "vllm/transformers_utils/tokenizer_group/__init__.py",
    "vllm/transformers_utils/tokenizers/mistral.py",
    "vllm/usage/usage_lib.py",
    "vllm/utils.py",
    "vllm/v1/attention/backends/flash_attn.py",
    "vllm/v1/core/encoder_cache_manager.py",
    "vllm/v1/core/kv_cache_manager.py",
    "vllm/v1/core/kv_cache_utils.py",
    "vllm/v1/core/scheduler.py",
    "vllm/v1/engine/__init__.py",
    "vllm/v1/engine/async_llm.py",
    "vllm/v1/engine/core.py",
    "vllm/v1/engine/core_client.py",
    "vllm/v1/engine/detokenizer.py",
    "vllm/v1/engine/llm_engine.py",
    "vllm/v1/engine/output_processor.py",
    "vllm/v1/executor/abstract.py",
    "vllm/v1/executor/multiproc_executor.py",
    "vllm/v1/executor/ray_executor.py",
    "vllm/v1/executor/ray_utils.py",
    "vllm/v1/executor/uniproc_executor.py",
    "vllm/v1/kv_cache_interface.py",
    "vllm/v1/metrics/__init__.py",
    "vllm/v1/metrics/loggers.py",
    "vllm/v1/metrics/stats.py",
    "vllm/v1/utils.py",
    "vllm/v1/worker/gpu_input_batch.py",
    "vllm/v1/worker/gpu_model_runner.py",
    "vllm/v1/worker/gpu_worker.py",
    "vllm/worker/cpu_enc_dec_model_runner.py",
    "vllm/worker/cpu_model_runner.py",
    "vllm/worker/cpu_pooling_model_runner.py",
    "vllm/worker/cpu_worker.py",
    "vllm/worker/enc_dec_model_runner.py",
    "vllm/worker/hpu_model_runner.py",
    "vllm/worker/hpu_worker.py",
    "vllm/worker/model_runner.py",
    "vllm/worker/model_runner_base.py",
    "vllm/worker/multi_step_model_runner.py",
    "vllm/worker/neuron_model_runner.py",
    "vllm/worker/neuron_worker.py",
    "vllm/worker/openvino_model_runner.py",
    "vllm/worker/openvino_worker.py",
    "vllm/worker/pooling_model_runner.py",
    "vllm/worker/tpu_model_runner.py",
    "vllm/worker/tpu_worker.py",
    "vllm/worker/worker.py",
    "vllm/worker/worker_base.py",
    "vllm/worker/xpu_model_runner.py"
  ],
  "allowed": [
    "vllm/distributed/device_communicators/pynccl.py",
    "vllm/worker/multi_step_model_runner.py",
    "vllm/distributed/parallel_state.py",
    "vllm/utils.py"
  ],
  "disallowed": [
    ".buildkite/nightly-benchmarks/scripts/nightly-annotate.sh",
    ".buildkite/nightly-benchmarks/scripts/run-nightly-benchmarks.sh",
    ".buildkite/nightly-benchmarks/tests/genai-perf-tests.json",
    ".buildkite/run-cpu-test.sh",
    ".buildkite/run-gh200-test.sh",
    ".buildkite/run-hpu-test.sh",
    ".buildkite/run-neuron-test.sh",
    ".buildkite/run-openvino-test.sh",
    ".buildkite/run-tpu-test.sh",
    ".buildkite/run-xpu-test.sh",
    ".buildkite/test-pipeline.yaml",
    ".github/workflows/actionlint.yml",
    ".github/workflows/clang-format.yml",
    ".github/workflows/codespell.yml",
    ".github/workflows/matchers/ruff.json",
    ".github/workflows/mypy.yaml",
    ".github/workflows/png-lint.yml",
    ".github/workflows/pre-commit.yml",
    ".github/workflows/ruff.yml",
    ".github/workflows/shellcheck.yml",
    ".github/workflows/sphinx-lint.yml",
    ".github/workflows/yapf.yml",
    ".pre-commit-config.yaml",
    "Dockerfile.cpu",
    "Dockerfile.hpu",
    "Dockerfile.rocm",
    "README.md",
    "SECURITY.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_latency.py",
    "benchmarks/benchmark_long_document_qa_throughput.py",
    "benchmarks/benchmark_prefix_caching.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/kernels/benchmark_lora.py",
    "benchmarks/kernels/benchmark_moe.py",
    "benchmarks/kernels/utils.py",
    "cmake/utils.cmake",
    "csrc/activation_kernels.cu",
    "csrc/core/scalar_type.hpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/cpu_types_arm.hpp",
    "csrc/cpu/cpu_types_vsx.hpp",
    "csrc/cpu/cpu_types_x86.hpp",
    "csrc/cutlass_extensions/common.hpp",
    "csrc/ops.h",
    "csrc/prepare_inputs/advance_step.cu",
    "csrc/torch_bindings.cpp",
    "docs/README.md",
    "docs/requirements-docs.txt",
    "docs/source/api/inference_params.md",
    "docs/source/api/model/adapters.md",
    "docs/source/api/model/index.md",
    "docs/source/api/model/interfaces.md",
    "docs/source/api/model/interfaces_base.md",
    "docs/source/api/multimodal/index.md",
    "docs/source/api/multimodal/inputs.md",
    "docs/source/community/sponsors.md",
    "docs/source/conf.py",
    "docs/source/contributing/model/basic.md",
    "docs/source/contributing/model/index.md",
    "docs/source/contributing/model/multimodal.md",
    "docs/source/contributing/model/registration.md",
    "docs/source/contributing/model/tests.md",
    "docs/source/contributing/overview.md",
    "docs/source/contributing/profiling/profiling_index.md",
    "docs/source/deployment/docker.md",
    "docs/source/deployment/frameworks/bentoml.md",
    "docs/source/deployment/frameworks/cerebrium.md",
    "docs/source/deployment/frameworks/dstack.md",
    "docs/source/deployment/frameworks/index.md",
    "docs/source/deployment/frameworks/modal.md",
    "docs/source/deployment/frameworks/skypilot.md",
    "docs/source/deployment/integrations/llamastack.md",
    "docs/source/deployment/k8s.md",
    "docs/source/design/automatic_prefix_caching.md",
    "docs/source/design/input_processing/input_processing_pipeline.md",
    "docs/source/design/input_processing/model_inputs_index.md",
    "docs/source/design/mm_processing.md",
    "docs/source/features/compatibility_matrix.md",
    "docs/source/features/quantization/auto_awq.md",
    "docs/source/features/quantization/bnb.md",
    "docs/source/features/quantization/fp8.md",
    "docs/source/features/quantization/fp8_e4m3_kvcache.md",
    "docs/source/features/quantization/gguf.md",
    "docs/source/features/quantization/int8.md",
    "docs/source/features/quantization/supported_hardware.md",
    "docs/source/features/spec_decode.md",
    "docs/source/features/structured_outputs.md",
    "docs/source/features/tool_calling.md",
    "docs/source/getting_started/faq.md",
    "docs/source/getting_started/installation/ai_accelerator/hpu-gaudi.inc.md",
    "docs/source/getting_started/installation/ai_accelerator/index.md",
    "docs/source/getting_started/installation/ai_accelerator/neuron.inc.md",
    "docs/source/getting_started/installation/ai_accelerator/openvino.inc.md",
    "docs/source/getting_started/installation/ai_accelerator/tpu.inc.md",
    "docs/source/getting_started/installation/cpu-arm.md",
    "docs/source/getting_started/installation/cpu/apple.inc.md",
    "docs/source/getting_started/installation/cpu/arm.inc.md",
    "docs/source/getting_started/installation/cpu/build.inc.md",
    "docs/source/getting_started/installation/cpu/index.md",
    "docs/source/getting_started/installation/cpu/x86.inc.md",
    "docs/source/getting_started/installation/device.template.md",
    "docs/source/getting_started/installation/gpu-rocm.md",
    "docs/source/getting_started/installation/gpu/cuda.inc.md",
    "docs/source/getting_started/installation/gpu/index.md",
    "docs/source/getting_started/installation/gpu/rocm.inc.md",
    "docs/source/getting_started/installation/gpu/xpu.inc.md",
    "docs/source/getting_started/installation/index.md",
    "docs/source/getting_started/installation/python_env_setup.inc.md",
    "docs/source/getting_started/quickstart.md",
    "docs/source/getting_started/troubleshooting.md",
    "docs/source/index.md",
    "docs/source/models/extensions/runai_model_streamer.md",
    "docs/source/models/generative_models.md",
    "docs/source/models/pooling_models.md",
    "docs/source/models/supported_models.md",
    "docs/source/performance/optimization.md",
    "docs/source/serving/distributed_serving.md",
    "docs/source/serving/integrations/langchain.md",
    "docs/source/serving/integrations/llamaindex.md",
    "docs/source/serving/metrics.md",
    "docs/source/serving/multimodal_inputs.md",
    "docs/source/serving/offline_inference.md",
    "docs/source/serving/openai_compatible_server.md",
    "examples/offline_inference/arctic.py",
    "examples/offline_inference/audio_language.py",
    "examples/offline_inference/basic.py",
    "examples/offline_inference/basic_with_model_default_sampling.py",
    "examples/offline_inference/chat.py",
    "examples/offline_inference/chat_with_tools.py",
    "examples/offline_inference/classification.py",
    "examples/offline_inference/cli.py",
    "examples/offline_inference/distributed.py",
    "examples/offline_inference/embedding.py",
    "examples/offline_inference/encoder_decoder.py",
    "examples/offline_inference/florence2_inference.py",
    "examples/offline_inference/gguf_inference.py",
    "examples/offline_inference/mlpspeculator.py",
    "examples/offline_inference/neuron.py",
    "examples/offline_inference/neuron_int8_quantization.py",
    "examples/offline_inference/openai/openai_batch.md",
    "examples/offline_inference/openai/openai_example_batch.jsonl",
    "examples/offline_inference/pixtral.py",
    "examples/offline_inference/prefix_caching.py",
    "examples/offline_inference/profiling.py",
    "examples/offline_inference/rlhf.py",
    "examples/offline_inference/scoring.py",
    "examples/offline_inference/simple_profiling.py",
    "examples/offline_inference/structured_outputs.py",
    "examples/offline_inference/torchrun_example.py",
    "examples/offline_inference/tpu.py",
    "examples/offline_inference/vision_language.py",
    "examples/offline_inference/vision_language_embedding.py",
    "examples/offline_inference/vision_language_multi_image.py",
    "examples/offline_inference/whisper.py",
    "examples/online_serving/disaggregated_prefill.sh",
    "examples/online_serving/openai_chat_completion_client_for_multimodal.py",
    "examples/template_deepseek_vl2.jinja",
    "examples/template_pixtral_hf.jinja",
    "format.sh",
    "pyproject.toml",
    "requirements-lint.txt",
    "requirements-test.in",
    "requirements-test.txt",
    "setup.py",
    "tests/conftest.py",
    "tests/distributed/test_torchrun_example.py",
    "tests/engine/test_custom_executor.py",
    "tests/engine/test_multiproc_workers.py",
    "tests/entrypoints/llm/test_collective_rpc.py",
    "tests/entrypoints/llm/test_encode.py",
    "tests/entrypoints/openai/test_lora_adapters.py",
    "tests/entrypoints/openai/test_lora_lineage.py",
    "tests/entrypoints/openai/test_score.py",
    "tests/entrypoints/openai/test_serving_chat.py",
    "tests/entrypoints/openai/test_serving_models.py",
    "tests/entrypoints/openai/test_shutdown.py",
    "tests/entrypoints/test_chat_utils.py",
    "tests/kernels/test_activation.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_attention_selector.py",
    "tests/kernels/test_encoder_decoder_attn.py",
    "tests/kernels/test_moe.py",
    "tests/kv_transfer/test_send_recv.py",
    "tests/lora/conftest.py",
    "tests/lora/test_layers.py",
    "tests/lora/test_lora_checkpoints.py",
    "tests/lora/test_lora_huggingface.py",
    "tests/lora/test_lora_manager.py",
    "tests/lora/test_mixtral.py",
    "tests/lora/test_peft_helper.py",
    "tests/lora/test_punica_ops_sizes.py",
    "tests/lora/test_punica_ops_variation.py",
    "tests/lora/test_quant_model.py",
    "tests/lora/utils.py",
    "tests/model_executor/test_model_load_with_params.py",
    "tests/models/decoder_only/audio_language/test_ultravox.py",
    "tests/models/decoder_only/language/test_gguf.py",
    "tests/models/decoder_only/language/test_jamba.py",
    "tests/models/decoder_only/language/test_mamba.py",
    "tests/models/decoder_only/language/test_models.py",
    "tests/models/decoder_only/vision_language/test_models.py",
    "tests/models/decoder_only/vision_language/test_qwen2_vl.py",
    "tests/models/decoder_only/vision_language/vlm_utils/model_utils.py",
    "tests/models/embedding/language/test_cls_models.py",
    "tests/models/embedding/language/test_embedding.py",
    "tests/models/multimodal/__init__.py",
    "tests/models/multimodal/processing/__init__.py",
    "tests/models/multimodal/processing/test_common.py",
    "tests/models/multimodal/processing/test_idefics3.py",
    "tests/models/multimodal/processing/test_internvl.py",
    "tests/models/multimodal/processing/test_llava_next.py",
    "tests/models/multimodal/processing/test_llava_onevision.py",
    "tests/models/multimodal/processing/test_phi3v.py",
    "tests/models/multimodal/processing/test_qwen.py",
    "tests/models/multimodal/processing/test_qwen2_vl.py",
    "tests/models/registry.py",
    "tests/models/test_initialization.py",
    "tests/multi_step/test_correctness_async_llm.py",
    "tests/multi_step/test_correctness_llm.py",
    "tests/multimodal/test_processing.py",
    "tests/multimodal/utils.py",
    "tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_attention_backend.py",
    "tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_platform.py",
    "tests/plugins_tests/test_platform_plugins.py",
    "tests/quantization/test_compressed_tensors.py",
    "tests/quantization/test_fp8.py",
    "tests/quantization/test_lm_head.py",
    "tests/quantization/test_quark.py",
    "tests/quantization/test_register_quantization_config.py",
    "tests/spec_decode/e2e/test_integration_dist_tp4.py",
    "tests/tensorizer_loader/test_tensorizer.py",
    "tests/test_utils.py",
    "tests/utils.py",
    "tests/v1/core/test_prefix_caching.py",
    "tests/v1/engine/test_async_llm.py",
    "tests/v1/engine/test_engine_core.py",
    "tests/v1/engine/test_engine_core_client.py",
    "tests/v1/engine/test_output_processor.py",
    "tests/v1/test_utils.py",
    "tests/weight_loading/models.txt",
    "tests/weight_loading/test_weight_loading.py",
    "tools/actionlint.sh",
    "tools/profiler/print_layerwise_table.py",
    "tools/profiler/visualize_layerwise_profile.py",
    "tools/shellcheck.sh",
    "tools/sphinx-lint.sh",
    "vllm/__init__.py",
    "vllm/_custom_ops.py",
    "vllm/attention/backends/abstract.py",
    "vllm/attention/backends/blocksparse_attn.py",
    "vllm/attention/backends/flash_attn.py",
    "vllm/attention/backends/flashinfer.py",
    "vllm/attention/layer.py",
    "vllm/attention/selector.py",
    "vllm/compilation/backends.py",
    "vllm/compilation/decorators.py",
    "vllm/config.py",
    "vllm/connections.py",
    "vllm/distributed/kv_transfer/kv_connector/simple_connector.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/async_llm_engine.py",
    "vllm/engine/llm_engine.py",
    "vllm/engine/multiprocessing/__init__.py",
    "vllm/engine/multiprocessing/client.py",
    "vllm/engine/multiprocessing/engine.py",
    "vllm/engine/output_processor/single_step.py",
    "vllm/engine/protocol.py",
    "vllm/entrypoints/chat_utils.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/api_server.py",
    "vllm/entrypoints/openai/cli_args.py",
    "vllm/entrypoints/openai/run_batch.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/entrypoints/openai/serving_models.py",
    "vllm/entrypoints/openai/serving_score.py",
    "vllm/envs.py",
    "vllm/executor/cpu_executor.py",
    "vllm/executor/distributed_gpu_executor.py",
    "vllm/executor/executor_base.py",
    "vllm/executor/gpu_executor.py",
    "vllm/executor/hpu_executor.py",
    "vllm/executor/mp_distributed_executor.py",
    "vllm/executor/multiproc_worker_utils.py",
    "vllm/executor/multiproc_xpu_executor.py",
    "vllm/executor/neuron_executor.py",
    "vllm/executor/openvino_executor.py",
    "vllm/executor/ray_distributed_executor.py",
    "vllm/executor/ray_hpu_executor.py",
    "vllm/executor/ray_tpu_executor.py",
    "vllm/executor/ray_utils.py",
    "vllm/executor/ray_xpu_executor.py",
    "vllm/executor/tpu_executor.py",
    "vllm/executor/uniproc_executor.py",
    "vllm/executor/xpu_executor.py",
    "vllm/forward_context.py",
    "vllm/inputs/__init__.py",
    "vllm/inputs/data.py",
    "vllm/inputs/preprocess.py",
    "vllm/inputs/registry.py",
    "vllm/lora/layers.py",
    "vllm/lora/models.py",
    "vllm/lora/ops/torch_ops/__init__.py",
    "vllm/lora/ops/torch_ops/lora_ops.py",
    "vllm/lora/ops/triton_ops/__init__.py",
    "vllm/lora/ops/triton_ops/bgmv_expand.py",
    "vllm/lora/ops/triton_ops/bgmv_expand_slice.py",
    "vllm/lora/ops/triton_ops/bgmv_shrink.py",
    "vllm/lora/ops/triton_ops/sgmv_expand.py",
    "vllm/lora/ops/triton_ops/sgmv_shrink.py",
    "vllm/lora/ops/triton_ops/utils.py",
    "vllm/lora/peft_helper.py",
    "vllm/lora/punica_wrapper/punica_cpu.py",
    "vllm/lora/punica_wrapper/punica_gpu.py",
    "vllm/lora/punica_wrapper/punica_selector.py",
    "vllm/lora/worker_manager.py",
    "vllm/model_executor/custom_op.py",
    "vllm/model_executor/guided_decoding/xgrammar_decoding.py",
    "vllm/model_executor/layers/activation.py",
    "vllm/model_executor/layers/fused_moe/fused_moe.py",
    "vllm/model_executor/layers/fused_moe/layer.py",
    "vllm/model_executor/layers/fused_moe/moe_torch_iterative.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/logits_processor.py",
    "vllm/model_executor/layers/quantization/__init__.py",
    "vllm/model_executor/layers/quantization/base_config.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/utils.py",
    "vllm/model_executor/layers/quantization/fp8.py",
    "vllm/model_executor/layers/quantization/quark/__init__.py",
    "vllm/model_executor/layers/quantization/quark/quark.py",
    "vllm/model_executor/layers/quantization/quark/quark_moe.py",
    "vllm/model_executor/layers/quantization/quark/schemes/__init__.py",
    "vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py",
    "vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py",
    "vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py",
    "vllm/model_executor/layers/quantization/quark/utils.py",
    "vllm/model_executor/layers/quantization/utils/fp8_utils.py",
    "vllm/model_executor/layers/rejection_sampler.py",
    "vllm/model_executor/layers/rotary_embedding.py",
    "vllm/model_executor/layers/vocab_parallel_embedding.py",
    "vllm/model_executor/model_loader/loader.py",
    "vllm/model_executor/model_loader/tensorizer.py",
    "vllm/model_executor/model_loader/utils.py",
    "vllm/model_executor/model_loader/weight_utils.py",
    "vllm/model_executor/models/aria.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/blip2.py",
    "vllm/model_executor/models/chameleon.py",
    "vllm/model_executor/models/chatglm.py",
    "vllm/model_executor/models/commandr.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/deepseek_v2.py",
    "vllm/model_executor/models/deepseek_v3.py",
    "vllm/model_executor/models/deepseek_vl2.py",
    "vllm/model_executor/models/eagle.py",
    "vllm/model_executor/models/exaone.py",
    "vllm/model_executor/models/fairseq2_llama.py",
    "vllm/model_executor/models/falcon.py",
    "vllm/model_executor/models/fuyu.py",
    "vllm/model_executor/models/gemma.py",
    "vllm/model_executor/models/gemma2.py",
    "vllm/model_executor/models/glm4_vision_encoder.py",
    "vllm/model_executor/models/gpt2.py",
    "vllm/model_executor/models/gpt_j.py",
    "vllm/model_executor/models/granite.py",
    "vllm/model_executor/models/idefics3.py",
    "vllm/model_executor/models/interfaces.py",
    "vllm/model_executor/models/interfaces_base.py",
    "vllm/model_executor/models/intern_vit.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/llava_onevision.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/minicpm3.py",
    "vllm/model_executor/models/minicpmv.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mllama.py",
    "vllm/model_executor/models/molmo.py",
    "vllm/model_executor/models/nemotron.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/phi.py",
    "vllm/model_executor/models/phi3.py",
    "vllm/model_executor/models/phi3_small.py",
    "vllm/model_executor/models/phi3v.py",
    "vllm/model_executor/models/phimoe.py",
    "vllm/model_executor/models/qwen.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_audio.py",
    "vllm/model_executor/models/qwen2_rm.py",
    "vllm/model_executor/models/qwen2_vl.py",
    "vllm/model_executor/models/registry.py",
    "vllm/model_executor/models/roberta.py",
    "vllm/model_executor/models/solar.py",
    "vllm/model_executor/models/stablelm.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/ultravox.py",
    "vllm/model_executor/parameter.py",
    "vllm/multimodal/__init__.py",
    "vllm/multimodal/base.py",
    "vllm/multimodal/inputs.py",
    "vllm/multimodal/processing.py",
    "vllm/multimodal/profiling.py",
    "vllm/multimodal/registry.py",
    "vllm/platforms/__init__.py",
    "vllm/platforms/cpu.py",
    "vllm/platforms/cuda.py",
    "vllm/platforms/hpu.py",
    "vllm/platforms/interface.py",
    "vllm/platforms/neuron.py",
    "vllm/platforms/openvino.py",
    "vllm/platforms/rocm.py",
    "vllm/platforms/tpu.py",
    "vllm/platforms/xpu.py",
    "vllm/plugins/__init__.py",
    "vllm/profiler/layerwise_profile.py",
    "vllm/spec_decode/medusa_worker.py",
    "vllm/spec_decode/multi_step_worker.py",
    "vllm/spec_decode/ngram_worker.py",
    "vllm/spec_decode/smaller_tp_proposer_worker.py",
    "vllm/spec_decode/spec_decode_worker.py",
    "vllm/transformers_utils/config.py",
    "vllm/transformers_utils/configs/__init__.py",
    "vllm/transformers_utils/configs/aria.py",
    "vllm/transformers_utils/configs/deepseek_vl2.py",
    "vllm/transformers_utils/processors/__init__.py",
    "vllm/transformers_utils/processors/deepseek_vl2.py",
    "vllm/transformers_utils/tokenizer.py",
    "vllm/transformers_utils/tokenizer_group/__init__.py",
    "vllm/transformers_utils/tokenizers/mistral.py",
    "vllm/usage/usage_lib.py",
    "vllm/v1/attention/backends/flash_attn.py",
    "vllm/v1/core/encoder_cache_manager.py",
    "vllm/v1/core/kv_cache_manager.py",
    "vllm/v1/core/kv_cache_utils.py",
    "vllm/v1/core/scheduler.py",
    "vllm/v1/engine/__init__.py",
    "vllm/v1/engine/async_llm.py",
    "vllm/v1/engine/core.py",
    "vllm/v1/engine/core_client.py",
    "vllm/v1/engine/detokenizer.py",
    "vllm/v1/engine/llm_engine.py",
    "vllm/v1/engine/output_processor.py",
    "vllm/v1/executor/abstract.py",
    "vllm/v1/executor/multiproc_executor.py",
    "vllm/v1/executor/ray_executor.py",
    "vllm/v1/executor/ray_utils.py",
    "vllm/v1/executor/uniproc_executor.py",
    "vllm/v1/kv_cache_interface.py",
    "vllm/v1/metrics/__init__.py",
    "vllm/v1/metrics/loggers.py",
    "vllm/v1/metrics/stats.py",
    "vllm/v1/utils.py",
    "vllm/v1/worker/gpu_input_batch.py",
    "vllm/v1/worker/gpu_model_runner.py",
    "vllm/v1/worker/gpu_worker.py",
    "vllm/worker/cpu_enc_dec_model_runner.py",
    "vllm/worker/cpu_model_runner.py",
    "vllm/worker/cpu_pooling_model_runner.py",
    "vllm/worker/cpu_worker.py",
    "vllm/worker/enc_dec_model_runner.py",
    "vllm/worker/hpu_model_runner.py",
    "vllm/worker/hpu_worker.py",
    "vllm/worker/model_runner.py",
    "vllm/worker/model_runner_base.py",
    "vllm/worker/neuron_model_runner.py",
    "vllm/worker/neuron_worker.py",
    "vllm/worker/openvino_model_runner.py",
    "vllm/worker/openvino_worker.py",
    "vllm/worker/pooling_model_runner.py",
    "vllm/worker/tpu_model_runner.py",
    "vllm/worker/tpu_worker.py",
    "vllm/worker/worker.py",
    "vllm/worker/worker_base.py",
    "vllm/worker/xpu_model_runner.py"
  ],
  "ok": false
}