diff --git a/model_patch.diff b/model_patch.diff
new file mode 100644
index 000000000..e69de29bb
diff --git a/vllm/core/block_manager_v1.py b/vllm/core/block_manager_v1.py
index b2aaeb33c..5f5396dae 100644
--- a/vllm/core/block_manager_v1.py
+++ b/vllm/core/block_manager_v1.py
@@ -313,7 +313,8 @@ class BlockSpaceManagerV1(BlockSpaceManager):
 
         # Compute a new hash for the block so that it can be shared by other
         # Sequences
-        new_hash = seq.hash_of_block(len(seq.logical_token_blocks) - 1)
+        last_logical_idx = len(seq.logical_token_blocks) - 1
+        new_hash = seq.hash_of_block(last_logical_idx)
 
         # if new_hash is already in the cached table, then free last_block
         # and return the cached version
@@ -328,7 +329,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):
         self,
         seq: Sequence,
     ) -> bool:
-        token_ids_len = len(seq.data.get_token_ids())
+        token_ids_len = seq.data.get_len()
         return token_ids_len > 0 and token_ids_len % seq.block_size == 0
 
     def _maybe_promote_last_block(
@@ -353,10 +354,10 @@ class BlockSpaceManagerV1(BlockSpaceManager):
         if not self.enable_caching:
             return self.gpu_allocator.allocate()
         block_hash: Optional[int] = None
+        last_logical_idx = len(seq.logical_token_blocks) - 1
         if (self._is_last_block_full(seq)):
-            block_hash = seq.hash_of_block(len(seq.logical_token_blocks) - 1)
-        num_hashed_tokens = seq.num_hashed_tokens_of_block(
-            len(seq.logical_token_blocks) - 1)
+            block_hash = seq.hash_of_block(last_logical_idx)
+        num_hashed_tokens = seq.num_hashed_tokens_of_block(last_logical_idx)
 
         # num_hashed_tokens is used to compute future hashes
         # (e.g. in the hashing function, it is used to ask the sequence for
@@ -377,16 +378,16 @@ class BlockSpaceManagerV1(BlockSpaceManager):
         """Allocate a physical slot for a new token."""
         logical_blocks = seq.logical_token_blocks
         block_table = self.block_tables[seq.seq_id]
+        lt = len(block_table)
+        ll = len(logical_blocks)
         # If we need to allocate a new physical block
-        if len(block_table) < len(logical_blocks):
+        if lt < ll:
             # Currently this code only supports adding one physical block
-            assert len(block_table) == len(logical_blocks) - 1
+            assert lt == ll - 1
 
-            if (self.block_sliding_window
-                    and len(block_table) >= self.block_sliding_window):
+            if self.block_sliding_window and lt >= self.block_sliding_window:
                 # reuse a block
-                block_table.append(block_table[len(block_table) %
-                                               self.block_sliding_window])
+                block_table.append(block_table[lt % self.block_sliding_window])
             else:
                 # The sequence has a new logical block.
                 # Allocate a new physical block.
@@ -567,11 +568,11 @@ class BlockSpaceManagerV1(BlockSpaceManager):
     def compute_full_blocks_in_seq(self, seq: Sequence):
         if seq.seq_id not in self.block_tables:
             return
-        max_full_block = seq.get_len() // self.block_size - 1
+        max_full_block = seq.data.get_len() // self.block_size - 1
         block_table = self.block_tables[seq.seq_id]
         if max_full_block == -1:
             return
-        for i in reversed(range(max_full_block)):
+        for i in reversed(range(max_full_block + 1)):
             if block_table[i].computed:
                 break
             block_table[i].computed = True
@@ -583,10 +584,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):
         # NOTE We exclude the last block to avoid the case where the entire
         # prompt is cached. This would cause erroneous behavior in model
         # runner.
-        return [
-            b.block_number
-            for b in takewhile(lambda b: b.computed, block_table[:-1])
-        ]
+        return [b.block_number for b in takewhile(lambda b: b.computed, block_table[:-1])]
 
     def get_common_computed_block_ids(self, seqs: List[Sequence]) -> List[int]:
         """Return the block ids that are common for a given sequence group.
@@ -598,7 +596,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):
             return []
 
         ids_list = [self.get_all_computed_blocks(seq) for seq in seqs]
-        return commonprefix([ids for ids in ids_list if ids != []])
+        return commonprefix([ids for ids in ids_list if ids])
 
     def mark_blocks_as_computed(self, seq_group: SequenceGroup):
         if self.enable_caching:
