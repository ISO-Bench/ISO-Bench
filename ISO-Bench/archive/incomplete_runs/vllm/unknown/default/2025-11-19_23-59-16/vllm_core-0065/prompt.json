{
  "task": "vLLM core performance",
  "description": "Run vLLM performance checks with Dockerfile-based env",
  "constraints": [
    "No public API breakage",
    "All TestPack checks must pass"
  ],
  "target_files": [
    "vllm/model_executor/models/llama.py"
  ],
  "success": {
    "primary_metric": "functional_match",
    "rules": [
      "Do not modify tests or metrics harness",
      "Preserve external behavior; optimize internals only"
    ]
  },
  "commits": {
    "pre": "4a18fd14ba4a349291c798a16bf62fa8a9af0b6b",
    "human": "b2e0ad3b598ed0e022cdbd678a20821d411873c2"
  }
}