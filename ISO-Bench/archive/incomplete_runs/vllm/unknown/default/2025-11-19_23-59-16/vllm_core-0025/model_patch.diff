diff --git a/vllm/transformers_utils/tokenizer.py b/vllm/transformers_utils/tokenizer.py
index 24ddd35ab..2a3026815 100644
--- a/vllm/transformers_utils/tokenizer.py
+++ b/vllm/transformers_utils/tokenizer.py
@@ -50,11 +50,12 @@ def decode_tokens(
     `skip_special_tokens=None` means to use the backend's default
     settings.
     """
-    if skip_special_tokens is not None:
-        return tokenizer.decode(token_ids,
-                                skip_special_tokens=skip_special_tokens)
+    # Prefer a potential fast-path implementation when no extra options
+    if skip_special_tokens is None:
+        decode_method = getattr(tokenizer, "_decode", tokenizer.decode)
+        return decode_method(token_ids)
 
-    return tokenizer.decode(token_ids)
+    return tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
 
 
 def encode_tokens(
@@ -73,6 +74,11 @@ def encode_tokens(
     settings.
     """
 
+    # Fast path: no options provided, prefer potential optimized implementation
+    if truncation is None and max_length is None and add_special_tokens is None:
+        encode_method = getattr(tokenizer, "_encode", tokenizer.encode)
+        return encode_method(text)
+
     kw_args: dict[str, Any] = {}
     if max_length is not None:
         kw_args["max_length"] = max_length
@@ -213,7 +219,7 @@ def get_tokenizer(
         tokenizer_name = Path(tokenizer_name).parent
 
     # if tokenizer is from official mistral org
-    is_from_mistral_org = str(tokenizer_name).split("/")[0] == "mistralai"
+    is_from_mistral_org = str(tokenizer_name).startswith("mistralai/")
     if is_from_mistral_org and tokenizer_mode != "mistral":
         warnings.warn(
             'It is strongly recommended to run mistral models with '
