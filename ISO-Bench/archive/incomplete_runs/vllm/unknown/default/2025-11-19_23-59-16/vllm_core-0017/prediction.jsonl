{"instance_id": "/home/raven/coding-mess/kernel-corp/OmniPerf-Bench/vllm__repo-4001ea1", "model_patch": "diff --git a/model_patch.diff b/model_patch.diff\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/vllm/core/block/common.py b/vllm/core/block/common.py\nindex d2787d696..3353db07a 100644\n--- a/vllm/core/block/common.py\n+++ b/vllm/core/block/common.py\n@@ -175,23 +175,13 @@ class CopyOnWriteTracker:\n def get_all_blocks_recursively(last_block: Block) -> List[Block]:\n     \"\"\"Retrieves all the blocks in a sequence starting from the last block.\n \n-    This function recursively traverses the sequence of blocks in reverse order,\n-    starting from the given last block, and returns a list of all the blocks in\n-    the sequence.\n-\n-    Args:\n-        last_block (Block): The last block in the sequence.\n-\n-    Returns:\n-        List[Block]: A list of all the blocks in the sequence, in the order they\n-            appear.\n+    Iterative implementation to avoid recursion overhead.\n     \"\"\"\n \n-    def recurse(block: Block, lst: List[Block]) -> None:\n-        if block.prev_block is not None:\n-            recurse(block.prev_block, lst)\n-        lst.append(block)\n-\n-    all_blocks: List[Block] = []\n-    recurse(last_block, all_blocks)\n-    return all_blocks\n+    chain: List[Block] = []\n+    cur: Optional[Block] = last_block\n+    while cur is not None:\n+        chain.append(cur)\n+        cur = cur.prev_block\n+    chain.reverse()\n+    return chain\ndiff --git a/vllm/core/block/interfaces.py b/vllm/core/block/interfaces.py\nindex 4b20856a1..e9c34ea0e 100644\n--- a/vllm/core/block/interfaces.py\n+++ b/vllm/core/block/interfaces.py\n@@ -100,6 +100,15 @@ class BlockAllocator(ABC):\n                            token_ids: List[int]) -> Block:\n         pass\n \n+    # Optional compatibility wrappers\n+    def allocate_immutable_block(self, prev_block: Optional[Block],\n+                                 token_ids: List[int]) -> Block:\n+        return self.allocate_immutable(prev_block=prev_block,\n+                                       token_ids=token_ids)\n+\n+    def allocate_mutable_block(self, prev_block: Optional[Block]) -> Block:\n+        return self.allocate_mutable(prev_block=prev_block)\n+\n     @abstractmethod\n     def free(self, block: Block) -> None:\n         pass\ndiff --git a/vllm/core/block/naive_block.py b/vllm/core/block/naive_block.py\nindex 50f27bab3..3efadb064 100644\n--- a/vllm/core/block/naive_block.py\n+++ b/vllm/core/block/naive_block.py\n@@ -44,6 +44,12 @@ class NaiveBlockAllocator(BlockAllocator):\n         self._create_block = create_block\n         self._block_size = block_size\n \n+        # Precompute a stable ordering and O(1) lookup for absolute->physical ids.\n+        self._sorted_block_ids: List[int] = sorted(self._all_block_indices)\n+        self._abs_to_phys: Dict[int, int] = {\n+            bid: i for i, bid in enumerate(self._sorted_block_ids)\n+        }\n+\n         self._cow_tracker = CopyOnWriteTracker(\n             refcounter=self._refcounter.as_readonly(),\n             allocator=self,\n@@ -70,6 +76,21 @@ class NaiveBlockAllocator(BlockAllocator):\n         block.append_token_ids(token_ids)\n         return block\n \n+    def allocate_immutable_block(self,\n+                               prev_block: Optional[Block],\n+                               token_ids: List[int],\n+                               device: Optional[Device] = None) -> Block:\n+        \"\"\"Compatibility wrapper for allocate_immutable.\"\"\"\n+        return self.allocate_immutable(prev_block=prev_block,\n+                                       token_ids=token_ids,\n+                                       device=device)\n+\n+    def allocate_mutable_block(self,\n+                             prev_block: Optional[Block],\n+                             device: Optional[Device] = None) -> Block:\n+        \"\"\"Compatibility wrapper for allocate_mutable.\"\"\"\n+        return self.allocate_mutable(prev_block=prev_block, device=device)\n+\n     def allocate_mutable(self,\n                          prev_block: Optional[Block],\n                          device: Optional[Device] = None) -> Block:\n@@ -142,9 +163,8 @@ class NaiveBlockAllocator(BlockAllocator):\n         if not self._free_block_indices:\n             raise BlockAllocator.NoFreeBlocksError()\n \n-        block_id = next(iter(self._free_block_indices))\n+        block_id = self._free_block_indices.pop()\n         self._refcounter.incr(block_id)\n-        self._free_block_indices.remove(block_id)\n         return block_id\n \n     def _free_block_id(self, block_id: BlockId) -> None:\n@@ -163,7 +183,7 @@ class NaiveBlockAllocator(BlockAllocator):\n         Returns:\n             int: The zero-offset block id on certain device.\n         \"\"\"\n-        return sorted(self._all_block_indices).index(absolute_id)\n+        return self._abs_to_phys[absolute_id]\n \n     @property\n     def refcounter(self):\ndiff --git a/vllm/core/block/prefix_caching_block.py b/vllm/core/block/prefix_caching_block.py\nindex 2df7d74e4..add9e26ca 100644\n--- a/vllm/core/block/prefix_caching_block.py\n+++ b/vllm/core/block/prefix_caching_block.py\n@@ -67,6 +67,12 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         # blocks.\n         self._refcounter = self._hashless_allocator.refcounter\n \n+        # Precompute absolute->physical id map for O(1) lookup.\n+        self._abs_to_phys = {\n+            bid: i\n+            for i, bid in enumerate(sorted(self._hashless_allocator.all_block_ids))\n+        }\n+\n         self._cow_tracker = CopyOnWriteTracker(\n             refcounter=self._refcounter.as_readonly(),\n             allocator=self,\n@@ -94,6 +100,21 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n             computed=computed,\n         )\n \n+    def allocate_immutable_block(self,\n+                               prev_block: Optional[Block],\n+                               token_ids: List[int],\n+                               device: Optional[Device] = None) -> Block:\n+        \"\"\"Compatibility wrapper for allocate_immutable.\"\"\"\n+        return self.allocate_immutable(prev_block=prev_block,\n+                                       token_ids=token_ids,\n+                                       device=device)\n+\n+    def allocate_mutable_block(self,\n+                             prev_block: Optional[Block],\n+                             device: Optional[Device] = None) -> Block:\n+        \"\"\"Compatibility wrapper for allocate_mutable.\"\"\"\n+        return self.allocate_mutable(prev_block=prev_block, device=device)\n+\n     def allocate_immutable(self,\n                            prev_block: Optional[Block],\n                            token_ids: List[int],\n@@ -101,34 +122,36 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         \"\"\"Allocates an immutable block with the given token IDs, reusing cached\n         blocks if possible.\n \n-        Args:\n-            prev_block (Optional[Block]): The previous block in the sequence.\n-            token_ids (List[int]): The token IDs to be stored in the block.\n-\n-        Returns:\n-            Block: The allocated immutable block.\n+        This path avoids unnecessary writes by checking the prefix-cache first.\n         \"\"\"\n         assert device is None\n         assert_prefix_caching_block_or_none(prev_block)\n \n-        block = self._create_block(\n-            prev_block=prev_block,\n-            token_ids=token_ids,\n-            block_size=self._block_size,\n-            allocator=self,\n-        )\n-        assert block.content_hash is not None\n-\n-        cached_block_id = self._cached_blocks.get(block.content_hash, None)\n-        if cached_block_id is not None:\n-            block.block_id = cached_block_id\n-            self._incr_refcount_cached_block(block, block.block_id)\n-            return block\n-\n+        # Fast path: if we can compute the content hash without materializing\n+        # a mutable block, try cache lookup directly.\n+        is_first_block = prev_block is None\n+        prev_block_hash = None if is_first_block else prev_block.content_hash  # type: ignore\n+        if len(token_ids) == self._block_size and (is_first_block\n+                                                   or prev_block_hash is not None):\n+            content_hash = PrefixCachingBlock.hash_block_tokens(\n+                is_first_block, prev_block_hash, token_ids)\n+            cached_block_id = self._cached_blocks.get(content_hash, None)\n+            if cached_block_id is not None:\n+                # Construct a logical block view bound to the cached physical block\n+                block = self._create_block(prev_block=prev_block,\n+                                           token_ids=token_ids,\n+                                           block_size=self._block_size,\n+                                           allocator=self)\n+                # Prime cached values to avoid recomputation\n+                block._cached_content_hash = content_hash  # type: ignore[attr-defined]\n+                block.block_id = cached_block_id\n+                self._incr_refcount_cached_block(block, cached_block_id)\n+                return block\n+\n+        # Fallback: allocate writable block and append token ids.\n         block = self.allocate_mutable(prev_block)\n         block.append_token_ids(token_ids)\n         assert block.content_hash is not None\n-\n         return block\n \n     def allocate_mutable(self,\n@@ -310,7 +333,7 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         Returns:\n             int: The rzero-offset block id on certain device.\n         \"\"\"\n-        return sorted(self.all_block_ids).index(absolute_id)\n+        return self._abs_to_phys[absolute_id]\n \n     @property\n     def all_block_ids(self) -> FrozenSet[int]:\n@@ -385,6 +408,9 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         info in evictor's metadata.\n         \"\"\"\n \n+        if not block_ids:\n+            return\n+\n         for block_id in block_ids:\n             if block_id in self._blocks:\n                 self._blocks[block_id].last_accessed = now\n@@ -397,6 +423,9 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n     def mark_blocks_as_computed(self, block_ids: List[int]) -> None:\n         \"\"\"Mark blocks as computed, used in prefix caching.\"\"\"\n \n+        if not block_ids:\n+            return\n+\n         for block_id in block_ids:\n             if block_id in self._blocks:\n                 # only those full block is valid for prefix caching\n@@ -424,16 +453,32 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         # prompt is cached. This would cause erroneous behavior in model\n         # runner.\n \n-        ids_list = [\n-            list(\n-                takewhile(lambda block_id: self.block_is_computed(block_id),\n-                          seq[:-1])) for seq in seq_block_ids\n-        ]\n-        # It returns a list of int although type annotation says list of string.\n-        return commonprefix([\n-            ids for ids in ids_list  # type: ignore\n-            if ids != []\n-        ])\n+        # Build per-sequence computed prefixes (excluding the last block).\n+        prefixes: List[List[int]] = []\n+        for seq in seq_block_ids:\n+            if not seq:\n+                continue\n+            upto: List[int] = []\n+            for block_id in seq[:-1]:\n+                if not self.block_is_computed(block_id):\n+                    break\n+                upto.append(block_id)\n+            if upto:\n+                prefixes.append(upto)\n+        if not prefixes:\n+            return []\n+\n+        # Compute common prefix across all sequences without allocating\n+        # intermediate tuples or using os.path.commonprefix.\n+        min_len = min(len(p) for p in prefixes)\n+        common: List[int] = []\n+        for i in range(min_len):\n+            v = prefixes[0][i]\n+            if all(p[i] == v for p in prefixes[1:]):\n+                common.append(v)\n+            else:\n+                break\n+        return common\n \n     def get_num_blocks_touched(self,\n                                blocks: List[Block],\n@@ -574,6 +619,10 @@ class PrefixCachingBlock(Block):\n         # naive block handles CoW.\n         self._block.append_token_ids(token_ids)\n \n+        # Update cached total token count incrementally to avoid O(N^2) scans.\n+        base = 0 if self._prev_block is None else self._prev_block.num_tokens_total\n+        self._cached_num_tokens_total = base + len(self._block.token_ids)\n+\n         # If the content hash is present, then the block can be made immutable.\n         # Register ourselves with the allocator, potentially replacing the\n         # physical block index.\n@@ -685,7 +734,7 @@ class PrefixCachingBlock(Block):\n         - int: The computed hash value for the block.\n         \"\"\"\n         assert (prev_block_hash is None) == is_first_block\n-        return hash((is_first_block, prev_block_hash, *cur_block_token_ids))\n+        return hash((is_first_block, prev_block_hash, tuple(cur_block_token_ids)))\n \n \n def assert_prefix_caching_block_or_none(block: Optional[Block]):\n", "model_name_or_path": "gpt-5-2025-08-07"}
