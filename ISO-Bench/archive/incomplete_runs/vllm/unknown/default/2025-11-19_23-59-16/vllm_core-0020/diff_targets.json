{
  "changed": [
    ".buildkite/check-wheel-size.py",
    ".buildkite/run-amd-test.sh",
    ".buildkite/run-benchmarks.sh",
    ".buildkite/run-cpu-test.sh",
    ".buildkite/run-neuron-test.sh",
    ".buildkite/test-pipeline.yaml",
    ".buildkite/test-template.j2",
    ".github/ISSUE_TEMPLATE/200-installation.yml",
    ".github/ISSUE_TEMPLATE/300-usage.yml",
    ".github/ISSUE_TEMPLATE/400-bug report.yml",
    ".github/ISSUE_TEMPLATE/700-performance discussion.yml",
    ".github/ISSUE_TEMPLATE/750-RFC.yml",
    ".github/workflows/mypy.yaml",
    ".github/workflows/publish.yml",
    ".github/workflows/ruff.yml",
    ".github/workflows/scripts/build.sh",
    ".github/workflows/scripts/create_release.js",
    ".github/workflows/yapf.yml",
    ".gitignore",
    "CMakeLists.txt",
    "CONTRIBUTING.md",
    "Dockerfile",
    "Dockerfile.cpu",
    "Dockerfile.neuron",
    "Dockerfile.rocm",
    "MANIFEST.in",
    "README.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_latency.py",
    "benchmarks/benchmark_prefix_caching.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/benchmark_throughput.py",
    "benchmarks/kernels/benchmark_aqlm.py",
    "benchmarks/kernels/benchmark_mixtral_moe.py",
    "benchmarks/kernels/benchmark_paged_attention.py",
    "benchmarks/sonnet.txt",
    "cmake/cpu_extension.cmake",
    "cmake/utils.cmake",
    "collect_env.py",
    "csrc/attention/attention_dtypes.h",
    "csrc/attention/attention_kernels.cu",
    "csrc/attention/dtype_fp8_e5m2.cuh",
    "csrc/cache.h",
    "csrc/cache_kernels.cu",
    "csrc/cpu/activation.cpp",
    "csrc/cpu/attention.cpp",
    "csrc/cpu/cache.cpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/layernorm.cpp",
    "csrc/cpu/pos_encoding.cpp",
    "csrc/cpu/pybind.cpp",
    "csrc/cuda_compat.h",
    "csrc/layernorm_kernels.cu",
    "csrc/ops.h",
    "csrc/punica/bgmv/bgmv_bf16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_config.h",
    "csrc/punica/bgmv/bgmv_fp16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_impl.cuh",
    "csrc/punica/bgmv/generator.py",
    "csrc/punica/bgmv/vec_dtypes.cuh",
    "csrc/punica/punica_ops.cc",
    "csrc/punica/punica_ops.h",
    "csrc/punica/punica_pybind.cpp",
    "csrc/punica/type_convert.h",
    "csrc/pybind.cpp",
    "csrc/quantization/aqlm/gemm_kernels.cu",
    "csrc/quantization/fp8/amd_detail/hip_float8.h",
    "csrc/quantization/fp8/amd_detail/hip_float8_impl.h",
    "csrc/quantization/fp8/amd_detail/quant_utils.cuh",
    "csrc/quantization/fp8/fp8_cuda_kernels.cu",
    "csrc/quantization/gptq/q_gemm.cu",
    "csrc/quantization/gptq_marlin/gptq_marlin.cu",
    "csrc/quantization/gptq_marlin/gptq_marlin.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin_repack.cu",
    "csrc/quantization/marlin/marlin_cuda_kernel.cu",
    "csrc/reduction_utils.cuh",
    "docs/requirements-docs.txt",
    "docs/source/assets/dev/dockerfile-stages-dependency.png",
    "docs/source/conf.py",
    "docs/source/dev/dockerfile/dockerfile.rst",
    "docs/source/dev/engine/async_llm_engine.rst",
    "docs/source/dev/engine/llm_engine.rst",
    "docs/source/dev/sampling_params.rst",
    "docs/source/generate_examples.py",
    "docs/source/getting_started/amd-installation.rst",
    "docs/source/getting_started/cpu-installation.rst",
    "docs/source/getting_started/examples/examples_index.template.rst",
    "docs/source/getting_started/installation.rst",
    "docs/source/index.rst",
    "docs/source/models/adding_model.rst",
    "docs/source/models/engine_args.rst",
    "docs/source/models/performance.rst",
    "docs/source/models/supported_models.rst",
    "docs/source/quantization/fp8_e4m3_kvcache.rst",
    "docs/source/quantization/fp8_e5m2_kv_cache.rst",
    "docs/source/serving/deploying_with_docker.rst",
    "docs/source/serving/env_vars.rst",
    "docs/source/serving/openai_compatible_server.md",
    "docs/source/serving/run_on_sky.rst",
    "docs/source/serving/usage_stats.md",
    "examples/aqlm_example.py",
    "examples/fp8/README.md",
    "examples/fp8/extract_scales.py",
    "examples/fp8/quantizer/README.md",
    "examples/fp8/quantizer/quantize.py",
    "examples/llava_example.py",
    "examples/logging_configuration.md",
    "examples/offline_inference_arctic.py",
    "examples/offline_inference_with_prefix.py",
    "examples/openai_chatcompletion_client.py",
    "examples/production_monitoring/grafana.json",
    "examples/tensorize_vllm_model.py",
    "format.sh",
    "model_patch.diff",
    "patch_xformers.rocm.sh",
    "pyproject.toml",
    "requirements-build.txt",
    "requirements-common.txt",
    "requirements-cpu.txt",
    "requirements-cuda.txt",
    "requirements-dev.txt",
    "requirements-neuron.txt",
    "requirements-rocm.txt",
    "requirements.txt",
    "rocm_patch/commonpy_xformers-0.0.23.rocm.patch",
    "rocm_patch/flashpy_xformers-0.0.23.rocm.patch",
    "setup.py",
    "tests/async_engine/test_api_server.py",
    "tests/async_engine/test_async_llm_engine.py",
    "tests/async_engine/test_chat_template.py",
    "tests/async_engine/test_merge_async_iterators.py",
    "tests/async_engine/test_openapi_server_ray.py",
    "tests/basic_correctness/test_basic_correctness.py",
    "tests/basic_correctness/test_chunked_prefill.py",
    "tests/basic_correctness/test_preemption.py",
    "tests/conftest.py",
    "tests/core/block/conftest.py",
    "tests/core/block/e2e/conftest.py",
    "tests/core/block/e2e/test_correctness.py",
    "tests/core/block/test_block_manager_v2.py",
    "tests/core/block/test_block_table.py",
    "tests/core/block/test_common.py",
    "tests/core/block/test_cpu_gpu_block_allocator.py",
    "tests/core/block/test_naive_block.py",
    "tests/core/block/test_prefix_caching_block.py",
    "tests/core/test_block_manager.py",
    "tests/core/test_chunked_prefill_scheduler.py",
    "tests/core/test_scheduler.py",
    "tests/core/utils.py",
    "tests/distributed/test_basic_distributed_correctness.py",
    "tests/distributed/test_chunked_prefill_distributed.py",
    "tests/distributed/test_comm_ops.py",
    "tests/distributed/test_custom_all_reduce.py",
    "tests/distributed/test_pynccl.py",
    "tests/distributed/test_pynccl_library.py",
    "tests/engine/output_processor/test_multi_step.py",
    "tests/engine/test_detokenization.py",
    "tests/engine/test_multiproc_workers.py",
    "tests/engine/test_skip_tokenizer_init.py",
    "tests/engine/test_stop_reason.py",
    "tests/engine/test_stop_strings.py",
    "tests/entrypoints/openai/test_serving_chat.py",
    "tests/entrypoints/test_guided_processors.py",
    "tests/entrypoints/test_llm_generate.py",
    "tests/entrypoints/test_openai_server.py",
    "tests/entrypoints/test_server_oot_registration.py",
    "tests/fp8_kv/llama2-70b-fp8-kv/kv_cache_scales.json",
    "tests/fp8_kv/llama2-7b-fp8-kv/kv_cache_scales.json",
    "tests/kernels/conftest.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_cache.py",
    "tests/kernels/test_layernorm.py",
    "tests/kernels/test_moe.py",
    "tests/kernels/test_prefix_prefill.py",
    "tests/lora/conftest.py",
    "tests/lora/test_baichuan.py",
    "tests/lora/test_chatglm3.py",
    "tests/lora/test_layers.py",
    "tests/lora/test_lora_checkpoints.py",
    "tests/lora/test_punica.py",
    "tests/lora/test_quant_model.py",
    "tests/lora/test_worker.py",
    "tests/metrics/test_metrics.py",
    "tests/model_executor/weight_utils.py",
    "tests/models/test_aqlm.py",
    "tests/models/test_big_models.py",
    "tests/models/test_fp8.py",
    "tests/models/test_gptq_marlin.py",
    "tests/models/test_llava.py",
    "tests/models/test_marlin.py",
    "tests/models/test_mistral.py",
    "tests/models/test_models.py",
    "tests/models/test_oot_registration.py",
    "tests/models/utils.py",
    "tests/prefix_caching/test_prefix_caching.py",
    "tests/quantization/test_configs.py",
    "tests/quantization/test_fp8.py",
    "tests/samplers/test_beam_search.py",
    "tests/samplers/test_ignore_eos.py",
    "tests/samplers/test_logits_processor.py",
    "tests/samplers/test_logprobs.py",
    "tests/samplers/test_rejection_sampler.py",
    "tests/samplers/test_sampler.py",
    "tests/samplers/test_seeded_generate.py",
    "tests/spec_decode/e2e/__init__.py",
    "tests/spec_decode/e2e/conftest.py",
    "tests/spec_decode/e2e/test_compatibility.py",
    "tests/spec_decode/e2e/test_logprobs.py",
    "tests/spec_decode/e2e/test_multistep_correctness.py",
    "tests/spec_decode/e2e/test_ngram_correctness.py",
    "tests/spec_decode/test_batch_expansion.py",
    "tests/spec_decode/test_dynamic_spec_decode.py",
    "tests/spec_decode/test_metrics.py",
    "tests/spec_decode/test_multi_step_worker.py",
    "tests/spec_decode/test_ngram_worker.py",
    "tests/spec_decode/test_spec_decode_worker.py",
    "tests/spec_decode/utils.py",
    "tests/tensorizer_loader/__init__.py",
    "tests/tensorizer_loader/tensorize_vllm_model_for_testing.py",
    "tests/tensorizer_loader/test_tensorizer.py",
    "tests/test_config.py",
    "tests/test_logger.py",
    "tests/test_logits_processor.py",
    "tests/test_sequence.py",
    "tests/tokenization/test_detokenize.py",
    "tests/tokenization/test_tokenizer.py",
    "tests/worker/test_model_runner.py",
    "tests/worker/test_swap.py",
    "vllm/__init__.py",
    "vllm/_custom_ops.py",
    "vllm/attention/__init__.py",
    "vllm/attention/backends/abstract.py",
    "vllm/attention/backends/flash_attn.py",
    "vllm/attention/backends/flashinfer.py",
    "vllm/attention/backends/rocm_flash_attn.py",
    "vllm/attention/backends/torch_sdpa.py",
    "vllm/attention/backends/xformers.py",
    "vllm/attention/layer.py",
    "vllm/attention/ops/paged_attn.py",
    "vllm/attention/ops/prefix_prefill.py",
    "vllm/attention/ops/triton_flash_attention.py",
    "vllm/attention/selector.py",
    "vllm/config.py",
    "vllm/core/block/__init__.py",
    "vllm/core/block/block_table.py",
    "vllm/core/block/common.py",
    "vllm/core/block/cpu_gpu_block_allocator.py",
    "vllm/core/block/interfaces.py",
    "vllm/core/block/naive_block.py",
    "vllm/core/block/prefix_caching_block.py",
    "vllm/core/block_manager.py",
    "vllm/core/block_manager_v2.py",
    "vllm/core/evictor.py",
    "vllm/core/evictor_v2.py",
    "vllm/core/interfaces.py",
    "vllm/core/policy.py",
    "vllm/core/scheduler.py",
    "vllm/distributed/__init__.py",
    "vllm/distributed/device_communicators/__init__.py",
    "vllm/distributed/device_communicators/pynccl.py",
    "vllm/distributed/device_communicators/pynccl_utils.py",
    "vllm/distributed/utils.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/async_llm_engine.py",
    "vllm/engine/llm_engine.py",
    "vllm/engine/metrics.py",
    "vllm/engine/output_processor/__init__.py",
    "vllm/engine/output_processor/interfaces.py",
    "vllm/engine/output_processor/multi_step.py",
    "vllm/engine/output_processor/single_step.py",
    "vllm/engine/output_processor/stop_checker.py",
    "vllm/engine/output_processor/util.py",
    "vllm/engine/ray_utils.py",
    "vllm/entrypoints/api_server.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/api_server.py",
    "vllm/entrypoints/openai/cli_args.py",
    "vllm/entrypoints/openai/protocol.py",
    "vllm/entrypoints/openai/serving_chat.py",
    "vllm/entrypoints/openai/serving_completion.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/envs.py",
    "vllm/executor/cpu_executor.py",
    "vllm/executor/distributed_gpu_executor.py",
    "vllm/executor/executor_base.py",
    "vllm/executor/gpu_executor.py",
    "vllm/executor/multiproc_worker_utils.py",
    "vllm/executor/neuron_executor.py",
    "vllm/executor/ray_gpu_executor.py",
    "vllm/executor/utils.py",
    "vllm/logger.py",
    "vllm/logging/__init__.py",
    "vllm/logging/formatter.py",
    "vllm/lora/fully_sharded_layers.py",
    "vllm/lora/layers.py",
    "vllm/lora/lora.py",
    "vllm/lora/models.py",
    "vllm/lora/punica.py",
    "vllm/lora/utils.py",
    "vllm/lora/worker_manager.py",
    "vllm/model_executor/guided_decoding.py",
    "vllm/model_executor/guided_decoding/__init__.py",
    "vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py",
    "vllm/model_executor/guided_logits_processors.py",
    "vllm/model_executor/layers/activation.py",
    "vllm/model_executor/layers/fused_moe/__init__.py",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/fused_moe.py",
    "vllm/model_executor/layers/layernorm.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/logits_processor.py",
    "vllm/model_executor/layers/ops/sample.py",
    "vllm/model_executor/layers/quantization/__init__.py",
    "vllm/model_executor/layers/quantization/aqlm.py",
    "vllm/model_executor/layers/quantization/awq.py",
    "vllm/model_executor/layers/quantization/base_config.py",
    "vllm/model_executor/layers/quantization/deepspeedfp.py",
    "vllm/model_executor/layers/quantization/fp8.py",
    "vllm/model_executor/layers/quantization/gptq.py",
    "vllm/model_executor/layers/quantization/gptq_marlin.py",
    "vllm/model_executor/layers/quantization/marlin.py",
    "vllm/model_executor/layers/quantization/schema.py",
    "vllm/model_executor/layers/quantization/squeezellm.py",
    "vllm/model_executor/layers/rejection_sampler.py",
    "vllm/model_executor/layers/rotary_embedding.py",
    "vllm/model_executor/layers/sampler.py",
    "vllm/model_executor/layers/vocab_parallel_embedding.py",
    "vllm/model_executor/model_loader.py",
    "vllm/model_executor/model_loader/__init__.py",
    "vllm/model_executor/model_loader/loader.py",
    "vllm/model_executor/model_loader/tensorizer.py",
    "vllm/model_executor/model_loader/utils.py",
    "vllm/model_executor/model_loader/weight_utils.py",
    "vllm/model_executor/models/__init__.py",
    "vllm/model_executor/models/arctic.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/bloom.py",
    "vllm/model_executor/models/chatglm.py",
    "vllm/model_executor/models/commandr.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/decilm.py",
    "vllm/model_executor/models/deepseek.py",
    "vllm/model_executor/models/falcon.py",
    "vllm/model_executor/models/gemma.py",
    "vllm/model_executor/models/gpt2.py",
    "vllm/model_executor/models/gpt_bigcode.py",
    "vllm/model_executor/models/gpt_j.py",
    "vllm/model_executor/models/gpt_neox.py",
    "vllm/model_executor/models/internlm2.py",
    "vllm/model_executor/models/jais.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mixtral_quant.py",
    "vllm/model_executor/models/mpt.py",
    "vllm/model_executor/models/olmo.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/orion.py",
    "vllm/model_executor/models/phi.py",
    "vllm/model_executor/models/qwen.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_moe.py",
    "vllm/model_executor/models/stablelm.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/xverse.py",
    "vllm/model_executor/neuron_model_loader.py",
    "vllm/model_executor/parallel_utils/README.md",
    "vllm/model_executor/parallel_utils/__init__.py",
    "vllm/model_executor/parallel_utils/communication_op.py",
    "vllm/model_executor/parallel_utils/cupy_utils.py",
    "vllm/model_executor/parallel_utils/custom_all_reduce.py",
    "vllm/model_executor/parallel_utils/parallel_state.py",
    "vllm/model_executor/parallel_utils/utils.py",
    "vllm/model_executor/sampling_metadata.py",
    "vllm/model_executor/weight_utils.py",
    "vllm/outputs.py",
    "vllm/sampling_params.py",
    "vllm/sequence.py",
    "vllm/spec_decode/__init__.py",
    "vllm/spec_decode/batch_expansion.py",
    "vllm/spec_decode/interfaces.py",
    "vllm/spec_decode/metrics.py",
    "vllm/spec_decode/multi_step_worker.py",
    "vllm/spec_decode/ngram_worker.py",
    "vllm/spec_decode/spec_decode_worker.py",
    "vllm/spec_decode/top1_proposer.py",
    "vllm/spec_decode/util.py",
    "vllm/test_utils.py",
    "vllm/transformers_utils/config.py",
    "vllm/transformers_utils/configs/__init__.py",
    "vllm/transformers_utils/configs/arctic.py",
    "vllm/transformers_utils/configs/dbrx.py",
    "vllm/transformers_utils/configs/jais.py",
    "vllm/transformers_utils/detokenizer.py",
    "vllm/transformers_utils/tokenizer.py",
    "vllm/transformers_utils/tokenizer_group/__init__.py",
    "vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py",
    "vllm/transformers_utils/tokenizers/baichuan.py",
    "vllm/usage/__init__.py",
    "vllm/usage/usage_lib.py",
    "vllm/utils.py",
    "vllm/worker/cache_engine.py",
    "vllm/worker/cpu_model_runner.py",
    "vllm/worker/cpu_worker.py",
    "vllm/worker/model_runner.py",
    "vllm/worker/neuron_model_runner.py",
    "vllm/worker/neuron_worker.py",
    "vllm/worker/worker.py",
    "vllm/worker/worker_base.py"
  ],
  "allowed": [
    "vllm/model_executor/layers/quantization/fp8.py",
    "vllm/_custom_ops.py"
  ],
  "disallowed": [
    ".buildkite/check-wheel-size.py",
    ".buildkite/run-amd-test.sh",
    ".buildkite/run-benchmarks.sh",
    ".buildkite/run-cpu-test.sh",
    ".buildkite/run-neuron-test.sh",
    ".buildkite/test-pipeline.yaml",
    ".buildkite/test-template.j2",
    ".github/ISSUE_TEMPLATE/200-installation.yml",
    ".github/ISSUE_TEMPLATE/300-usage.yml",
    ".github/ISSUE_TEMPLATE/400-bug report.yml",
    ".github/ISSUE_TEMPLATE/700-performance discussion.yml",
    ".github/ISSUE_TEMPLATE/750-RFC.yml",
    ".github/workflows/mypy.yaml",
    ".github/workflows/publish.yml",
    ".github/workflows/ruff.yml",
    ".github/workflows/scripts/build.sh",
    ".github/workflows/scripts/create_release.js",
    ".github/workflows/yapf.yml",
    ".gitignore",
    "CMakeLists.txt",
    "CONTRIBUTING.md",
    "Dockerfile",
    "Dockerfile.cpu",
    "Dockerfile.neuron",
    "Dockerfile.rocm",
    "MANIFEST.in",
    "README.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_latency.py",
    "benchmarks/benchmark_prefix_caching.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/benchmark_throughput.py",
    "benchmarks/kernels/benchmark_aqlm.py",
    "benchmarks/kernels/benchmark_mixtral_moe.py",
    "benchmarks/kernels/benchmark_paged_attention.py",
    "benchmarks/sonnet.txt",
    "cmake/cpu_extension.cmake",
    "cmake/utils.cmake",
    "collect_env.py",
    "csrc/attention/attention_dtypes.h",
    "csrc/attention/attention_kernels.cu",
    "csrc/attention/dtype_fp8_e5m2.cuh",
    "csrc/cache.h",
    "csrc/cache_kernels.cu",
    "csrc/cpu/activation.cpp",
    "csrc/cpu/attention.cpp",
    "csrc/cpu/cache.cpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/layernorm.cpp",
    "csrc/cpu/pos_encoding.cpp",
    "csrc/cpu/pybind.cpp",
    "csrc/cuda_compat.h",
    "csrc/layernorm_kernels.cu",
    "csrc/ops.h",
    "csrc/punica/bgmv/bgmv_bf16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_config.h",
    "csrc/punica/bgmv/bgmv_fp16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_impl.cuh",
    "csrc/punica/bgmv/generator.py",
    "csrc/punica/bgmv/vec_dtypes.cuh",
    "csrc/punica/punica_ops.cc",
    "csrc/punica/punica_ops.h",
    "csrc/punica/punica_pybind.cpp",
    "csrc/punica/type_convert.h",
    "csrc/pybind.cpp",
    "csrc/quantization/aqlm/gemm_kernels.cu",
    "csrc/quantization/fp8/amd_detail/hip_float8.h",
    "csrc/quantization/fp8/amd_detail/hip_float8_impl.h",
    "csrc/quantization/fp8/amd_detail/quant_utils.cuh",
    "csrc/quantization/fp8/fp8_cuda_kernels.cu",
    "csrc/quantization/gptq/q_gemm.cu",
    "csrc/quantization/gptq_marlin/gptq_marlin.cu",
    "csrc/quantization/gptq_marlin/gptq_marlin.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin_repack.cu",
    "csrc/quantization/marlin/marlin_cuda_kernel.cu",
    "csrc/reduction_utils.cuh",
    "docs/requirements-docs.txt",
    "docs/source/assets/dev/dockerfile-stages-dependency.png",
    "docs/source/conf.py",
    "docs/source/dev/dockerfile/dockerfile.rst",
    "docs/source/dev/engine/async_llm_engine.rst",
    "docs/source/dev/engine/llm_engine.rst",
    "docs/source/dev/sampling_params.rst",
    "docs/source/generate_examples.py",
    "docs/source/getting_started/amd-installation.rst",
    "docs/source/getting_started/cpu-installation.rst",
    "docs/source/getting_started/examples/examples_index.template.rst",
    "docs/source/getting_started/installation.rst",
    "docs/source/index.rst",
    "docs/source/models/adding_model.rst",
    "docs/source/models/engine_args.rst",
    "docs/source/models/performance.rst",
    "docs/source/models/supported_models.rst",
    "docs/source/quantization/fp8_e4m3_kvcache.rst",
    "docs/source/quantization/fp8_e5m2_kv_cache.rst",
    "docs/source/serving/deploying_with_docker.rst",
    "docs/source/serving/env_vars.rst",
    "docs/source/serving/openai_compatible_server.md",
    "docs/source/serving/run_on_sky.rst",
    "docs/source/serving/usage_stats.md",
    "examples/aqlm_example.py",
    "examples/fp8/README.md",
    "examples/fp8/extract_scales.py",
    "examples/fp8/quantizer/README.md",
    "examples/fp8/quantizer/quantize.py",
    "examples/llava_example.py",
    "examples/logging_configuration.md",
    "examples/offline_inference_arctic.py",
    "examples/offline_inference_with_prefix.py",
    "examples/openai_chatcompletion_client.py",
    "examples/production_monitoring/grafana.json",
    "examples/tensorize_vllm_model.py",
    "format.sh",
    "model_patch.diff",
    "patch_xformers.rocm.sh",
    "pyproject.toml",
    "requirements-build.txt",
    "requirements-common.txt",
    "requirements-cpu.txt",
    "requirements-cuda.txt",
    "requirements-dev.txt",
    "requirements-neuron.txt",
    "requirements-rocm.txt",
    "requirements.txt",
    "rocm_patch/commonpy_xformers-0.0.23.rocm.patch",
    "rocm_patch/flashpy_xformers-0.0.23.rocm.patch",
    "setup.py",
    "tests/async_engine/test_api_server.py",
    "tests/async_engine/test_async_llm_engine.py",
    "tests/async_engine/test_chat_template.py",
    "tests/async_engine/test_merge_async_iterators.py",
    "tests/async_engine/test_openapi_server_ray.py",
    "tests/basic_correctness/test_basic_correctness.py",
    "tests/basic_correctness/test_chunked_prefill.py",
    "tests/basic_correctness/test_preemption.py",
    "tests/conftest.py",
    "tests/core/block/conftest.py",
    "tests/core/block/e2e/conftest.py",
    "tests/core/block/e2e/test_correctness.py",
    "tests/core/block/test_block_manager_v2.py",
    "tests/core/block/test_block_table.py",
    "tests/core/block/test_common.py",
    "tests/core/block/test_cpu_gpu_block_allocator.py",
    "tests/core/block/test_naive_block.py",
    "tests/core/block/test_prefix_caching_block.py",
    "tests/core/test_block_manager.py",
    "tests/core/test_chunked_prefill_scheduler.py",
    "tests/core/test_scheduler.py",
    "tests/core/utils.py",
    "tests/distributed/test_basic_distributed_correctness.py",
    "tests/distributed/test_chunked_prefill_distributed.py",
    "tests/distributed/test_comm_ops.py",
    "tests/distributed/test_custom_all_reduce.py",
    "tests/distributed/test_pynccl.py",
    "tests/distributed/test_pynccl_library.py",
    "tests/engine/output_processor/test_multi_step.py",
    "tests/engine/test_detokenization.py",
    "tests/engine/test_multiproc_workers.py",
    "tests/engine/test_skip_tokenizer_init.py",
    "tests/engine/test_stop_reason.py",
    "tests/engine/test_stop_strings.py",
    "tests/entrypoints/openai/test_serving_chat.py",
    "tests/entrypoints/test_guided_processors.py",
    "tests/entrypoints/test_llm_generate.py",
    "tests/entrypoints/test_openai_server.py",
    "tests/entrypoints/test_server_oot_registration.py",
    "tests/fp8_kv/llama2-70b-fp8-kv/kv_cache_scales.json",
    "tests/fp8_kv/llama2-7b-fp8-kv/kv_cache_scales.json",
    "tests/kernels/conftest.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_cache.py",
    "tests/kernels/test_layernorm.py",
    "tests/kernels/test_moe.py",
    "tests/kernels/test_prefix_prefill.py",
    "tests/lora/conftest.py",
    "tests/lora/test_baichuan.py",
    "tests/lora/test_chatglm3.py",
    "tests/lora/test_layers.py",
    "tests/lora/test_lora_checkpoints.py",
    "tests/lora/test_punica.py",
    "tests/lora/test_quant_model.py",
    "tests/lora/test_worker.py",
    "tests/metrics/test_metrics.py",
    "tests/model_executor/weight_utils.py",
    "tests/models/test_aqlm.py",
    "tests/models/test_big_models.py",
    "tests/models/test_fp8.py",
    "tests/models/test_gptq_marlin.py",
    "tests/models/test_llava.py",
    "tests/models/test_marlin.py",
    "tests/models/test_mistral.py",
    "tests/models/test_models.py",
    "tests/models/test_oot_registration.py",
    "tests/models/utils.py",
    "tests/prefix_caching/test_prefix_caching.py",
    "tests/quantization/test_configs.py",
    "tests/quantization/test_fp8.py",
    "tests/samplers/test_beam_search.py",
    "tests/samplers/test_ignore_eos.py",
    "tests/samplers/test_logits_processor.py",
    "tests/samplers/test_logprobs.py",
    "tests/samplers/test_rejection_sampler.py",
    "tests/samplers/test_sampler.py",
    "tests/samplers/test_seeded_generate.py",
    "tests/spec_decode/e2e/__init__.py",
    "tests/spec_decode/e2e/conftest.py",
    "tests/spec_decode/e2e/test_compatibility.py",
    "tests/spec_decode/e2e/test_logprobs.py",
    "tests/spec_decode/e2e/test_multistep_correctness.py",
    "tests/spec_decode/e2e/test_ngram_correctness.py",
    "tests/spec_decode/test_batch_expansion.py",
    "tests/spec_decode/test_dynamic_spec_decode.py",
    "tests/spec_decode/test_metrics.py",
    "tests/spec_decode/test_multi_step_worker.py",
    "tests/spec_decode/test_ngram_worker.py",
    "tests/spec_decode/test_spec_decode_worker.py",
    "tests/spec_decode/utils.py",
    "tests/tensorizer_loader/__init__.py",
    "tests/tensorizer_loader/tensorize_vllm_model_for_testing.py",
    "tests/tensorizer_loader/test_tensorizer.py",
    "tests/test_config.py",
    "tests/test_logger.py",
    "tests/test_logits_processor.py",
    "tests/test_sequence.py",
    "tests/tokenization/test_detokenize.py",
    "tests/tokenization/test_tokenizer.py",
    "tests/worker/test_model_runner.py",
    "tests/worker/test_swap.py",
    "vllm/__init__.py",
    "vllm/attention/__init__.py",
    "vllm/attention/backends/abstract.py",
    "vllm/attention/backends/flash_attn.py",
    "vllm/attention/backends/flashinfer.py",
    "vllm/attention/backends/rocm_flash_attn.py",
    "vllm/attention/backends/torch_sdpa.py",
    "vllm/attention/backends/xformers.py",
    "vllm/attention/layer.py",
    "vllm/attention/ops/paged_attn.py",
    "vllm/attention/ops/prefix_prefill.py",
    "vllm/attention/ops/triton_flash_attention.py",
    "vllm/attention/selector.py",
    "vllm/config.py",
    "vllm/core/block/__init__.py",
    "vllm/core/block/block_table.py",
    "vllm/core/block/common.py",
    "vllm/core/block/cpu_gpu_block_allocator.py",
    "vllm/core/block/interfaces.py",
    "vllm/core/block/naive_block.py",
    "vllm/core/block/prefix_caching_block.py",
    "vllm/core/block_manager.py",
    "vllm/core/block_manager_v2.py",
    "vllm/core/evictor.py",
    "vllm/core/evictor_v2.py",
    "vllm/core/interfaces.py",
    "vllm/core/policy.py",
    "vllm/core/scheduler.py",
    "vllm/distributed/__init__.py",
    "vllm/distributed/device_communicators/__init__.py",
    "vllm/distributed/device_communicators/pynccl.py",
    "vllm/distributed/device_communicators/pynccl_utils.py",
    "vllm/distributed/utils.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/async_llm_engine.py",
    "vllm/engine/llm_engine.py",
    "vllm/engine/metrics.py",
    "vllm/engine/output_processor/__init__.py",
    "vllm/engine/output_processor/interfaces.py",
    "vllm/engine/output_processor/multi_step.py",
    "vllm/engine/output_processor/single_step.py",
    "vllm/engine/output_processor/stop_checker.py",
    "vllm/engine/output_processor/util.py",
    "vllm/engine/ray_utils.py",
    "vllm/entrypoints/api_server.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/api_server.py",
    "vllm/entrypoints/openai/cli_args.py",
    "vllm/entrypoints/openai/protocol.py",
    "vllm/entrypoints/openai/serving_chat.py",
    "vllm/entrypoints/openai/serving_completion.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/envs.py",
    "vllm/executor/cpu_executor.py",
    "vllm/executor/distributed_gpu_executor.py",
    "vllm/executor/executor_base.py",
    "vllm/executor/gpu_executor.py",
    "vllm/executor/multiproc_worker_utils.py",
    "vllm/executor/neuron_executor.py",
    "vllm/executor/ray_gpu_executor.py",
    "vllm/executor/utils.py",
    "vllm/logger.py",
    "vllm/logging/__init__.py",
    "vllm/logging/formatter.py",
    "vllm/lora/fully_sharded_layers.py",
    "vllm/lora/layers.py",
    "vllm/lora/lora.py",
    "vllm/lora/models.py",
    "vllm/lora/punica.py",
    "vllm/lora/utils.py",
    "vllm/lora/worker_manager.py",
    "vllm/model_executor/guided_decoding.py",
    "vllm/model_executor/guided_decoding/__init__.py",
    "vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py",
    "vllm/model_executor/guided_logits_processors.py",
    "vllm/model_executor/layers/activation.py",
    "vllm/model_executor/layers/fused_moe/__init__.py",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/fused_moe.py",
    "vllm/model_executor/layers/layernorm.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/logits_processor.py",
    "vllm/model_executor/layers/ops/sample.py",
    "vllm/model_executor/layers/quantization/__init__.py",
    "vllm/model_executor/layers/quantization/aqlm.py",
    "vllm/model_executor/layers/quantization/awq.py",
    "vllm/model_executor/layers/quantization/base_config.py",
    "vllm/model_executor/layers/quantization/deepspeedfp.py",
    "vllm/model_executor/layers/quantization/gptq.py",
    "vllm/model_executor/layers/quantization/gptq_marlin.py",
    "vllm/model_executor/layers/quantization/marlin.py",
    "vllm/model_executor/layers/quantization/schema.py",
    "vllm/model_executor/layers/quantization/squeezellm.py",
    "vllm/model_executor/layers/rejection_sampler.py",
    "vllm/model_executor/layers/rotary_embedding.py",
    "vllm/model_executor/layers/sampler.py",
    "vllm/model_executor/layers/vocab_parallel_embedding.py",
    "vllm/model_executor/model_loader.py",
    "vllm/model_executor/model_loader/__init__.py",
    "vllm/model_executor/model_loader/loader.py",
    "vllm/model_executor/model_loader/tensorizer.py",
    "vllm/model_executor/model_loader/utils.py",
    "vllm/model_executor/model_loader/weight_utils.py",
    "vllm/model_executor/models/__init__.py",
    "vllm/model_executor/models/arctic.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/bloom.py",
    "vllm/model_executor/models/chatglm.py",
    "vllm/model_executor/models/commandr.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/decilm.py",
    "vllm/model_executor/models/deepseek.py",
    "vllm/model_executor/models/falcon.py",
    "vllm/model_executor/models/gemma.py",
    "vllm/model_executor/models/gpt2.py",
    "vllm/model_executor/models/gpt_bigcode.py",
    "vllm/model_executor/models/gpt_j.py",
    "vllm/model_executor/models/gpt_neox.py",
    "vllm/model_executor/models/internlm2.py",
    "vllm/model_executor/models/jais.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mixtral_quant.py",
    "vllm/model_executor/models/mpt.py",
    "vllm/model_executor/models/olmo.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/orion.py",
    "vllm/model_executor/models/phi.py",
    "vllm/model_executor/models/qwen.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_moe.py",
    "vllm/model_executor/models/stablelm.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/xverse.py",
    "vllm/model_executor/neuron_model_loader.py",
    "vllm/model_executor/parallel_utils/README.md",
    "vllm/model_executor/parallel_utils/__init__.py",
    "vllm/model_executor/parallel_utils/communication_op.py",
    "vllm/model_executor/parallel_utils/cupy_utils.py",
    "vllm/model_executor/parallel_utils/custom_all_reduce.py",
    "vllm/model_executor/parallel_utils/parallel_state.py",
    "vllm/model_executor/parallel_utils/utils.py",
    "vllm/model_executor/sampling_metadata.py",
    "vllm/model_executor/weight_utils.py",
    "vllm/outputs.py",
    "vllm/sampling_params.py",
    "vllm/sequence.py",
    "vllm/spec_decode/__init__.py",
    "vllm/spec_decode/batch_expansion.py",
    "vllm/spec_decode/interfaces.py",
    "vllm/spec_decode/metrics.py",
    "vllm/spec_decode/multi_step_worker.py",
    "vllm/spec_decode/ngram_worker.py",
    "vllm/spec_decode/spec_decode_worker.py",
    "vllm/spec_decode/top1_proposer.py",
    "vllm/spec_decode/util.py",
    "vllm/test_utils.py",
    "vllm/transformers_utils/config.py",
    "vllm/transformers_utils/configs/__init__.py",
    "vllm/transformers_utils/configs/arctic.py",
    "vllm/transformers_utils/configs/dbrx.py",
    "vllm/transformers_utils/configs/jais.py",
    "vllm/transformers_utils/detokenizer.py",
    "vllm/transformers_utils/tokenizer.py",
    "vllm/transformers_utils/tokenizer_group/__init__.py",
    "vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py",
    "vllm/transformers_utils/tokenizers/baichuan.py",
    "vllm/usage/__init__.py",
    "vllm/usage/usage_lib.py",
    "vllm/utils.py",
    "vllm/worker/cache_engine.py",
    "vllm/worker/cpu_model_runner.py",
    "vllm/worker/cpu_worker.py",
    "vllm/worker/model_runner.py",
    "vllm/worker/neuron_model_runner.py",
    "vllm/worker/neuron_worker.py",
    "vllm/worker/worker.py",
    "vllm/worker/worker_base.py"
  ],
  "ok": false
}