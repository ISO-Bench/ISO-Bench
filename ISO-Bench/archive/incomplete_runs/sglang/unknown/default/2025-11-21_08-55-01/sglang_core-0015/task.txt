I've uploaded a python code repository in the directory /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0015.
Consider the following test script showing an example usage of the repository:

<test_script>
import torch
import time
from vllm.model_executor.layers.fused_moe import moe_align_block_size

# Benchmark the MoE align block size operation
num_tokens = 4096
num_experts = 64
topk = 2
block_size = 128

# Create input data
topk_ids = torch.randint(0, num_experts, (num_tokens * topk,), dtype=torch.int32, device='cuda')

# Time the operation
torch.cuda.synchronize()
start = time.time()

sorted_ids, expert_ids, num_tokens_post_pad = moe_align_block_size(
    topk_ids, num_experts, block_size, topk
)

torch.cuda.synchronize()
duration = time.time() - start

print(f"Duration: {duration:.4f} seconds")

</test_script>

Can you help me implement the necessary changes to the repository so that the runtime of the <test_script> is optimized?

Basic guidelines:
1. Your task is to make changes to non-test files in the /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0015 directory to improve the performance of the <test_script>.
2. Make changes while ensuring the repository is functionally equivalent to the original.
3. Do not overoptimize for just the specific inputs in <test_script>. Make general performance improvements for the usage scenario shown.
4. You may need to rebuild the repo for your changes to take effect before testing. Some rebuilds may take time to run, so be patient with running them.

Follow these steps to improve performance:
1. As a first step, explore the repository structure.
2. Create a script ONLY inside /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0015/.bench_scratch (e.g., /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0015/.bench_scratch/test_opt.py) to reproduce and time the example, then execute it with python <filename.py> from the repo root.
3. Edit the source code of the repository to improve performance.
4. Rebuild and rerun your script to confirm that performance has improved.

Here is an example of the kind of optimizations that have been shown to improve performance in this codebase:

<example_optimization_diff>
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/configs/README b/python/sglang/srt/layers/moe/fused_moe_triton/configs/README
index 4aa527f27..3679e698a 100644
--- a/python/sglang/srt/layers/moe/fused_moe_triton/configs/README
+++ b/python/sglang/srt/layers/moe/fused_moe_triton/configs/README
@@ -3,6 +3,9 @@ For different settings of
 - E (number of experts)
 - N (intermediate size)
 - device_name (torch.cuda.get_device_name())
+- dtype: The data type used by the fused MoE kernel for computation. Supported types include fp8_w8a8, int8_w8a8, int8_w8a16, int4_w4a16, etc. This determines the precision and quantization scheme for both weights and activations.
+- block_shape: The block quantization shape introduced starting from DeepSeek V3/R1 models. This parameter defines the granularity for block-wise quantization, typically specified as `[block_n, block_k]` where `block_n` and `block_k` represent the block dimensions. For example, DeepSeek V3 commonly uses `[128, 128]` block shapes for efficient block-wise FP8 quantization.
+
 the JSON file contains a mapping from M (batch size) to the chosen configuration.
 
 The example configurations provided are for the Mixtral model for TP2 on H100
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json b/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
similarity index 100%
rename from python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
rename to python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json b/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json
similarity index 100%
rename from python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json
rename to python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json b/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
similarity index 100%
rename from python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
rename to python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json b/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json
similarity index 100%
rename from python/sglang/srt/layers/moe/fused_moe_triton/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json
rename to python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json
</example_optimization_diff>

IMPORTANT: The above diff is an EXAMPLE of optimizations that were successful in a different context.
These changes have NOT been applied to your codebase yet.
Your task is to:
1. Understand the optimization pattern shown (e.g., torch.zeros â†’ torch.empty)
2. Look at the CURRENT code in the target files
3. Find places where you can apply SIMILAR optimizations
4. MAKE THE CHANGES yourself using str_replace_editor

The codebase you're working with is at the BASE commit - it does NOT have these optimizations yet.
You need to IMPLEMENT similar optimizations yourself.

HERE'S WHAT YOU NEED TO DO:
1. The files CURRENTLY contain torch.zeros() calls that need optimization
2. You need to CHANGE torch.zeros to torch.empty where appropriate
3. You need to REMOVE .fill_() operations that are unnecessary
4. These are NEW changes you're making - not already in the code

START WITH THIS COMMAND to see what needs changing:
```bash
grep -n 'torch.zeros\|fill_' vllm/model_executor/layers/fused_moe/moe_align_block_size.py benchmarks/kernels/benchmark_moe_align_block_size.py
```

CRITICAL: You MUST make actual code changes. Look for patterns like:
- Analyze the target files for performance bottlenecks
- Look for unnecessary memory allocations or initializations
- Consider more efficient algorithms or data structures

Target files to optimize:
- python/sglang/srt/layers/moe/fused_moe_triton/configs/README
- python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
- python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json

IMPORTANT: You MUST make actual code changes to at least one file.
The task will fail if no files are modified.

## Constraints
- No public API breakage
- All TestPack checks must pass

## Target Files (ONLY modify these)
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/README`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=144,N=512,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=1024,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=1024,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=20,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=24,N=1024,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_H20,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=256,device_name=AMD_Radeon_Graphics,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=64,device_name=NVIDIA_L20,dtype=int8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=256,N=64,device_name=NVIDIA_L40S,dtype=int8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=1280,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=2560,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=320,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=64,N=640,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=14336,device_name=AMD_Instinct_MI300X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=14336,device_name=AMD_Instinct_MI325X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=14336,device_name=AMD_Radeon_Graphics.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=14336,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=AMD_Instinct_MI300X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=AMD_Instinct_MI325X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=AMD_Radeon_Graphics.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=1792,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=2048,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=AMD_Instinct_MI300X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=AMD_Instinct_MI325X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=AMD_Radeon_Graphics.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=3584,device_name=NVIDIA_L40S.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=AMD_Radeon_Graphics,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=4096,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=AMD_Instinct_MI300X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=AMD_Instinct_MI325X.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=AMD_Radeon_Graphics.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=7168,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=8192,device_name=AMD_Radeon_Graphics,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_1_0/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=192,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=192,device_name=NVIDIA_H20.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=192,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=384,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=384,device_name=NVIDIA_H20.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=384,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=768,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=768,device_name=NVIDIA_H100_80GB_HBM3.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=768,device_name=NVIDIA_H20.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=768,device_name=NVIDIA_H200.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=128,N=96,device_name=NVIDIA_H20.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=264,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=264,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=264,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=264,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=272,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=272,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=272,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=272,N=64,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_2_0/E=288,N=64,device_name=NVIDIA_A800-SXM4-80GB.json`
- `python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py`

## SPECIFIC OPTIMIZATION TARGETS:
Based on the human commit analysis, focus on these areas:
- Memory allocation patterns (torch.zeros vs torch.empty)
- Tensor initialization strategies
- Kernel parameter optimization
- Buffer reuse and caching

### Human Developer's Approach:
```
Add triton version as a fused_moe_triton config search key to avoid performace decrease in different Triton version (#5955)
```

### Files Modified (statistics):
```
python/sglang/srt/layers/moe/fused_moe_triton/configs/README     | 3 +++
 ...14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json           | 0
 ...=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 ...=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 ...=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json | 0
 .../E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 ...=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 ...=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 .../E=144,N=512,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 .../E=16,N=1024,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 .../{ => triton_3_1_0}/E=16,N=1024,device_name=NVIDIA_H200.json  | 0
 .../E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json           | 0
 .../E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json           | 0
 .../E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 ...14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json          | 0
 ...=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json           | 0
 .../E=16,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 .../E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json           | 0
 .../E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 ...=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 ...=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json | 0
 ...,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 ...=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json           | 0
 ...,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 ...=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json | 0
 .../E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json           | 0
 ...=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json | 0
 ...6,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json           | 0
 .../E=20,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 .../E=24,N=1024,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 ...IA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128, 128].json | 0
 ...,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json | 0
 ...IA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128, 128].json | 0
 ...,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json | 0
 ...DIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...=256,N=128,device_name=NVIDIA_H20,block_shape=[128, 128].json | 0
 ...ce_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...e_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...MD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...MD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...MD_Radeon_Graphics,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...e_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...e_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128, 128].json | 0
 ...e_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json            | 0
 .../E=256,N=64,device_name=NVIDIA_L20,dtype=int8_w8a8.json       | 0
 .../E=256,N=64,device_name=NVIDIA_L40S,dtype=int8_w8a8.json      | 0
 ...DIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json           | 0
 .../E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json           | 0
 ...,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 .../E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json      | 0
 .../{ => triton_3_1_0}/E=64,N=1280,device_name=NVIDIA_H200.json  | 0
 ...,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json      | 0
 .../{ => triton_3_1_0}/E=64,N=2560,device_name=NVIDIA_H200.json  | 0
 ...4,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 .../E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../{ => triton_3_1_0}/E=64,N=320,device_name=NVIDIA_H200.json   | 0
 ...e_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 .../E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json            | 0
 ...N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json | 0
 ...4,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 .../E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../{ => triton_3_1_0}/E=64,N=640,device_name=NVIDIA_H200.json   | 0
 .../E=8,N=14336,device_name=AMD_Instinct_MI300X.json             | 0
 .../E=8,N=14336,device_name=AMD_Instinct_MI325X.json             | 0
 .../E=8,N=14336,device_name=AMD_Radeon_Graphics.json             | 0
 ...N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json      | 0
 .../{ => triton_3_1_0}/E=8,N=14336,device_name=NVIDIA_H200.json  | 0
 .../E=8,N=1792,device_name=AMD_Instinct_MI300X.json              | 0
 .../E=8,N=1792,device_name=AMD_Instinct_MI325X.json              | 0
 .../E=8,N=1792,device_name=AMD_Radeon_Graphics.json              | 0
 .../E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json            | 0
 .../E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 .../E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 .../E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../{ => triton_3_1_0}/E=8,N=1792,device_name=NVIDIA_H200.json   | 0
 .../E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 ...,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 .../E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../{ => triton_3_1_0}/E=8,N=2048,device_name=NVIDIA_H200.json   | 0
 .../E=8,N=3584,device_name=AMD_Instinct_MI300X.json              | 0
 .../E=8,N=3584,device_name=AMD_Instinct_MI325X.json              | 0
 .../E=8,N=3584,device_name=AMD_Radeon_Graphics.json              | 0
 .../E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json            | 0
 .../E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 ...=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json | 0
 ...,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 .../E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../{ => triton_3_1_0}/E=8,N=3584,device_name=NVIDIA_H200.json   | 0
 .../{ => triton_3_1_0}/E=8,N=3584,device_name=NVIDIA_L40S.json   | 0
 ...=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json | 0
 ...=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json | 0
 ...=8,N=4096,device_name=AMD_Radeon_Graphics,dtype=fp8_w8a8.json | 0
 .../E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 ...,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 .../E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../{ => triton_3_1_0}/E=8,N=4096,device_name=NVIDIA_H200.json   | 0
 .../E=8,N=7168,device_name=AMD_Instinct_MI300X.json              | 0
 .../E=8,N=7168,device_name=AMD_Instinct_MI325X.json              | 0
 .../E=8,N=7168,device_name=AMD_Radeon_Graphics.json              | 0
 .../E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json            | 0
 ...,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json            | 0
 .../E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../{ => triton_3_1_0}/E=8,N=7168,device_name=NVIDIA_H200.json   | 0
 ...=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json | 0
 ...=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json | 0
 ...=8,N=8192,device_name=AMD_Radeon_Graphics,dtype=fp8_w8a8.json | 0
 ...,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json | 0
 .../E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json       | 0
 .../E=128,N=192,device_name=NVIDIA_A800-SXM4-80GB.json           | 0
 .../E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 .../{ => triton_3_2_0}/E=128,N=192,device_name=NVIDIA_H20.json   | 0
 .../{ => triton_3_2_0}/E=128,N=192,device_name=NVIDIA_H200.json  | 0
 .../E=128,N=384,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 ...ce_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../{ => triton_3_2_0}/E=128,N=384,device_name=NVIDIA_H20.json   | 0
 ...e_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../{ => triton_3_2_0}/E=128,N=384,device_name=NVIDIA_H200.json  | 0
 .../E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 .../E=128,N=768,device_name=NVIDIA_A800-SXM4-80GB.json           | 0
 .../E=128,N=768,device_name=NVIDIA_H100_80GB_HBM3.json           | 0
 ...ce_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../{ => triton_3_2_0}/E=128,N=768,device_name=NVIDIA_H20.json   | 0
 ...e_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../{ => triton_3_2_0}/E=128,N=768,device_name=NVIDIA_H200.json  | 0
 .../{ => triton_3_2_0}/E=128,N=96,device_name=NVIDIA_H20.json    | 0
 ...DIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...e_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...e_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json | 0
 ...e_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...ce_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...e_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json | 0
 ...DIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 ...ce_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128, 128].json | 0
 .../E=272,N=64,device_name=NVIDIA_A800-SXM4-80GB.json            | 0
 .../E=288,N=64,device_name=NVIDIA_A800-SXM4-80GB.json            | 0
 python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py       | 9 ++++++++-
 158 files changed, 11 insertions(+), 1 deletion(-)
```

## IMMEDIATE ACTION REQUIREMENTS:
1. Start editing files by iteration 3
2. Create and run /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0015/.bench_scratch/test_opt.py before and after edits (do not create timing scripts outside /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0015/.bench_scratch)
3. Make at least 3 concrete optimizations
4. Commit changes by iteration 8
5. Use finish command by iteration 10

## TASK COMPLETION COMMAND:
When you have made optimizations:
```bash
git add -A
git reset -q .bench_scratch || true
git commit -m 'Optimize MoE align sum kernels performance'
git diff $(git merge-base HEAD origin/HEAD || git rev-parse HEAD~1) -- . ':(exclude).bench_scratch' > /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0015/model_patch.diff || true
finish
```

START IMPLEMENTING IMMEDIATELY. NO MORE ANALYSIS.
