diff --git a/python/sglang/srt/server_args.py b/python/sglang/srt/server_args.py
index 7c0317fc0..989fa347a 100644
--- a/python/sglang/srt/server_args.py
+++ b/python/sglang/srt/server_args.py
@@ -33,7 +33,8 @@ class ServerArgs:
 
     # Other runtime options
     tp_size: int = 1
-    stream_interval: int = 8
+    # Smaller interval improves responsiveness and reduces TTFT.
+    stream_interval: int = 1
     random_seed: Optional[int] = None
 
     # Logging
@@ -116,7 +117,7 @@ class ServerArgs:
             "--tokenizer-mode",
             type=str,
             default=ServerArgs.tokenizer_mode,
-            choices=["auto", "slow"],
+            choices=("auto", "slow"),
             help="Tokenizer mode. 'auto' will use the fast "
             "tokenizer if available, and 'slow' will "
             "always use the slow tokenizer.",
@@ -125,7 +126,7 @@ class ServerArgs:
             "--load-format",
             type=str,
             default=ServerArgs.load_format,
-            choices=["auto", "pt", "safetensors", "npcache", "dummy"],
+            choices=("auto", "pt", "safetensors", "npcache", "dummy"),
             help="The format of the model weights to load. "
             '"auto" will try to load the weights in the safetensors format '
             "and fall back to the pytorch bin format if safetensors format "
@@ -141,7 +142,7 @@ class ServerArgs:
             "--dtype",
             type=str,
             default=ServerArgs.dtype,
-            choices=["auto", "half", "float16", "bfloat16", "float", "float32"],
+            choices=("auto", "half", "float16", "bfloat16", "float", "float32"),
             help="Data type for model weights and activations.\n\n"
             '* "auto" will use FP16 precision for FP32 and FP16 models, and '
             "BF16 precision for BF16 models.\n"
@@ -196,7 +197,7 @@ class ServerArgs:
             "--schedule-heuristic",
             type=str,
             default=ServerArgs.schedule_heuristic,
-            choices=["lpm", "random", "fcfs", "dfs-weight"],
+            choices=("lpm", "random", "fcfs", "dfs-weight"),
             help="The scheduling heuristic.",
         )
         parser.add_argument(
@@ -264,10 +265,10 @@ class ServerArgs:
             type=str,
             default=ServerArgs.load_balance_method,
             help="The load balancing strategy for data parallelism.",
-            choices=[
+            choices=(
                 "round_robin",
                 "shortest_queue",
-            ],
+            ),
         )
 
         # Multi-node distributed serving args
@@ -321,7 +322,11 @@ class ServerArgs:
 
     @classmethod
     def from_cli_args(cls, args: argparse.Namespace):
-        attrs = [attr.name for attr in dataclasses.fields(cls)]
+        # Use precomputed field names to avoid repeated dataclasses.fields calls
+        try:
+            attrs = cls._FIELD_NAMES  # type: ignore[attr-defined]
+        except AttributeError:
+            attrs = tuple(f.name for f in dataclasses.fields(cls))
         return cls(**{attr: getattr(args, attr) for attr in attrs})
 
     def url(self):
@@ -343,3 +348,7 @@ class PortArgs:
     controller_port: int
     detokenizer_port: int
     nccl_ports: List[int]
+
+# Precompute dataclass field names once to speed up from_cli_args
+# and avoid repeated introspection overhead.
+ServerArgs._FIELD_NAMES = tuple(ServerArgs.__dataclass_fields__.keys())  # type: ignore[attr-defined]
