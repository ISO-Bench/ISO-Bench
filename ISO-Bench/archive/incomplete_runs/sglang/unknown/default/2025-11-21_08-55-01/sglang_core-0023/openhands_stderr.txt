OpenAI Codex v0.60.1 (research preview)
--------
workdir: /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023
model: gpt-5
provider: openai
approval: never
sandbox: danger-full-access
reasoning effort: high
reasoning summaries: auto
session id: 019aa4ac-0fbc-7c71-8408-308002619742
--------
user
I've uploaded a python code repository in the directory /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023.
Consider the following test script showing an example usage of the repository:

<test_script>
# This is a performance optimization task
# The specific operations to optimize are in the files listed below
# Focus on performance improvements in the target functions

</test_script>

Can you help me implement the necessary changes to the repository so that the runtime of the <test_script> is optimized?

Basic guidelines:
1. Your task is to make changes to non-test files in the /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 directory to improve the performance of the <test_script>.
2. Make changes while ensuring the repository is functionally equivalent to the original.
3. Do not overoptimize for just the specific inputs in <test_script>. Make general performance improvements for the usage scenario shown.
4. You may need to rebuild the repo for your changes to take effect before testing. Some rebuilds may take time to run, so be patient with running them.

Follow these steps to improve performance:
1. As a first step, explore the repository structure.
2. Create a script ONLY inside /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/.bench_scratch (e.g., /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/.bench_scratch/test_opt.py) to reproduce and time the example, then execute it with python <filename.py> from the repo root.
3. Edit the source code of the repository to improve performance.
4. Rebuild and rerun your script to confirm that performance has improved.

Here is an example of the kind of optimizations that have been shown to improve performance in this codebase:

<example_optimization_diff>
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a..2cd64d532 100644
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -1628,7 +1628,7 @@ class DeepseekV2ForCausalLM(nn.Module):
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
                         names_to_remove += [shared_expert_weight_name]
</example_optimization_diff>

IMPORTANT: The above diff is an EXAMPLE of optimizations that were successful in a different context.
These changes have NOT been applied to your codebase yet.
Your task is to:
1. Understand the optimization pattern shown (e.g., torch.zeros → torch.empty)
2. Look at the CURRENT code in the target files
3. Find places where you can apply SIMILAR optimizations
4. MAKE THE CHANGES yourself using str_replace_editor

The codebase you're working with is at the BASE commit - it does NOT have these optimizations yet.
You need to IMPLEMENT similar optimizations yourself.

HERE'S WHAT YOU NEED TO DO:
1. The files CURRENTLY contain torch.zeros() calls that need optimization
2. You need to CHANGE torch.zeros to torch.empty where appropriate
3. You need to REMOVE .fill_() operations that are unnecessary
4. These are NEW changes you're making - not already in the code

START WITH THIS COMMAND to see what needs changing:
```bash
grep -n 'torch.zeros\|fill_' vllm/model_executor/layers/fused_moe/moe_align_block_size.py benchmarks/kernels/benchmark_moe_align_block_size.py
```

CRITICAL: You MUST make actual code changes. Look for patterns like:
- Analyze the target files for performance bottlenecks
- Look for unnecessary memory allocations or initializations
- Consider more efficient algorithms or data structures

Target files to optimize:
- python/sglang/srt/models/deepseek_v2.py

IMPORTANT: You MUST make actual code changes to at least one file.
The task will fail if no files are modified.

## Constraints
- No public API breakage
- All TestPack checks must pass

## Target Files (ONLY modify these)
- `python/sglang/srt/models/deepseek_v2.py`

## SPECIFIC OPTIMIZATION TARGETS:
Based on the human commit analysis, focus on these areas:
- Memory allocation patterns (torch.zeros vs torch.empty)
- Tensor initialization strategies
- Kernel parameter optimization
- Buffer reuse and caching

### Human Developer's Approach:
```
Speedup shared expert weight construction by avoid cloning (#5188)
```

### Files Modified (statistics):
```
python/sglang/srt/models/deepseek_v2.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
```

## IMMEDIATE ACTION REQUIREMENTS:
1. Start editing files by iteration 3
2. Create and run /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/.bench_scratch/test_opt.py before and after edits (do not create timing scripts outside /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/.bench_scratch)
3. Make at least 3 concrete optimizations
4. Commit changes by iteration 8
5. Use finish command by iteration 10

## TASK COMPLETION COMMAND:
When you have made optimizations:
```bash
git add -A
git reset -q .bench_scratch || true
git commit -m 'Optimize MoE align sum kernels performance'
git diff $(git merge-base HEAD origin/HEAD || git rev-parse HEAD~1) -- . ':(exclude).bench_scratch' > /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/model_patch.diff || true
finish
```

START IMPLEMENTING IMMEDIATELY. NO MORE ANALYSIS.

mcp startup: no servers


thinking
**Optimizing code repository**

I need to optimize code in the repository sglang_core-0023. The instructions tell me to search for torch.zeros or fill_ in specific files like moe_align_block_size.py, but I should only modify deepseek_v2.py. The search might lead me to vllm files, but I can adapt. The optimization involves removing clone operations when copying weights_dict, changing torch.zeros to torch.empty, and speeding up weight construction by avoiding cloning. I’ll run through the steps: explore, create a test script, execute, edit the source, rebuild, and commit with the appropriate message.
thinking
**Starting repository exploration**

I need to begin with the tool preamble message before executing any shell commands, as per the guidelines. I'll start by exploring the repository using the rg command to find occurrences of torch.zeros and fill_, while also opening the deepseek_v2.py file. Additionally, I'll search for any unnecessary clone() uses. Finally, I’ll proceed with shell commands like ls and rg to get the necessary information. Let's get this process rolling!
codex
I’ll scan the repository for torch.zeros/fill_ patterns and inspect deepseek_v2.py for similar optimization opportunities, then create a timing script in .bench_scratch to benchmark before/after.
exec
bash -lc 'ls -la' in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 10ms:
total 108
drwxrwxr-x  15 ubuntu ubuntu  4096 Nov 21 04:28 .
drwxrwxr-x 105 ubuntu ubuntu  4096 Nov 21 04:28 ..
-rw-rw-r--   1 ubuntu ubuntu    35 Nov 21 04:28 .clang-format-ignore
drwxrwxr-x   2 ubuntu ubuntu  4096 Nov 21 04:28 .devcontainer
-rw-rw-r--   1 ubuntu ubuntu   341 Nov 21 04:28 .editorconfig
-rw-rw-r--   1 ubuntu ubuntu    75 Nov 21 04:28 .git
drwxrwxr-x   4 ubuntu ubuntu  4096 Nov 21 04:28 .github
-rw-rw-r--   1 ubuntu ubuntu  3650 Nov 21 04:28 .gitignore
-rw-rw-r--   1 ubuntu ubuntu     0 Nov 21 04:28 .gitmodules
-rw-rw-r--   1 ubuntu ubuntu    50 Nov 21 04:28 .isort.cfg
-rw-rw-r--   1 ubuntu ubuntu  1369 Nov 21 04:28 .pre-commit-config.yaml
drwxrwxr-x   3 ubuntu ubuntu  4096 Nov 21 04:28 3rdparty
-rw-rw-r--   1 ubuntu ubuntu 11346 Nov 21 04:28 LICENSE
-rw-rw-r--   1 ubuntu ubuntu  1720 Nov 21 04:28 Makefile
-rw-rw-r--   1 ubuntu ubuntu  6545 Nov 21 04:28 README.md
drwxrwxr-x   2 ubuntu ubuntu  4096 Nov 21 04:28 assets
drwxrwxr-x  32 ubuntu ubuntu  4096 Nov 21 04:28 benchmark
drwxrwxr-x   2 ubuntu ubuntu  4096 Nov 21 04:28 docker
drwxrwxr-x  10 ubuntu ubuntu  4096 Nov 21 04:28 docs

thinking
**Searching for specific patterns**

I need to locate instances of `torch.zeros` and `fill_` in specific files and also across the entire repository. The instruction to "START WITH THIS COMMAND" directs me to a potential path for vllm that may not be available here. Nonetheless, I can use `grep` to search for those patterns within our repo. I plan to run `ripgrep` targeting `torch.zeros` and `fill_`, particularly in the `deepseek_v2.py` file within the Python directory.
exec
bash -lc "rg -n \"torch\\.zeros|fill_\\(|clone\\(\\)\" -S python | head -n 200" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 17ms:
python/sglang/test/test_block_fp8.py:300:    C = torch.zeros(C_shape, dtype=torch.float32, device=A.device)
python/sglang/test/test_block_fp8.py:422:    out = torch.zeros(B * topk, w2.shape[1], dtype=a.dtype, device=a.device)
python/sglang/test/attention/test_flashattn_backend.py:48:                "req_to_token": torch.zeros(
python/sglang/srt/distributed/device_communicators/shm_broadcast.py:107:                torch.frombuffer(metadata_buffer, dtype=torch.uint8).fill_(0)
python/sglang/test/attention/test_flashattn_mla_backend.py:43:                "req_to_token": torch.zeros(
python/sglang/srt/sampling/penaltylib/min_new_tokens.py:50:        self.stop_token_penalties = torch.zeros(
python/sglang/srt/sampling/penaltylib/min_new_tokens.py:67:        self.len_output_tokens = torch.zeros(
python/sglang/srt/sampling/sampling_batch_info.py:102:                    torch.zeros(len(reqs), dtype=torch.bool)
python/sglang/srt/sampling/sampling_batch_info.py:178:            self.linear_penalty = torch.zeros(
python/sglang/srt/sampling/sampling_batch_info.py:256:                else torch.zeros(bs1, dtype=torch.bool, device=device)
python/sglang/srt/sampling/sampling_batch_info.py:261:                else torch.zeros(bs2, dtype=torch.bool, device=device)
python/sglang/srt/mem_cache/radix_cache.py:185:            page_aligned_kv_indices = kv_indices[:page_aligned_len].clone()
python/sglang/srt/mem_cache/radix_cache.py:189:            page_aligned_kv_indices = kv_indices.clone()
python/sglang/srt/mem_cache/radix_cache.py:215:            page_aligned_kv_indices = kv_indices[:page_aligned_len].clone()
python/sglang/srt/mem_cache/radix_cache.py:218:            page_aligned_kv_indices = kv_indices.clone()
python/sglang/srt/sampling/penaltylib/frequency_penalty.py:25:        self.cumulated_frequency_penalties = torch.zeros(
python/sglang/srt/distributed/device_communicators/pynccl.py:114:            data = torch.zeros(1, device=device)
python/sglang/srt/mem_cache/memory_pool.py:64:            self.req_to_token = torch.zeros(
python/sglang/srt/mem_cache/memory_pool.py:249:                torch.zeros(
python/sglang/srt/mem_cache/memory_pool.py:257:                torch.zeros(

thinking
**Searching for specific occurrences**

I'm looking into the ripgrep output, which got truncated after 200 lines. It hasn't shown any occurrences for the target file deepseek_v2.py yet—maybe there just aren't any mentions of torch.zeros inside it, or the output got cut off early. So, I'm thinking I should search specifically for deepseek_v2.py to check for anything related to "clone" or "zeros." This way, I can pinpoint what I'm trying to find!
exec
bash -lc "rg -n \"zeros\\(|fill_\\(|clone\\(|torch\\.empty\\(\" -S python/sglang/srt/models/deepseek_v2.py || true" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 12ms:
170:            torch.empty((config.n_routed_experts, config.hidden_size))
174:                torch.empty((config.n_routed_experts))
318:        topk_weights = torch.empty(
849:        attn_output = torch.empty(
861:            attn_logits = torch.empty(
966:            k = torch.empty(
1631:                                weights_dict[shared_expert_weight_name].clone(),
exec
bash -lc "rg -n \"\\.clone\\(\\)\" -S python/sglang/srt/models/deepseek_v2.py | sed -n '1,200p'" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 11ms:
1631:                                weights_dict[shared_expert_weight_name].clone(),

thinking
**Evaluation of file optimizations**

I see there's only one clone in the specified file, and we need at least three optimizations within "deepseek_v2.py." The constraints only allow modifications to this file. I noticed we're using torch.empty in several places, but there might also be potential for optimizing torch.zeros that are not specifically in this file. I'll focus on finding further micro-optimizations, like avoiding unnecessary memory operations or datatype conversions. I'll go ahead and open the file for inspection.
exec
bash -lc "sed -n '1,220p' python/sglang/srt/models/deepseek_v2.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 10ms:
# Copyright 2023-2024 SGLang Team
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

# Adapted from:
# https://github.com/vllm-project/vllm/blob/fb6af8bc086328ca6659e72d11ffd4309ce4de22/vllm/model_executor/models/deepseek_v2.py
"""Inference-only DeepseekV2 model."""

import logging
import os
exec
bash -lc "sed -n '220,520p' python/sglang/srt/models/deepseek_v2.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 10ms:
            top_k=config.num_experts_per_tok + min(self.n_share_experts_fusion, 1),
            hidden_size=config.hidden_size,
            intermediate_size=config.moe_intermediate_size,
            renormalize=config.norm_topk_prob,
            quant_config=quant_config,
            use_grouped_topk=True,
            num_expert_group=config.n_group,
            topk_group=config.topk_group,
            correction_bias=self.gate.e_score_correction_bias,
            routed_scaling_factor=self.routed_scaling_factor,
            prefix=add_prefix("experts", prefix),
            **(
                dict(deepep_mode=DeepEPMode[global_server_args_dict["deepep_mode"]])
                if global_server_args_dict["enable_deepep_moe"]
                else {}
            ),
        )

        if config.n_shared_experts is not None and self.n_share_experts_fusion == 0:
            intermediate_size = config.moe_intermediate_size * config.n_shared_experts
exec
bash -lc "sed -n '520,1040p' python/sglang/srt/models/deepseek_v2.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 9ms:
            prefix=add_prefix("attn_mqa", prefix),
        )

        self.attn_mha = RadixAttention(
            self.num_local_heads,
            self.qk_nope_head_dim + self.qk_rope_head_dim,
            self.scaling,
            num_kv_heads=self.num_local_heads,
            layer_id=layer_id,
            v_head_dim=self.v_head_dim,
            quant_config=quant_config,
            prefix=add_prefix("attn_mha", prefix),
        )

        self.w_kc = None
        self.w_vc = None
        self.w_scale = None

        self.w_scale_k = None
        self.w_scale_v = None
exec
bash -lc "sed -n '1040,1560p' python/sglang/srt/models/deepseek_v2.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 10ms:
            # Only initialize the info once
            if forward_batch.num_prefix_chunks is None:
                forward_batch.prepare_chunked_prefix_cache_info(q.device)

            forward_batch.set_attn_attend_prefix_cache(True)
            attn_output = self._chunked_prefix_attn_mha(
                q=q,
                accum_output=attn_output,
                accum_lse=lse,
                forward_batch=forward_batch,
            )

        attn_output = attn_output.reshape(-1, self.num_local_heads * self.v_head_dim)
        output, _ = self.o_proj(attn_output)
        return output


class _FFNInputMode(Enum):
    # The MLP sublayer requires 1/tp_size tokens as input
    SCATTERED = auto()
exec
bash -lc "sed -n '1560,2120p' python/sglang/srt/models/deepseek_v2.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 10ms:
            ).split([self_attn.qk_nope_head_dim, self_attn.v_head_dim], dim=1)
            if not use_deep_gemm_bmm:
                self_attn.w_kc = w_kc.transpose(1, 2).contiguous().transpose(1, 2)
                self_attn.w_vc = w_vc.contiguous().transpose(1, 2)
                if (
                    hasattr(self_attn.kv_b_proj, "weight_scale")
                    and self_attn.w_scale is None
                ):
                    self_attn.w_scale = self_attn.kv_b_proj.weight_scale
                    if _is_hip:
                        self_attn.w_scale *= 2.0
            else:
                num_tiles_k = self_attn.qk_nope_head_dim // weight_block_size[1]
                num_tiles_n = self_attn.v_head_dim // weight_block_size[0]
                ws_kc, ws_vc = block_scale.unflatten(
                    0, (-1, (num_tiles_k + num_tiles_n))
                ).split([num_tiles_k, num_tiles_n], dim=1)
                self_attn.w_scale_k = ws_kc.transpose(1, 2).contiguous()
                self_attn.w_scale_v = ws_vc.contiguous()
                self_attn.w_kc = w_kc.transpose(1, 2).contiguous()






thinking
**Optimizing cloning lines**

I've identified that the cloning lines are around 1631, but there's also mention of them later around 1720. After examining the file sequence, I see the cloning is related to load_weights in DeepseekV2MoE within the 1560-1720 range. I can optimize this by removing the .clone() to avoid unnecessary allocation. Also, I need to implement at least three optimizations. I'll check for replacing torch.zeros with torch.empty and assess where empty_like might be better for memory efficiency. Looking for redundant operations will be important too.
thinking
**Examining memory layout optimizations**

I’m noticing many .contiguous() calls might be necessary for memory layout. In forward_normal_chunked_kv, they create k with torch.empty_like(q) and then fill from k_nope and k_pe, which looks good. I need to check for zero allocations used just for filling, like topk_weights initialized with torch.empty, which is already empty. I verified there are no torch.zeros or fill_ calls in this file.

Additional optimizations could involve the calls to transpose(1, 2).contiguous().transpose(1, 2), which might not be needed. It seems they ensure contiguity along the last dimension. A simpler option could be w_kc.contiguous(). I'll dig into it more.
thinking
**Reviewing weight memory optimizations**

I’m checking the shape of w_kc, which seems to be (tile?, dim). They use transpose(1, 2).contiguous().transpose(1, 2) to make the last dimension contiguous, which is a common trick. It looks like just using contiguous can ensure memory contiguity too, but there might be a copy produced. If w_kc is already contiguous along dimension 1, I'm curious why they use the transpose trick.

In the load_weights function, they replicate weights using .clone(), which is expensive, so I can skip that. We need three optimizations, and I can also optimize by using weights_list as a dictionary to reduce repeated creations. I’ll keep looking for places to avoid clones.
thinking
**Investigating memory allocation in DeepseekV2**

I noticed in DeepseekV2AttentionMLA.forward_absorb, they create torch.empty or zeros. I should look for torch.full((0, top_k), -1, dtype=torch.int, device=...) to see if there's room for optimization. Using dtype torch.int32 could be beneficial, but it seems torch.int is already int32 on CPU and CUDA. That makes sense.

I want to check for any unnecessary .to(torch.bfloat16) conversions as well. I need to focus on memory allocation patterns and buffer reuse. For example, in forward_normal_chunked_kv, k is allocated with torch.empty_like(q) and later filled, which looks fine. I'll also look into forward_normal, where attn_output is allocated as torch.empty. Let's search for all occurrences of "torch.empty(" to analyze and potentially adjust for device arguments.
thinking
**Exploring optimization opportunities**

I’m considering optimizations in the DeepseekV2 code. For example, Tqdm can have 'disable=True' when not needed, but I worry about changing user experience too much.

There are potential improvements, like appending weights without cloning. We need to think through the weight loading process carefully. I also noticed some possible micro-optimizations within loops, like minimizing attribute lookups and avoiding repeated string concatenations.

Additionally, in forward_normal_chunked_kv, I could evaluate memory usage more effectively. I want to consider precomputing certain values outside heavy loops, and I need to focus on keeping function integrity while making optimizations.
thinking
**Optimizing buffer allocation in DeepseekV2**

I'm looking into optimizing the buffer allocation for prefix chunks in DeepseekV2, specifically regarding the kv indices which may vary in shape. Instead of creating new buffers like 'tmp_output' and 'tmp_lse' in each loop iteration, I can preallocate them once outside the loop and alternate between the two to reduce overhead.

This would mean creating two temp buffers and using them based on whether the iteration is odd or even. I need to ensure that the shapes of 'accum_output' and 'accum_lse' remain known before the loop, which they do. This approach should improve efficiency without altering functionality. Also, I want to explore other minor optimizations in the code.
exec
bash -lc "rg -n \"fill_\\(\" -S python/sglang/srt/models/deepseek_v2.py || true" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 11ms:

exec
bash -lc "sed -n '1,200p' python/sglang/srt/managers/schedule_batch.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 11ms:
from __future__ import annotations

import hashlib
from enum import Enum, auto

# Copyright 2023-2024 SGLang Team
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""
Store information about requests and batches.
exec
bash -lc "rg -n \"class DeepseekV2ForCausalLM\" python/sglang/srt/models/deepseek_v2.py && sed -n '1320,1680p' python/sglang/srt/models/deepseek_v2.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 12ms:
1402:class DeepseekV2ForCausalLM(nn.Module):
            hidden_states += residual
            residual = None
            hidden_states, local_hidden_states = (
                forward_batch.gathered_buffer[: forward_batch.input_ids.shape[0]],
                hidden_states,
            )
            tp_all_gather(
                list(hidden_states.tensor_split(self.attn_tp_size)), local_hidden_states
            )

        return hidden_states, residual


class DeepseekV2Model(nn.Module):
    fall_back_to_pt_during_load = False

    def __init__(
        self,
        config: PretrainedConfig,






thinking
**Evaluating code dependencies**

I'm considering that if `n_routed_experts` is set to None, that could cause the code to break. The initial condition checks if `self.n_share_experts_fusion` is greater than 0, but the code uses `expert_params_mapping` regardless of that check. This is potentially problematic because it relies on `self.config.n_routed_experts`. I realize I can't load weights if that parameter is None, so I'll need to assign it a small integer, like 2, to ensure proper functioning.
thinking
**Exploring MoE module concerns**

I'm looking at the FusedMoE or EPMoE modules, which are imported from `sglang.srt.layers.moe.fused_moe_triton`. It seems like they might require a GPU environment and compiled kernels. The code constructs the module but doesn't perform any forwarding, which could still result in importing compiled extensions. If we're in a CPU environment, issues could arise. However, it appears that our environment likely supports a GPU. To avoid complications with creating heavy MoE modules, I could instantiate `DeepseekV2ForCausalLM` while keeping `config.n_routed_experts` small and not None.
thinking
**Assessing weight loading issues**

I'm thinking about how `load_weights` relies on `expert_params_mapping` to understand the mapping for experts. It calls `MoEImpl.make_expert_params_mapping`, which might work independently of other factors. This may exist within the FusedMoE classes. To avoid pulling in heavier imports, I could set `global_server_args_dict["enable_deepep_moe"]` and `enable_ep_moe` to False. The import of FusedMoE could bring in triton dependencies, but the mapping method itself might not require them. It seems this repository is configured to handle these imports properly.
thinking
**Exploring alternative testing methods**

To avoid heavy instantiation of the model, I could test the replicating algorithm by invoking `DeepseekV2ForCausalLM.load_weights`, which uses object attributes like config. Instead, I might focus on constructing a minimal object to test the function, though that could get messy. Since the test harness measures performance rather than in-depth functionality, I could write a script that uses the modified code by importing the module and computing something. The performance improvement might not be directly measurable, but the evaluation will check file changes and script execution time. I’ll create a small config and run `load_weights` with a larger synthetic weights list to stress-test the replication code.
thinking
**Optimizing testing strategy**

Instead of fully instantiating the model, I could test by importing the module and calling a method while providing a minimal `params_dict` to avoid a KeyError. This may require creating a simple model structure that includes MoE layer parameters. However, I can set `global_server_args_dict["enable_deepep_moe"]` to control the instantiation of heavy components. A straightforward way could involve creating a subclass to override `load_weights`, though that’s not allowed. Instead, I’ll construct an instance of `DeepseekV2ForCausalLM` using `__new__` to set only the necessary attributes without heavy initialization, and then call `load_weights`. This should allow me to effectively measure performance and reflect on any changes made within the code.
thinking
**Implementing test script**

I need to ensure that `post_load_weights` and other methods don’t invoke unintentionally. The `load_weights` method calls `self.post_load_weights()` at the end, which I want to avoid by raising an exception in `make_expert_params_mapping`. I’ll create a `DummyConfig` class with necessary attributes, and for quant_config, I’ll use a `DummyQuantConfig` that returns "w8a8_int8".

Next, I’ll build an initial weights list simulating heavy replication, ensuring keys like 'model.layers.{layer}.mlp.shared_experts.{suffix}' exist. Then, I’ll monkey-patch `FusedMoE.make_expert_params_mapping` to raise an exception, and call `model.load_weights(weights)` in a try/except block, measuring how long it takes. Finally, I’ll create the script to run before and after the code modifications to track any performance differences. Let's start coding!
exec
bash -lc "mkdir -p .bench_scratch && python - << 'PY'
import time
import torch
from types import SimpleNamespace

# Configure environment flags to use FusedMoE path
from sglang.srt.managers.schedule_batch import global_server_args_dict
global_server_args_dict[\"enable_deepep_moe\"] = False
global_server_args_dict[\"enable_ep_moe\"] = False

# Prepare minimal config and model instance without heavy init
from sglang.srt.models.deepseek_v2 import DeepseekV2ForCausalLM

# Create a bare instance without calling __init__
model = DeepseekV2ForCausalLM.__new__(DeepseekV2ForCausalLM)
# Minimal attributes required by load_weights' first block
model.n_share_experts_fusion = 8  # force replication path
model.quant_config = SimpleNamespace(get_name=lambda: \"w8a8_int8\")
model.config = SimpleNamespace(
    first_k_dense_replace=0,
    num_hidden_layers=32,
    moe_layer_freq=1,
    n_routed_experts=16,
)

# Build synthetic weights for shared experts
if model.quant_config.get_name() == \"w8a8_int8\":
    suffix_list = [
        \"down_proj.weight\",
        \"down_proj.weight_scale\",
        \"gate_proj.weight\",
        \"gate_proj.weight_scale\",
        \"up_proj.weight\",
        \"up_proj.weight_scale\",
    ]
else:
    suffix_list = [
        \"down_proj.weight\",
        \"down_proj.weight_scale_inv\",
        \"gate_proj.weight\",
        \"gate_proj.weight_scale_inv\",
        \"up_proj.weight\",
        \"up_proj.weight_scale_inv\",
    ]

weights = []
for layer in range(model.config.num_hidden_layers):
    for suffix in suffix_list:
        name = f\"model.layers.{layer}.mlp.shared_experts.{suffix}\"
        # Small placeholder tensors
        if suffix.endswith(\"weight\"):
            t = torch.randn(8, 8)
        else:
            t = torch.randn(8)
        weights.append((name, t))

# Monkey-patch to stop right after replication step to avoid heavy work
from sglang.srt.layers.moe.fused_moe_triton import FusedMoE

class StopAfterReplication(Exception):
    pass

def stop_make_expert_params_mapping(*args, **kwargs):
    raise StopAfterReplication

FusedMoE.make_expert_params_mapping_backup = FusedMoE.make_expert_params_mapping
FusedMoE.make_expert_params_mapping = staticmethod(stop_make_expert_params_mapping)

# Timing helper
def run_once():
    start = time.perf_counter()
    try:
        DeepseekV2ForCausalLM.load_weights(model, list(weights))
    except StopAfterReplication:
        pass
    finally:
        # restore patch just in case
        FusedMoE.make_expert_params_mapping = FusedMoE.make_expert_params_mapping_backup
    return time.perf_counter() - start

# Warmup
run_once()
# Measure
times = [run_once() for _ in range(5)]
print({\"iters\": len(times), \"avg_s\": sum(times)/len(times), \"runs\": times})
PY" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 exited 1 in 1.44s:
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
Traceback (most recent call last):
  File "<stdin>", line 6, in <module>
ModuleNotFoundError: No module named 'sglang.srt'

thinking
I'm facing an issue with the environment not being able to import the module path 'sglang.srt'. It seems the repository 'python' isn't included in sys.path. To fix this, I can adjust the script to add the local repository 'python' directory to sys.path. Essentially, I need to combine the repository root '/home/ubuntu/...' with '/python' to include the correct path. I'll modify the script accordingly to ensure it's set up right!
exec
bash -lc "python - << 'PY'
import time, sys, os
repo_root = os.getcwd()
sys.path.insert(0, os.path.join(repo_root, 'python'))
import torch
from types import SimpleNamespace

# Configure environment flags to use FusedMoE path
from sglang.srt.managers.schedule_batch import global_server_args_dict
global_server_args_dict[\"enable_deepep_moe\"] = False
global_server_args_dict[\"enable_ep_moe\"] = False

# Prepare minimal config and model instance without heavy init
from sglang.srt.models.deepseek_v2 import DeepseekV2ForCausalLM

# Create a bare instance without calling __init__
model = DeepseekV2ForCausalLM.__new__(DeepseekV2ForCausalLM)
# Minimal attributes required by load_weights' first block
model.n_share_experts_fusion = 8  # force replication path
model.quant_config = SimpleNamespace(get_name=lambda: \"w8a8_int8\")
model.config = SimpleNamespace(
    first_k_dense_replace=0,
    num_hidden_layers=32,
    moe_layer_freq=1,
    n_routed_experts=16,
)

# Build synthetic weights for shared experts
if model.quant_config.get_name() == \"w8a8_int8\":
    suffix_list = [
        \"down_proj.weight\",
        \"down_proj.weight_scale\",
        \"gate_proj.weight\",
        \"gate_proj.weight_scale\",
        \"up_proj.weight\",
        \"up_proj.weight_scale\",
    ]
else:
    suffix_list = [
        \"down_proj.weight\",
        \"down_proj.weight_scale_inv\",
        \"gate_proj.weight\",
        \"gate_proj.weight_scale_inv\",
        \"up_proj.weight\",
        \"up_proj.weight_scale_inv\",
    ]

weights = []
for layer in range(model.config.num_hidden_layers):
    for suffix in suffix_list:
        name = f\"model.layers.{layer}.mlp.shared_experts.{suffix}\"
        # Small placeholder tensors
        if suffix.endswith(\"weight\"):
            t = torch.randn(8, 8)
        else:
            t = torch.randn(8)
        weights.append((name, t))

# Monkey-patch to stop right after replication step to avoid heavy work
from sglang.srt.layers.moe.fused_moe_triton import FusedMoE

class StopAfterReplication(Exception):
    pass

def stop_make_expert_params_mapping(*args, **kwargs):
    raise StopAfterReplication

FusedMoE.make_expert_params_mapping_backup = FusedMoE.make_expert_params_mapping
FusedMoE.make_expert_params_mapping = staticmethod(stop_make_expert_params_mapping)

# Timing helper
def run_once():
    # Re-patch each run (load_weights restores on exit)
    FusedMoE.make_expert_params_mapping = staticmethod(stop_make_expert_params_mapping)
    start = time.perf_counter()
    try:
        DeepseekV2ForCausalLM.load_weights(model, list(weights))
    except StopAfterReplication:
        pass
    finally:
        # restore patch just in case
        FusedMoE.make_expert_params_mapping = FusedMoE.make_expert_params_mapping_backup
    return time.perf_counter() - start

# Warmup
run_once()
# Measure
times = [run_once() for _ in range(5)]
print({\"iters\": len(times), \"avg_s\": sum(times)/len(times), \"runs\": times})
PY" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 exited 1 in 4.93s:
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
Traceback (most recent call last):
  File "<stdin>", line 8, in <module>
  File "/home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/python/sglang/srt/managers/schedule_batch.py", line 46, in <module>
    from sglang.srt.configs.model_config import ModelConfig
  File "/home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/python/sglang/srt/configs/model_config.py", line 26, in <module>
    from sglang.srt.layers.quantization import QUANTIZATION_METHODS
  File "/home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/python/sglang/srt/layers/quantization/__init__.py", line 54, in <module>
    from sglang.srt.layers.quantization.awq import AWQConfig
  File "/home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/python/sglang/srt/layers/quantization/awq.py", line 6, in <module>
    from sgl_kernel import awq_dequantize
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/sgl_kernel/__init__.py", line 5, in <module>
    common_ops = _load_architecture_specific_ops()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/sgl_kernel/load_utils.py", line 188, in _load_architecture_specific_ops
    raise ImportError(error_msg)
ImportError:
[sgl_kernel] CRITICAL: Could not load any common_ops library!



thinking
**Troubleshooting import issues**

I’m running into problems because the `sgl_kernel` can’t load GPU libraries, and this is causing import failures. The repository’s code requires `awq_dequantize`, which leads to the need for `sgl_kernel`. To fix this, I have to ensure that I’m not importing modules that depend on `sgl_kernel`.

However, `schedule_batch` triggers a chain of imports, including `quantization` and `awq`, leading to the same issue. Even using conditional imports from `deepseek_v2.py` doesn't solve it, since `schedule_batch` is imported at the top. I need to find a way around this, maybe by setting an environment variable or mocking `awq_dequantize`.
thinking
**Exploring environment variables**

I’m considering if I can set an environment variable to disable the `sgl_kernel` imports. That might help avoid the import issues I've been facing. Next, I think I should take a closer look at `quantization/__init__.py` to understand how `awq` is being loaded. This could give me more insight into how to prevent `sgl_kernel` from being required in the first place, thus resolving the import conflicts. Let's dig into it!
exec
bash -lc "sed -n '1,200p' python/sglang/srt/layers/quantization/__init__.py" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 9ms:
# Adapted from https://raw.githubusercontent.com/vllm-project/vllm/v0.5.5/vllm/model_executor/layers/quantization/__init__.py
import builtins
import inspect
import re
from copy import deepcopy
from typing import Callable, Dict, Optional, Type, Union

import torch

try:
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
    from vllm.model_executor.layers.quantization.awq_marlin import (
        AWQMarlinConfig,
        AWQMoEMethod,
    )
    from vllm.model_executor.layers.quantization.bitsandbytes import BitsAndBytesConfig
    from vllm.model_executor.layers.quantization.compressed_tensors.compressed_tensors_moe import (
        CompressedTensorsW8A8Fp8MoEMethod,
        CompressedTensorsWNA16MoEMethod,
    )


thinking
**Considering script optimization**

I'm thinking that the harness may just need the script to exist and run quickly. It seems that the performance improvement check might be manual. In this system, we might not run tests before regression, though instructions suggest we should run them both before and after. I plan to implement a script with two functions: 'baseline' using clone and 'optimized' using view alias, and I'll time both. But the real optimization lies in modifying deepseek_v2.py.
thinking
**Creating optimization script**

Alright, I'll create a script named `.bench_scratch/test_opt.py` that will emulate the "replicate shared expert weights" process, comparing clones versus no clones. I plan to time both functions to measure improvement when not using clones. After we modify `deepseek_v2.py` to avoid clones, the actual code should align with our "optimized" function. So, let’s proceed with creating the script based on this plan!
file update
A /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/.bench_scratch/test_opt.py
import os
import sys
import time
import torch

# This micro-benchmark simulates the shared expert weight replication logic
# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
# 1) Baseline: replicate tensors using .clone()
# 2) Optimized: reuse the same tensor reference (no clone)
#
# We avoid importing the full sglang stack here to keep the benchmark runnable
# in a minimal environment without GPU kernels.


def build_weights(num_layers: int, suffix_list):
    weights = []
    for layer in range(num_layers):
        for suffix in suffix_list:
            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
            # Use modest sizes to keep the benchmark quick but non-trivial
            if suffix.endswith("weight"):
                t = torch.randn(512, 512, dtype=torch.bfloat16)
            else:
                t = torch.randn(512, dtype=torch.bfloat16)
            weights.append((name, t))
    return weights


def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
    weights_list = list(weights)
    weights_dict = dict(weights_list)
    names_to_remove = []
    for moe_layer in range(num_layers):
        for num_repeat in range(n_share_experts_fusion):
            for suffix in suffix_list:
                shared_expert_weight_name = (
                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                )
                weights_list.append(
                    (
                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
                        weights_dict[shared_expert_weight_name].clone(),
                    )
                )
                names_to_remove.append(shared_expert_weight_name)
    # filter out shared_experts entries
    names_to_remove = set(names_to_remove)
    return [w for w in weights_list if w[0] not in names_to_remove]


def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
    weights_list = list(weights)
    weights_dict = dict(weights_list)
    names_to_remove = set()
    for moe_layer in range(num_layers):
        for num_repeat in range(n_share_experts_fusion):
            for suffix in suffix_list:
                shared_expert_weight_name = (
                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                )
                weights_list.append(
                    (
                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
                        weights_dict[shared_expert_weight_name],
                    )
                )
                names_to_remove.add(shared_expert_weight_name)
    # filter out shared_experts entries
    return [w for w in weights_list if w[0] not in names_to_remove]


def time_fn(fn, *args, repeat=5):
    # Warmup
    fn(*args)
    times = []
    for _ in range(repeat):
        start = time.perf_counter()
        fn(*args)
        times.append(time.perf_counter() - start)
    return sum(times) / len(times), times


def main():
    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
    n_share = int(os.getenv("BENCH_SHARES", "8"))
    suffix_list = [
        "down_proj.weight",
        "down_proj.weight_scale",
        "gate_proj.weight",
        "gate_proj.weight_scale",
        "up_proj.weight",
        "up_proj.weight_scale",
    ]

    base_weights = build_weights(num_layers, suffix_list)

    t_base, runs_base = time_fn(
        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
    )
    t_opt, runs_opt = time_fn(
        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
    )

    print(
        {
            "layers": num_layers,
            "shares": n_share,
            "avg_s_baseline": t_base,
            "avg_s_optimized": t_opt,
            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
            "runs_baseline": runs_base,
            "runs_optimized": runs_opt,
        }
    )


if __name__ == "__main__":
    main()

apply_patch(auto_approved=true) exited 0 in 7ms:
Success. Updated the following files:
A .bench_scratch/test_opt.py
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+

file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+

exec
bash -lc 'python .bench_scratch/test_opt.py' in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 2.19s:
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
{'layers': 32, 'shares': 8, 'avg_s_baseline': 0.023391711604199374, 'avg_s_optimized': 0.0006970393966184929, 'speedup': 33.558665001832374, 'runs_baseline': [0.02373591200739611, 0.0232096090039704, 0.023279531000298448, 0.023374183001578785, 0.02335932300775312], 'runs_optimized': [0.0007039170013740659, 0.0006994279974605888, 0.0006857669941382483, 0.0007005569932516664, 0.0006955279968678951]}
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+


thinking
**Implementing code optimizations**

I’m really pleased that the script runs and shows over a 33x speedup for the optimized simulation! Next, I need to implement some code changes in deepseek_v2.py. I should remove the .clone() method where replicates are appended. It’ll also be helpful to replace the names_to_remove from a list to a set for better performance. Additionally, optimizing the _chunked_prefix_attn_mha by preallocating temporary buffers sounds like a good idea. Let's start implementing this patch!
file update
M /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/python/sglang/srt/models/deepseek_v2.py
@@ -1609,3 +1609,4 @@
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
@@ -1624,2 +1625,3 @@
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
@@ -1630,6 +1632,6 @@
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]
apply_patch(auto_approved=true) exited 0 in 10ms:
Success. Updated the following files:
M python/sglang/srt/models/deepseek_v2.py
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..b565584237df005d9df11b503aa6b7595e10ffc9
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -1607,7 +1607,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1623,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..b565584237df005d9df11b503aa6b7595e10ffc9
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -1607,7 +1607,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1623,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales


thinking
**Implementing optimizations**

I’m getting ready to implement ping-pong buffer optimization in the _chunked_prefix_attn_mha method. First, I need to locate this method in the code. Then I’ll modify the necessary lines accordingly. It’s important to approach this step carefully to ensure everything works smoothly after the tweaks. Let’s dive into the code and make those adjustments!
file update
M /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/python/sglang/srt/models/deepseek_v2.py
@@ -943,2 +943,8 @@
         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
@@ -979,6 +985,9 @@
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

apply_patch(auto_approved=true) exited 0 in 10ms:
Success. Updated the following files:
M python/sglang/srt/models/deepseek_v2.py
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales



thinking
**Evaluating optimizations**

I've identified two optimization sets that need to be supplemented with a third concrete optimization. We've already made three unique modifications: removing clones, using a set for names to remove, and preallocating ping-pong buffers.

I wonder if we should adjust the dtype of `topk_weights` to match the gating dtype, but that's optional. Although there are checks for `torch.zeros`, there aren't any in this file. It seems the only relevant thing is 'torch.full' for shape 0, which isn’t applicable.
thinking
**Reviewing code optimizations**

To ensure safety, I've considered removing unnecessary `.clone()` calls, but it looks like there aren't any clones left in the file. Instead, I may see some 'view(-1, self.num_local_heads, self.qk_head_dim)' sequences and a 'reshape,' but they don't seem redundant.

As for the 'torch.cuda.empty_cache()' in the `set_embed_and_head` method, it could slow things down, but it doesn't affect core functions and is called infrequently, so I'll leave it in place. I'll run the test script again to confirm everything is still functioning properly.
exec
bash -lc 'python .bench_scratch/test_opt.py' in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 2.19s:
/home/ubuntu/OmniPerf-Bench/bench-env/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
{'layers': 32, 'shares': 8, 'avg_s_baseline': 0.023248785000760108, 'avg_s_optimized': 0.0006809147977037356, 'speedup': 34.14345683066738, 'runs_baseline': [0.02333463099785149, 0.023296870000194758, 0.0231585670117056, 0.02324399899225682, 0.023209858001791872], 'runs_optimized': [0.0006915869889780879, 0.0006725069979438558, 0.0006935270066605881, 0.0006814569933339953, 0.0006654960016021505]}
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

exec
bash -lc 'git status --porcelain' in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 15ms:
 M python/sglang/srt/models/deepseek_v2.py
?? .bench_scratch/
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

exec
bash -lc "git add -A && git reset -q .bench_scratch || true && git commit -m 'Optimize MoE align sum kernels performance' && git diff "'$(git merge-base HEAD origin/HEAD || git rev-parse HEAD~1) -- . '"':(exclude).bench_scratch' > model_patch.diff || true && echo 'Committed and wrote model_patch.diff'" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 74ms:
[agent/sglang_core/5239d795 05094a00f] Optimize MoE align sum kernels performance
 Committer: Ubuntu <ubuntu@ip-172-31-16-122.ec2.internal>
Your name and email address were configured automatically based
on your username and hostname. Please check that they are accurate.
You can suppress this message by setting them explicitly. Run the
following command and follow the instructions in your editor to edit
your configuration file:

    git config --global --edit

After doing this, you may fix the identity used for this commit with:

    git commit --amend --reset-author

 1 file changed, 18 insertions(+), 7 deletions(-)
Committed and wrote model_patch.diff
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

Plan update
Implemented clone-avoidance for shared expert weights, switched removal list to a set for O(1) membership, and preallocated ping-pong buffers to avoid per-chunk allocations in chunked MHA. Added a runnable micro-benchmark to demonstrate the impact of clone removal. Committed changes and exported patch.
  ✓ Explore repository structure
  ✓ Add timing benchmark script
  ✓ Optimize deepseek_v2 weight cloning
  ✓ Preallocate buffers in chunked MHA
  ✓ Commit and export patch
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

exec
bash -lc finish in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 exited 127 in 9ms:
bash: line 1: finish: command not found
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

exec
bash -lc 'git diff $(git merge-base HEAD origin/HEAD || git rev-parse HEAD~1) -- . '"':(exclude).bench_scratch' > /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/model_patch.diff || true && ls -l model_patch.diff /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/model_patch.diff" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 51ms:
-rw-rw-r-- 1 ubuntu ubuntu 3206 Nov 21 04:32 /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023/model_patch.diff
-rw-rw-r-- 1 ubuntu ubuntu 3206 Nov 21 04:32 model_patch.diff
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

exec
bash -lc "nl -ba python/sglang/srt/models/deepseek_v2.py | sed -n '1600,1700p'" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 10ms:
  1600	            weights_dict = dict(weights_list)
  1601	            if self.quant_config.get_name() == "w8a8_int8":
  1602	                suffix_list = [
  1603	                    "down_proj.weight",
  1604	                    "down_proj.weight_scale",
  1605	                    "gate_proj.weight",
  1606	                    "gate_proj.weight_scale",
  1607	                    "up_proj.weight",
  1608	                    "up_proj.weight_scale",
  1609	                ]
  1610	            else:
  1611	                suffix_list = [
  1612	                    "down_proj.weight",
  1613	                    "down_proj.weight_scale_inv",
  1614	                    "gate_proj.weight",
  1615	                    "gate_proj.weight_scale_inv",
  1616	                    "up_proj.weight",
  1617	                    "up_proj.weight_scale_inv",
  1618	                ]
  1619	            # Use a set for O(1) membership checks and avoid duplicates
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

exec
bash -lc "nl -ba python/sglang/srt/models/deepseek_v2.py | sed -n '1040,1160p'" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 11ms:
  1040	        )
  1041
  1042	        # Do mha for extended part without prefix
  1043	        forward_batch.set_attn_attend_prefix_cache(False)
  1044	        attn_output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
  1045	        lse = torch.transpose(lse, 0, 1).contiguous()
  1046
  1047	        # Do mha attention with chunked prefix cache if there are any sequence with prefix
  1048	        if any(forward_batch.extend_prefix_lens_cpu):
  1049	            # Only initialize the info once
  1050	            if forward_batch.num_prefix_chunks is None:
  1051	                forward_batch.prepare_chunked_prefix_cache_info(q.device)
  1052
  1053	            forward_batch.set_attn_attend_prefix_cache(True)
  1054	            attn_output = self._chunked_prefix_attn_mha(
  1055	                q=q,
  1056	                accum_output=attn_output,
  1057	                accum_lse=lse,
  1058	                forward_batch=forward_batch,
  1059	            )
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

exec
bash -lc "nl -ba python/sglang/srt/models/deepseek_v2.py | sed -n '960,1080p'" in /home/ubuntu/OmniPerf-Bench/perf-agents-bench/.work/worktrees/sglang_core/sglang_core-0023 succeeded in 11ms:
   960
   961	            kv_a_normed, k_pe = latent_cache.split(
   962	                [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1
   963	            )
   964	            kv_a_normed = kv_a_normed.squeeze(1).contiguous()
   965	            kv = self.kv_b_proj(kv_a_normed)[0]
   966	            kv = kv.view(
   967	                -1, self.num_local_heads, self.qk_nope_head_dim + self.v_head_dim
   968	            )
   969	            v = kv[..., self.qk_nope_head_dim :]
   970	            k_nope = kv[..., : self.qk_nope_head_dim]
   971
   972	            k = torch.empty(
   973	                (
   974	                    k_nope.shape[0],
   975	                    self.num_local_heads,
   976	                    self.qk_nope_head_dim + self.qk_rope_head_dim,
   977	                ),
   978	                dtype=v.dtype,
   979	                device=v.device,
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py
new file mode 100644
index 0000000000000000000000000000000000000000..6670476bb6e815c9b89a3b61d6db8ba7039b224f
--- /dev/null
+++ b/.bench_scratch/test_opt.py
@@ -0,0 +1,119 @@
+import os
+import sys
+import time
+import torch
+
+# This micro-benchmark simulates the shared expert weight replication logic
+# in python/sglang/srt/models/deepseek_v2.py and compares two strategies:
+# 1) Baseline: replicate tensors using .clone()
+# 2) Optimized: reuse the same tensor reference (no clone)
+#
+# We avoid importing the full sglang stack here to keep the benchmark runnable
+# in a minimal environment without GPU kernels.
+
+
+def build_weights(num_layers: int, suffix_list):
+    weights = []
+    for layer in range(num_layers):
+        for suffix in suffix_list:
+            name = f"model.layers.{layer}.mlp.shared_experts.{suffix}"
+            # Use modest sizes to keep the benchmark quick but non-trivial
+            if suffix.endswith("weight"):
+                t = torch.randn(512, 512, dtype=torch.bfloat16)
+            else:
+                t = torch.randn(512, dtype=torch.bfloat16)
+            weights.append((name, t))
+    return weights
+
+
+def replicate_with_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = []
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name].clone(),
+                    )
+                )
+                names_to_remove.append(shared_expert_weight_name)
+    # filter out shared_experts entries
+    names_to_remove = set(names_to_remove)
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def replicate_without_clone(weights, num_layers: int, n_share_experts_fusion: int, suffix_list):
+    weights_list = list(weights)
+    weights_dict = dict(weights_list)
+    names_to_remove = set()
+    for moe_layer in range(num_layers):
+        for num_repeat in range(n_share_experts_fusion):
+            for suffix in suffix_list:
+                shared_expert_weight_name = (
+                    f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
+                )
+                weights_list.append(
+                    (
+                        f"model.layers.{moe_layer}.mlp.experts.{num_repeat}.{suffix}",
+                        weights_dict[shared_expert_weight_name],
+                    )
+                )
+                names_to_remove.add(shared_expert_weight_name)
+    # filter out shared_experts entries
+    return [w for w in weights_list if w[0] not in names_to_remove]
+
+
+def time_fn(fn, *args, repeat=5):
+    # Warmup
+    fn(*args)
+    times = []
+    for _ in range(repeat):
+        start = time.perf_counter()
+        fn(*args)
+        times.append(time.perf_counter() - start)
+    return sum(times) / len(times), times
+
+
+def main():
+    num_layers = int(os.getenv("BENCH_LAYERS", "32"))
+    n_share = int(os.getenv("BENCH_SHARES", "8"))
+    suffix_list = [
+        "down_proj.weight",
+        "down_proj.weight_scale",
+        "gate_proj.weight",
+        "gate_proj.weight_scale",
+        "up_proj.weight",
+        "up_proj.weight_scale",
+    ]
+
+    base_weights = build_weights(num_layers, suffix_list)
+
+    t_base, runs_base = time_fn(
+        replicate_with_clone, base_weights, num_layers, n_share, suffix_list
+    )
+    t_opt, runs_opt = time_fn(
+        replicate_without_clone, base_weights, num_layers, n_share, suffix_list
+    )
+
+    print(
+        {
+            "layers": num_layers,
+            "shares": n_share,
+            "avg_s_baseline": t_base,
+            "avg_s_optimized": t_opt,
+            "speedup": (t_base / t_opt) if t_opt > 0 else float("inf"),
+            "runs_baseline": runs_base,
+            "runs_optimized": runs_opt,
+        }
+    )
+
+
+if __name__ == "__main__":
+    main()
+
diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py
index 26c5e617a43a8e7511d80560168536d242247c03..8f2385d3ee33d6f31d2e4a70222b9f6a7d2ec444
--- a/python/sglang/srt/models/deepseek_v2.py
+++ b/python/sglang/srt/models/deepseek_v2.py
@@ -941,6 +941,12 @@
     ) -> torch.Tensor:

         assert forward_batch.num_prefix_chunks is not None
+        # Preallocate ping-pong buffers to avoid per-chunk allocations
+        tmp_output_a = torch.empty_like(accum_output)
+        tmp_output_b = torch.empty_like(accum_output)
+        tmp_lse_a = torch.empty_like(accum_lse)
+        tmp_lse_b = torch.empty_like(accum_lse)
+
         for i in range(forward_batch.num_prefix_chunks):
             forward_batch.set_prefix_chunk_idx(i)

@@ -977,10 +983,13 @@

             output, lse = self.attn_mha(q, k, v, forward_batch, save_kv_cache=False)
             lse = torch.transpose(lse, 0, 1).contiguous()
-            tmp_output = torch.empty_like(accum_output)
-            tmp_lse = torch.empty_like(accum_lse)
-            merge_state_v2(output, lse, accum_output, accum_lse, tmp_output, tmp_lse)
-            accum_output, accum_lse = tmp_output, tmp_lse
+            # Alternate between two buffers so src/dst never alias
+            if (i & 1) == 0:
+                out_buf, lse_buf = tmp_output_a, tmp_lse_a
+            else:
+                out_buf, lse_buf = tmp_output_b, tmp_lse_b
+            merge_state_v2(output, lse, accum_output, accum_lse, out_buf, lse_buf)
+            accum_output, accum_lse = out_buf, lse_buf

         return accum_output

@@ -1607,7 +1616,8 @@
                     "up_proj.weight",
                     "up_proj.weight_scale_inv",
                 ]
-            names_to_remove = []
+            # Use a set for O(1) membership checks and avoid duplicates
+            names_to_remove = set()
             for moe_layer in tqdm(
                 range(
                     self.config.first_k_dense_replace,
@@ -1622,16 +1632,17 @@
                         shared_expert_weight_name = (
                             f"model.layers.{moe_layer}.mlp.shared_experts.{suffix}"
                         )
+                        # Avoid unnecessary tensor cloning; reuse the same tensor
                         weights_list.append(
                             (
                                 f"model.layers.{moe_layer}."
                                 f"mlp.experts."
                                 f"{self.config.n_routed_experts + num_repeat}"
                                 f".{suffix}",
-                                weights_dict[shared_expert_weight_name].clone(),
+                                weights_dict[shared_expert_weight_name],
                             )
                         )
-                        names_to_remove += [shared_expert_weight_name]
+                        names_to_remove.add(shared_expert_weight_name)
             weights = [w for w in weights_list if w[0] not in names_to_remove]

         # Params for weights, fp8 weight scales, fp8 activation scales

codex
I created a fast, reproducible benchmark and applied targeted performance optimizations in the MoE weight loading and chunked MHA paths.

Benchmark added
- File: .bench_scratch/test_opt.py
- What it does: Simulates the “shared expert weight replication” step to compare baseline (clone per replica) vs optimized (no clone) behavior.
- How to run:
  - From repo root: python .bench_scratch/test_opt.py
  - Example output shows large speedup (33–34x) from avoiding clones.

Key optimizations
- Avoid redundant tensor cloning when replicating shared expert weights
  - Change: Reuse the same tensor reference instead of cloned copies.
  - File: python/sglang/srt/models/deepseek_v2.py:1635
  - Before: weights_dict[shared_expert_weight_name].clone()
  - After: weights_dict[shared_expert_weight_name]
  - Benefit: Eliminates extra allocations/copies during weight construction.

- Use set for removal bookkeeping instead of list
  - Change: Convert names_to_remove to a set to ensure O(1) membership checks and avoid duplicates.
  - File: python/sglang/srt/models/deepseek_v2.py:1619, 1645–1646
  - Benefit: Faster and more memory-efficient filtering.

- Preallocate ping-pong buffers in chunked prefix MHA to avoid per-iteration allocations
  - Change: Allocate two temporary buffers outside the loop and alternate between them.
  - File: python/sglang/srt/models/deepseek_v2.py:972–994
  - Before: Allocate new tensors via torch.empty_like on each iteration.
  - After: Allocate tmp_output_a/tmp_output_b and tmp_lse_a/tmp_lse_b once and reuse.
  - Benefit: Reduces allocator pressure and improves throughput in long-prefix chunked paths.

Notes on torch.zeros/fill_
- The target file had no torch.zeros or fill_ calls to replace. Existing initializations are already using torch.empty where appropriate.

What I changed (file references)
- python/sglang/srt/models/deepseek_v2.py:1619
  - Switch names_to_remove to set()
- python/sglang/srt/models/deepseek_v2.py:1635–1646
  - Avoid clone; add names to the set
- python/sglang/srt/models/deepseek_v2.py:972–994
  - Preallocate and reuse ping-pong buffers in _chunked_prefix_attn_mha

How to validate
- Run the benchmark: python .bench_scratch/test_opt.py
- You should see a large improvement in the “optimized” replication path relative to “baseline”.
- Functional behavior stays the same (no public API changes), only performance is improved.

Commit and patch
- Commit message: Optimize MoE align sum kernels performance
- Patch file generated at: model_patch.diff

If you want, I can also run additional micro-benchmarks or help you validate on your specific workload.
file update:
diff --git a/.bench_scratch/test_opt.py b/.bench_scratch/test_opt.py