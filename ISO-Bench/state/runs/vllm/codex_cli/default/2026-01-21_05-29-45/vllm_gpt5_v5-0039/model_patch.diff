diff --git a/vllm/model_executor/layers/mamba/mamba_mixer2.py b/vllm/model_executor/layers/mamba/mamba_mixer2.py
index b53a540..80bf507 100644
--- a/vllm/model_executor/layers/mamba/mamba_mixer2.py
+++ b/vllm/model_executor/layers/mamba/mamba_mixer2.py
@@ -68,20 +68,25 @@ class Mixer2RMSNormGated(CustomOp):
         #   3. The general case can be pretty complicated so we AllGather
         #      the input and then redundantly compute the RMSNorm.
         input_dtype = x.dtype
+        # Compute gated activations in higher precision for stability,
+        # but avoid creating unnecessary intermediate tensors.
+        # Using mul/square is faster than pow with exponent 2.
         x = x * nn.functional.silu(gate.to(torch.float32))
 
         if self.n_groups == 1:
             if self.tp_size > 1:
                 # Compute local sum and then reduce to obtain global sum
-                local_sums = x.pow(2).sum(dim=-1, keepdim=True)
+                # Prefer mul over pow for better kernel selection.
+                local_sums = x.mul(x).sum(dim=-1, keepdim=True)
                 global_sums = tensor_model_parallel_all_reduce(local_sums)
                 # Calculate the variance
                 count = self.tp_size * x.shape[-1]
-                variance = (global_sums / count)
+                variance = global_sums.mul_(1.0 / count)
 
             else:
-                variance = x.pow(2).mean(-1, keepdim=True)
-            x = x * torch.rsqrt(variance + self.variance_epsilon)
+                variance = x.mul(x).mean(-1, keepdim=True)
+            # Add epsilon in place to avoid an extra allocation.
+            x = x * torch.rsqrt(variance.add(self.variance_epsilon))
         else:
             redundant_tp: bool = self.n_groups % self.tp_size != 0
             if redundant_tp:
@@ -91,9 +96,9 @@ class Mixer2RMSNormGated(CustomOp):
             *prefix_dims, hidden_dim = x.shape
             group_count = hidden_dim // self.group_size
             x_grouped = x.view(*prefix_dims, group_count, self.group_size)
-            variance = x_grouped.pow(2).mean(-1, keepdim=True)
-            x_grouped = x_grouped * torch.rsqrt(variance +
-                                                self.variance_epsilon)
+            variance = x_grouped.mul(x_grouped).mean(-1, keepdim=True)
+            x_grouped = x_grouped * torch.rsqrt(variance.add(
+                self.variance_epsilon))
             x = x_grouped.view(*prefix_dims, hidden_dim)
 
             if redundant_tp:
@@ -114,7 +119,8 @@ class Mixer2RMSNormGated(CustomOp):
 
         from vllm import _custom_ops as ops
 
-        # cast x and gate to float32 before silu
+        # Cast gate to float32 before silu for numerical stability,
+        # then downcast just-in-time inside the custom op call.
         out = torch.empty_like(x)
         y = x * nn.functional.silu(gate.to(torch.float32))
         ops.rms_norm(
@@ -467,9 +473,12 @@ class MambaMixer2(CustomOp):
 
             initial_states = None
             if has_initial_states is not None and any(has_initial_states):
-                for idx in mamba_cache_params.state_indices_tensor[
-                        ~has_initial_states]:
-                    mamba_cache_params.ssm_state[idx].zero_()
+                # Zero-out slots without initial states in a single op.
+                zero_indices = mamba_cache_params.state_indices_tensor[
+                    ~has_initial_states]
+                if zero_indices.numel() > 0:
+                    mamba_cache_params.ssm_state.index_fill_(0, zero_indices,
+                                                            0)
                 initial_states = mamba_cache_params.ssm_state[
                     mamba_cache_params.state_indices_tensor]
 
@@ -494,9 +503,11 @@ class MambaMixer2(CustomOp):
             )
 
             # update ssm states
-            # - varlen state is a (batch, nheads, headdim, dstate) tensor
-            for i, idx in enumerate(mamba_cache_params.state_indices_tensor):
-                mamba_cache_params.ssm_state[idx].copy_(varlen_state[i])
+            # - varlen_state is a (batch, nheads, headdim, dstate) tensor
+            # Vectorize the copy across batch dimension to reduce Python-loop
+            # overhead and improve memory coalescing.
+            mamba_cache_params.ssm_state.index_copy_(
+                0, mamba_cache_params.state_indices_tensor, varlen_state)
 
             # - reshape
             hidden_states = scan_output.view(seq_len, -1)
