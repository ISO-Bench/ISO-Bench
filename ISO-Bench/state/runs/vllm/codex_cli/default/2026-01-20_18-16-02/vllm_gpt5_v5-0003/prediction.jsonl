{"instance_id": "/root/OmniPerf-Bench/vllm__repo-8d59dbb", "model_patch": "diff --git a/vllm/core/evictor_v2.py b/vllm/core/evictor_v2.py\nindex 3dd12e2..14d5053 100644\n--- a/vllm/core/evictor_v2.py\n+++ b/vllm/core/evictor_v2.py\n@@ -60,6 +60,8 @@ class BlockMetaData():\n     blocks with the same content hash, but their physical id is unique.\n     \"\"\"\n \n+    __slots__ = (\"content_hash\", \"num_hashed_tokens\", \"last_accessed\")\n+\n     def __init__(self, content_hash: int, num_hashed_tokens: int,\n                  last_accessed: float):\n         self.content_hash = content_hash\n@@ -82,23 +84,16 @@ class LRUEvictor(Evictor):\n         return block_id in self.free_table\n \n     def evict(self) -> Tuple[int, int]:\n-        if len(self.free_table) == 0:\n+        if not self.free_table:\n             raise ValueError(\"No usable cache memory left\")\n \n-        evicted_block = next(iter(self.free_table.values()))\n-        evicted_block_id = next(iter(self.free_table.keys()))\n-        # The blocks with the lowest timestamps should be placed consecutively\n-        # at the start of OrderedDict. Loop through all these blocks to\n-        # find the one with maximum number of hashed tokens.\n-        for _id, block in self.free_table.items():\n-            if evicted_block.last_accessed > block.last_accessed or (\n-                    evicted_block.last_accessed == block.last_accessed and\n-                    evicted_block.num_hashed_tokens < block.num_hashed_tokens):\n-                evicted_block = block\n-                evicted_block_id = _id\n+        # Choose the block with the smallest last_accessed; break ties by\n+        # evicting the one with the largest num_hashed_tokens.\n+        evicted_block_id, evicted_block = min(\n+            self.free_table.items(),\n+            key=lambda kv: (kv[1].last_accessed, -kv[1].num_hashed_tokens))\n \n         self.free_table.pop(evicted_block_id)\n-\n         return evicted_block_id, evicted_block.content_hash\n \n     def add(self, block_id: int, content_hash: int, num_hashed_tokens: int,\n", "model_name_or_path": "gpt-5-2025-08-07"}
