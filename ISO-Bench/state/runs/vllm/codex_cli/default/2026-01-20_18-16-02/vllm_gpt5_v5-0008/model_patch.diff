diff --git a/vllm/model_executor/layers/mamba/mamba_mixer.py b/vllm/model_executor/layers/mamba/mamba_mixer.py
index 796c8d9..1833a51 100644
--- a/vllm/model_executor/layers/mamba/mamba_mixer.py
+++ b/vllm/model_executor/layers/mamba/mamba_mixer.py
@@ -141,7 +141,9 @@ class MambaMixer(CustomOp):
         attn_metadata: AttentionMetadata = get_forward_context().attn_metadata
 
         # 1. Gated MLP's linear projection
-        projected_states = self.in_proj(hidden_states)[0].transpose(-2, -1)
+        # Cast to projection weight dtype to avoid implicit conversions
+        hs = hidden_states.to(self.in_proj.weight.dtype)
+        projected_states = self.in_proj(hs)[0].transpose(-2, -1)
         hidden_states, gate = projected_states.chunk(2, dim=-2)
 
         # 2. Convolution sequence transformation
@@ -178,12 +180,14 @@ class MambaMixer(CustomOp):
         # 3. State Space Model sequence transformation
         # 3.a. input varying initialization of time_step, B and C
 
+        # Ensure inputs to GEMM-backed layers are contiguous for better kernel
+        # selection (especially with fused/LoRA paths)
         if self.is_lora_enabled:
-            #   lora kernel requires contiguous tensor
             ssm_parameters = self.x_proj(
                 hidden_states.transpose(-2, -1).contiguous())[0]
         else:
-            ssm_parameters = self.x_proj(hidden_states.transpose(-2, -1))[0]
+            ssm_parameters = self.x_proj(
+                hidden_states.transpose(-2, -1).contiguous())[0]
 
         time_step, B, C = torch.split(
             ssm_parameters,
@@ -235,11 +239,11 @@ class MambaMixer(CustomOp):
             scan_outputs = scan_outputs.transpose(0, 1)
 
         # 4. Final linear projection
+        # Keep output projection input contiguous to reduce potential reorders
         if self.is_lora_enabled:
-            #  lora kernel requires contiguous tensor
             contextualized_states = self.out_proj(
                 scan_outputs.transpose(-2, -1).contiguous())[0]
         else:
             contextualized_states = self.out_proj(
-                scan_outputs.transpose(-2, -1))[0]
+                scan_outputs.transpose(-2, -1).contiguous())[0]
         return contextualized_states
diff --git a/vllm/model_executor/layers/mamba/mamba_mixer2.py b/vllm/model_executor/layers/mamba/mamba_mixer2.py
index 36edac2..c5380f5 100644
--- a/vllm/model_executor/layers/mamba/mamba_mixer2.py
+++ b/vllm/model_executor/layers/mamba/mamba_mixer2.py
@@ -492,7 +492,9 @@ class MambaMixer2(MambaBase, CustomOp):
         groups_time_state_size = self.n_groups * self.ssm_state_size
 
         # 1. Gated MLP's linear projection
-        projected_states, _ = self.in_proj(hidden_states)
+        # Cast to weight dtype to avoid internal type conversions
+        projected_states, _ = self.in_proj(
+            hidden_states.to(self.in_proj.weight.dtype))
 
         if mup_vector is not None:
             projected_states = projected_states * mup_vector
@@ -512,7 +514,7 @@ class MambaMixer2(MambaBase, CustomOp):
 
         # - get hidden_states, B and C after depthwise convolution.
         split_hidden_states_B_C_fn = lambda hidden_states_B_C: torch.split(
-            hidden_states_B_C,
+            hidden_states_B_C.contiguous(),
             [
                 self.intermediate_size // self.tp_size,
                 groups_time_state_size // self.tp_size,
diff --git a/vllm/model_executor/layers/mamba/ops/mamba_ssm.py b/vllm/model_executor/layers/mamba/ops/mamba_ssm.py
index 3f67fc3..84002b8 100644
--- a/vllm/model_executor/layers/mamba/ops/mamba_ssm.py
+++ b/vllm/model_executor/layers/mamba/ops/mamba_ssm.py
@@ -264,7 +264,8 @@ def selective_state_update(state,
         assert dt_bias.shape == (nheads, dim)
     if state_batch_indices is not None:
         assert state_batch_indices.shape == (batch, )
-    out = torch.empty_like(x)
+    # Pre-allocate output as contiguous to match Triton kernel expectations
+    out = torch.empty_like(x).contiguous()
     grid = lambda META: (triton.cdiv(dim, META['BLOCK_SIZE_M']), batch, nheads)
     z_strides = ((z.stride(0), z.stride(1), z.stride(2)) if z is not None else
                  (0, 0, 0))
diff --git a/vllm/model_executor/layers/mamba/ops/ssd_combined.py b/vllm/model_executor/layers/mamba/ops/ssd_combined.py
index b121275..8615839 100644
--- a/vllm/model_executor/layers/mamba/ops/ssd_combined.py
+++ b/vllm/model_executor/layers/mamba/ops/ssd_combined.py
@@ -50,15 +50,15 @@ def _mamba_chunk_scan_combined_fwd(x,
         assert D.shape == (nheads, headdim) or D.shape == (nheads, )
     if seq_idx is not None:
         assert seq_idx.shape == (batch, seqlen)
+    # Ensure last-dim contiguous for better memory access in Triton/GEMMs
     if B.stride(-1) != 1:
         B = B.contiguous()
     if C.stride(-1) != 1:
         C = C.contiguous()
-    if x.stride(-1) != 1 and x.stride(
-            1) != 1:  # Either M or K dimension should be contiguous
+    # Prefer contiguous inputs to avoid implicit reorders in kernels
+    if x.stride(-1) != 1 and x.stride(1) != 1:
         x = x.contiguous()
-    if z is not None and z.stride(-1) != 1 and z.stride(
-            1) != 1:  # Either M or K dimension should be contiguous
+    if z is not None and z.stride(-1) != 1 and z.stride(1) != 1:
         z = z.contiguous()
     if D is not None and D.stride(-1) != 1:
         D = D.contiguous()
