{"instance_id": "/root/OmniPerf-Bench/vllm__repo-5460070", "model_patch": "diff --git a/vllm/core/block/naive_block.py b/vllm/core/block/naive_block.py\nindex 50f27ba..7ea59ec 100644\n--- a/vllm/core/block/naive_block.py\n+++ b/vllm/core/block/naive_block.py\n@@ -44,6 +44,12 @@ class NaiveBlockAllocator(BlockAllocator):\n         self._create_block = create_block\n         self._block_size = block_size\n \n+        # Precompute a stable mapping from absolute block id -> physical index.\n+        # This avoids repeatedly sorting and searching when translating ids.\n+        # Keep it in sync with the allocator's ids.\n+        sorted_ids = sorted(self._all_block_indices)\n+        self._abs_to_phys = {bid: i for i, bid in enumerate(sorted_ids)}\n+\n         self._cow_tracker = CopyOnWriteTracker(\n             refcounter=self._refcounter.as_readonly(),\n             allocator=self,\n@@ -163,7 +169,8 @@ class NaiveBlockAllocator(BlockAllocator):\n         Returns:\n             int: The zero-offset block id on certain device.\n         \"\"\"\n-        return sorted(self._all_block_indices).index(absolute_id)\n+        # O(1) using the cached mapping (previously O(N log N) + O(N)).\n+        return self._abs_to_phys[absolute_id]\n \n     @property\n     def refcounter(self):\n@@ -298,6 +305,12 @@ class NaiveBlock(Block):\n             If not provided, it defaults to self.\n     \"\"\"\n \n+    # Reduce per-instance memory + speed up attribute access.\n+    __slots__ = (\n+        \"_token_ids\", \"_block_size\", \"_prev_block\", \"_block_id\",\n+        \"_allocator\", \"_cow_target\"\n+    )\n+\n     def __init__(self,\n                  prev_block: Optional[Block],\n                  token_ids: List[int],\n@@ -305,14 +318,18 @@ class NaiveBlock(Block):\n                  allocator: BlockAllocator,\n                  block_id: Optional[int] = None,\n                  _cow_target: Optional[Block] = None):\n-        self._token_ids: List[int] = []\n+        # Avoid an extra list copy on initialization when possible by\n+        # taking ownership of the provided list (common in immutable allocs).\n+        # Fallback to an empty list when no tokens provided.\n+        self._token_ids: List[int] = token_ids if token_ids else []\n         self._block_size = block_size\n         self._prev_block = prev_block\n         self._block_id = block_id\n         self._allocator = allocator\n         self._cow_target = _cow_target if _cow_target is not None else self\n-\n-        self._append_token_ids_no_cow(token_ids)\n+        # Ensure capacity constraints; if we took ownership above this is O(1).\n+        if token_ids:\n+            assert len(token_ids) <= self._block_size\n \n     def append_token_ids(self, token_ids: List[int]) -> None:\n         \"\"\"Appends the given token IDs to the block, instructing the allocator\n@@ -329,7 +346,12 @@ class NaiveBlock(Block):\n \n     def _append_token_ids_no_cow(self, token_ids: List[int]) -> None:\n         assert self.num_empty_slots >= len(token_ids)\n-        self._token_ids.extend(token_ids)\n+        # Fast-path when the block is empty: adopt the list directly to avoid\n+        # a second copy. Otherwise extend.\n+        if not self._token_ids and isinstance(token_ids, list):\n+            self._token_ids = token_ids\n+        else:\n+            self._token_ids.extend(token_ids)\n \n     @property\n     def computed(self) -> bool:\ndiff --git a/vllm/core/block/prefix_caching_block.py b/vllm/core/block/prefix_caching_block.py\nindex 2df7d74..a6f2489 100644\n--- a/vllm/core/block/prefix_caching_block.py\n+++ b/vllm/core/block/prefix_caching_block.py\n@@ -48,6 +48,10 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         # A mapping of blockId to Block to track those cached blocks\n         self._blocks: Dict[BlockId, Block] = {}\n \n+        # Track basic cache statistics for visibility and tests/benchmarks.\n+        self._cache_hits: int = 0\n+        self._cache_lookups: int = 0\n+\n         # An allocator for blocks that do not have prefix hashes.\n         self._hashless_allocator = NaiveBlockAllocator(\n             create_block=self._create_block,  # type: ignore\n@@ -72,6 +76,10 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n             allocator=self,\n         )\n \n+        # Stats\n+        self._cache_hits = 0\n+        self._cache_lookups = 0\n+\n     # Implements Block.Factory.\n     def _create_block(\n         self,\n@@ -111,25 +119,43 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         assert device is None\n         assert_prefix_caching_block_or_none(prev_block)\n \n-        block = self._create_block(\n-            prev_block=prev_block,\n-            token_ids=token_ids,\n-            block_size=self._block_size,\n-            allocator=self,\n-        )\n-        assert block.content_hash is not None\n+        # Fast-path compute hash based on previous hash and current tokens\n+        # without allocating a physical block first.\n+        is_first = prev_block is None\n+        prev_hash = None if is_first else prev_block.content_hash  # type: ignore\n+\n+        if not is_first and prev_hash is None:\n+            # Parent not yet hashable (not full). Use standard mutable path.\n+            blk = self.allocate_mutable(prev_block)\n+            blk.append_token_ids(token_ids)\n+            assert blk.content_hash is not None\n+            return blk\n+\n+        chash = PrefixCachingBlock.hash_block_tokens(is_first, prev_hash,\n+                                                     token_ids)\n+        self._cache_lookups += 1\n+        cached_block_id = self._cached_blocks.get(chash, None)\n \n-        cached_block_id = self._cached_blocks.get(block.content_hash, None)\n         if cached_block_id is not None:\n+            # Construct a lightweight logical block and bind to cached id.\n+            block = self._create_block(\n+                prev_block=prev_block,\n+                token_ids=token_ids,\n+                block_size=self._block_size,\n+                allocator=self,\n+            )\n+            block._cached_content_hash = chash  # type: ignore[attr-defined]\n             block.block_id = cached_block_id\n             self._incr_refcount_cached_block(block, block.block_id)\n+            self._cache_hits += 1\n             return block\n \n-        block = self.allocate_mutable(prev_block)\n-        block.append_token_ids(token_ids)\n-        assert block.content_hash is not None\n-\n-        return block\n+        # Cache miss: allocate mutable and append to trigger promotion and\n+        # registration in the cache.\n+        blk = self.allocate_mutable(prev_block)\n+        blk.append_token_ids(token_ids)\n+        assert blk.content_hash is not None\n+        return blk\n \n     def allocate_mutable(self,\n                          prev_block: Optional[Block],\n@@ -310,7 +336,9 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         Returns:\n             int: The rzero-offset block id on certain device.\n         \"\"\"\n-        return sorted(self.all_block_ids).index(absolute_id)\n+        # Avoid repeated sorts: delegate to underlying allocator which now\n+        # caches the mapping.\n+        return self._hashless_allocator.get_physical_block_id(absolute_id)\n \n     @property\n     def all_block_ids(self) -> FrozenSet[int]:\n@@ -322,6 +350,12 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n             return True\n         return False\n \n+    # Lightweight stats for benchmarking prefix cache effectiveness.\n+    def get_prefix_cache_hit_rate(self) -> float:\n+        if self._cache_lookups == 0:\n+            return 0.0\n+        return self._cache_hits / float(self._cache_lookups)\n+\n     def promote_to_immutable_block(self, block: Block) -> BlockId:\n         \"\"\"Once a mutable block is full, it can be promoted to an immutable\n         block. This means that its content can be referenced by future blocks\n@@ -513,6 +547,13 @@ class PrefixCachingBlock(Block):\n             of this block. Defaults to None.\n     \"\"\"\n \n+    # Reduce per-instance overhead on critical path of block creation.\n+    __slots__ = (\n+        \"_prev_block\", \"_cached_content_hash\", \"_cached_num_tokens_total\",\n+        \"_prefix_caching_allocator\", \"_last_accessed\", \"_computed\",\n+        \"_block\"\n+    )\n+\n     def __init__(\n         self,\n         prev_block: Optional[Block],\n@@ -543,6 +584,19 @@ class PrefixCachingBlock(Block):\n             allocator=prefix_caching_allocator,\n             _cow_target=self,\n         )\n+        # Eager compute total tokens for O(1) retrieval.\n+        prev_total = 0\n+        if prev_block is not None:\n+            prev_total = prev_block.num_tokens_total  # type: ignore\n+        self._cached_num_tokens_total = prev_total + len(token_ids)\n+\n+        # If already full, precompute content hash when possible.\n+        if self.is_full:\n+            is_first = prev_block is None\n+            prev_hash = None if is_first else prev_block.content_hash  # type: ignore\n+            if is_first or prev_hash is not None:\n+                self._cached_content_hash = PrefixCachingBlock.hash_block_tokens(\n+                    is_first, prev_hash, self._block.token_ids)\n \n     @property\n     def computed(self) -> bool:\n@@ -574,6 +628,15 @@ class PrefixCachingBlock(Block):\n         # naive block handles CoW.\n         self._block.append_token_ids(token_ids)\n \n+        # Maintain O(1) running total tokens for the chain.\n+        if self._cached_num_tokens_total is None:\n+            prev_total = 0\n+            if self._prev_block is not None:\n+                prev_total = self._prev_block.num_tokens_total  # type: ignore\n+            self._cached_num_tokens_total = prev_total + len(self._block.token_ids)\n+        else:\n+            self._cached_num_tokens_total += len(token_ids)\n+\n         # If the content hash is present, then the block can be made immutable.\n         # Register ourselves with the allocator, potentially replacing the\n         # physical block index.\n@@ -685,6 +748,8 @@ class PrefixCachingBlock(Block):\n         - int: The computed hash value for the block.\n         \"\"\"\n         assert (prev_block_hash is None) == is_first_block\n+        # Use CPython's tuple hash which is implemented in C and fast for\n+        # small tuples. This avoids Python-level loops per call.\n         return hash((is_first_block, prev_block_hash, *cur_block_token_ids))\n \n \n", "model_name_or_path": "gpt-5-2025-08-07"}
