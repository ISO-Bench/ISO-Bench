diff --git a/vllm/attention/backends/mla/common.py b/vllm/attention/backends/mla/common.py
index 8184b07..c34e2f8 100644
--- a/vllm/attention/backends/mla/common.py
+++ b/vllm/attention/backends/mla/common.py
@@ -296,7 +296,8 @@ class MLACommonBackend(AttentionBackend):
 
     @staticmethod
     def get_supported_head_sizes() -> List[int]:
-        return [576]
+        # Use an immutable tuple to avoid per-call list allocations.
+        return (576,)
 
 
 T = TypeVar("T", bound="MLACommonMetadata")
diff --git a/vllm/v1/attention/backends/mla/common.py b/vllm/v1/attention/backends/mla/common.py
index c98262e..66f0618 100644
--- a/vllm/v1/attention/backends/mla/common.py
+++ b/vllm/v1/attention/backends/mla/common.py
@@ -267,7 +267,8 @@ class MLACommonBackend(AttentionBackend):
 
     @staticmethod
     def get_supported_head_sizes() -> list[int]:
-        return [576]
+        # Return an immutable tuple to avoid per-call list allocations.
+        return (576,)
 
     @staticmethod
     def use_cascade_attention(*args, **kwargs) -> bool:
