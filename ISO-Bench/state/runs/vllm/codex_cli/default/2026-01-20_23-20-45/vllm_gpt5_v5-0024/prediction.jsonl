{"instance_id": "/root/OmniPerf-Bench/vllm__repo-5fc5ce0", "model_patch": "diff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 45a3b48..8a509c2 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -16,7 +16,7 @@ project(vllm_extensions LANGUAGES CXX)\n # CUDA by default, can be overridden by using -DVLLM_TARGET_DEVICE=... (used by setup.py)\n set(VLLM_TARGET_DEVICE \"cuda\" CACHE STRING \"Target device backend for vLLM\")\n \n-message(STATUS \"Build type: ${CMAKE_BUILD_TYPE}\")\n+set(CMAKE_CUDA_FLAGS_RELWITHDEBINFO \"${CMAKE_CUDA_FLAGS_RELWITHDEBINFO} -O3 -DNDEBUG\")\n message(STATUS \"Target device: ${VLLM_TARGET_DEVICE}\")\n \n include(${CMAKE_CURRENT_LIST_DIR}/cmake/utils.cmake)\n", "model_name_or_path": "gpt-5-2025-08-07"}
