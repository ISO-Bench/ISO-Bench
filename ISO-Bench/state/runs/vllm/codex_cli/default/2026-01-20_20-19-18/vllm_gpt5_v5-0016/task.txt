I've uploaded a python code repository in the directory /root/OmniPerf-Bench/perf-agents-bench/.work/worktrees/vllm_core/vllm_gpt5_v5-0016.
Consider the following test script showing an example usage of the repository:

<test_script>
import torch
import time
from vllm.model_executor.layers.fused_moe import moe_align_block_size

# Benchmark the MoE align block size operation
num_tokens = 4096
num_experts = 64
topk = 2
block_size = 128

# Create input data
topk_ids = torch.randint(0, num_experts, (num_tokens * topk,), dtype=torch.int32, device='cuda')

# Time the operation
torch.cuda.synchronize()
start = time.time()

sorted_ids, expert_ids, num_tokens_post_pad = moe_align_block_size(
    topk_ids, num_experts, block_size, topk
)

torch.cuda.synchronize()
duration = time.time() - start

print(f"Duration: {duration:.4f} seconds")

</test_script>

Can you help me implement the necessary changes to the repository so that the runtime of the <test_script> is optimized?

Basic guidelines:
1. Your task is to make changes to non-test files in the /root/OmniPerf-Bench/perf-agents-bench/.work/worktrees/vllm_core/vllm_gpt5_v5-0016 directory to improve the performance of the <test_script>.
2. Make changes while ensuring the repository is functionally equivalent to the original.
3. Do not overoptimize for just the specific inputs in <test_script>. Make general performance improvements for the usage scenario shown.
4. You may need to rebuild the repo for your changes to take effect before testing. Some rebuilds may take time to run, so be patient with running them.

Follow these steps to improve performance:
1. As a first step, explore the repository structure and understand the target files.
2. Create a script ONLY inside /root/OmniPerf-Bench/perf-agents-bench/.work/worktrees/vllm_core/vllm_gpt5_v5-0016/.bench_scratch (e.g., /root/OmniPerf-Bench/perf-agents-bench/.work/worktrees/vllm_core/vllm_gpt5_v5-0016/.bench_scratch/test_opt.py) to reproduce and time the example, then execute it with python <filename.py> from the repo root.
3. Profile and identify performance bottlenecks in the target files.
4. Edit the source code of the repository to improve performance.
5. Rebuild and rerun your script to confirm that performance has improved.

Common optimization strategies to consider:
- Reduce unnecessary memory allocations
- Avoid redundant computations
- Optimize data structures and algorithms
- Improve cache locality
- Reduce synchronization overhead
- Use more efficient library calls where available

Target files to optimize:
- benchmarks/kernels/benchmark_grouped_gemm_cutlass.py
- csrc/moe/moe_permute_unpermute_op.cu
- tests/kernels/moe/test_cutlass_moe.py

IMPORTANT: You MUST make actual code changes to at least one file.
The task will fail if no files are modified.

## Constraints
- No public API breakage
- All TestPack checks must pass

## Target Files (ONLY modify these)
- `benchmarks/kernels/benchmark_grouped_gemm_cutlass.py`
- `csrc/moe/moe_permute_unpermute_op.cu`
- `tests/kernels/moe/test_cutlass_moe.py`
- `tests/kernels/moe/test_pplx_cutlass_moe.py`
- `vllm/model_executor/layers/fused_moe/cutlass_moe.py`
- `vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py`

## Files Modified (statistics)
The following files were changed in the reference optimization:
```
.../kernels/benchmark_grouped_gemm_cutlass.py      | 35 +-----------
 csrc/moe/moe_permute_unpermute_op.cu               | 53 ++++--------------
 tests/kernels/moe/test_cutlass_moe.py              | 14 +----
 tests/kernels/moe/test_pplx_cutlass_moe.py         | 22 --------
 .../model_executor/layers/fused_moe/cutlass_moe.py | 62 ++++++++--------------
 .../compressed_tensors/compressed_tensors_moe.py   | 26 +--------
 6 files changed, 38 insertions(+), 174 deletions(-)
```

## TASK COMPLETION COMMAND:
When you have made optimizations:
```bash
git add -A
git reset -q .bench_scratch || true
git commit -m 'Optimize MoE align sum kernels performance'
git diff $(git merge-base HEAD origin/HEAD || git rev-parse HEAD~1) -- . ':(exclude).bench_scratch' > /root/OmniPerf-Bench/perf-agents-bench/.work/worktrees/vllm_core/vllm_gpt5_v5-0016/model_patch.diff || true
finish
```

START IMPLEMENTING IMMEDIATELY. NO MORE ANALYSIS.
