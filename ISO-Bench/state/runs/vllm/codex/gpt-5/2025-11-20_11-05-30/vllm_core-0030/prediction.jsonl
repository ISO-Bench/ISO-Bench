{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-5c04bb8", "model_patch": "diff --git a/vllm/model_executor/models/qwen2_5_vl.py b/vllm/model_executor/models/qwen2_5_vl.py\nindex 5904ad1f1..370fa219a 100644\n--- a/vllm/model_executor/models/qwen2_5_vl.py\n+++ b/vllm/model_executor/models/qwen2_5_vl.py\n@@ -25,7 +25,7 @@\n # limitations under the License.\n \"\"\"Inference-only Qwen2.5-VL model compatible with HuggingFace weights.\"\"\"\n from collections.abc import Iterable, Mapping\n-from functools import partial\n+from functools import lru_cache, partial\n from typing import Callable, Literal, Optional, TypedDict, Union\n \n import torch\n@@ -198,7 +198,8 @@ class Qwen2_5_VisionMLP(nn.Module):\n def all_gather_interleave(local_tensor, hidden_size: int, tp_size: int):\n     \"\"\"All-gather the input tensor interleavely across model parallel group.\"\"\"\n     import torch.distributed as dist\n-    gathered_tensors = [torch.zeros_like(local_tensor) for _ in range(tp_size)]\n+    # Allocate without initialization since all_gather writes into buffers.\n+    gathered_tensors = [torch.empty_like(local_tensor) for _ in range(tp_size)]\n     dist.all_gather(gathered_tensors,\n                     local_tensor,\n                     group=parallel_state.get_tp_group().device_group)\n@@ -478,8 +479,9 @@ class Qwen2_5_VisionRotaryEmbedding(nn.Module):\n         super().__init__()\n         self.dim = dim\n         self.theta = theta\n-        inv_freq = 1.0 / (theta\n-                          **(torch.arange(0, dim, 2, dtype=torch.float) / dim))\n+        # Build arange on CPU to avoid device sync/alloc on accelerators.\n+        inv_freq = 1.0 / (theta**(\n+            torch.arange(0, dim, 2, dtype=torch.float, device=\"cpu\") / dim))\n         self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n         self._seq_len_cached = 0\n         self._freqs_cached = None\n@@ -488,9 +490,6 @@ class Qwen2_5_VisionRotaryEmbedding(nn.Module):\n         if seqlen > self._seq_len_cached:\n             seqlen *= 2\n             self._seq_len_cached = seqlen\n-            self.inv_freq = 1.0 / (self.theta**(torch.arange(\n-                0, self.dim, 2, dtype=torch.float, device=self.inv_freq.device)\n-                                                / self.dim))\n             seq = torch.arange(seqlen,\n                                device=self.inv_freq.device,\n                                dtype=self.inv_freq.dtype)\n", "model_name_or_path": "gpt-5-2025-08-07"}
