{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-270a5da", "model_patch": "diff --git a/vllm/model_executor/layers/mamba/mamba_mixer2.py b/vllm/model_executor/layers/mamba/mamba_mixer2.py\nindex b53a540ed..0f0c05bca 100644\n--- a/vllm/model_executor/layers/mamba/mamba_mixer2.py\n+++ b/vllm/model_executor/layers/mamba/mamba_mixer2.py\n@@ -466,10 +466,15 @@ class MambaMixer2(CustomOp):\n         if has_prefill:\n \n             initial_states = None\n-            if has_initial_states is not None and any(has_initial_states):\n-                for idx in mamba_cache_params.state_indices_tensor[\n-                        ~has_initial_states]:\n-                    mamba_cache_params.ssm_state[idx].zero_()\n+            if has_initial_states is not None and torch.any(\n+                    has_initial_states):\n+                # Vectorized zero init for ssm_state on the subset without\n+                # initial states to avoid per-index kernel launches.\n+                zero_indices = mamba_cache_params.state_indices_tensor[\n+                    ~has_initial_states]\n+                if zero_indices.numel() > 0:\n+                    mamba_cache_params.ssm_state[zero_indices].zero_()\n+                # Gather initial states in a single advanced-indexing op.\n                 initial_states = mamba_cache_params.ssm_state[\n                     mamba_cache_params.state_indices_tensor]\n \n@@ -494,9 +499,10 @@ class MambaMixer2(CustomOp):\n             )\n \n             # update ssm states\n-            # - varlen state is a (batch, nheads, headdim, dstate) tensor\n-            for i, idx in enumerate(mamba_cache_params.state_indices_tensor):\n-                mamba_cache_params.ssm_state[idx].copy_(varlen_state[i])\n+            # - varlen_state is (batch, nheads, headdim, dstate); perform\n+            #   a single batched copy using advanced indexing.\n+            mamba_cache_params.ssm_state[\n+                mamba_cache_params.state_indices_tensor].copy_(varlen_state)\n \n             # - reshape\n             hidden_states = scan_output.view(seq_len, -1)\n", "model_name_or_path": "gpt-5-2025-08-07"}
