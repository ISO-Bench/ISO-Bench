{
  "changed": [
    ".buildkite/check-wheel-size.py",
    ".buildkite/download-images.sh",
    ".buildkite/nightly-benchmarks/kickoff-pipeline.sh",
    ".buildkite/nightly-benchmarks/sample.yaml",
    ".buildkite/run-amd-test.sh",
    ".buildkite/run-benchmarks.sh",
    ".buildkite/run-cpu-test.sh",
    ".buildkite/run-neuron-test.sh",
    ".buildkite/test-pipeline.yaml",
    ".buildkite/test-template-aws.j2",
    ".buildkite/test-template.j2",
    ".clang-format",
    ".github/ISSUE_TEMPLATE/200-installation.yml",
    ".github/ISSUE_TEMPLATE/300-usage.yml",
    ".github/ISSUE_TEMPLATE/400-bug report.yml",
    ".github/ISSUE_TEMPLATE/700-performance discussion.yml",
    ".github/ISSUE_TEMPLATE/750-RFC.yml",
    ".github/workflows/clang-format.yml",
    ".github/workflows/mypy.yaml",
    ".github/workflows/publish.yml",
    ".github/workflows/ruff.yml",
    ".github/workflows/scripts/build.sh",
    ".github/workflows/scripts/create_release.js",
    ".github/workflows/yapf.yml",
    ".gitignore",
    "CMakeLists.txt",
    "CONTRIBUTING.md",
    "Dockerfile",
    "Dockerfile.cpu",
    "Dockerfile.neuron",
    "Dockerfile.rocm",
    "MANIFEST.in",
    "README.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_latency.py",
    "benchmarks/benchmark_prefix_caching.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/benchmark_throughput.py",
    "benchmarks/cutlass_benchmarks/w8a8_benchmarks.py",
    "benchmarks/cutlass_benchmarks/weight_shapes.py",
    "benchmarks/kernels/benchmark_aqlm.py",
    "benchmarks/kernels/benchmark_marlin.py",
    "benchmarks/kernels/benchmark_mixtral_moe.py",
    "benchmarks/kernels/benchmark_moe.py",
    "benchmarks/kernels/benchmark_paged_attention.py",
    "benchmarks/kernels/benchmark_rope.py",
    "benchmarks/kernels/benchmark_shapes.py",
    "benchmarks/launch_tgi_server.sh",
    "benchmarks/overheads/benchmark_hashing.py",
    "benchmarks/sonnet.txt",
    "cmake/cpu_extension.cmake",
    "cmake/hipify.py",
    "cmake/utils.cmake",
    "collect_env.py",
    "csrc/activation_kernels.cu",
    "csrc/attention/attention_dtypes.h",
    "csrc/attention/attention_generic.cuh",
    "csrc/attention/attention_kernels.cu",
    "csrc/attention/attention_utils.cuh",
    "csrc/attention/dtype_bfloat16.cuh",
    "csrc/attention/dtype_float16.cuh",
    "csrc/attention/dtype_float32.cuh",
    "csrc/attention/dtype_fp8.cuh",
    "csrc/attention/dtype_fp8_e5m2.cuh",
    "csrc/cache.h",
    "csrc/cache_kernels.cu",
    "csrc/cpu/activation.cpp",
    "csrc/cpu/attention.cpp",
    "csrc/cpu/cache.cpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/layernorm.cpp",
    "csrc/cpu/pos_encoding.cpp",
    "csrc/cpu/pybind.cpp",
    "csrc/cuda_compat.h",
    "csrc/cuda_utils.h",
    "csrc/cuda_utils_kernels.cu",
    "csrc/custom_all_reduce.cu",
    "csrc/custom_all_reduce.cuh",
    "csrc/custom_all_reduce_test.cu",
    "csrc/dispatch_utils.h",
    "csrc/layernorm_kernels.cu",
    "csrc/moe/moe_ops.cpp",
    "csrc/moe/moe_ops.h",
    "csrc/moe/topk_softmax_kernels.cu",
    "csrc/moe_align_block_size_kernels.cu",
    "csrc/ops.h",
    "csrc/pos_encoding_kernels.cu",
    "csrc/punica/bgmv/bgmv_bf16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_config.h",
    "csrc/punica/bgmv/bgmv_fp16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_impl.cuh",
    "csrc/punica/bgmv/generator.py",
    "csrc/punica/bgmv/vec_dtypes.cuh",
    "csrc/punica/punica_ops.cc",
    "csrc/punica/punica_ops.h",
    "csrc/punica/punica_pybind.cpp",
    "csrc/punica/type_convert.h",
    "csrc/pybind.cpp",
    "csrc/quantization/aqlm/gemm_kernels.cu",
    "csrc/quantization/awq/dequantize.cuh",
    "csrc/quantization/awq/gemm_kernels.cu",
    "csrc/quantization/compressed_tensors/int8_quant_kernels.cu",
    "csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c2x.hpp",
    "csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c3x.hpp",
    "csrc/quantization/cutlass_w8a8/common.hpp",
    "csrc/quantization/cutlass_w8a8/scaled_mm_dq_c2x.cu",
    "csrc/quantization/cutlass_w8a8/scaled_mm_dq_c3x.cu",
    "csrc/quantization/cutlass_w8a8/scaled_mm_dq_entry.cu",
    "csrc/quantization/fp8/amd/hip_float8.h",
    "csrc/quantization/fp8/amd/hip_float8_impl.h",
    "csrc/quantization/fp8/amd/quant_utils.cuh",
    "csrc/quantization/fp8/common.cu",
    "csrc/quantization/fp8/nvidia/quant_utils.cuh",
    "csrc/quantization/fp8_e5m2_kvcache/quant_utils.cuh",
    "csrc/quantization/gptq/compat.cuh",
    "csrc/quantization/gptq/matrix_view.cuh",
    "csrc/quantization/gptq/q_gemm.cu",
    "csrc/quantization/gptq/qdq_2.cuh",
    "csrc/quantization/gptq/qdq_3.cuh",
    "csrc/quantization/gptq/qdq_4.cuh",
    "csrc/quantization/gptq/qdq_8.cuh",
    "csrc/quantization/gptq/qdq_util.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin.cu",
    "csrc/quantization/gptq_marlin/gptq_marlin.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin_dtypes.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin_repack.cu",
    "csrc/quantization/marlin/LICENSE",
    "csrc/quantization/marlin/marlin_cuda_kernel.cu",
    "csrc/quantization/marlin/sparse/LICENSE",
    "csrc/quantization/marlin/sparse/common/base.h",
    "csrc/quantization/marlin/sparse/common/mem.h",
    "csrc/quantization/marlin/sparse/common/mma.h",
    "csrc/quantization/marlin/sparse/marlin_24_cuda_kernel.cu",
    "csrc/quantization/squeezellm/quant_cuda_kernel.cu",
    "csrc/reduction_utils.cuh",
    "docs/requirements-docs.txt",
    "docs/source/assets/dev/dockerfile-stages-dependency.png",
    "docs/source/community/meetups.rst",
    "docs/source/community/sponsors.md",
    "docs/source/conf.py",
    "docs/source/dev/dockerfile/dockerfile.rst",
    "docs/source/dev/engine/async_llm_engine.rst",
    "docs/source/dev/engine/llm_engine.rst",
    "docs/source/dev/multimodal/multimodal_index.rst",
    "docs/source/dev/offline_inference/llm.rst",
    "docs/source/dev/offline_inference/llm_inputs.rst",
    "docs/source/dev/offline_inference/offline_index.rst",
    "docs/source/dev/sampling_params.rst",
    "docs/source/generate_examples.py",
    "docs/source/getting_started/amd-installation.rst",
    "docs/source/getting_started/cpu-installation.rst",
    "docs/source/getting_started/examples/examples_index.template.rst",
    "docs/source/getting_started/installation.rst",
    "docs/source/index.rst",
    "docs/source/models/adding_model.rst",
    "docs/source/models/engine_args.rst",
    "docs/source/models/performance.rst",
    "docs/source/models/supported_models.rst",
    "docs/source/models/vlm.rst",
    "docs/source/quantization/fp8_e4m3_kvcache.rst",
    "docs/source/quantization/fp8_e5m2_kv_cache.rst",
    "docs/source/serving/deploying_with_docker.rst",
    "docs/source/serving/deploying_with_dstack.rst",
    "docs/source/serving/deploying_with_lws.rst",
    "docs/source/serving/env_vars.rst",
    "docs/source/serving/integrations.rst",
    "docs/source/serving/openai_compatible_server.md",
    "docs/source/serving/run_on_sky.rst",
    "docs/source/serving/usage_stats.md",
    "examples/aqlm_example.py",
    "examples/fp8/README.md",
    "examples/fp8/extract_scales.py",
    "examples/fp8/quantizer/README.md",
    "examples/fp8/quantizer/quantize.py",
    "examples/gradio_openai_chatbot_webserver.py",
    "examples/llava_example.py",
    "examples/llm_engine_example.py",
    "examples/logging_configuration.md",
    "examples/lora_with_quantization_inference.py",
    "examples/multilora_inference.py",
    "examples/offline_inference_arctic.py",
    "examples/offline_inference_distributed.py",
    "examples/offline_inference_embedding.py",
    "examples/offline_inference_neuron.py",
    "examples/offline_inference_openai.md",
    "examples/offline_inference_with_prefix.py",
    "examples/openai_chatcompletion_client.py",
    "examples/openai_embedding_client.py",
    "examples/openai_example_batch.jsonl",
    "examples/production_monitoring/README.md",
    "examples/production_monitoring/grafana.json",
    "examples/save_sharded_state.py",
    "examples/tensorize_vllm_model.py",
    "format.sh",
    "model_patch.diff",
    "patch_xformers.rocm.sh",
    "pyproject.toml",
    "requirements-build.txt",
    "requirements-common.txt",
    "requirements-cpu.txt",
    "requirements-cuda.txt",
    "requirements-dev.txt",
    "requirements-neuron.txt",
    "requirements-rocm.txt",
    "requirements.txt",
    "rocm_patch/commonpy_xformers-0.0.23.rocm.patch",
    "rocm_patch/flashpy_xformers-0.0.23.rocm.patch",
    "setup.py",
    "tests/async_engine/test_api_server.py",
    "tests/async_engine/test_async_llm_engine.py",
    "tests/async_engine/test_chat_template.py",
    "tests/async_engine/test_openapi_server_ray.py",
    "tests/basic_correctness/test_basic_correctness.py",
    "tests/basic_correctness/test_chunked_prefill.py",
    "tests/basic_correctness/test_preemption.py",
    "tests/conftest.py",
    "tests/core/block/conftest.py",
    "tests/core/block/e2e/__init__.py",
    "tests/core/block/e2e/conftest.py",
    "tests/core/block/e2e/test_correctness.py",
    "tests/core/block/e2e/test_correctness_sliding_window.py",
    "tests/core/block/test_block_manager_v2.py",
    "tests/core/block/test_block_table.py",
    "tests/core/block/test_common.py",
    "tests/core/block/test_cpu_gpu_block_allocator.py",
    "tests/core/block/test_naive_block.py",
    "tests/core/block/test_prefix_caching_block.py",
    "tests/core/test_block_manager.py",
    "tests/core/test_chunked_prefill_scheduler.py",
    "tests/core/test_scheduler.py",
    "tests/core/utils.py",
    "tests/distributed/__init__.py",
    "tests/distributed/test_basic_distributed_correctness.py",
    "tests/distributed/test_chunked_prefill_distributed.py",
    "tests/distributed/test_comm_ops.py",
    "tests/distributed/test_custom_all_reduce.py",
    "tests/distributed/test_pynccl.py",
    "tests/engine/__init__.py",
    "tests/engine/output_processor/__init__.py",
    "tests/engine/output_processor/test_multi_step.py",
    "tests/engine/output_processor/test_stop_checker.py",
    "tests/engine/test_detokenization.py",
    "tests/engine/test_multiproc_workers.py",
    "tests/engine/test_skip_tokenizer_init.py",
    "tests/engine/test_stop_reason.py",
    "tests/engine/test_stop_strings.py",
    "tests/entrypoints/__init__.py",
    "tests/entrypoints/openai/test_serving_chat.py",
    "tests/entrypoints/test_guided_processors.py",
    "tests/entrypoints/test_llm_encode.py",
    "tests/entrypoints/test_llm_generate.py",
    "tests/entrypoints/test_llm_generate_multiple_loras.py",
    "tests/entrypoints/test_openai_run_batch.py",
    "tests/entrypoints/test_openai_server.py",
    "tests/entrypoints/test_server_oot_registration.py",
    "tests/fp8_kv/llama2-70b-fp8-kv/kv_cache_scales.json",
    "tests/fp8_kv/llama2-7b-fp8-kv/kv_cache_scales.json",
    "tests/kernels/__init__.py",
    "tests/kernels/conftest.py",
    "tests/kernels/test_activation.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_attention_selector.py",
    "tests/kernels/test_blocksparse_attention.py",
    "tests/kernels/test_cache.py",
    "tests/kernels/test_cutlass.py",
    "tests/kernels/test_flash_attn.py",
    "tests/kernels/test_int8_quant.py",
    "tests/kernels/test_layernorm.py",
    "tests/kernels/test_marlin_gemm.py",
    "tests/kernels/test_moe.py",
    "tests/kernels/test_pos_encoding.py",
    "tests/kernels/test_prefix_prefill.py",
    "tests/kernels/test_rand.py",
    "tests/kernels/test_sampler.py",
    "tests/kernels/utils.py",
    "tests/lora/conftest.py",
    "tests/lora/data/__init__.py",
    "tests/lora/data/long_context_test_data.py",
    "tests/lora/test_baichuan.py",
    "tests/lora/test_chatglm3.py",
    "tests/lora/test_layer_variation.py",
    "tests/lora/test_layers.py",
    "tests/lora/test_llama.py",
    "tests/lora/test_long_context.py",
    "tests/lora/test_lora_checkpoints.py",
    "tests/lora/test_lora_manager.py",
    "tests/lora/test_mixtral.py",
    "tests/lora/test_phi.py",
    "tests/lora/test_punica.py",
    "tests/lora/test_quant_model.py",
    "tests/lora/test_tokenizer_group.py",
    "tests/lora/test_utils.py",
    "tests/lora/test_worker.py",
    "tests/metrics/__init__.py",
    "tests/metrics/test_metrics.py",
    "tests/model_executor/__init__.py",
    "tests/model_executor/weight_utils.py",
    "tests/models/__init__.py",
    "tests/models/test_aqlm.py",
    "tests/models/test_big_models.py",
    "tests/models/test_embedding.py",
    "tests/models/test_fp8.py",
    "tests/models/test_gptq_marlin.py",
    "tests/models/test_gptq_marlin_24.py",
    "tests/models/test_llava.py",
    "tests/models/test_marlin.py",
    "tests/models/test_mistral.py",
    "tests/models/test_models.py",
    "tests/models/test_oot_registration.py",
    "tests/models/test_registry.py",
    "tests/models/utils.py",
    "tests/multimodal/__init__.py",
    "tests/multimodal/test_processor.py",
    "tests/prefix_caching/__init__.py",
    "tests/prefix_caching/test_disable_sliding_window.py",
    "tests/prefix_caching/test_prefix_caching.py",
    "tests/quantization/__init__.py",
    "tests/quantization/test_bitsandbytes.py",
    "tests/quantization/test_compressed_tensors.py",
    "tests/quantization/test_configs.py",
    "tests/quantization/test_fp8.py",
    "tests/samplers/__init__.py",
    "tests/samplers/test_beam_search.py",
    "tests/samplers/test_ignore_eos.py",
    "tests/samplers/test_logits_processor.py",
    "tests/samplers/test_logprobs.py",
    "tests/samplers/test_ranks.py",
    "tests/samplers/test_rejection_sampler.py",
    "tests/samplers/test_sampler.py",
    "tests/samplers/test_seeded_generate.py",
    "tests/spec_decode/e2e/__init__.py",
    "tests/spec_decode/e2e/conftest.py",
    "tests/spec_decode/e2e/test_compatibility.py",
    "tests/spec_decode/e2e/test_integration.py",
    "tests/spec_decode/e2e/test_integration_dist.py",
    "tests/spec_decode/e2e/test_logprobs.py",
    "tests/spec_decode/e2e/test_multistep_correctness.py",
    "tests/spec_decode/e2e/test_ngram_correctness.py",
    "tests/spec_decode/test_batch_expansion.py",
    "tests/spec_decode/test_dynamic_spec_decode.py",
    "tests/spec_decode/test_metrics.py",
    "tests/spec_decode/test_multi_step_worker.py",
    "tests/spec_decode/test_ngram_worker.py",
    "tests/spec_decode/test_spec_decode_worker.py",
    "tests/spec_decode/test_utils.py",
    "tests/spec_decode/utils.py",
    "tests/tensorizer_loader/__init__.py",
    "tests/tensorizer_loader/test_tensorizer.py",
    "tests/test_cache_block_hashing.py",
    "tests/test_config.py",
    "tests/test_inputs.py",
    "tests/test_logger.py",
    "tests/test_logits_processor.py",
    "tests/test_regression.py",
    "tests/test_sequence.py",
    "tests/test_sharded_state_loader.py",
    "tests/test_utils.py",
    "tests/tokenization/test_cached_tokenizer.py",
    "tests/tokenization/test_detokenize.py",
    "tests/tokenization/test_image_processor.py",
    "tests/tokenization/test_tokenizer.py",
    "tests/tokenization/test_tokenizer_group.py",
    "tests/utils.py",
    "tests/worker/test_model_runner.py",
    "tests/worker/test_swap.py",
    "vllm/__init__.py",
    "vllm/_custom_ops.py",
    "vllm/attention/__init__.py",
    "vllm/attention/backends/__init__.py",
    "vllm/attention/backends/abstract.py",
    "vllm/attention/backends/blocksparse_attn.py",
    "vllm/attention/backends/flash_attn.py",
    "vllm/attention/backends/flashinfer.py",
    "vllm/attention/backends/rocm_flash_attn.py",
    "vllm/attention/backends/torch_sdpa.py",
    "vllm/attention/backends/xformers.py",
    "vllm/attention/layer.py",
    "vllm/attention/ops/__init__.py",
    "vllm/attention/ops/blocksparse_attention/__init__.py",
    "vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py",
    "vllm/attention/ops/blocksparse_attention/interface.py",
    "vllm/attention/ops/blocksparse_attention/utils.py",
    "vllm/attention/ops/paged_attn.py",
    "vllm/attention/ops/triton_flash_attention.py",
    "vllm/attention/selector.py",
    "vllm/config.py",
    "vllm/core/block/__init__.py",
    "vllm/core/block/block_table.py",
    "vllm/core/block/common.py",
    "vllm/core/block/cpu_gpu_block_allocator.py",
    "vllm/core/block/interfaces.py",
    "vllm/core/block/naive_block.py",
    "vllm/core/block/prefix_caching_block.py",
    "vllm/core/block/utils.py",
    "vllm/core/block_manager.py",
    "vllm/core/block_manager_v2.py",
    "vllm/core/embedding_model_block_manager.py",
    "vllm/core/evictor.py",
    "vllm/core/evictor_v2.py",
    "vllm/core/interfaces.py",
    "vllm/core/policy.py",
    "vllm/core/scheduler.py",
    "vllm/distributed/__init__.py",
    "vllm/distributed/communication_op.py",
    "vllm/distributed/device_communicators/__init__.py",
    "vllm/distributed/device_communicators/custom_all_reduce.py",
    "vllm/distributed/device_communicators/custom_all_reduce_utils.py",
    "vllm/distributed/device_communicators/pynccl.py",
    "vllm/distributed/device_communicators/pynccl_wrapper.py",
    "vllm/distributed/parallel_state.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/async_llm_engine.py",
    "vllm/engine/llm_engine.py",
    "vllm/engine/metrics.py",
    "vllm/engine/output_processor/__init__.py",
    "vllm/engine/output_processor/interfaces.py",
    "vllm/engine/output_processor/multi_step.py",
    "vllm/engine/output_processor/single_step.py",
    "vllm/engine/output_processor/stop_checker.py",
    "vllm/engine/output_processor/util.py",
    "vllm/engine/ray_utils.py",
    "vllm/entrypoints/api_server.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/api_server.py",
    "vllm/entrypoints/openai/cli_args.py",
    "vllm/entrypoints/openai/protocol.py",
    "vllm/entrypoints/openai/run_batch.py",
    "vllm/entrypoints/openai/serving_chat.py",
    "vllm/entrypoints/openai/serving_completion.py",
    "vllm/entrypoints/openai/serving_embedding.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/envs.py",
    "vllm/executor/cpu_executor.py",
    "vllm/executor/distributed_gpu_executor.py",
    "vllm/executor/executor_base.py",
    "vllm/executor/gpu_executor.py",
    "vllm/executor/multiproc_gpu_executor.py",
    "vllm/executor/multiproc_worker_utils.py",
    "vllm/executor/neuron_executor.py",
    "vllm/executor/ray_gpu_executor.py",
    "vllm/executor/utils.py",
    "vllm/inputs.py",
    "vllm/logger.py",
    "vllm/logging/__init__.py",
    "vllm/logging/formatter.py",
    "vllm/lora/fully_sharded_layers.py",
    "vllm/lora/layers.py",
    "vllm/lora/lora.py",
    "vllm/lora/models.py",
    "vllm/lora/punica.py",
    "vllm/lora/request.py",
    "vllm/lora/utils.py",
    "vllm/lora/worker_manager.py",
    "vllm/model_executor/__init__.py",
    "vllm/model_executor/custom_op.py",
    "vllm/model_executor/guided_decoding.py",
    "vllm/model_executor/guided_decoding/__init__.py",
    "vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py",
    "vllm/model_executor/guided_logits_processors.py",
    "vllm/model_executor/input_metadata.py",
    "vllm/model_executor/layers/activation.py",
    "vllm/model_executor/layers/attention/__init__.py",
    "vllm/model_executor/layers/attention/attention.py",
    "vllm/model_executor/layers/attention/backends/__init__.py",
    "vllm/model_executor/layers/attention/backends/flash_attn.py",
    "vllm/model_executor/layers/attention/backends/xformers.py",
    "vllm/model_executor/layers/attention/ops/__init__.py",
    "vllm/model_executor/layers/attention/ops/paged_attn.py",
    "vllm/model_executor/layers/attention/ops/prefix_prefill.py",
    "vllm/model_executor/layers/fused_moe/__init__.py",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/fused_moe.py",
    "vllm/model_executor/layers/layernorm.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/logits_processor.py",
    "vllm/model_executor/layers/ops/__init__.py",
    "vllm/model_executor/layers/ops/rand.py",
    "vllm/model_executor/layers/ops/sample.py",
    "vllm/model_executor/layers/pooler.py",
    "vllm/model_executor/layers/quantization/__init__.py",
    "vllm/model_executor/layers/quantization/aqlm.py",
    "vllm/model_executor/layers/quantization/awq.py",
    "vllm/model_executor/layers/quantization/base_config.py",
    "vllm/model_executor/layers/quantization/bitsandbytes.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/__init__.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_unquantized.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_statictensor.py",
    "vllm/model_executor/layers/quantization/deepspeedfp.py",
    "vllm/model_executor/layers/quantization/fp8.py",
    "vllm/model_executor/layers/quantization/gptq.py",
    "vllm/model_executor/layers/quantization/gptq_marlin.py",
    "vllm/model_executor/layers/quantization/gptq_marlin_24.py",
    "vllm/model_executor/layers/quantization/marlin.py",
    "vllm/model_executor/layers/quantization/schema.py",
    "vllm/model_executor/layers/quantization/squeezellm.py",
    "vllm/model_executor/layers/quantization/utils/__init__.py",
    "vllm/model_executor/layers/quantization/utils/format_24.py",
    "vllm/model_executor/layers/quantization/utils/marlin_24_perms.py",
    "vllm/model_executor/layers/quantization/utils/marlin_perms.py",
    "vllm/model_executor/layers/quantization/utils/marlin_utils.py",
    "vllm/model_executor/layers/quantization/utils/quant_utils.py",
    "vllm/model_executor/layers/rejection_sampler.py",
    "vllm/model_executor/layers/rotary_embedding.py",
    "vllm/model_executor/layers/sampler.py",
    "vllm/model_executor/layers/vocab_parallel_embedding.py",
    "vllm/model_executor/model_loader.py",
    "vllm/model_executor/model_loader/__init__.py",
    "vllm/model_executor/model_loader/loader.py",
    "vllm/model_executor/model_loader/neuron.py",
    "vllm/model_executor/model_loader/tensorizer.py",
    "vllm/model_executor/model_loader/utils.py",
    "vllm/model_executor/model_loader/weight_utils.py",
    "vllm/model_executor/models/__init__.py",
    "vllm/model_executor/models/arctic.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/bloom.py",
    "vllm/model_executor/models/chatglm.py",
    "vllm/model_executor/models/commandr.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/decilm.py",
    "vllm/model_executor/models/deepseek.py",
    "vllm/model_executor/models/falcon.py",
    "vllm/model_executor/models/gemma.py",
    "vllm/model_executor/models/gpt2.py",
    "vllm/model_executor/models/gpt_bigcode.py",
    "vllm/model_executor/models/gpt_j.py",
    "vllm/model_executor/models/gpt_neox.py",
    "vllm/model_executor/models/internlm2.py",
    "vllm/model_executor/models/jais.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llama_embedding.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mixtral_quant.py",
    "vllm/model_executor/models/mpt.py",
    "vllm/model_executor/models/neuron/llama.py",
    "vllm/model_executor/models/neuron/mistral.py",
    "vllm/model_executor/models/olmo.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/orion.py",
    "vllm/model_executor/models/phi.py",
    "vllm/model_executor/models/phi3_small.py",
    "vllm/model_executor/models/qwen.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_moe.py",
    "vllm/model_executor/models/stablelm.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/vlm_base.py",
    "vllm/model_executor/models/xverse.py",
    "vllm/model_executor/neuron_model_loader.py",
    "vllm/model_executor/parallel_utils/README.md",
    "vllm/model_executor/parallel_utils/__init__.py",
    "vllm/model_executor/parallel_utils/communication_op.py",
    "vllm/model_executor/parallel_utils/cupy_utils.py",
    "vllm/model_executor/parallel_utils/custom_all_reduce.py",
    "vllm/model_executor/parallel_utils/parallel_state.py",
    "vllm/model_executor/parallel_utils/utils.py",
    "vllm/model_executor/pooling_metadata.py",
    "vllm/model_executor/sampling_metadata.py",
    "vllm/model_executor/utils.py",
    "vllm/model_executor/weight_utils.py",
    "vllm/multimodal/__init__.py",
    "vllm/multimodal/base.py",
    "vllm/multimodal/image.py",
    "vllm/multimodal/registry.py",
    "vllm/outputs.py",
    "vllm/pooling_params.py",
    "vllm/sampling_params.py",
    "vllm/sequence.py",
    "vllm/spec_decode/__init__.py",
    "vllm/spec_decode/batch_expansion.py",
    "vllm/spec_decode/interfaces.py",
    "vllm/spec_decode/metrics.py",
    "vllm/spec_decode/multi_step_worker.py",
    "vllm/spec_decode/ngram_worker.py",
    "vllm/spec_decode/proposer_worker_base.py",
    "vllm/spec_decode/spec_decode_worker.py",
    "vllm/spec_decode/top1_proposer.py",
    "vllm/spec_decode/util.py",
    "vllm/test_utils.py",
    "vllm/transformers_utils/config.py",
    "vllm/transformers_utils/configs/__init__.py",
    "vllm/transformers_utils/configs/arctic.py",
    "vllm/transformers_utils/configs/chatglm.py",
    "vllm/transformers_utils/configs/dbrx.py",
    "vllm/transformers_utils/configs/jais.py",
    "vllm/transformers_utils/configs/mpt.py",
    "vllm/transformers_utils/configs/starcoder2.py",
    "vllm/transformers_utils/detokenizer.py",
    "vllm/transformers_utils/image_processor.py",
    "vllm/transformers_utils/tokenizer.py",
    "vllm/transformers_utils/tokenizer_group/__init__.py",
    "vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py",
    "vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py",
    "vllm/transformers_utils/tokenizer_group/tokenizer_group.py",
    "vllm/transformers_utils/tokenizers/baichuan.py",
    "vllm/usage/__init__.py",
    "vllm/usage/usage_lib.py",
    "vllm/utils.py",
    "vllm/worker/cache_engine.py",
    "vllm/worker/cpu_model_runner.py",
    "vllm/worker/cpu_worker.py",
    "vllm/worker/embedding_model_runner.py",
    "vllm/worker/model_runner.py",
    "vllm/worker/neuron_model_runner.py",
    "vllm/worker/neuron_worker.py",
    "vllm/worker/worker.py",
    "vllm/worker/worker_base.py"
  ],
  "allowed": [
    "vllm/model_executor/layers/quantization/fp8.py",
    "vllm/_custom_ops.py"
  ],
  "disallowed": [
    ".buildkite/check-wheel-size.py",
    ".buildkite/download-images.sh",
    ".buildkite/nightly-benchmarks/kickoff-pipeline.sh",
    ".buildkite/nightly-benchmarks/sample.yaml",
    ".buildkite/run-amd-test.sh",
    ".buildkite/run-benchmarks.sh",
    ".buildkite/run-cpu-test.sh",
    ".buildkite/run-neuron-test.sh",
    ".buildkite/test-pipeline.yaml",
    ".buildkite/test-template-aws.j2",
    ".buildkite/test-template.j2",
    ".clang-format",
    ".github/ISSUE_TEMPLATE/200-installation.yml",
    ".github/ISSUE_TEMPLATE/300-usage.yml",
    ".github/ISSUE_TEMPLATE/400-bug report.yml",
    ".github/ISSUE_TEMPLATE/700-performance discussion.yml",
    ".github/ISSUE_TEMPLATE/750-RFC.yml",
    ".github/workflows/clang-format.yml",
    ".github/workflows/mypy.yaml",
    ".github/workflows/publish.yml",
    ".github/workflows/ruff.yml",
    ".github/workflows/scripts/build.sh",
    ".github/workflows/scripts/create_release.js",
    ".github/workflows/yapf.yml",
    ".gitignore",
    "CMakeLists.txt",
    "CONTRIBUTING.md",
    "Dockerfile",
    "Dockerfile.cpu",
    "Dockerfile.neuron",
    "Dockerfile.rocm",
    "MANIFEST.in",
    "README.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_latency.py",
    "benchmarks/benchmark_prefix_caching.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/benchmark_throughput.py",
    "benchmarks/cutlass_benchmarks/w8a8_benchmarks.py",
    "benchmarks/cutlass_benchmarks/weight_shapes.py",
    "benchmarks/kernels/benchmark_aqlm.py",
    "benchmarks/kernels/benchmark_marlin.py",
    "benchmarks/kernels/benchmark_mixtral_moe.py",
    "benchmarks/kernels/benchmark_moe.py",
    "benchmarks/kernels/benchmark_paged_attention.py",
    "benchmarks/kernels/benchmark_rope.py",
    "benchmarks/kernels/benchmark_shapes.py",
    "benchmarks/launch_tgi_server.sh",
    "benchmarks/overheads/benchmark_hashing.py",
    "benchmarks/sonnet.txt",
    "cmake/cpu_extension.cmake",
    "cmake/hipify.py",
    "cmake/utils.cmake",
    "collect_env.py",
    "csrc/activation_kernels.cu",
    "csrc/attention/attention_dtypes.h",
    "csrc/attention/attention_generic.cuh",
    "csrc/attention/attention_kernels.cu",
    "csrc/attention/attention_utils.cuh",
    "csrc/attention/dtype_bfloat16.cuh",
    "csrc/attention/dtype_float16.cuh",
    "csrc/attention/dtype_float32.cuh",
    "csrc/attention/dtype_fp8.cuh",
    "csrc/attention/dtype_fp8_e5m2.cuh",
    "csrc/cache.h",
    "csrc/cache_kernels.cu",
    "csrc/cpu/activation.cpp",
    "csrc/cpu/attention.cpp",
    "csrc/cpu/cache.cpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/layernorm.cpp",
    "csrc/cpu/pos_encoding.cpp",
    "csrc/cpu/pybind.cpp",
    "csrc/cuda_compat.h",
    "csrc/cuda_utils.h",
    "csrc/cuda_utils_kernels.cu",
    "csrc/custom_all_reduce.cu",
    "csrc/custom_all_reduce.cuh",
    "csrc/custom_all_reduce_test.cu",
    "csrc/dispatch_utils.h",
    "csrc/layernorm_kernels.cu",
    "csrc/moe/moe_ops.cpp",
    "csrc/moe/moe_ops.h",
    "csrc/moe/topk_softmax_kernels.cu",
    "csrc/moe_align_block_size_kernels.cu",
    "csrc/ops.h",
    "csrc/pos_encoding_kernels.cu",
    "csrc/punica/bgmv/bgmv_bf16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_bf16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_config.h",
    "csrc/punica/bgmv/bgmv_fp16_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp16_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_bf16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp16_fp16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_bf16.cu",
    "csrc/punica/bgmv/bgmv_fp32_fp32_fp16.cu",
    "csrc/punica/bgmv/bgmv_impl.cuh",
    "csrc/punica/bgmv/generator.py",
    "csrc/punica/bgmv/vec_dtypes.cuh",
    "csrc/punica/punica_ops.cc",
    "csrc/punica/punica_ops.h",
    "csrc/punica/punica_pybind.cpp",
    "csrc/punica/type_convert.h",
    "csrc/pybind.cpp",
    "csrc/quantization/aqlm/gemm_kernels.cu",
    "csrc/quantization/awq/dequantize.cuh",
    "csrc/quantization/awq/gemm_kernels.cu",
    "csrc/quantization/compressed_tensors/int8_quant_kernels.cu",
    "csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c2x.hpp",
    "csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c3x.hpp",
    "csrc/quantization/cutlass_w8a8/common.hpp",
    "csrc/quantization/cutlass_w8a8/scaled_mm_dq_c2x.cu",
    "csrc/quantization/cutlass_w8a8/scaled_mm_dq_c3x.cu",
    "csrc/quantization/cutlass_w8a8/scaled_mm_dq_entry.cu",
    "csrc/quantization/fp8/amd/hip_float8.h",
    "csrc/quantization/fp8/amd/hip_float8_impl.h",
    "csrc/quantization/fp8/amd/quant_utils.cuh",
    "csrc/quantization/fp8/common.cu",
    "csrc/quantization/fp8/nvidia/quant_utils.cuh",
    "csrc/quantization/fp8_e5m2_kvcache/quant_utils.cuh",
    "csrc/quantization/gptq/compat.cuh",
    "csrc/quantization/gptq/matrix_view.cuh",
    "csrc/quantization/gptq/q_gemm.cu",
    "csrc/quantization/gptq/qdq_2.cuh",
    "csrc/quantization/gptq/qdq_3.cuh",
    "csrc/quantization/gptq/qdq_4.cuh",
    "csrc/quantization/gptq/qdq_8.cuh",
    "csrc/quantization/gptq/qdq_util.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin.cu",
    "csrc/quantization/gptq_marlin/gptq_marlin.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin_dtypes.cuh",
    "csrc/quantization/gptq_marlin/gptq_marlin_repack.cu",
    "csrc/quantization/marlin/LICENSE",
    "csrc/quantization/marlin/marlin_cuda_kernel.cu",
    "csrc/quantization/marlin/sparse/LICENSE",
    "csrc/quantization/marlin/sparse/common/base.h",
    "csrc/quantization/marlin/sparse/common/mem.h",
    "csrc/quantization/marlin/sparse/common/mma.h",
    "csrc/quantization/marlin/sparse/marlin_24_cuda_kernel.cu",
    "csrc/quantization/squeezellm/quant_cuda_kernel.cu",
    "csrc/reduction_utils.cuh",
    "docs/requirements-docs.txt",
    "docs/source/assets/dev/dockerfile-stages-dependency.png",
    "docs/source/community/meetups.rst",
    "docs/source/community/sponsors.md",
    "docs/source/conf.py",
    "docs/source/dev/dockerfile/dockerfile.rst",
    "docs/source/dev/engine/async_llm_engine.rst",
    "docs/source/dev/engine/llm_engine.rst",
    "docs/source/dev/multimodal/multimodal_index.rst",
    "docs/source/dev/offline_inference/llm.rst",
    "docs/source/dev/offline_inference/llm_inputs.rst",
    "docs/source/dev/offline_inference/offline_index.rst",
    "docs/source/dev/sampling_params.rst",
    "docs/source/generate_examples.py",
    "docs/source/getting_started/amd-installation.rst",
    "docs/source/getting_started/cpu-installation.rst",
    "docs/source/getting_started/examples/examples_index.template.rst",
    "docs/source/getting_started/installation.rst",
    "docs/source/index.rst",
    "docs/source/models/adding_model.rst",
    "docs/source/models/engine_args.rst",
    "docs/source/models/performance.rst",
    "docs/source/models/supported_models.rst",
    "docs/source/models/vlm.rst",
    "docs/source/quantization/fp8_e4m3_kvcache.rst",
    "docs/source/quantization/fp8_e5m2_kv_cache.rst",
    "docs/source/serving/deploying_with_docker.rst",
    "docs/source/serving/deploying_with_dstack.rst",
    "docs/source/serving/deploying_with_lws.rst",
    "docs/source/serving/env_vars.rst",
    "docs/source/serving/integrations.rst",
    "docs/source/serving/openai_compatible_server.md",
    "docs/source/serving/run_on_sky.rst",
    "docs/source/serving/usage_stats.md",
    "examples/aqlm_example.py",
    "examples/fp8/README.md",
    "examples/fp8/extract_scales.py",
    "examples/fp8/quantizer/README.md",
    "examples/fp8/quantizer/quantize.py",
    "examples/gradio_openai_chatbot_webserver.py",
    "examples/llava_example.py",
    "examples/llm_engine_example.py",
    "examples/logging_configuration.md",
    "examples/lora_with_quantization_inference.py",
    "examples/multilora_inference.py",
    "examples/offline_inference_arctic.py",
    "examples/offline_inference_distributed.py",
    "examples/offline_inference_embedding.py",
    "examples/offline_inference_neuron.py",
    "examples/offline_inference_openai.md",
    "examples/offline_inference_with_prefix.py",
    "examples/openai_chatcompletion_client.py",
    "examples/openai_embedding_client.py",
    "examples/openai_example_batch.jsonl",
    "examples/production_monitoring/README.md",
    "examples/production_monitoring/grafana.json",
    "examples/save_sharded_state.py",
    "examples/tensorize_vllm_model.py",
    "format.sh",
    "model_patch.diff",
    "patch_xformers.rocm.sh",
    "pyproject.toml",
    "requirements-build.txt",
    "requirements-common.txt",
    "requirements-cpu.txt",
    "requirements-cuda.txt",
    "requirements-dev.txt",
    "requirements-neuron.txt",
    "requirements-rocm.txt",
    "requirements.txt",
    "rocm_patch/commonpy_xformers-0.0.23.rocm.patch",
    "rocm_patch/flashpy_xformers-0.0.23.rocm.patch",
    "setup.py",
    "tests/async_engine/test_api_server.py",
    "tests/async_engine/test_async_llm_engine.py",
    "tests/async_engine/test_chat_template.py",
    "tests/async_engine/test_openapi_server_ray.py",
    "tests/basic_correctness/test_basic_correctness.py",
    "tests/basic_correctness/test_chunked_prefill.py",
    "tests/basic_correctness/test_preemption.py",
    "tests/conftest.py",
    "tests/core/block/conftest.py",
    "tests/core/block/e2e/__init__.py",
    "tests/core/block/e2e/conftest.py",
    "tests/core/block/e2e/test_correctness.py",
    "tests/core/block/e2e/test_correctness_sliding_window.py",
    "tests/core/block/test_block_manager_v2.py",
    "tests/core/block/test_block_table.py",
    "tests/core/block/test_common.py",
    "tests/core/block/test_cpu_gpu_block_allocator.py",
    "tests/core/block/test_naive_block.py",
    "tests/core/block/test_prefix_caching_block.py",
    "tests/core/test_block_manager.py",
    "tests/core/test_chunked_prefill_scheduler.py",
    "tests/core/test_scheduler.py",
    "tests/core/utils.py",
    "tests/distributed/__init__.py",
    "tests/distributed/test_basic_distributed_correctness.py",
    "tests/distributed/test_chunked_prefill_distributed.py",
    "tests/distributed/test_comm_ops.py",
    "tests/distributed/test_custom_all_reduce.py",
    "tests/distributed/test_pynccl.py",
    "tests/engine/__init__.py",
    "tests/engine/output_processor/__init__.py",
    "tests/engine/output_processor/test_multi_step.py",
    "tests/engine/output_processor/test_stop_checker.py",
    "tests/engine/test_detokenization.py",
    "tests/engine/test_multiproc_workers.py",
    "tests/engine/test_skip_tokenizer_init.py",
    "tests/engine/test_stop_reason.py",
    "tests/engine/test_stop_strings.py",
    "tests/entrypoints/__init__.py",
    "tests/entrypoints/openai/test_serving_chat.py",
    "tests/entrypoints/test_guided_processors.py",
    "tests/entrypoints/test_llm_encode.py",
    "tests/entrypoints/test_llm_generate.py",
    "tests/entrypoints/test_llm_generate_multiple_loras.py",
    "tests/entrypoints/test_openai_run_batch.py",
    "tests/entrypoints/test_openai_server.py",
    "tests/entrypoints/test_server_oot_registration.py",
    "tests/fp8_kv/llama2-70b-fp8-kv/kv_cache_scales.json",
    "tests/fp8_kv/llama2-7b-fp8-kv/kv_cache_scales.json",
    "tests/kernels/__init__.py",
    "tests/kernels/conftest.py",
    "tests/kernels/test_activation.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_attention_selector.py",
    "tests/kernels/test_blocksparse_attention.py",
    "tests/kernels/test_cache.py",
    "tests/kernels/test_cutlass.py",
    "tests/kernels/test_flash_attn.py",
    "tests/kernels/test_int8_quant.py",
    "tests/kernels/test_layernorm.py",
    "tests/kernels/test_marlin_gemm.py",
    "tests/kernels/test_moe.py",
    "tests/kernels/test_pos_encoding.py",
    "tests/kernels/test_prefix_prefill.py",
    "tests/kernels/test_rand.py",
    "tests/kernels/test_sampler.py",
    "tests/kernels/utils.py",
    "tests/lora/conftest.py",
    "tests/lora/data/__init__.py",
    "tests/lora/data/long_context_test_data.py",
    "tests/lora/test_baichuan.py",
    "tests/lora/test_chatglm3.py",
    "tests/lora/test_layer_variation.py",
    "tests/lora/test_layers.py",
    "tests/lora/test_llama.py",
    "tests/lora/test_long_context.py",
    "tests/lora/test_lora_checkpoints.py",
    "tests/lora/test_lora_manager.py",
    "tests/lora/test_mixtral.py",
    "tests/lora/test_phi.py",
    "tests/lora/test_punica.py",
    "tests/lora/test_quant_model.py",
    "tests/lora/test_tokenizer_group.py",
    "tests/lora/test_utils.py",
    "tests/lora/test_worker.py",
    "tests/metrics/__init__.py",
    "tests/metrics/test_metrics.py",
    "tests/model_executor/__init__.py",
    "tests/model_executor/weight_utils.py",
    "tests/models/__init__.py",
    "tests/models/test_aqlm.py",
    "tests/models/test_big_models.py",
    "tests/models/test_embedding.py",
    "tests/models/test_fp8.py",
    "tests/models/test_gptq_marlin.py",
    "tests/models/test_gptq_marlin_24.py",
    "tests/models/test_llava.py",
    "tests/models/test_marlin.py",
    "tests/models/test_mistral.py",
    "tests/models/test_models.py",
    "tests/models/test_oot_registration.py",
    "tests/models/test_registry.py",
    "tests/models/utils.py",
    "tests/multimodal/__init__.py",
    "tests/multimodal/test_processor.py",
    "tests/prefix_caching/__init__.py",
    "tests/prefix_caching/test_disable_sliding_window.py",
    "tests/prefix_caching/test_prefix_caching.py",
    "tests/quantization/__init__.py",
    "tests/quantization/test_bitsandbytes.py",
    "tests/quantization/test_compressed_tensors.py",
    "tests/quantization/test_configs.py",
    "tests/quantization/test_fp8.py",
    "tests/samplers/__init__.py",
    "tests/samplers/test_beam_search.py",
    "tests/samplers/test_ignore_eos.py",
    "tests/samplers/test_logits_processor.py",
    "tests/samplers/test_logprobs.py",
    "tests/samplers/test_ranks.py",
    "tests/samplers/test_rejection_sampler.py",
    "tests/samplers/test_sampler.py",
    "tests/samplers/test_seeded_generate.py",
    "tests/spec_decode/e2e/__init__.py",
    "tests/spec_decode/e2e/conftest.py",
    "tests/spec_decode/e2e/test_compatibility.py",
    "tests/spec_decode/e2e/test_integration.py",
    "tests/spec_decode/e2e/test_integration_dist.py",
    "tests/spec_decode/e2e/test_logprobs.py",
    "tests/spec_decode/e2e/test_multistep_correctness.py",
    "tests/spec_decode/e2e/test_ngram_correctness.py",
    "tests/spec_decode/test_batch_expansion.py",
    "tests/spec_decode/test_dynamic_spec_decode.py",
    "tests/spec_decode/test_metrics.py",
    "tests/spec_decode/test_multi_step_worker.py",
    "tests/spec_decode/test_ngram_worker.py",
    "tests/spec_decode/test_spec_decode_worker.py",
    "tests/spec_decode/test_utils.py",
    "tests/spec_decode/utils.py",
    "tests/tensorizer_loader/__init__.py",
    "tests/tensorizer_loader/test_tensorizer.py",
    "tests/test_cache_block_hashing.py",
    "tests/test_config.py",
    "tests/test_inputs.py",
    "tests/test_logger.py",
    "tests/test_logits_processor.py",
    "tests/test_regression.py",
    "tests/test_sequence.py",
    "tests/test_sharded_state_loader.py",
    "tests/test_utils.py",
    "tests/tokenization/test_cached_tokenizer.py",
    "tests/tokenization/test_detokenize.py",
    "tests/tokenization/test_image_processor.py",
    "tests/tokenization/test_tokenizer.py",
    "tests/tokenization/test_tokenizer_group.py",
    "tests/utils.py",
    "tests/worker/test_model_runner.py",
    "tests/worker/test_swap.py",
    "vllm/__init__.py",
    "vllm/attention/__init__.py",
    "vllm/attention/backends/__init__.py",
    "vllm/attention/backends/abstract.py",
    "vllm/attention/backends/blocksparse_attn.py",
    "vllm/attention/backends/flash_attn.py",
    "vllm/attention/backends/flashinfer.py",
    "vllm/attention/backends/rocm_flash_attn.py",
    "vllm/attention/backends/torch_sdpa.py",
    "vllm/attention/backends/xformers.py",
    "vllm/attention/layer.py",
    "vllm/attention/ops/__init__.py",
    "vllm/attention/ops/blocksparse_attention/__init__.py",
    "vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py",
    "vllm/attention/ops/blocksparse_attention/interface.py",
    "vllm/attention/ops/blocksparse_attention/utils.py",
    "vllm/attention/ops/paged_attn.py",
    "vllm/attention/ops/triton_flash_attention.py",
    "vllm/attention/selector.py",
    "vllm/config.py",
    "vllm/core/block/__init__.py",
    "vllm/core/block/block_table.py",
    "vllm/core/block/common.py",
    "vllm/core/block/cpu_gpu_block_allocator.py",
    "vllm/core/block/interfaces.py",
    "vllm/core/block/naive_block.py",
    "vllm/core/block/prefix_caching_block.py",
    "vllm/core/block/utils.py",
    "vllm/core/block_manager.py",
    "vllm/core/block_manager_v2.py",
    "vllm/core/embedding_model_block_manager.py",
    "vllm/core/evictor.py",
    "vllm/core/evictor_v2.py",
    "vllm/core/interfaces.py",
    "vllm/core/policy.py",
    "vllm/core/scheduler.py",
    "vllm/distributed/__init__.py",
    "vllm/distributed/communication_op.py",
    "vllm/distributed/device_communicators/__init__.py",
    "vllm/distributed/device_communicators/custom_all_reduce.py",
    "vllm/distributed/device_communicators/custom_all_reduce_utils.py",
    "vllm/distributed/device_communicators/pynccl.py",
    "vllm/distributed/device_communicators/pynccl_wrapper.py",
    "vllm/distributed/parallel_state.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/async_llm_engine.py",
    "vllm/engine/llm_engine.py",
    "vllm/engine/metrics.py",
    "vllm/engine/output_processor/__init__.py",
    "vllm/engine/output_processor/interfaces.py",
    "vllm/engine/output_processor/multi_step.py",
    "vllm/engine/output_processor/single_step.py",
    "vllm/engine/output_processor/stop_checker.py",
    "vllm/engine/output_processor/util.py",
    "vllm/engine/ray_utils.py",
    "vllm/entrypoints/api_server.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/api_server.py",
    "vllm/entrypoints/openai/cli_args.py",
    "vllm/entrypoints/openai/protocol.py",
    "vllm/entrypoints/openai/run_batch.py",
    "vllm/entrypoints/openai/serving_chat.py",
    "vllm/entrypoints/openai/serving_completion.py",
    "vllm/entrypoints/openai/serving_embedding.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/envs.py",
    "vllm/executor/cpu_executor.py",
    "vllm/executor/distributed_gpu_executor.py",
    "vllm/executor/executor_base.py",
    "vllm/executor/gpu_executor.py",
    "vllm/executor/multiproc_gpu_executor.py",
    "vllm/executor/multiproc_worker_utils.py",
    "vllm/executor/neuron_executor.py",
    "vllm/executor/ray_gpu_executor.py",
    "vllm/executor/utils.py",
    "vllm/inputs.py",
    "vllm/logger.py",
    "vllm/logging/__init__.py",
    "vllm/logging/formatter.py",
    "vllm/lora/fully_sharded_layers.py",
    "vllm/lora/layers.py",
    "vllm/lora/lora.py",
    "vllm/lora/models.py",
    "vllm/lora/punica.py",
    "vllm/lora/request.py",
    "vllm/lora/utils.py",
    "vllm/lora/worker_manager.py",
    "vllm/model_executor/__init__.py",
    "vllm/model_executor/custom_op.py",
    "vllm/model_executor/guided_decoding.py",
    "vllm/model_executor/guided_decoding/__init__.py",
    "vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py",
    "vllm/model_executor/guided_logits_processors.py",
    "vllm/model_executor/input_metadata.py",
    "vllm/model_executor/layers/activation.py",
    "vllm/model_executor/layers/attention/__init__.py",
    "vllm/model_executor/layers/attention/attention.py",
    "vllm/model_executor/layers/attention/backends/__init__.py",
    "vllm/model_executor/layers/attention/backends/flash_attn.py",
    "vllm/model_executor/layers/attention/backends/xformers.py",
    "vllm/model_executor/layers/attention/ops/__init__.py",
    "vllm/model_executor/layers/attention/ops/paged_attn.py",
    "vllm/model_executor/layers/attention/ops/prefix_prefill.py",
    "vllm/model_executor/layers/fused_moe/__init__.py",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",
    "vllm/model_executor/layers/fused_moe/fused_moe.py",
    "vllm/model_executor/layers/layernorm.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/logits_processor.py",
    "vllm/model_executor/layers/ops/__init__.py",
    "vllm/model_executor/layers/ops/rand.py",
    "vllm/model_executor/layers/ops/sample.py",
    "vllm/model_executor/layers/pooler.py",
    "vllm/model_executor/layers/quantization/__init__.py",
    "vllm/model_executor/layers/quantization/aqlm.py",
    "vllm/model_executor/layers/quantization/awq.py",
    "vllm/model_executor/layers/quantization/base_config.py",
    "vllm/model_executor/layers/quantization/bitsandbytes.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/__init__.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_unquantized.py",
    "vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_statictensor.py",
    "vllm/model_executor/layers/quantization/deepspeedfp.py",
    "vllm/model_executor/layers/quantization/gptq.py",
    "vllm/model_executor/layers/quantization/gptq_marlin.py",
    "vllm/model_executor/layers/quantization/gptq_marlin_24.py",
    "vllm/model_executor/layers/quantization/marlin.py",
    "vllm/model_executor/layers/quantization/schema.py",
    "vllm/model_executor/layers/quantization/squeezellm.py",
    "vllm/model_executor/layers/quantization/utils/__init__.py",
    "vllm/model_executor/layers/quantization/utils/format_24.py",
    "vllm/model_executor/layers/quantization/utils/marlin_24_perms.py",
    "vllm/model_executor/layers/quantization/utils/marlin_perms.py",
    "vllm/model_executor/layers/quantization/utils/marlin_utils.py",
    "vllm/model_executor/layers/quantization/utils/quant_utils.py",
    "vllm/model_executor/layers/rejection_sampler.py",
    "vllm/model_executor/layers/rotary_embedding.py",
    "vllm/model_executor/layers/sampler.py",
    "vllm/model_executor/layers/vocab_parallel_embedding.py",
    "vllm/model_executor/model_loader.py",
    "vllm/model_executor/model_loader/__init__.py",
    "vllm/model_executor/model_loader/loader.py",
    "vllm/model_executor/model_loader/neuron.py",
    "vllm/model_executor/model_loader/tensorizer.py",
    "vllm/model_executor/model_loader/utils.py",
    "vllm/model_executor/model_loader/weight_utils.py",
    "vllm/model_executor/models/__init__.py",
    "vllm/model_executor/models/arctic.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/bloom.py",
    "vllm/model_executor/models/chatglm.py",
    "vllm/model_executor/models/commandr.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/decilm.py",
    "vllm/model_executor/models/deepseek.py",
    "vllm/model_executor/models/falcon.py",
    "vllm/model_executor/models/gemma.py",
    "vllm/model_executor/models/gpt2.py",
    "vllm/model_executor/models/gpt_bigcode.py",
    "vllm/model_executor/models/gpt_j.py",
    "vllm/model_executor/models/gpt_neox.py",
    "vllm/model_executor/models/internlm2.py",
    "vllm/model_executor/models/jais.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llama_embedding.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mixtral_quant.py",
    "vllm/model_executor/models/mpt.py",
    "vllm/model_executor/models/neuron/llama.py",
    "vllm/model_executor/models/neuron/mistral.py",
    "vllm/model_executor/models/olmo.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/orion.py",
    "vllm/model_executor/models/phi.py",
    "vllm/model_executor/models/phi3_small.py",
    "vllm/model_executor/models/qwen.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_moe.py",
    "vllm/model_executor/models/stablelm.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/vlm_base.py",
    "vllm/model_executor/models/xverse.py",
    "vllm/model_executor/neuron_model_loader.py",
    "vllm/model_executor/parallel_utils/README.md",
    "vllm/model_executor/parallel_utils/__init__.py",
    "vllm/model_executor/parallel_utils/communication_op.py",
    "vllm/model_executor/parallel_utils/cupy_utils.py",
    "vllm/model_executor/parallel_utils/custom_all_reduce.py",
    "vllm/model_executor/parallel_utils/parallel_state.py",
    "vllm/model_executor/parallel_utils/utils.py",
    "vllm/model_executor/pooling_metadata.py",
    "vllm/model_executor/sampling_metadata.py",
    "vllm/model_executor/utils.py",
    "vllm/model_executor/weight_utils.py",
    "vllm/multimodal/__init__.py",
    "vllm/multimodal/base.py",
    "vllm/multimodal/image.py",
    "vllm/multimodal/registry.py",
    "vllm/outputs.py",
    "vllm/pooling_params.py",
    "vllm/sampling_params.py",
    "vllm/sequence.py",
    "vllm/spec_decode/__init__.py",
    "vllm/spec_decode/batch_expansion.py",
    "vllm/spec_decode/interfaces.py",
    "vllm/spec_decode/metrics.py",
    "vllm/spec_decode/multi_step_worker.py",
    "vllm/spec_decode/ngram_worker.py",
    "vllm/spec_decode/proposer_worker_base.py",
    "vllm/spec_decode/spec_decode_worker.py",
    "vllm/spec_decode/top1_proposer.py",
    "vllm/spec_decode/util.py",
    "vllm/test_utils.py",
    "vllm/transformers_utils/config.py",
    "vllm/transformers_utils/configs/__init__.py",
    "vllm/transformers_utils/configs/arctic.py",
    "vllm/transformers_utils/configs/chatglm.py",
    "vllm/transformers_utils/configs/dbrx.py",
    "vllm/transformers_utils/configs/jais.py",
    "vllm/transformers_utils/configs/mpt.py",
    "vllm/transformers_utils/configs/starcoder2.py",
    "vllm/transformers_utils/detokenizer.py",
    "vllm/transformers_utils/image_processor.py",
    "vllm/transformers_utils/tokenizer.py",
    "vllm/transformers_utils/tokenizer_group/__init__.py",
    "vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py",
    "vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py",
    "vllm/transformers_utils/tokenizer_group/tokenizer_group.py",
    "vllm/transformers_utils/tokenizers/baichuan.py",
    "vllm/usage/__init__.py",
    "vllm/usage/usage_lib.py",
    "vllm/utils.py",
    "vllm/worker/cache_engine.py",
    "vllm/worker/cpu_model_runner.py",
    "vllm/worker/cpu_worker.py",
    "vllm/worker/embedding_model_runner.py",
    "vllm/worker/model_runner.py",
    "vllm/worker/neuron_model_runner.py",
    "vllm/worker/neuron_worker.py",
    "vllm/worker/worker.py",
    "vllm/worker/worker_base.py"
  ],
  "ok": false
}