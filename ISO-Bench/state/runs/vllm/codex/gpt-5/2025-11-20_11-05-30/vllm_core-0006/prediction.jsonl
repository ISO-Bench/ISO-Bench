{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-b0e96aa", "model_patch": "diff --git a/model_patch.diff b/model_patch.diff\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/vllm/attention/ops/triton_unified_attention.py b/vllm/attention/ops/triton_unified_attention.py\nindex c65f09523..e89f3f4f2 100644\n--- a/vllm/attention/ops/triton_unified_attention.py\n+++ b/vllm/attention/ops/triton_unified_attention.py\n@@ -108,6 +108,7 @@ def kernel_unified_attention_2d(\n \n     offs_m = tl.arange(0, BLOCK_M)\n     offs_d = tl.arange(0, HEAD_SIZE_PADDED)\n+    offs_n = tl.arange(0, BLOCK_SIZE)\n     query_pos = q_block_local_idx * BLOCK_Q + offs_m // num_queries_per_kv\n \n     query_offset_0 = cur_batch_in_all_start_index + query_pos\n@@ -146,13 +147,25 @@ def kernel_unified_attention_2d(\n                               other=0.0)\n \n     num_blocks = cdiv_fn(seq_len, BLOCK_SIZE)\n+    # compute the length of the longest sequence prefix spanned by any\n+    # query token in the current q_block (q_block_local_idx)\n+    max_seq_prefix_len = context_len + q_block_local_idx * BLOCK_Q + (\n+        BLOCK_M - 1) // num_queries_per_kv + 1\n+\n+    # adjust for potential padding in the last q_block by considering the\n+    # actual sequence length\n+    max_seq_prefix_len = tl.minimum(max_seq_prefix_len, seq_len)\n+\n+    # calculate the number of tiles (blocks) that need to be processed to\n+    # cover the longest sequence prefix (due to causal masking, blocks beyond\n+    # this prefix can be skipped)\n+    num_blocks = cdiv_fn(max_seq_prefix_len, BLOCK_SIZE)\n \n     # iterate through tiles\n     for j in range(0, num_blocks):\n \n         physical_block_idx = tl.load(block_tables_ptr + block_table_offset + j)\n \n-        offs_n = tl.arange(0, BLOCK_SIZE)\n \n         v_offset = (physical_block_idx * stride_v_cache_0 +\n                     kv_head_idx * stride_v_cache_2 +\n@@ -195,9 +208,7 @@ def kernel_unified_attention_2d(\n         seq_mask = seq_offset[None, :] < context_len + query_pos[:, None] + 1\n \n         # S : (BLOCK_M, BLOCK_SIZE)\n-        S = tl.zeros(shape=(BLOCK_M, BLOCK_SIZE), dtype=tl.float32)\n-\n-        S += scale * tl.dot(Q, K)\n+        S = scale * tl.dot(Q, K)\n \n         if USE_SOFTCAP:\n             S = apply_softcap(S, softcap)\n@@ -316,6 +327,7 @@ def kernel_unified_attention_3d(\n \n     # sequence len for this particular sequence\n     seq_len = tl.load(seq_lens_ptr + seq_idx)\n+    offs_n = tl.arange(0, BLOCK_SIZE)\n \n     # number of segments for this particular sequence\n     num_segments = NUM_SEGMENTS_PER_SEQ\n@@ -363,6 +375,19 @@ def kernel_unified_attention_3d(\n                               other=0.0)\n \n     num_blocks = cdiv_fn(seq_len, BLOCK_SIZE)\n+    # compute the length of the longest sequence prefix spanned by any\n+    # query token in the current q_block (q_block_local_idx)\n+    max_seq_prefix_len = context_len + q_block_local_idx * BLOCK_Q + (\n+        BLOCK_M - 1) // num_queries_per_kv + 1\n+\n+    # adjust for potential padding in the last q_block by considering the\n+    # actual sequence length\n+    max_seq_prefix_len = tl.minimum(max_seq_prefix_len, seq_len)\n+\n+    # calculate the number of tiles (blocks) that need to be processed to\n+    # cover the longest sequence prefix (due to causal masking, blocks beyond\n+    # this prefix can be skipped)\n+    num_blocks = cdiv_fn(max_seq_prefix_len, BLOCK_SIZE)\n \n     # iterate through tiles within current segment\n     for j in range(\n@@ -371,7 +396,6 @@ def kernel_unified_attention_3d(\n     ):\n         physical_block_idx = tl.load(block_tables_ptr + block_table_offset + j)\n \n-        offs_n = tl.arange(0, BLOCK_SIZE)\n \n         v_offset = (physical_block_idx * stride_v_cache_0 +\n                     kv_head_idx * stride_v_cache_2 +\n@@ -414,9 +438,7 @@ def kernel_unified_attention_3d(\n         seq_mask = seq_offset[None, :] < context_len + query_pos[:, None] + 1\n \n         # S : (BLOCK_M, BLOCK_SIZE)\n-        S = tl.zeros(shape=(BLOCK_M, BLOCK_SIZE), dtype=tl.float32)\n-\n-        S += scale * tl.dot(Q, K)\n+        S = scale * tl.dot(Q, K)\n \n         if USE_SOFTCAP:\n             S = apply_softcap(S, softcap)\ndiff --git a/vllm/utils/__init__.py b/vllm/utils/__init__.py\nindex bfdbd6824..bb29cdb82 100644\n--- a/vllm/utils/__init__.py\n+++ b/vllm/utils/__init__.py\n@@ -711,7 +711,8 @@ def make_async(\n     \"\"\"\n \n     def _async_wrapper(*args: P.args, **kwargs: P.kwargs) -> asyncio.Future:\n-        loop = asyncio.get_event_loop()\n+        # Use get_running_loop which avoids deprecated behavior and is faster.\n+        loop = asyncio.get_running_loop()\n         p_func = partial(func, *args, **kwargs)\n         return loop.run_in_executor(executor=executor, func=p_func)\n \n@@ -733,6 +734,9 @@ async def merge_async_iterators(\n     When it yields, it yields a tuple (i, item) where i is the index of the\n     iterator that yields the item.\n     \"\"\"\n+    # Fast paths for trivial cases\n+    if len(iterators) == 0:\n+        return\n     if len(iterators) == 1:\n         # Fast-path single iterator case.\n         async for item in iterators[0]:\n@@ -787,20 +791,20 @@ def get_ip() -> str:\n     # IP is not set, try to get it from the network interface\n \n     # try ipv4\n-    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n     try:\n-        s.connect((\"8.8.8.8\", 80))  # Doesn't need to be reachable\n-        return s.getsockname()[0]\n+        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n+            s.connect((\"8.8.8.8\", 80))  # Doesn't need to be reachable\n+            return s.getsockname()[0]\n     except Exception:\n         pass\n \n     # try ipv6\n     try:\n-        s = socket.socket(socket.AF_INET6, socket.SOCK_DGRAM)\n         # Google's public DNS server, see\n         # https://developers.google.com/speed/public-dns/docs/using#addresses\n-        s.connect((\"2001:4860:4860::8888\", 80))  # Doesn't need to be reachable\n-        return s.getsockname()[0]\n+        with socket.socket(socket.AF_INET6, socket.SOCK_DGRAM) as s:\n+            s.connect((\"2001:4860:4860::8888\", 80))  # Doesn't need to be reachable\n+            return s.getsockname()[0]\n     except Exception:\n         pass\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
