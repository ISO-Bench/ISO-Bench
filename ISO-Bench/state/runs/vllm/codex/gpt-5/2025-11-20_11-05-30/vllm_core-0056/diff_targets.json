{
  "changed": [
    ".buildkite/run-amd-test.sh",
    ".buildkite/test-pipeline.yaml",
    "CMakeLists.txt",
    "Dockerfile",
    "Dockerfile.s390x",
    "README.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/kernels/benchmark_moe.py",
    "benchmarks/kernels/deepgemm/README.md",
    "benchmarks/kernels/deepgemm/benchmark_fp8_block_dense_gemm.py",
    "cmake/cpu_extension.cmake",
    "cmake/external_projects/vllm_flash_attn.cmake",
    "csrc/cpu/attention.cpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/cpu_types_vxe.hpp",
    "csrc/cpu/quant.cpp",
    "docs/source/assets/contributing/dockerfile-stages-dependency.png",
    "docs/source/assets/design/v1/metrics/intervals-1.png",
    "docs/source/assets/design/v1/metrics/intervals-2.png",
    "docs/source/assets/design/v1/metrics/intervals-3.png",
    "docs/source/community/meetups.md",
    "docs/source/contributing/model/multimodal.md",
    "docs/source/deployment/nginx.md",
    "docs/source/design/v1/metrics.md",
    "docs/source/design/v1/prefix_caching.md",
    "docs/source/features/reasoning_outputs.md",
    "docs/source/index.md",
    "docs/source/models/generative_models.md",
    "docs/source/models/supported_models.md",
    "docs/source/serving/distributed_serving.md",
    "docs/source/serving/openai_compatible_server.md",
    "examples/offline_inference/data_parallel.py",
    "examples/offline_inference/llm_engine_example.py",
    "examples/offline_inference/rlhf.py",
    "examples/offline_inference/rlhf_colocate.py",
    "examples/offline_inference/rlhf_utils.py",
    "examples/offline_inference/vision_language.py",
    "examples/online_serving/openai_chat_completion_structured_outputs_with_reasoning.py",
    "examples/online_serving/openai_chat_completion_with_reasoning_streaming.py",
    "examples/online_serving/openai_transcription_client.py",
    "examples/online_serving/opentelemetry/dummy_client.py",
    "model_patch.diff",
    "requirements-common.txt",
    "requirements-cpu.txt",
    "requirements-cuda.txt",
    "requirements-rocm.txt",
    "tests/core/test_scheduler.py",
    "tests/core/utils.py",
    "tests/entrypoints/openai/test_return_tokens_as_ids.py",
    "tests/entrypoints/openai/test_transcription_validation.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_awq.py",
    "tests/kernels/test_moe.py",
    "tests/kernels/test_prefix_prefill.py",
    "tests/lora/test_chatglm3_tp.py",
    "tests/lora/test_mixtral.py",
    "tests/lora/test_qwen2vl.py",
    "tests/lora/test_ultravox.py",
    "tests/lora/test_worker.py",
    "tests/models/decoder_only/vision_language/test_models.py",
    "tests/models/multimodal/processing/test_common.py",
    "tests/models/registry.py",
    "tests/v1/sample/test_sampling_params_e2e.py",
    "tests/v1/worker/test_gpu_input_batch.py",
    "vllm/attention/backends/mla/common.py",
    "vllm/attention/backends/utils.py",
    "vllm/attention/backends/xformers.py",
    "vllm/attention/layer.py",
    "vllm/attention/ops/chunked_prefill_paged_decode.py",
    "vllm/attention/ops/prefix_prefill.py",
    "vllm/compilation/backends.py",
    "vllm/config.py",
    "vllm/core/scheduler.py",
    "vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/llm_engine.py",
    "vllm/entrypoints/chat_utils.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/protocol.py",
    "vllm/entrypoints/openai/serving_chat.py",
    "vllm/entrypoints/openai/serving_completion.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/entrypoints/openai/serving_transcription.py",
    "vllm/envs.py",
    "vllm/executor/ray_utils.py",
    "vllm/executor/uniproc_executor.py",
    "vllm/forward_context.py",
    "vllm/inputs/preprocess.py",
    "vllm/inputs/registry.py",
    "vllm/lora/layers.py",
    "vllm/lora/utils.py",
    "vllm/model_executor/guided_decoding/__init__.py",
    "vllm/model_executor/guided_decoding/outlines_logits_processors.py",
    "vllm/model_executor/guided_decoding/reasoner/__init__.py",
    "vllm/model_executor/guided_decoding/reasoner/deepseek_reasoner.py",
    "vllm/model_executor/guided_decoding/reasoner/reasoner.py",
    "vllm/model_executor/guided_decoding/xgrammar_decoding.py",
    "vllm/model_executor/layers/fused_moe/layer.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/quantization/gptq_marlin.py",
    "vllm/model_executor/models/arctic.py",
    "vllm/model_executor/models/aria.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/bart.py",
    "vllm/model_executor/models/chameleon.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/deepseek.py",
    "vllm/model_executor/models/deepseek_v2.py",
    "vllm/model_executor/models/exaone.py",
    "vllm/model_executor/models/florence2.py",
    "vllm/model_executor/models/fuyu.py",
    "vllm/model_executor/models/granite.py",
    "vllm/model_executor/models/granitemoe.py",
    "vllm/model_executor/models/idefics3.py",
    "vllm/model_executor/models/internlm2.py",
    "vllm/model_executor/models/jamba.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/mamba.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/minicpmv.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mixtral_quant.py",
    "vllm/model_executor/models/mllama.py",
    "vllm/model_executor/models/molmo.py",
    "vllm/model_executor/models/nemotron.py",
    "vllm/model_executor/models/olmoe.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/orion.py",
    "vllm/model_executor/models/paligemma.py",
    "vllm/model_executor/models/phi4mm.py",
    "vllm/model_executor/models/phi4mm_audio.py",
    "vllm/model_executor/models/phi4mm_utils.py",
    "vllm/model_executor/models/phimoe.py",
    "vllm/model_executor/models/pixtral.py",
    "vllm/model_executor/models/prithvi_geospatial_mae.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_moe.py",
    "vllm/model_executor/models/registry.py",
    "vllm/model_executor/models/solar.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/transformers.py",
    "vllm/model_executor/models/utils.py",
    "vllm/model_executor/models/vision_siglip_navit.py",
    "vllm/model_executor/models/whisper.py",
    "vllm/multimodal/processing.py",
    "vllm/multimodal/registry.py",
    "vllm/platforms/__init__.py",
    "vllm/platforms/cuda.py",
    "vllm/sampling_params.py",
    "vllm/spec_decode/draft_model_runner.py",
    "vllm/utils.py",
    "vllm/v1/attention/backends/flash_attn.py",
    "vllm/v1/attention/backends/mla/common.py",
    "vllm/v1/attention/backends/mla/flashmla.py",
    "vllm/v1/attention/backends/mla/triton_mla.py",
    "vllm/v1/attention/backends/rocm_attn.py",
    "vllm/v1/engine/core.py",
    "vllm/v1/engine/processor.py",
    "vllm/v1/metrics/loggers.py",
    "vllm/v1/worker/gpu_input_batch.py",
    "vllm/v1/worker/gpu_model_runner.py",
    "vllm/v1/worker/tpu_model_runner.py",
    "vllm/v1/worker/tpu_worker.py",
    "vllm/worker/worker_base.py"
  ],
  "allowed": [
    "vllm/entrypoints/openai/serving_transcription.py",
    "vllm/entrypoints/llm.py",
    "vllm/entrypoints/openai/serving_completion.py",
    "vllm/entrypoints/openai/serving_chat.py"
  ],
  "disallowed": [
    ".buildkite/run-amd-test.sh",
    ".buildkite/test-pipeline.yaml",
    "CMakeLists.txt",
    "Dockerfile",
    "Dockerfile.s390x",
    "README.md",
    "benchmarks/backend_request_func.py",
    "benchmarks/benchmark_serving.py",
    "benchmarks/kernels/benchmark_moe.py",
    "benchmarks/kernels/deepgemm/README.md",
    "benchmarks/kernels/deepgemm/benchmark_fp8_block_dense_gemm.py",
    "cmake/cpu_extension.cmake",
    "cmake/external_projects/vllm_flash_attn.cmake",
    "csrc/cpu/attention.cpp",
    "csrc/cpu/cpu_types.hpp",
    "csrc/cpu/cpu_types_vxe.hpp",
    "csrc/cpu/quant.cpp",
    "docs/source/assets/contributing/dockerfile-stages-dependency.png",
    "docs/source/assets/design/v1/metrics/intervals-1.png",
    "docs/source/assets/design/v1/metrics/intervals-2.png",
    "docs/source/assets/design/v1/metrics/intervals-3.png",
    "docs/source/community/meetups.md",
    "docs/source/contributing/model/multimodal.md",
    "docs/source/deployment/nginx.md",
    "docs/source/design/v1/metrics.md",
    "docs/source/design/v1/prefix_caching.md",
    "docs/source/features/reasoning_outputs.md",
    "docs/source/index.md",
    "docs/source/models/generative_models.md",
    "docs/source/models/supported_models.md",
    "docs/source/serving/distributed_serving.md",
    "docs/source/serving/openai_compatible_server.md",
    "examples/offline_inference/data_parallel.py",
    "examples/offline_inference/llm_engine_example.py",
    "examples/offline_inference/rlhf.py",
    "examples/offline_inference/rlhf_colocate.py",
    "examples/offline_inference/rlhf_utils.py",
    "examples/offline_inference/vision_language.py",
    "examples/online_serving/openai_chat_completion_structured_outputs_with_reasoning.py",
    "examples/online_serving/openai_chat_completion_with_reasoning_streaming.py",
    "examples/online_serving/openai_transcription_client.py",
    "examples/online_serving/opentelemetry/dummy_client.py",
    "model_patch.diff",
    "requirements-common.txt",
    "requirements-cpu.txt",
    "requirements-cuda.txt",
    "requirements-rocm.txt",
    "tests/core/test_scheduler.py",
    "tests/core/utils.py",
    "tests/entrypoints/openai/test_return_tokens_as_ids.py",
    "tests/entrypoints/openai/test_transcription_validation.py",
    "tests/kernels/test_attention.py",
    "tests/kernels/test_awq.py",
    "tests/kernels/test_moe.py",
    "tests/kernels/test_prefix_prefill.py",
    "tests/lora/test_chatglm3_tp.py",
    "tests/lora/test_mixtral.py",
    "tests/lora/test_qwen2vl.py",
    "tests/lora/test_ultravox.py",
    "tests/lora/test_worker.py",
    "tests/models/decoder_only/vision_language/test_models.py",
    "tests/models/multimodal/processing/test_common.py",
    "tests/models/registry.py",
    "tests/v1/sample/test_sampling_params_e2e.py",
    "tests/v1/worker/test_gpu_input_batch.py",
    "vllm/attention/backends/mla/common.py",
    "vllm/attention/backends/utils.py",
    "vllm/attention/backends/xformers.py",
    "vllm/attention/layer.py",
    "vllm/attention/ops/chunked_prefill_paged_decode.py",
    "vllm/attention/ops/prefix_prefill.py",
    "vllm/compilation/backends.py",
    "vllm/config.py",
    "vllm/core/scheduler.py",
    "vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py",
    "vllm/engine/arg_utils.py",
    "vllm/engine/llm_engine.py",
    "vllm/entrypoints/chat_utils.py",
    "vllm/entrypoints/openai/protocol.py",
    "vllm/entrypoints/openai/serving_engine.py",
    "vllm/envs.py",
    "vllm/executor/ray_utils.py",
    "vllm/executor/uniproc_executor.py",
    "vllm/forward_context.py",
    "vllm/inputs/preprocess.py",
    "vllm/inputs/registry.py",
    "vllm/lora/layers.py",
    "vllm/lora/utils.py",
    "vllm/model_executor/guided_decoding/__init__.py",
    "vllm/model_executor/guided_decoding/outlines_logits_processors.py",
    "vllm/model_executor/guided_decoding/reasoner/__init__.py",
    "vllm/model_executor/guided_decoding/reasoner/deepseek_reasoner.py",
    "vllm/model_executor/guided_decoding/reasoner/reasoner.py",
    "vllm/model_executor/guided_decoding/xgrammar_decoding.py",
    "vllm/model_executor/layers/fused_moe/layer.py",
    "vllm/model_executor/layers/linear.py",
    "vllm/model_executor/layers/quantization/gptq_marlin.py",
    "vllm/model_executor/models/arctic.py",
    "vllm/model_executor/models/aria.py",
    "vllm/model_executor/models/baichuan.py",
    "vllm/model_executor/models/bart.py",
    "vllm/model_executor/models/chameleon.py",
    "vllm/model_executor/models/dbrx.py",
    "vllm/model_executor/models/deepseek.py",
    "vllm/model_executor/models/deepseek_v2.py",
    "vllm/model_executor/models/exaone.py",
    "vllm/model_executor/models/florence2.py",
    "vllm/model_executor/models/fuyu.py",
    "vllm/model_executor/models/granite.py",
    "vllm/model_executor/models/granitemoe.py",
    "vllm/model_executor/models/idefics3.py",
    "vllm/model_executor/models/internlm2.py",
    "vllm/model_executor/models/jamba.py",
    "vllm/model_executor/models/llama.py",
    "vllm/model_executor/models/llava.py",
    "vllm/model_executor/models/mamba.py",
    "vllm/model_executor/models/minicpm.py",
    "vllm/model_executor/models/minicpmv.py",
    "vllm/model_executor/models/mixtral.py",
    "vllm/model_executor/models/mixtral_quant.py",
    "vllm/model_executor/models/mllama.py",
    "vllm/model_executor/models/molmo.py",
    "vllm/model_executor/models/nemotron.py",
    "vllm/model_executor/models/olmoe.py",
    "vllm/model_executor/models/opt.py",
    "vllm/model_executor/models/orion.py",
    "vllm/model_executor/models/paligemma.py",
    "vllm/model_executor/models/phi4mm.py",
    "vllm/model_executor/models/phi4mm_audio.py",
    "vllm/model_executor/models/phi4mm_utils.py",
    "vllm/model_executor/models/phimoe.py",
    "vllm/model_executor/models/pixtral.py",
    "vllm/model_executor/models/prithvi_geospatial_mae.py",
    "vllm/model_executor/models/qwen2.py",
    "vllm/model_executor/models/qwen2_moe.py",
    "vllm/model_executor/models/registry.py",
    "vllm/model_executor/models/solar.py",
    "vllm/model_executor/models/starcoder2.py",
    "vllm/model_executor/models/transformers.py",
    "vllm/model_executor/models/utils.py",
    "vllm/model_executor/models/vision_siglip_navit.py",
    "vllm/model_executor/models/whisper.py",
    "vllm/multimodal/processing.py",
    "vllm/multimodal/registry.py",
    "vllm/platforms/__init__.py",
    "vllm/platforms/cuda.py",
    "vllm/sampling_params.py",
    "vllm/spec_decode/draft_model_runner.py",
    "vllm/utils.py",
    "vllm/v1/attention/backends/flash_attn.py",
    "vllm/v1/attention/backends/mla/common.py",
    "vllm/v1/attention/backends/mla/flashmla.py",
    "vllm/v1/attention/backends/mla/triton_mla.py",
    "vllm/v1/attention/backends/rocm_attn.py",
    "vllm/v1/engine/core.py",
    "vllm/v1/engine/processor.py",
    "vllm/v1/metrics/loggers.py",
    "vllm/v1/worker/gpu_input_batch.py",
    "vllm/v1/worker/gpu_model_runner.py",
    "vllm/v1/worker/tpu_model_runner.py",
    "vllm/v1/worker/tpu_worker.py",
    "vllm/worker/worker_base.py"
  ],
  "ok": false
}