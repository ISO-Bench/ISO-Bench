{"instance_id": "vllm-project__vllm-029c71d", "model_patch": "diff --git a/vllm/core/block/prefix_caching_block.py b/vllm/core/block/prefix_caching_block.py\nindex 432a6651a..f658615a0 100644\n--- a/vllm/core/block/prefix_caching_block.py\n+++ b/vllm/core/block/prefix_caching_block.py\n@@ -152,9 +152,10 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n                                             token_ids=token_ids,\n                                             block_size=self._block_size,\n                                             physical_block_id=None)\n-        assert block.content_hash is not None\n+        content_hash = block.content_hash\n+        assert content_hash is not None\n \n-        cached_block_id = self._cached_blocks.get(block.content_hash, None)\n+        cached_block_id = self._cached_blocks.get(content_hash, None)\n         if cached_block_id is not None:\n             self.metric_data.query(hit=True)\n             block.block_id = cached_block_id\n@@ -241,8 +242,9 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n \n         # Add the cached block to the evictor\n         # (This keeps the cached block around so it can be reused)\n+        tracker = self._block_tracker[block_id]\n         self.evictor.add(block_id, block.content_hash, block.num_tokens_total,\n-                         self._block_tracker[block_id].last_accessed)\n+                         tracker.last_accessed)\n \n         # Stop tracking the block\n         self._untrack_block_id(block_id)\n@@ -412,9 +414,7 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n \n     def is_block_cached(self, block: Block) -> bool:\n         assert block.content_hash is not None\n-        if block.content_hash in self._cached_blocks:\n-            return True\n-        return False\n+        return block.content_hash in self._cached_blocks\n \n     def promote_to_immutable_block(self, block: Block) -> BlockId:\n         \"\"\"Once a mutable block is full, it can be promoted to an immutable\n@@ -498,8 +498,9 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         \"\"\"\n \n         for block_id in block_ids:\n-            if self._block_tracker[block_id].active:\n-                self._block_tracker[block_id].last_accessed = now\n+            tracker = self._block_tracker[block_id]\n+            if tracker.active:\n+                tracker.last_accessed = now\n             elif block_id in self.evictor:\n                 self.evictor.update(block_id, now)\n             else:\n@@ -512,16 +513,18 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n     def _track_block_id(self, block_id: Optional[BlockId],\n                         computed: bool) -> None:\n         assert block_id is not None\n-        self._block_tracker[block_id].enable()\n-        self._block_tracker[block_id].computed = computed\n+        tracker = self._block_tracker[block_id]\n+        tracker.enable()\n+        tracker.computed = computed\n \n     def _untrack_block_id(self, block_id: Optional[BlockId]) -> None:\n         assert block_id is not None\n         self._block_tracker[block_id].disable()\n \n     def block_is_computed(self, block_id: int) -> bool:\n-        if self._block_tracker[block_id].active:\n-            return self._block_tracker[block_id].computed\n+        tracker = self._block_tracker[block_id]\n+        if tracker.active:\n+            return tracker.computed\n         else:\n             return block_id in self.evictor\n \n@@ -575,9 +578,9 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n \n         Args:\n             blocks (List[Block]): The potential blocks to swap.\n-            num_lookahead_slots (int): number of lookahead slots (0 for \n+            num_lookahead_slots (int): number of lookahead slots (0 for\n                 swap out).\n-        \n+\n         Returns:\n             int: the number of blocks that will be touched by\n                 swapping in/out the given blocks and num_lookahead_slots.\n@@ -586,16 +589,18 @@ class PrefixCachingBlockAllocator(BlockAllocator):\n         for block in blocks:\n             if not block.is_full:\n                 num_touched_blocks += 1\n-                if num_lookahead_slots > block.num_empty_slots:\n+                num_empty = block.num_empty_slots\n+                if num_lookahead_slots > num_empty:\n                     num_touched_blocks += cdiv(\n-                        num_lookahead_slots - block.num_empty_slots,\n+                        num_lookahead_slots - num_empty,\n                         self._block_size)\n             else:\n                 # If the block has a match in the cache and the cached block\n                 # is not referenced, then we still count it as a touched block\n+                content_hash = block.content_hash\n                 if not self.is_block_cached(block) or \\\n-                    (block.content_hash is not None and \\\n-                     self._cached_blocks[block.content_hash] in self.evictor):\n+                    (content_hash is not None and \\\n+                     self._cached_blocks[content_hash] in self.evictor):\n                     num_touched_blocks += 1\n         return num_touched_blocks\n \n@@ -795,17 +800,19 @@ class PrefixCachingBlock(Block):\n         full.\n         \"\"\"\n         # If the hash is already computed, return it.\n-        if self._cached_content_hash is not None:\n-            return self._cached_content_hash\n+        cached_hash = self._cached_content_hash\n+        if cached_hash is not None:\n+            return cached_hash\n \n         # We cannot compute a hash for the current block because it is not full.\n         if not self.is_full:\n             return None\n \n-        is_first_block = self._prev_block is None\n+        prev_block = self._prev_block\n+        is_first_block = prev_block is None\n         prev_block_hash = (\n             None if is_first_block else\n-            self._prev_block.content_hash  # type: ignore\n+            prev_block.content_hash  # type: ignore\n         )\n \n         # Previous block exists but does not yet have a hash.\n@@ -840,7 +847,7 @@ class PrefixCachingBlock(Block):\n         - int: The computed hash value for the block.\n         \"\"\"\n         assert (prev_block_hash is None) == is_first_block\n-        return hash((is_first_block, prev_block_hash, *cur_block_token_ids))\n+        return hash((is_first_block, prev_block_hash, tuple(cur_block_token_ids)))\n \n \n class ComputedBlocksTracker:\n", "model_name_or_path": "gpt-5-2025-08-07"}
