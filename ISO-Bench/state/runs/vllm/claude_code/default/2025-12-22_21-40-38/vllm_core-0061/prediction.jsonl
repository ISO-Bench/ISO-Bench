{"instance_id": "vllm-project__vllm-9bde5ba", "model_patch": "diff --git a/vllm/v1/core/block_pool.py b/vllm/v1/core/block_pool.py\nindex 43f30f710..30b3a6729 100644\n--- a/vllm/v1/core/block_pool.py\n+++ b/vllm/v1/core/block_pool.py\n@@ -68,8 +68,8 @@ class BlockPool:\n             The cached block if it exists, or None.\n         \"\"\"\n         if block_hash in self.cached_block_hash_to_block:\n-            first_block_id = list(\n-                self.cached_block_hash_to_block[block_hash].keys())[0]\n+            first_block_id = next(iter(\n+                self.cached_block_hash_to_block[block_hash].keys()))\n             return self.cached_block_hash_to_block[block_hash][first_block_id]\n         return None\n \n@@ -171,8 +171,7 @@ class BlockPool:\n                 f\"Cannot get {num_blocks} free blocks from the pool\")\n \n         ret: list[KVCacheBlock] = []\n-        idx = 0\n-        while idx < num_blocks:\n+        for _ in range(num_blocks):\n             # First allocate blocks.\n             curr_block = self.free_block_queue.popleft()\n             assert curr_block.ref_cnt == 0\n@@ -183,7 +182,6 @@ class BlockPool:\n \n             curr_block.incr_ref()\n             ret.append(curr_block)\n-            idx += 1\n \n         return ret\n \n@@ -199,15 +197,20 @@ class BlockPool:\n             True if the block is evicted, False otherwise.\n         \"\"\"\n         block_hash = block.block_hash\n-        if block_hash and block_hash in self.cached_block_hash_to_block:\n-            block.reset_hash()\n-            del self.cached_block_hash_to_block[block_hash][block.block_id]\n+        if block_hash is None:\n+            return False\n+\n+        block_dict = self.cached_block_hash_to_block.get(block_hash)\n+        if block_dict is None:\n+            return False\n \n-            if len(self.cached_block_hash_to_block[block_hash]) == 0:\n-                del self.cached_block_hash_to_block[block_hash]\n+        block.reset_hash()\n+        del block_dict[block.block_id]\n \n-            return True\n-        return False\n+        if not block_dict:\n+            del self.cached_block_hash_to_block[block_hash]\n+\n+        return True\n \n     def touch(self, blocks: list[KVCacheBlock]) -> None:\n         \"\"\"Touch a block increases its reference count by 1, and may remove\n@@ -217,11 +220,13 @@ class BlockPool:\n         Args:\n             blocks: A list of blocks to touch.\n         \"\"\"\n+        null_block = self.null_block\n+        free_block_queue = self.free_block_queue\n         for block in blocks:\n             # ref_cnt=0 means this block is in the free list (i.e. eviction\n             # candidate), so remove it.\n-            if block.ref_cnt == 0 and block != self.null_block:\n-                self.free_block_queue.remove(block)\n+            if block.ref_cnt == 0 and block != null_block:\n+                free_block_queue.remove(block)\n             block.incr_ref()\n \n     def free_blocks(self, ordered_blocks: Iterable[KVCacheBlock]) -> None:\n@@ -232,11 +237,13 @@ class BlockPool:\n             ordered_blocks: A list of blocks to free ordered by their eviction\n                 priority.\n         \"\"\"\n+        null_block = self.null_block\n+        free_block_queue = self.free_block_queue\n         for block in ordered_blocks:\n             block.decr_ref()\n             # null_block should not be added to the free list.\n-            if block.ref_cnt == 0 and block != self.null_block:\n-                self.free_block_queue.append(block)\n+            if block.ref_cnt == 0 and block != null_block:\n+                free_block_queue.append(block)\n \n     def reset_prefix_cache(self) -> bool:\n         \"\"\"Reset prefix cache. This function may be used in RLHF\n@@ -254,13 +261,14 @@ class BlockPool:\n                 \"blocks (%d) are not freed yet\", num_used_blocks - 1)\n             return False\n \n+        # Remove all hashes from cached blocks only (optimization).\n+        for block_dict in self.cached_block_hash_to_block.values():\n+            for block_id in block_dict:\n+                self.blocks[block_id].reset_hash()\n+\n         # Remove all hashes so that no new blocks will hit.\n         self.cached_block_hash_to_block = defaultdict(dict)\n \n-        # Remove all hashes from all blocks.\n-        for block in self.blocks:\n-            block.reset_hash()\n-\n         logger.info(\"Successfully reset prefix cache\")\n         return True\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
