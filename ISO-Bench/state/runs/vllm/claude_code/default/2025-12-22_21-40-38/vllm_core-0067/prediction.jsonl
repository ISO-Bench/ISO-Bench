{"instance_id": "vllm-project__vllm-f67e9e9", "model_patch": "diff --git a/vllm/attention/ops/prefix_prefill.py b/vllm/attention/ops/prefix_prefill.py\nindex e0478c2ae..ae4d5a72f 100644\n--- a/vllm/attention/ops/prefix_prefill.py\n+++ b/vllm/attention/ops/prefix_prefill.py\n@@ -109,7 +109,7 @@ if triton.__version__ >= \"2.1.0\":\n                     other=0.0)  # [M,D]\n \n         # initialize pointer to m and l\n-        m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")  # [M]\n+        m_i = tl.full([BLOCK_M], -float(\"inf\"), dtype=tl.float32)  # [M]\n         l_i = tl.zeros([BLOCK_M], dtype=tl.float32)  # [M]\n         acc = tl.zeros([BLOCK_M, BLOCK_DMODEL_PADDED],\n                        dtype=tl.float32)  # [M,D]\n@@ -145,8 +145,7 @@ if triton.__version__ >= \"2.1.0\":\n             else:\n                 k = k_load\n \n-            qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)  # [M,N]\n-            qk = tl.dot(q, k, acc=qk, input_precision=IN_PRECISION)\n+            qk = tl.dot(q, k, input_precision=IN_PRECISION)\n             qk = tl.where((start_n + offs_n[None, :]) < cur_batch_ctx_len, qk,\n                           float(\"-inf\"))\n             qk *= sm_scale\n@@ -219,8 +218,7 @@ if triton.__version__ >= \"2.1.0\":\n                         ((start_n + offs_n[None, :]) < cur_batch_query_len),\n                         other=0.0)\n \n-            qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n-            qk = tl.dot(q, k, acc=qk, input_precision=IN_PRECISION)\n+            qk = tl.dot(q, k, input_precision=IN_PRECISION)\n             qk *= sm_scale\n             # apply causal mask\n             qk = tl.where(offs_m[:, None] >= (start_n + offs_n[None, :]), qk,\n@@ -338,7 +336,7 @@ if triton.__version__ >= \"2.1.0\":\n                     other=0.0)\n \n         # # initialize pointer to m and l\n-        m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\n+        m_i = tl.full([BLOCK_M], -float(\"inf\"), dtype=tl.float32)\n         l_i = tl.zeros([BLOCK_M], dtype=tl.float32)\n         acc = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32)\n \n@@ -363,8 +361,7 @@ if triton.__version__ >= \"2.1.0\":\n             k = tl.load(K_cache + off_k,\n                         mask=(start_n + offs_n[None, :]) < cur_batch_ctx_len,\n                         other=0.0)\n-            qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n-            qk += tl.dot(q, k)\n+            qk = tl.dot(q, k)\n             qk = tl.where((start_n + offs_n[None, :]) < cur_batch_ctx_len, qk,\n                           float(\"-inf\"))\n             qk *= sm_scale\n@@ -414,8 +411,7 @@ if triton.__version__ >= \"2.1.0\":\n                         < cur_batch_seq_len - cur_batch_ctx_len,\n                         other=0.0)\n \n-            qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n-            qk += tl.dot(q, k)\n+            qk = tl.dot(q, k)\n             qk *= sm_scale\n             qk = tl.where(offs_m[:, None] >= (start_n + offs_n[None, :]), qk,\n                           float(\"-inf\"))\n@@ -546,7 +542,7 @@ if triton.__version__ >= \"2.1.0\":\n                     other=0.0)\n \n         # # initialize pointer to m and l\n-        m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\n+        m_i = tl.full([BLOCK_M], -float(\"inf\"), dtype=tl.float32)\n         l_i = tl.zeros([BLOCK_M], dtype=tl.float32)\n         acc = tl.zeros([BLOCK_M, BLOCK_DMODEL_PADDED], dtype=tl.float32)\n \n@@ -582,8 +578,7 @@ if triton.__version__ >= \"2.1.0\":\n             else:\n                 k = k_load\n \n-            qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n-            qk = tl.dot(q, k, acc=qk, input_precision=IN_PRECISION)\n+            qk = tl.dot(q, k, input_precision=IN_PRECISION)\n             qk = tl.where((start_n + offs_n[None, :]) < cur_batch_ctx_len, qk,\n                           float(\"-inf\"))\n             qk *= sm_scale\n@@ -657,8 +652,7 @@ if triton.__version__ >= \"2.1.0\":\n                          < cur_batch_seq_len - cur_batch_ctx_len),\n                         other=0.0)\n \n-            qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)\n-            qk = tl.dot(q, k, acc=qk, input_precision='ieee')\n+            qk = tl.dot(q, k, input_precision='ieee')\n             qk *= sm_scale\n             qk = tl.where(offs_m[:, None] >= (start_n + offs_n[None, :]), qk,\n                           float(\"-inf\"))\n", "model_name_or_path": "gpt-5-2025-08-07"}
