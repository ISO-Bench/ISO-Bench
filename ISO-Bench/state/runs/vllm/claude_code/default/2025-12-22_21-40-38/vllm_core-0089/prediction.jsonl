{"instance_id": "vllm-project__vllm-1da8f0e", "model_patch": "diff --git a/vllm/v1/worker/gpu_input_batch.py b/vllm/v1/worker/gpu_input_batch.py\nindex 25d95ac6e..ad4de45c1 100644\n--- a/vllm/v1/worker/gpu_input_batch.py\n+++ b/vllm/v1/worker/gpu_input_batch.py\n@@ -58,10 +58,10 @@ class InputBatch:\n         self.num_computed_tokens_cpu = np.empty(max_num_reqs, dtype=np.int32)\n \n         # Attention-related.\n-        self.block_table = torch.zeros((max_num_reqs, max_num_blocks_per_req),\n+        self.block_table = torch.empty((max_num_reqs, max_num_blocks_per_req),\n                                        device=self.device,\n                                        dtype=torch.int32)\n-        self.block_table_cpu_tensor = torch.zeros(\n+        self.block_table_cpu_tensor = torch.empty(\n             (max_num_reqs, max_num_blocks_per_req),\n             device=\"cpu\",\n             dtype=torch.int32,\ndiff --git a/vllm/v1/worker/gpu_model_runner.py b/vllm/v1/worker/gpu_model_runner.py\nindex e75be21ef..d8d2ac05d 100644\n--- a/vllm/v1/worker/gpu_model_runner.py\n+++ b/vllm/v1/worker/gpu_model_runner.py\n@@ -106,13 +106,13 @@ class GPUModelRunner:\n             reversed(self.vllm_config.compilation_config.capture_sizes))\n \n         # Persistent buffers for CUDA graphs.\n-        self.input_ids = torch.zeros(self.max_num_tokens,\n+        self.input_ids = torch.empty(self.max_num_tokens,\n                                      dtype=torch.int32,\n                                      device=self.device)\n-        self.positions = torch.zeros(self.max_num_tokens,\n+        self.positions = torch.empty(self.max_num_tokens,\n                                      dtype=torch.int64,\n                                      device=self.device)\n-        self.inputs_embeds = torch.zeros(\n+        self.inputs_embeds = torch.empty(\n             (self.max_num_tokens, self.hidden_size),\n             dtype=self.dtype,\n             device=self.device)\n@@ -627,7 +627,7 @@ class GPUModelRunner:\n             num_blocks, self.block_size, self.num_kv_heads, self.head_size)\n         for _ in range(self.num_attn_layers):\n             self.kv_caches.append(\n-                torch.zeros(kv_cache_shape,\n+                torch.empty(kv_cache_shape,\n                             dtype=self.kv_cache_dtype,\n                             device=self.device))\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
