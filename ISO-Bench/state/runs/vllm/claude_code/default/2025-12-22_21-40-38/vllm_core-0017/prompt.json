{
  "task": "vLLM core performance",
  "description": "Run vLLM performance checks with Dockerfile-based env",
  "constraints": [
    "No public API breakage",
    "All TestPack checks must pass"
  ],
  "target_files": [
    "benchmarks/benchmark_latency.py",
    "tests/conftest.py",
    "tests/core/block/test_block_table.py",
    "tests/core/block/test_cpu_gpu_block_allocator.py",
    "tests/core/block/test_naive_block.py",
    "tests/core/block/test_prefix_caching_block.py",
    "tests/spec_decode/test_batch_expansion.py",
    "vllm/core/block/block_table.py",
    "vllm/core/block/common.py",
    "vllm/core/block/cpu_gpu_block_allocator.py",
    "vllm/core/block/interfaces.py",
    "vllm/core/block/naive_block.py",
    "vllm/core/block/prefix_caching_block.py",
    "vllm/core/block_manager_v2.py",
    "vllm/engine/llm_engine.py",
    "vllm/entrypoints/openai/serving_completion.py",
    "vllm/model_executor/sampling_metadata.py",
    "vllm/outputs.py",
    "vllm/sequence.py"
  ],
  "success": {
    "primary_metric": "functional_match",
    "rules": [
      "Do not modify tests or metrics harness",
      "Preserve external behavior; optimize internals only"
    ]
  },
  "commits": {
    "pre": "54600709b6d419fb243ce718a48ab7d40f5c3eb7",
    "human": "3476ed0809ec91a3457da0cb90543133a4f4b519"
  }
}