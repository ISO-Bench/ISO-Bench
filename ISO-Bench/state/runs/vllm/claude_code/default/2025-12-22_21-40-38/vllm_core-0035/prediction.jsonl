{"instance_id": "vllm-project__vllm-63d635d", "model_patch": "diff --git a/vllm/model_executor/models/qwen2_5_vl.py b/vllm/model_executor/models/qwen2_5_vl.py\nindex ef3d28c80..5ed77a96a 100644\n--- a/vllm/model_executor/models/qwen2_5_vl.py\n+++ b/vllm/model_executor/models/qwen2_5_vl.py\n@@ -539,23 +539,30 @@ class Qwen2_5_VisionTransformer(nn.Module):\n \n     def rot_pos_emb(self, grid_thw: torch.Tensor) -> torch.Tensor:\n         pos_ids = []\n+        merge_size = self.spatial_merge_size\n         for t, h, w in grid_thw:\n-            hpos_ids = torch.arange(h).unsqueeze(1).expand(-1, w)\n-            wpos_ids = torch.arange(w).unsqueeze(0).expand(h, -1)\n-            hpos_ids = hpos_ids.reshape(\n-                h // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-                w // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-            ).permute(0, 2, 1, 3).flatten()\n-            wpos_ids = wpos_ids.reshape(\n-                h // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-                w // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-            ).permute(0, 2, 1, 3).flatten()\n-            pos_ids.append(\n-                torch.stack([hpos_ids, wpos_ids], dim=-1).repeat(t, 1))\n+            # Create position IDs more efficiently using vectorized operations\n+            h_merge = h // merge_size\n+            w_merge = w // merge_size\n+\n+            # Generate position indices directly in the desired order\n+            hpos_ids = torch.arange(h, device=grid_thw.device, dtype=torch.long)\n+            wpos_ids = torch.arange(w, device=grid_thw.device, dtype=torch.long)\n+\n+            # Use broadcasting to create the grid\n+            hpos_grid = hpos_ids.view(-1, 1).expand(h, w)\n+            wpos_grid = wpos_ids.view(1, -1).expand(h, w)\n+\n+            # Reshape and reorder in one go\n+            hpos_flat = hpos_grid.reshape(h_merge, merge_size, w_merge, merge_size).permute(0, 2, 1, 3).flatten()\n+            wpos_flat = wpos_grid.reshape(h_merge, merge_size, w_merge, merge_size).permute(0, 2, 1, 3).flatten()\n+\n+            # Stack and repeat\n+            pos_pair = torch.stack([hpos_flat, wpos_flat], dim=-1)\n+            if t > 1:\n+                pos_pair = pos_pair.repeat(t, 1)\n+            pos_ids.append(pos_pair)\n+\n         pos_ids = torch.cat(pos_ids, dim=0)\n         max_grid_size = grid_thw[:, 1:].max()\n         rotary_pos_emb_full = self.rotary_pos_emb(max_grid_size)\n@@ -569,31 +576,45 @@ class Qwen2_5_VisionTransformer(nn.Module):\n         vit_merger_window_size = (self.window_size //\n                                   self.spatial_merge_size // self.patch_size)\n \n+        device = grid_thw.device\n+        merge_unit = self.spatial_merge_unit\n+\n         for grid_t, grid_h, grid_w in grid_thw:\n             llm_grid_h = grid_h // self.spatial_merge_size\n             llm_grid_w = grid_w // self.spatial_merge_size\n-            index = torch.arange(grid_t * llm_grid_h * llm_grid_w).reshape(\n+            total_size = grid_t * llm_grid_h * llm_grid_w\n+\n+            # Create index tensor on the right device from the start\n+            index = torch.arange(total_size, device=device, dtype=torch.long).reshape(\n                 grid_t, llm_grid_h, llm_grid_w)\n+\n             pad_h = vit_merger_window_size - llm_grid_h % vit_merger_window_size\n             pad_w = vit_merger_window_size - llm_grid_w % vit_merger_window_size\n             num_windows_h = (llm_grid_h + pad_h) // vit_merger_window_size\n             num_windows_w = (llm_grid_w + pad_w) // vit_merger_window_size\n+\n+            # Apply padding\n             index_padded = F.pad(index, (0, pad_w, 0, pad_h), 'constant', -100)\n-            index_padded = index_padded.reshape(grid_t, num_windows_h,\n-                                                vit_merger_window_size,\n-                                                num_windows_w,\n-                                                vit_merger_window_size)\n-            index_padded = index_padded.permute(0, 1, 3, 2, 4).reshape(\n-                grid_t, num_windows_h * num_windows_w, vit_merger_window_size,\n-                vit_merger_window_size)\n-            seqlens = (index_padded != -100).sum([2, 3]).reshape(-1)\n-            index_padded = index_padded.reshape(-1)\n-            index_new = index_padded[index_padded != -100]\n+\n+            # Reshape and permute in a single chain\n+            index_padded = index_padded.reshape(\n+                grid_t, num_windows_h, vit_merger_window_size,\n+                num_windows_w, vit_merger_window_size\n+            ).permute(0, 1, 3, 2, 4).reshape(\n+                grid_t, num_windows_h * num_windows_w,\n+                vit_merger_window_size, vit_merger_window_size\n+            )\n+\n+            # Compute seqlens and filter indices\n+            seqlens = (index_padded != -100).sum([2, 3]).flatten()\n+            index_flat = index_padded.flatten()\n+            index_new = index_flat[index_flat != -100]\n+\n             window_index.append(index_new + window_index_id)\n-            cu_seqlens_tmp = seqlens.cumsum(\n-                0) * self.spatial_merge_unit + cu_window_seqlens[-1]\n+            cu_seqlens_tmp = seqlens.cumsum(0) * merge_unit + cu_window_seqlens[-1]\n             cu_window_seqlens.extend(cu_seqlens_tmp.tolist())\n-            window_index_id += (grid_t * llm_grid_h * llm_grid_w).item()\n+            window_index_id += total_size.item()\n+\n         window_index = torch.cat(window_index, dim=0)\n         return window_index, cu_window_seqlens\n \n@@ -625,10 +646,10 @@ class Qwen2_5_VisionTransformer(nn.Module):\n             seq_len // self.spatial_merge_unit, self.spatial_merge_unit, -1)\n         rotary_pos_emb = rotary_pos_emb[window_index, :, :]\n         rotary_pos_emb = rotary_pos_emb.reshape(seq_len, -1)\n-        # compute cu_seqlens\n-        cu_seqlens = torch.repeat_interleave(grid_thw[:, 1] * grid_thw[:, 2],\n-                                             grid_thw[:, 0]).cumsum(\n-                                                 dim=0, dtype=torch.int32)\n+        # compute cu_seqlens more efficiently\n+        seq_lengths = grid_thw[:, 1] * grid_thw[:, 2]\n+        cu_seqlens = torch.repeat_interleave(seq_lengths, grid_thw[:, 0]).cumsum(\n+            dim=0, dtype=torch.int32)\n         cu_seqlens = F.pad(cu_seqlens, (1, 0), \"constant\", 0)\n \n         # transformers\ndiff --git a/vllm/model_executor/models/qwen2_vl.py b/vllm/model_executor/models/qwen2_vl.py\nindex ac3d154dd..73346ced4 100644\n--- a/vllm/model_executor/models/qwen2_vl.py\n+++ b/vllm/model_executor/models/qwen2_vl.py\n@@ -581,23 +581,30 @@ class Qwen2VisionTransformer(nn.Module):\n \n     def rot_pos_emb(self, grid_thw: torch.Tensor) -> torch.Tensor:\n         pos_ids = []\n+        merge_size = self.spatial_merge_size\n         for t, h, w in grid_thw:\n-            hpos_ids = torch.arange(h).unsqueeze(1).expand(-1, w)\n-            wpos_ids = torch.arange(w).unsqueeze(0).expand(h, -1)\n-            hpos_ids = hpos_ids.reshape(\n-                h // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-                w // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-            ).permute(0, 2, 1, 3).flatten()\n-            wpos_ids = wpos_ids.reshape(\n-                h // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-                w // self.spatial_merge_size,\n-                self.spatial_merge_size,\n-            ).permute(0, 2, 1, 3).flatten()\n-            pos_ids.append(\n-                torch.stack([hpos_ids, wpos_ids], dim=-1).repeat(t, 1))\n+            # Create position IDs more efficiently using vectorized operations\n+            h_merge = h // merge_size\n+            w_merge = w // merge_size\n+\n+            # Generate position indices directly in the desired order\n+            hpos_ids = torch.arange(h, device=grid_thw.device, dtype=torch.long)\n+            wpos_ids = torch.arange(w, device=grid_thw.device, dtype=torch.long)\n+\n+            # Use broadcasting to create the grid\n+            hpos_grid = hpos_ids.view(-1, 1).expand(h, w)\n+            wpos_grid = wpos_ids.view(1, -1).expand(h, w)\n+\n+            # Reshape and reorder in one go\n+            hpos_flat = hpos_grid.reshape(h_merge, merge_size, w_merge, merge_size).permute(0, 2, 1, 3).flatten()\n+            wpos_flat = wpos_grid.reshape(h_merge, merge_size, w_merge, merge_size).permute(0, 2, 1, 3).flatten()\n+\n+            # Stack and repeat\n+            pos_pair = torch.stack([hpos_flat, wpos_flat], dim=-1)\n+            if t > 1:\n+                pos_pair = pos_pair.repeat(t, 1)\n+            pos_ids.append(pos_pair)\n+\n         pos_ids = torch.cat(pos_ids, dim=0)\n         max_grid_size = grid_thw[:, 1:].max()\n         rotary_pos_emb_full = self.rotary_pos_emb(max_grid_size)\n@@ -616,10 +623,10 @@ class Qwen2VisionTransformer(nn.Module):\n         # compute position embedding\n         rotary_pos_emb = self.rot_pos_emb(grid_thw)\n \n-        # compute cu_seqlens\n-        cu_seqlens = torch.repeat_interleave(grid_thw[:, 1] * grid_thw[:, 2],\n-                                             grid_thw[:, 0]).cumsum(\n-                                                 dim=0, dtype=torch.int32)\n+        # compute cu_seqlens more efficiently\n+        seq_lengths = grid_thw[:, 1] * grid_thw[:, 2]\n+        cu_seqlens = torch.repeat_interleave(seq_lengths, grid_thw[:, 0]).cumsum(\n+            dim=0, dtype=torch.int32)\n         cu_seqlens = F.pad(cu_seqlens, (1, 0), \"constant\", 0)\n \n         # transformers\n", "model_name_or_path": "gpt-5-2025-08-07"}
