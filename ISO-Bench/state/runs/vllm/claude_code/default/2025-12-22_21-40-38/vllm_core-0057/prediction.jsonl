{"instance_id": "vllm-project__vllm-bc8a8ce", "model_patch": "diff --git a/vllm/v1/sample/logits_processor.py b/vllm/v1/sample/logits_processor.py\nindex 3a4c25964..d11daa288 100644\n--- a/vllm/v1/sample/logits_processor.py\n+++ b/vllm/v1/sample/logits_processor.py\n@@ -229,7 +229,7 @@ class MinPLogitsProcessor(LogitsProcessor):\n         super().__init__()\n         self.min_p_count: int = 0\n \n-        self.min_p_cpu_tensor = torch.zeros((max_num_reqs, ),\n+        self.min_p_cpu_tensor = torch.empty((max_num_reqs, ),\n                                             dtype=torch.float32,\n                                             device=\"cpu\",\n                                             pin_memory=pin_memory)\n@@ -301,16 +301,13 @@ class MinPLogitsProcessor(LogitsProcessor):\n \n         # Convert logits to probability distribution\n         probability_values = torch.nn.functional.softmax(logits, dim=-1)\n-        # Calculate maximum probabilities per sequence\n+        # Calculate maximum probabilities per sequence and adjust min_p\n         max_probabilities = torch.amax(probability_values,\n                                        dim=-1,\n                                        keepdim=True)\n-        # Adjust min_p\n-        adjusted_min_p = max_probabilities.mul_(self.min_p)\n-        # Identify valid tokens using threshold comparison\n-        invalid_token_mask = probability_values < adjusted_min_p\n-        # Apply mask using boolean indexing\n-        logits[invalid_token_mask] = -float('inf')\n+        max_probabilities.mul_(self.min_p)\n+        # Identify and mask invalid tokens using in-place operation\n+        logits.masked_fill_(probability_values < max_probabilities, -float('inf'))\n         return logits\n \n \n@@ -322,7 +319,7 @@ class LogitBiasLogitsProcessor(LogitsProcessor):\n         self.device = device\n         self.pin_memory = pin_memory\n \n-        self.bias_tensor: torch.Tensor = torch.tensor(())\n+        self.bias_tensor: torch.Tensor = torch.empty(0, dtype=torch.float32, device=device)\n         self.logits_slice = (self._device_tensor([], torch.int32),\n                              self._device_tensor([], torch.int32))\n \n@@ -381,6 +378,8 @@ class LogitBiasLogitsProcessor(LogitsProcessor):\n                                  self._device_tensor(tok_ids, torch.int32))\n \n     def _device_tensor(self, data: list, dtype: torch.dtype) -> torch.Tensor:\n+        if not data:\n+            return torch.empty(0, dtype=dtype, device=self.device)\n         return (torch.tensor(data,\n                              device=\"cpu\",\n                              dtype=dtype,\n@@ -480,6 +479,8 @@ class MinTokensLogitsProcessor(LogitsProcessor):\n                                  self._device_tensor(tok_ids, torch.int32))\n \n     def _device_tensor(self, data: list, dtype: torch.dtype) -> torch.Tensor:\n+        if not data:\n+            return torch.empty(0, dtype=dtype, device=self.device)\n         return (torch.tensor(data,\n                              device=\"cpu\",\n                              dtype=dtype,\n", "model_name_or_path": "gpt-5-2025-08-07"}
