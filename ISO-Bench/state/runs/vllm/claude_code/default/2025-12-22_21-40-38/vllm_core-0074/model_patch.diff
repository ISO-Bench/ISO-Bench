diff --git a/vllm/worker/model_runner.py b/vllm/worker/model_runner.py
index 2b287a5d2..8f7207b0f 100644
--- a/vllm/worker/model_runner.py
+++ b/vllm/worker/model_runner.py
@@ -1222,8 +1222,8 @@ class GPUModelRunnerBase(ModelRunnerBase[TModelInputForGPU]):
 
         # Prepare dummy inputs. These will be reused for all batch sizes.
         max_batch_size = max(_BATCH_SIZES_TO_CAPTURE)
-        input_tokens = torch.zeros(max_batch_size, dtype=torch.long).cuda()
-        input_positions = torch.zeros(max_batch_size, dtype=torch.long).cuda()
+        input_tokens = torch.empty(max_batch_size, dtype=torch.long).cuda()
+        input_positions = torch.empty(max_batch_size, dtype=torch.long).cuda()
 
         # Prepare dummy previous_hidden_states only if needed by the model.
         # This is used by draft models such as EAGLE.
diff --git a/vllm/worker/tpu_model_runner.py b/vllm/worker/tpu_model_runner.py
index 01daa64b5..f14c925f9 100644
--- a/vllm/worker/tpu_model_runner.py
+++ b/vllm/worker/tpu_model_runner.py
@@ -102,7 +102,7 @@ class TPUModelRunner(ModelRunnerBase[ModelInputForTPU]):
         self.block_size = self.cache_config.block_size
         self.max_num_blocks_per_seq = (self.model_config.max_model_len //
                                        self.block_size)
-        self.block_tables = np.zeros(
+        self.block_tables = np.empty(
             (self.scheduler_config.max_num_seqs, self.max_num_blocks_per_seq),
             dtype=np.int32)
         self.attn_backend = get_attn_backend(
@@ -159,13 +159,13 @@ class TPUModelRunner(ModelRunnerBase[ModelInputForTPU]):
     ) -> None:
         if is_prompt:
             seq_len = (seq_len + 15) // 16 * 16
-            token_ids = torch.zeros((batch_size, seq_len),
+            token_ids = torch.empty((batch_size, seq_len),
                                     dtype=torch.int32,
                                     device=self.device)
-            position_ids = torch.zeros((batch_size, seq_len),
+            position_ids = torch.empty((batch_size, seq_len),
                                        dtype=torch.int32,
                                        device=self.device)
-            slot_mapping = torch.zeros((batch_size, seq_len),
+            slot_mapping = torch.empty((batch_size, seq_len),
                                        dtype=torch.int64,
                                        device=self.device)
             attn_metadata = self.attn_backend.make_metadata(
@@ -181,16 +181,16 @@ class TPUModelRunner(ModelRunnerBase[ModelInputForTPU]):
                                     device=self.device)
         else:
             assert seq_len == 1
-            token_ids = torch.zeros((batch_size, seq_len),
+            token_ids = torch.empty((batch_size, seq_len),
                                     dtype=torch.int32,
                                     device=self.device)
-            position_ids = torch.zeros((batch_size, seq_len),
+            position_ids = torch.empty((batch_size, seq_len),
                                        dtype=torch.int32,
                                        device=self.device)
-            slot_mapping = torch.zeros((batch_size, seq_len),
+            slot_mapping = torch.empty((batch_size, seq_len),
                                        dtype=torch.int64,
                                        device=self.device)
-            block_tables = torch.zeros(
+            block_tables = torch.empty(
                 (batch_size, self.max_num_blocks_per_seq),
                 dtype=torch.int32,
                 device=self.device)
diff --git a/vllm/worker/tpu_worker.py b/vllm/worker/tpu_worker.py
index 320b15d36..4b563da09 100644
--- a/vllm/worker/tpu_worker.py
+++ b/vllm/worker/tpu_worker.py
@@ -170,15 +170,19 @@ class TPUWorker(LoraNotSupportedWorkerBase, LocalOrDistributedWorkerBase):
         cpu_cache_shape = self.model_runner.attn_backend.get_kv_cache_shape(
             num_cpu_blocks, self.block_size, num_kv_heads, head_size)
         for _ in range(num_layers):
-            tpu_k_cache = torch.zeros(tpu_cache_shape,
+            tpu_k_cache = torch.empty(tpu_cache_shape,
+                                      dtype=dtype,
+                                      device=self.device)
+            tpu_v_cache = torch.empty(tpu_cache_shape,
                                       dtype=dtype,
                                       device=self.device)
-            tpu_v_cache = torch.zeros_like(tpu_k_cache)
             self.tpu_cache.append((tpu_k_cache, tpu_v_cache))
-            cpu_k_cache = torch.zeros(cpu_cache_shape,
+            cpu_k_cache = torch.empty(cpu_cache_shape,
+                                      dtype=dtype,
+                                      device="cpu")
+            cpu_v_cache = torch.empty(cpu_cache_shape,
                                       dtype=dtype,
                                       device="cpu")
-            cpu_v_cache = torch.zeros_like(cpu_k_cache)
             self.cpu_cache.append((cpu_k_cache, cpu_v_cache))
         self._warmup_model()
 
