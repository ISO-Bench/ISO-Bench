{"instance_id": "vllm-project__vllm-95baec8", "model_patch": "diff --git a/vllm/core/block_manager_v1.py b/vllm/core/block_manager_v1.py\nindex b2aaeb33c..9d52c2751 100644\n--- a/vllm/core/block_manager_v1.py\n+++ b/vllm/core/block_manager_v1.py\n@@ -266,7 +266,8 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n     def allocate(self, seq_group: SequenceGroup) -> None:\n         # NOTE: Here we assume that all sequences in the group have the same\n         # prompt.\n-        seq = seq_group.get_seqs(status=SequenceStatus.WAITING)[0]\n+        waiting_seqs = seq_group.get_seqs(status=SequenceStatus.WAITING)\n+        seq = waiting_seqs[0]\n \n         # Allocate new physical token blocks that will store the prompt tokens.\n         num_prompt_blocks = len(seq.logical_token_blocks)\n@@ -289,7 +290,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n             block_table.append(block)\n \n         # Assign the block table for each sequence.\n-        for seq in seq_group.get_seqs(status=SequenceStatus.WAITING):\n+        for seq in waiting_seqs:\n             self.block_tables[seq.seq_id] = block_table.copy()\n \n     def can_append_slots(self,\n@@ -425,8 +426,14 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         # When forking, we must make sure that each block's `ref_count`\n         # is only incremented by one, so we deduplicate them by wrapping\n         # them in a set.\n-        for block in set(src_block_table):\n-            block.ref_count += 1\n+        if self.block_sliding_window is not None:\n+            # Only need deduplication with sliding window\n+            for block in set(src_block_table):\n+                block.ref_count += 1\n+        else:\n+            # No duplicates without sliding window - avoid set creation\n+            for block in src_block_table:\n+                block.ref_count += 1\n \n     def _get_physical_blocks(\n             self, seq_group: SequenceGroup) -> List[PhysicalTokenBlock]:\n@@ -461,6 +468,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n \n         # CPU block -> GPU block.\n         mapping: Dict[PhysicalTokenBlock, PhysicalTokenBlock] = {}\n+        block_number_mapping: Dict[int, int] = {}\n         for seq in seq_group.get_seqs(status=SequenceStatus.SWAPPED):\n             new_block_table: BlockTable = []\n             block_table = self.block_tables[seq.seq_id]\n@@ -473,15 +481,12 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n                     gpu_block = self.gpu_allocator.allocate(\n                         cpu_block.block_hash, cpu_block.num_hashed_tokens)\n                     mapping[cpu_block] = gpu_block\n+                    block_number_mapping[cpu_block.block_number] = gpu_block.block_number\n                 new_block_table.append(gpu_block)\n                 # Free the CPU block swapped in to GPU.\n                 self.cpu_allocator.free(cpu_block)\n             self.block_tables[seq.seq_id] = new_block_table\n \n-        block_number_mapping = {\n-            cpu_block.block_number: gpu_block.block_number\n-            for cpu_block, gpu_block in mapping.items()\n-        }\n         return block_number_mapping\n \n     def can_swap_out(self, seq_group: SequenceGroup) -> bool:\n@@ -491,6 +496,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n     def swap_out(self, seq_group: SequenceGroup) -> Dict[int, int]:\n         # GPU block -> CPU block.\n         mapping: Dict[PhysicalTokenBlock, PhysicalTokenBlock] = {}\n+        block_number_mapping: Dict[int, int] = {}\n         for seq in seq_group.get_seqs(status=SequenceStatus.RUNNING):\n             new_block_table: BlockTable = []\n             block_table = self.block_tables[seq.seq_id]\n@@ -503,15 +509,12 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n                     cpu_block = self.cpu_allocator.allocate(\n                         gpu_block.block_hash, gpu_block.num_hashed_tokens)\n                     mapping[gpu_block] = cpu_block\n+                    block_number_mapping[gpu_block.block_number] = cpu_block.block_number\n                 new_block_table.append(cpu_block)\n                 # Free the GPU block swapped out to CPU.\n                 self.gpu_allocator.free(gpu_block)\n             self.block_tables[seq.seq_id] = new_block_table\n \n-        block_number_mapping = {\n-            gpu_block.block_number: cpu_block.block_number\n-            for gpu_block, cpu_block in mapping.items()\n-        }\n         return block_number_mapping\n \n     def _free_block_table(self, block_table: BlockTable) -> None:\n@@ -520,14 +523,21 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         # the block table, we must make sure to not free blocks more\n         # than once. If no sliding window is used, there is no block\n         # reuse in the block table, so we must free all blocks.\n-        blocks_to_free = (block_table[-self.block_sliding_window:]\n-                          if self.block_sliding_window is not None else\n-                          block_table)\n-        for block in set(blocks_to_free):\n-            if block.device == Device.GPU:\n-                self.gpu_allocator.free(block)\n-            else:\n-                self.cpu_allocator.free(block)\n+        if self.block_sliding_window is not None:\n+            blocks_to_free = block_table[-self.block_sliding_window:]\n+            # Need deduplication with sliding window\n+            for block in set(blocks_to_free):\n+                if block.device == Device.GPU:\n+                    self.gpu_allocator.free(block)\n+                else:\n+                    self.cpu_allocator.free(block)\n+        else:\n+            # No duplicates without sliding window - avoid set creation\n+            for block in block_table:\n+                if block.device == Device.GPU:\n+                    self.gpu_allocator.free(block)\n+                else:\n+                    self.cpu_allocator.free(block)\n \n     def free(self, seq: Sequence) -> None:\n         if seq.seq_id not in self.block_tables:\n@@ -571,7 +581,8 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         block_table = self.block_tables[seq.seq_id]\n         if max_full_block == -1:\n             return\n-        for i in reversed(range(max_full_block)):\n+        # Iterate backwards without creating reversed iterator\n+        for i in range(max_full_block - 1, -1, -1):\n             if block_table[i].computed:\n                 break\n             block_table[i].computed = True\n", "model_name_or_path": "gpt-5-2025-08-07"}
