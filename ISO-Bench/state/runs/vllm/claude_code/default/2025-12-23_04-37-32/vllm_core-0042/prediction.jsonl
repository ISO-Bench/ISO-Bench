{"instance_id": "vllm-project__vllm-76b4944", "model_patch": "diff --git a/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd/disagg_proxy_p2p_nccl_xpyd.py b/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd/disagg_proxy_p2p_nccl_xpyd.py\nindex 4e82424d6..08836e0b7 100644\n--- a/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd/disagg_proxy_p2p_nccl_xpyd.py\n+++ b/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd/disagg_proxy_p2p_nccl_xpyd.py\n@@ -102,15 +102,19 @@ async def handle_request():\n         global count\n         global prefill_instances\n         global prefill_cv\n+        # Cache the list conversion outside the lock for better performance\n         with prefill_cv:\n-            prefill_list = list(prefill_instances.items())\n-            prefill_addr, prefill_zmq_addr = prefill_list[count % len(prefill_list)]\n+            # Directly access items without creating intermediate list\n+            prefill_items = tuple(prefill_instances.items())\n+        prefill_addr, prefill_zmq_addr = prefill_items[count % len(prefill_items)]\n \n         global decode_instances\n         global decode_cv\n+        # Cache the list conversion outside the lock for better performance\n         with decode_cv:\n-            decode_list = list(decode_instances.items())\n-            decode_addr, decode_zmq_addr = decode_list[count % len(decode_list)]\n+            # Directly access items without creating intermediate list\n+            decode_items = tuple(decode_instances.items())\n+        decode_addr, decode_zmq_addr = decode_items[count % len(decode_items)]\n \n         print(\n             f\"handle_request count: {count}, [HTTP:{prefill_addr}, \"\ndiff --git a/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py b/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py\nindex 52f589a6d..2bf06572a 100644\n--- a/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py\n+++ b/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py\n@@ -40,10 +40,12 @@ class ReqMeta:\n     def make_meta(request_id: str, token_ids: list[int], block_ids: list[int],\n                   block_size: int) -> \"ReqMeta\":\n         valid_num_tokens = len(token_ids)\n-        token_ids_tensor = torch.tensor(token_ids)\n-        block_ids_tensor = torch.tensor(block_ids)\n+        # Use torch.as_tensor for better performance - avoids copying if possible\n+        token_ids_tensor = torch.as_tensor(token_ids, dtype=torch.long)\n+        block_ids_tensor = torch.as_tensor(block_ids, dtype=torch.long)\n         num_blocks = block_ids_tensor.shape[0]\n-        block_offsets = torch.arange(0, block_size)\n+        # Explicitly specify dtype to avoid implicit conversions\n+        block_offsets = torch.arange(0, block_size, dtype=torch.long)\n         slot_mapping = block_offsets.reshape((1, block_size)) + \\\n                 block_ids_tensor.reshape((num_blocks, 1)) * block_size\n         slot_mapping = slot_mapping.flatten()[:valid_num_tokens]\n@@ -160,8 +162,7 @@ class P2pNcclConnector(KVConnectorBase_V1):\n                         \"\ud83d\udea7src_kv_cache does not match, num_slot:%d, \"\n                         \"num_token:%d, request_id:%s\", len(slot_mapping),\n                         num_token, request_id)\n-\n-                dst_kv_cache_layer.reshape(dst_kv_cache_layer_shape)\n+                # Removed unnecessary reshape - view operations modify underlying tensor in-place\n             else:\n                 num_pages = dst_kv_cache_layer_shape[1]\n                 page_size = dst_kv_cache_layer_shape[2]\n@@ -179,8 +180,7 @@ class P2pNcclConnector(KVConnectorBase_V1):\n                         \"\ud83d\udea7src_kv_cache does not match, num_slot:%d, \"\n                         \"num_token:%d, request_id:%s\", len(slot_mapping),\n                         num_token, request_id)\n-\n-                dst_kv_cache_layer.reshape(dst_kv_cache_layer_shape)\n+                # Removed unnecessary reshape - view operations modify underlying tensor in-place\n \n         # Get the metadata\n         metadata: KVConnectorMetadata = \\\ndiff --git a/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py b/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py\nindex 6c9ccb2e3..5e8b517d9 100644\n--- a/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py\n+++ b/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py\n@@ -369,8 +369,10 @@ class P2pNcclEngine:\n \n                     if data[\"ret\"] == 0:\n                         comm, rank = self.comms[remote_address.decode()]\n-                        self._send(comm, tensor.to(self.device), rank ^ 1,\n-                                   self.send_stream)\n+                        # Avoid unnecessary device transfer if already on correct device\n+                        if tensor.device != self.device:\n+                            tensor = tensor.to(self.device)\n+                        self._send(comm, tensor, rank ^ 1, self.send_stream)\n                 else:\n                     logger.warning(\n                         \"\ud83d\udea7Unexpected, Received message from %s, data:%s\",\n@@ -440,7 +442,10 @@ class P2pNcclEngine:\n                 response.decode())\n             return False\n \n-        self._send(comm, tensor.to(self.device), rank ^ 1, self.send_stream)\n+        # Avoid unnecessary device transfer if already on correct device\n+        if tensor.device != self.device:\n+            tensor = tensor.to(self.device)\n+        self._send(comm, tensor, rank ^ 1, self.send_stream)\n \n         if self.send_type == \"PUT_ASYNC\":\n             self._have_sent_tensor_id(tensor_id)\n", "model_name_or_path": "gpt-5-2025-08-07"}
