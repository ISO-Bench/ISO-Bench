{"instance_id": "vllm-project__vllm-95baec8", "model_patch": "diff --git a/model_patch.diff b/model_patch.diff\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/vllm/core/block_manager_v1.py b/vllm/core/block_manager_v1.py\nindex b2aaeb33c..4582f2b79 100644\n--- a/vllm/core/block_manager_v1.py\n+++ b/vllm/core/block_manager_v1.py\n@@ -1,6 +1,6 @@\n \"\"\"A block manager that manages token blocks.\"\"\"\n from abc import ABC, abstractmethod\n-from itertools import count, takewhile\n+from itertools import count\n from os.path import commonprefix\n from typing import Dict, List, Optional, Set\n \n@@ -313,7 +313,8 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n \n         # Compute a new hash for the block so that it can be shared by other\n         # Sequences\n-        new_hash = seq.hash_of_block(len(seq.logical_token_blocks) - 1)\n+        last_logical_idx = len(seq.logical_token_blocks) - 1\n+        new_hash = seq.hash_of_block(last_logical_idx)\n \n         # if new_hash is already in the cached table, then free last_block\n         # and return the cached version\n@@ -328,7 +329,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         self,\n         seq: Sequence,\n     ) -> bool:\n-        token_ids_len = len(seq.data.get_token_ids())\n+        token_ids_len = seq.data.get_len()\n         return token_ids_len > 0 and token_ids_len % seq.block_size == 0\n \n     def _maybe_promote_last_block(\n@@ -353,10 +354,10 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         if not self.enable_caching:\n             return self.gpu_allocator.allocate()\n         block_hash: Optional[int] = None\n+        last_logical_idx = len(seq.logical_token_blocks) - 1\n         if (self._is_last_block_full(seq)):\n-            block_hash = seq.hash_of_block(len(seq.logical_token_blocks) - 1)\n-        num_hashed_tokens = seq.num_hashed_tokens_of_block(\n-            len(seq.logical_token_blocks) - 1)\n+            block_hash = seq.hash_of_block(last_logical_idx)\n+        num_hashed_tokens = seq.num_hashed_tokens_of_block(last_logical_idx)\n \n         # num_hashed_tokens is used to compute future hashes\n         # (e.g. in the hashing function, it is used to ask the sequence for\n@@ -377,16 +378,16 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         \"\"\"Allocate a physical slot for a new token.\"\"\"\n         logical_blocks = seq.logical_token_blocks\n         block_table = self.block_tables[seq.seq_id]\n+        lt = len(block_table)\n+        ll = len(logical_blocks)\n         # If we need to allocate a new physical block\n-        if len(block_table) < len(logical_blocks):\n+        if lt < ll:\n             # Currently this code only supports adding one physical block\n-            assert len(block_table) == len(logical_blocks) - 1\n+            assert lt == ll - 1\n \n-            if (self.block_sliding_window\n-                    and len(block_table) >= self.block_sliding_window):\n+            if self.block_sliding_window and lt >= self.block_sliding_window:\n                 # reuse a block\n-                block_table.append(block_table[len(block_table) %\n-                                               self.block_sliding_window])\n+                block_table.append(block_table[lt % self.block_sliding_window])\n             else:\n                 # The sequence has a new logical block.\n                 # Allocate a new physical block.\n@@ -571,7 +572,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         block_table = self.block_tables[seq.seq_id]\n         if max_full_block == -1:\n             return\n-        for i in reversed(range(max_full_block)):\n+        for i in reversed(range(max_full_block + 1)):\n             if block_table[i].computed:\n                 break\n             block_table[i].computed = True\n@@ -583,10 +584,12 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         # NOTE We exclude the last block to avoid the case where the entire\n         # prompt is cached. This would cause erroneous behavior in model\n         # runner.\n-        return [\n-            b.block_number\n-            for b in takewhile(lambda b: b.computed, block_table[:-1])\n-        ]\n+        res: List[int] = []\n+        for b in block_table[:-1]:\n+            if not b.computed:\n+                break\n+            res.append(b.block_number)\n+        return res\n \n     def get_common_computed_block_ids(self, seqs: List[Sequence]) -> List[int]:\n         \"\"\"Return the block ids that are common for a given sequence group.\n", "model_name_or_path": "gpt-5-2025-08-07"}
