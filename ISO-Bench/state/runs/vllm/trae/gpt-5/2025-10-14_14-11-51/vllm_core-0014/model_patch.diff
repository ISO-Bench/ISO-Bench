diff --git a/tests/v1/test_serial_utils.py b/tests/v1/test_serial_utils.py
index bc0e0cbd8..cd31e3e9b 100644
--- a/tests/v1/test_serial_utils.py
+++ b/tests/v1/test_serial_utils.py
@@ -50,7 +50,7 @@ def test_encode_decode():
         large_non_contig_tensor=torch.rand(1024, 512)[:, 10:20],
     )
 
-    encoder = MsgpackEncoder()
+    encoder = MsgpackEncoder(size_threshold=256)
     decoder = MsgpackDecoder(MyType)
 
     encoded = encoder.encode(obj)
diff --git a/vllm/envs.py b/vllm/envs.py
index f80bf878f..bd7e3c7d1 100644
--- a/vllm/envs.py
+++ b/vllm/envs.py
@@ -605,6 +605,11 @@ environment_variables: dict[str, Callable[[], Any]] = {
     "VLLM_V1_OUTPUT_PROC_CHUNK_SIZE":
     lambda: int(os.getenv("VLLM_V1_OUTPUT_PROC_CHUNK_SIZE", "128")),
 
+    # Threshold (in bytes) below which small numpy/tensor buffers are inlined
+    # in the V1 msgpack serializer to reduce aux buffer overhead.
+    "VLLM_V1_MSGBUF_INLINE_THRESHOLD":
+    lambda: int(os.getenv("VLLM_V1_MSGBUF_INLINE_THRESHOLD", "512")),
+
     # If set, vLLM will disable the MLA attention optimizations.
     "VLLM_MLA_DISABLE":
     lambda: bool(int(os.getenv("VLLM_MLA_DISABLE", "0"))),
diff --git a/vllm/v1/serial_utils.py b/vllm/v1/serial_utils.py
index 3af6793fd..5252ec938 100644
--- a/vllm/v1/serial_utils.py
+++ b/vllm/v1/serial_utils.py
@@ -1,5 +1,6 @@
 # SPDX-License-Identifier: Apache-2.0
 
+import os
 import pickle
 from collections.abc import Sequence
 from inspect import isclass
@@ -16,7 +17,8 @@ CUSTOM_TYPE_PICKLE = 1
 CUSTOM_TYPE_CLOUDPICKLE = 2
 CUSTOM_TYPE_RAW_VIEW = 3
 
-# TODO calibrate this size
+# Default inline threshold for small buffers. Can be overridden via
+# constructor or the env var VLLM_V1_MSGBUF_INLINE_THRESHOLD.
 MIN_NOCOPY_BUF_SIZE = 512
 
 bytestr = Union[bytes, bytearray, memoryview, zmq.Frame]
@@ -29,7 +31,14 @@ class MsgpackEncoder:
     not thread-safe when encoding tensors / numpy arrays.
     """
 
-    def __init__(self):
+    def __init__(self, size_threshold: Optional[int] = None):
+        # Resolve the size threshold once during initialization to avoid repeated
+        # environment lookups during encoding.
+        if size_threshold is None:
+            size_threshold = int(
+                os.getenv("VLLM_V1_MSGBUF_INLINE_THRESHOLD", MIN_NOCOPY_BUF_SIZE))
+        self.size_threshold = int(size_threshold)
+
         self.encoder = msgpack.Encoder(enc_hook=self.enc_hook)
         # This is used as a local stash of buffers that we can then access from
         # our custom `msgspec` hook, `enc_hook`. We don't have a way to
@@ -38,7 +47,7 @@ class MsgpackEncoder:
 
     def encode(self, obj: Any) -> Sequence[bytestr]:
         try:
-            self.aux_buffers = bufs = [b'']
+            self.aux_buffers = bufs = [b""]
             bufs[0] = self.encoder.encode(obj)
             # This `bufs` list allows us to collect direct pointers to backing
             # buffers of tensors and np arrays, and return them along with the
@@ -62,7 +71,7 @@ class MsgpackEncoder:
             return self._encode_ndarray(obj.numpy())
 
         # Fall back to pickle for object or void kind ndarrays.
-        if isinstance(obj, np.ndarray) and obj.dtype.kind not in ('O', 'V'):
+        if isinstance(obj, np.ndarray) and obj.dtype.kind not in ("O", "V"):
             return self._encode_ndarray(obj)
 
         if isinstance(obj, FunctionType):
@@ -70,18 +79,20 @@ class MsgpackEncoder:
             # problems serializing methods.
             return msgpack.Ext(CUSTOM_TYPE_CLOUDPICKLE, cloudpickle.dumps(obj))
 
-        return msgpack.Ext(CUSTOM_TYPE_PICKLE,
-                           pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL))
+        return msgpack.Ext(
+            CUSTOM_TYPE_PICKLE,
+            pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL))
 
     def _encode_ndarray(
         self, obj: np.ndarray
     ) -> tuple[str, tuple[int, ...], Union[int, memoryview]]:
         assert self.aux_buffers is not None
+        # Fast path: reuse underlying contiguous buffer when available.
         arr_data = obj.data if obj.data.c_contiguous else obj.tobytes()
-        if not obj.shape or obj.nbytes < MIN_NOCOPY_BUF_SIZE:
-            # Encode small arrays and scalars inline. Using this extension type
-            # ensures we can avoid copying when decoding.
-            data = msgpack.Ext(CUSTOM_TYPE_RAW_VIEW, arr_data)
+        # Inline small arrays and scalars; otherwise append to aux_buffers.
+        if not obj.shape or obj.nbytes < self.size_threshold:
+            # Wrap in memoryview to avoid copying for bytes-like objects.
+            data = msgpack.Ext(CUSTOM_TYPE_RAW_VIEW, memoryview(arr_data))
         else:
             # Otherwise encode index of backing buffer to avoid copy.
             data = len(self.aux_buffers)
@@ -102,12 +113,12 @@ class MsgpackDecoder:
 
     def __init__(self, t: Optional[Any] = None):
         args = () if t is None else (t, )
-        self.decoder = msgpack.Decoder(*args,
-                                       ext_hook=self.ext_hook,
-                                       dec_hook=self.dec_hook)
+        self.decoder = msgpack.Decoder(
+            *args, ext_hook=self.ext_hook, dec_hook=self.dec_hook)
         self.aux_buffers: Sequence[bytestr] = ()
 
     def decode(self, bufs: Union[bytestr, Sequence[bytestr]]) -> Any:
+        # Fast path for single-buffer inputs.
         if isinstance(bufs, (bytes, bytearray, memoryview, zmq.Frame)):
             # TODO - This check can become `isinstance(bufs, bytestr)`
             # as of Python 3.10.
