{"instance_id": "vllm-project__vllm-dd572c0", "model_patch": "diff --git a/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py b/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py\nindex 628aa5c7b..3e916414f 100644\n--- a/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py\n+++ b/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py\n@@ -55,6 +55,7 @@ def _silu_mul_fp8_quant_deep_gemm(\n \n     # Meta ---------------------------------------------------------------\n     BLOCK: tl.constexpr,\n+    NUM_STAGES: tl.constexpr,\n ):\n     G = H // GROUP_SIZE\n \n@@ -71,24 +72,19 @@ def _silu_mul_fp8_quant_deep_gemm(\n \n     cols = tl.arange(0, BLOCK)\n     cols = cols.to(tl.int64)\n-    mask_h = cols < BLOCK\n+    offset_i_h = cols * stride_i_h\n+    offset_yq_h = cols * stride_yq_h\n \n-    t = tl.zeros([], tl.int64)\n-    while t < n_tokens:\n+    for t in tl.range(0, n_tokens, num_stages=NUM_STAGES):\n         base_i_offset = (e * stride_i_e + t * stride_i_t +\n                          g * GROUP_SIZE * stride_i_h)\n         base_yq_offset = (e * stride_yq_e + t * stride_yq_t +\n                           g * GROUP_SIZE * stride_yq_h)\n         base_ys_offset = e * stride_ys_e + t * stride_ys_t + g * stride_ys_g\n \n-        mask = mask_h\n-        x = tl.load(input_ptr + base_i_offset + cols * stride_i_h,\n-                    mask=mask,\n-                    other=0.0).to(tl.float32)\n+        x = tl.load(input_ptr + base_i_offset + offset_i_h).to(tl.float32)\n         y2 = tl.load(input_ptr + base_i_offset + H * stride_i_h +\n-                     cols * stride_i_h,\n-                     mask=mask,\n-                     other=0.0).to(tl.float32)\n+                     offset_i_h).to(tl.float32)\n \n         x = x * (1.0 / (1.0 + tl.exp(-x)))\n         y = x * y2\n@@ -99,11 +95,9 @@ def _silu_mul_fp8_quant_deep_gemm(\n             tl.log2(scale_raw))) if use_ue8m0 else scale_raw\n         y_q = tl.clamp(y / y_s, fp8_min, fp8_max).to(y_q_ptr.dtype.element_ty)\n \n-        tl.store(y_q_ptr + base_yq_offset + cols * stride_yq_h, y_q, mask=mask)\n+        tl.store(y_q_ptr + base_yq_offset + offset_yq_h, y_q)\n         tl.store(y_s_ptr + base_ys_offset, y_s)\n \n-        t += 1\n-\n \n def silu_mul_fp8_quant_deep_gemm(\n     y: torch.Tensor,  # (E, T, 2*H) float32\n@@ -180,6 +174,7 @@ def silu_mul_fp8_quant_deep_gemm(\n         fp8_max,\n         is_blackwell_deep_gemm_used(),\n         BLOCK=group_size,\n+        NUM_STAGES=2,\n         num_warps=4,\n     )\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
