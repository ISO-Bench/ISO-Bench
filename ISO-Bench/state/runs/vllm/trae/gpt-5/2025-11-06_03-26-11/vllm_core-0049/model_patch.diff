diff --git a/model_patch.diff b/model_patch.diff
new file mode 100644
index 000000000..e69de29bb
diff --git a/tests/core/test_block_manager.py b/tests/core/test_block_manager.py
index 44ac05a14..9e42ad8f9 100644
--- a/tests/core/test_block_manager.py
+++ b/tests/core/test_block_manager.py
@@ -4,7 +4,7 @@ from typing import List
 
 from vllm import SamplingParams
 from vllm.block import PhysicalTokenBlock
-from vllm.core.block_manager import (BlockAllocator, BlockSpaceManager,
+from vllm.core.block_manager import (UncachedBlockAllocator, BlockSpaceManager,
                                      AllocStatus)
 from vllm.utils import Device
 from vllm.sequence import Sequence, SequenceGroup, SequenceStatus, Logprob
@@ -15,7 +15,7 @@ from .utils import create_dummy_prompt
 def test_block_allocator_allocate():
     block_size = 4
     num_cpu_blocks = 4
-    cpu_allocator = BlockAllocator(Device.CPU, block_size, num_cpu_blocks)
+    cpu_allocator = UncachedBlockAllocator(Device.CPU, block_size, num_cpu_blocks)
 
     # Allocate all available cpu blocks.
     num_free = num_cpu_blocks
@@ -24,7 +24,7 @@ def test_block_allocator_allocate():
         block = cpu_allocator.allocate()
         num_free -= 1
 
-        assert block.block_hash not in cpu_allocator.evictor
+        assert block not in cpu_allocator.free_blocks
         assert cpu_allocator.get_num_free_blocks() == num_free
 
     with pytest.raises(ValueError):
@@ -34,14 +34,14 @@ def test_block_allocator_allocate():
 def test_block_allocator_free():
     block_size = 4
     num_cpu_blocks = 4
-    cpu_allocator = BlockAllocator(Device.CPU, block_size, num_cpu_blocks)
+    cpu_allocator = UncachedBlockAllocator(Device.CPU, block_size, num_cpu_blocks)
 
     # Allocate all available cpu blocks.
     blocks: List[PhysicalTokenBlock] = []
     for _ in range(num_cpu_blocks):
         block = cpu_allocator.allocate()
         blocks.append(block)
-        assert block.block_hash not in cpu_allocator.evictor
+        assert block not in cpu_allocator.free_blocks
 
     # Free all allocated cpu blocks.
     num_free = 0
@@ -49,7 +49,7 @@ def test_block_allocator_free():
     for block in blocks:
         cpu_allocator.free(block)
         num_free += 1
-        assert block.block_hash in cpu_allocator.evictor
+        assert block in cpu_allocator.free_blocks
         assert cpu_allocator.get_num_free_blocks() == num_free
 
         with pytest.raises(ValueError):
diff --git a/vllm/core/block_manager.py b/vllm/core/block_manager.py
index 8b089a565..bd9143bf2 100644
--- a/vllm/core/block_manager.py
+++ b/vllm/core/block_manager.py
@@ -10,6 +10,72 @@ from vllm.utils import Device
 from vllm.core.evictor import Evictor, EvictionPolicy, make_evictor
 
 
+
+
+class UncachedBlockAllocator:
+    """A lightweight allocator for when prefix caching is disabled.
+
+    Uses a simple free list of PhysicalTokenBlock objects to avoid the
+    overhead of maintaining hash-indexed structures and eviction policies.
+    """
+
+    def __init__(self, device: Device, block_size: int, num_blocks: int) -> None:
+        self.device = device
+        self.block_size = block_size
+        self.num_blocks = num_blocks
+        self.current_num_blocks = 0
+        self.free_blocks: List[PhysicalTokenBlock] = []
+        self._default_hash_ctr = count()
+
+    def allocate(self,
+                 block_hash: Optional[int] = None,
+                 num_hashed_tokens: int = 0) -> PhysicalTokenBlock:
+        # Reuse freed blocks if available.
+        if self.free_blocks:
+            block = self.free_blocks.pop()
+            assert block.ref_count == 0
+            # Update block metadata to reflect new usage
+            block.block_hash = (next(self._default_hash_ctr)
+                                if block_hash is None else block_hash)
+            block.num_hashed_tokens = num_hashed_tokens
+            block.computed = False
+            block.ref_count = 1
+            return block
+
+        # Allocate a new block if capacity allows
+        if self.current_num_blocks < self.num_blocks:
+            new_block = PhysicalTokenBlock(device=self.device,
+                                           block_number=self.current_num_blocks,
+                                           block_size=self.block_size,
+                                           block_hash=(next(self._default_hash_ctr)
+                                                       if block_hash is None else block_hash),
+                                           num_hashed_tokens=num_hashed_tokens)
+            self.current_num_blocks += 1
+            new_block.ref_count = 1
+            return new_block
+
+        # Out of capacity and no reusable blocks
+        raise ValueError("No usable cache memory left")
+
+    def free(self, block: PhysicalTokenBlock) -> None:
+        if block.ref_count == 0:
+            raise ValueError(f"Double free! {block} is already freed.")
+        block.ref_count -= 1
+        if block.ref_count == 0:
+            block.computed = False
+            self.free_blocks.append(block)
+
+    def contains_block(self, block_hash: int) -> bool:
+        # No hashing/caching in uncached mode
+        return False
+
+    def update_hash(self, block_hash: int, block: PhysicalTokenBlock) -> None:
+        # Simply update the hash on the block
+        block.block_hash = block_hash
+
+    def get_num_free_blocks(self) -> int:
+        return (self.num_blocks - self.current_num_blocks + len(self.free_blocks))
+
 class BlockAllocator:
     """Manages free physical token blocks for a device.
 
@@ -154,14 +220,23 @@ class BlockSpaceManager:
         self.enable_caching = enable_caching
 
         self.watermark_blocks = int(watermark * num_gpu_blocks)
-        self.gpu_allocator = BlockAllocator(Device.GPU,
-                                            block_size,
-                                            num_gpu_blocks,
-                                            enable_caching=enable_caching)
-        self.cpu_allocator = BlockAllocator(Device.CPU,
-                                            block_size,
-                                            num_cpu_blocks,
-                                            enable_caching=enable_caching)
+        if enable_caching:
+            self.gpu_allocator = BlockAllocator(Device.GPU,
+                                                block_size,
+                                                num_gpu_blocks,
+                                                enable_caching=enable_caching)
+            self.cpu_allocator = BlockAllocator(Device.CPU,
+                                                block_size,
+                                                num_cpu_blocks,
+                                                enable_caching=enable_caching)
+        else:
+            # Use a lightweight allocator when caching is disabled for better perf
+            self.gpu_allocator = UncachedBlockAllocator(Device.GPU,
+                                                        block_size,
+                                                        num_gpu_blocks)
+            self.cpu_allocator = UncachedBlockAllocator(Device.CPU,
+                                                        block_size,
+                                                        num_cpu_blocks)
         # Mapping: seq_id -> BlockTable.
         self.block_tables: Dict[int, BlockTable] = {}
 
diff --git a/vllm/core/evictor.py b/vllm/core/evictor.py
index 1d81f5a97..802d5cc34 100644
--- a/vllm/core/evictor.py
+++ b/vllm/core/evictor.py
@@ -70,31 +70,19 @@ class LRUEvictor(Evictor):
         if len(free_blocks) == 0:
             raise ValueError("No usable cache memory left")
 
-        # Find lowest timestamp
-        lowest_timestamp = free_blocks[0].last_accessed
-        for block in free_blocks:
-            if block.last_accessed < lowest_timestamp:
-                lowest_timestamp = block.last_accessed
-
-        # Find all blocks with the lowest timestamp
-        least_recent: List[PhysicalTokenBlock] = []
+        # Single-pass selection of eviction candidate: lowest timestamp, then max num_hashed_tokens
+        evicted_block: Optional[PhysicalTokenBlock] = None
+        lowest_timestamp = None
+        highest_num_hashed_tokens = -1
         for block in free_blocks:
-            if block.last_accessed == lowest_timestamp:
-                least_recent.append(block)
-
-        # Find highest prefix count per block
-        highest_num_hashed_tokens = 0
-        for block in least_recent:
-            if block.num_hashed_tokens > highest_num_hashed_tokens:
+            ts = block.last_accessed
+            if lowest_timestamp is None or ts < lowest_timestamp:
+                lowest_timestamp = ts
+                highest_num_hashed_tokens = block.num_hashed_tokens
+                evicted_block = block
+            elif ts == lowest_timestamp and block.num_hashed_tokens > highest_num_hashed_tokens:
                 highest_num_hashed_tokens = block.num_hashed_tokens
-
-        evicted_block: Optional[PhysicalTokenBlock] = None
-
-        # Find the first block with the lowest timestamp
-        for block in least_recent:
-            if block.num_hashed_tokens == highest_num_hashed_tokens:
                 evicted_block = block
-                break
 
         assert evicted_block is not None
 
