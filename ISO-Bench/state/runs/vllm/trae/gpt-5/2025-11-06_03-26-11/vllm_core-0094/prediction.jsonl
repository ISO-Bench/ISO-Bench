{"instance_id": "vllm-project__vllm-67abdbb", "model_patch": "diff --git a/vllm/core/block_manager_v1.py b/vllm/core/block_manager_v1.py\nindex 622aca66a..ad26d3c51 100644\n--- a/vllm/core/block_manager_v1.py\n+++ b/vllm/core/block_manager_v1.py\n@@ -336,9 +336,9 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n \n         # Assign the self-attention block tables for each sequence.\n         if len(wait_seqs) == 1:\n-            self.block_tables[wait_seqs[0].seq_id] = block_table\n+            self.block_tables[seq.seq_id] = block_table\n         else:\n-            for seq in seq_group.get_seqs(status=SequenceStatus.WAITING):\n+            for seq in wait_seqs:\n                 self.block_tables[seq.seq_id] = block_table.copy()\n \n         # Allocate encoder sequence\ndiff --git a/vllm/sequence.py b/vllm/sequence.py\nindex ba477efc5..963e37b94 100644\n--- a/vllm/sequence.py\n+++ b/vllm/sequence.py\n@@ -655,15 +655,26 @@ class SequenceGroup:\n         return [seq for seq in self.seqs if not seq.is_finished()]\n \n     def get_finished_seqs(self) -> List[Sequence]:\n+        if self.is_single_seq:\n+            return self.seqs if self.seqs[0].is_finished() else []\n+\n         return [seq for seq in self.seqs if seq.is_finished()]\n \n     def update_num_computed_tokens(self, num_new_computed_tokens: int):\n         \"\"\"Update number of tokens computed so far.\"\"\"\n+        if self.is_single_seq:\n+            seq = self.seqs[0]\n+            if not seq.is_finished():\n+                seq.data.update_num_computed_tokens(num_new_computed_tokens)\n+            return\n         for seq in self.seqs:\n             if not seq.is_finished():\n                 seq.data.update_num_computed_tokens(num_new_computed_tokens)\n \n     def get_num_uncomputed_tokens(self) -> int:\n+        if self.is_single_seq:\n+            seq = self.seqs[0]\n+            return 0 if seq.is_finished() else seq.data.get_num_uncomputed_tokens()\n         num_uncomputed_tokens = 0\n         for seq in self.seqs:\n             if not seq.is_finished():\n", "model_name_or_path": "gpt-5-2025-08-07"}
