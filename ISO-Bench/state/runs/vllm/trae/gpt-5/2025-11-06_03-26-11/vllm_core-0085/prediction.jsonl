{"instance_id": "vllm-project__vllm-90f1e55", "model_patch": "diff --git a/csrc/moe/moe_permute_unpermute_op.cu b/csrc/moe/moe_permute_unpermute_op.cu\nindex 13aecd800..e827d9b11 100644\n--- a/csrc/moe/moe_permute_unpermute_op.cu\n+++ b/csrc/moe/moe_permute_unpermute_op.cu\n@@ -49,7 +49,7 @@ void moe_permute(\n   auto permuted_experts_id = torch::empty_like(topk_ids);\n   auto dst_row_id2src_row_id_map = torch::empty_like(src_row_id2dst_row_id_map);\n   auto align_expert_first_token_offset =\n-      torch::zeros_like(expert_first_token_offset);\n+      torch::empty_like(expert_first_token_offset);\n \n   CubKeyValueSorter sorter{};\n   int64_t* valid_num_ptr = nullptr;\ndiff --git a/vllm/model_executor/layers/fused_moe/cutlass_moe.py b/vllm/model_executor/layers/fused_moe/cutlass_moe.py\nindex ff49d7bb7..9f4b0cf12 100644\n--- a/vllm/model_executor/layers/fused_moe/cutlass_moe.py\n+++ b/vllm/model_executor/layers/fused_moe/cutlass_moe.py\n@@ -136,18 +136,10 @@ def run_cutlass_moe_fp8(\n                                      dtype=torch.int32,\n                                      device=device)\n \n-        # With expert_map each Rank processes only a subset of experts. As\n-        # a result not all of a_map and c2 tensors are filled. We fill it\n-        # zeros for correctness.\n-        if expert_map is not None:\n-            a_map = torch.zeros((local_topk_ids.numel()),\n-                                dtype=torch.int32,\n-                                device=device)\n-        else:\n-            a_map = torch.empty((local_topk_ids.numel()),\n-                                dtype=torch.int32,\n-                                device=device)\n-\n+        # Always allocate without initialization; fill only where needed.\n+        a_map = torch.empty((local_topk_ids.numel()),\n+                            dtype=torch.int32,\n+                            device=device)\n         c_map = torch.empty((local_topk_ids.numel()),\n                             dtype=torch.int32,\n                             device=device)\n@@ -156,6 +148,12 @@ def run_cutlass_moe_fp8(\n                                     problem_sizes1, problem_sizes2, a_map,\n                                     c_map, global_num_experts, N, K)\n \n+        # Zero only invalid entries to avoid reading garbage during shuffle.\n+        if expert_map is not None:\n+            invalid_mask = (local_topk_ids.reshape(-1) < 0)\n+            if invalid_mask.any().item():\n+                a_map.masked_fill_(invalid_mask, 0)\n+\n         a1q = ops.shuffle_rows(a1q, a_map)\n         a1q_scale = (ops.shuffle_rows(a1q_scale, a_map)\n                      if per_act_token else a1q_scale)\n@@ -186,7 +184,10 @@ def run_cutlass_moe_fp8(\n         c2, a2_scale, use_per_token_if_dynamic=per_act_token)\n \n     if expert_map is not None:\n-        c3.fill_(0)\n+        # Zero only rows corresponding to invalid tokens to avoid stale data.\n+        invalid_rows = (local_topk_ids.reshape(-1) < 0).nonzero(as_tuple=False).reshape(-1).to(dtype=torch.int64, device=c3.device)\n+        if invalid_rows.numel() > 0:\n+            c3.index_fill_(0, invalid_rows, 0)\n \n     ops.cutlass_moe_mm(c3, a2q, w2, a2q_scale, w2_scale, expert_offsets,\n                        problem_sizes2, ab_strides2, ab_strides2, c_strides2,\ndiff --git a/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py b/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py\nindex 1a31410c3..2c68ccd3e 100644\n--- a/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py\n+++ b/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py\n@@ -203,7 +203,7 @@ class CompressedTensorsW4A4MoeMethod(CompressedTensorsMoEMethod):\n         round_up_multiple = lambda x, m: (x + m - 1) // m * m\n         M_padded = round_up_multiple(M, 128)\n         K_padded = round_up_multiple(K, 4)\n-        padded_scale = torch.zeros((B, M_padded, K_padded), dtype=scale.dtype)\n+        padded_scale = torch.zeros((B, M_padded, K_padded), dtype=scale.dtype, device=scale.device)\n         padded_scale[:B, :M, :K] = scale\n         batches, rows, cols = padded_scale.shape\n         assert rows % 128 == 0\n", "model_name_or_path": "gpt-5-2025-08-07"}
