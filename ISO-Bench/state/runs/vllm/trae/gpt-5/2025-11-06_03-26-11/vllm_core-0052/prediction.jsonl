{"instance_id": "vllm-project__vllm-3014c92", "model_patch": "diff --git a/vllm/model_executor/layers/rotary_embedding.py b/vllm/model_executor/layers/rotary_embedding.py\nindex 9de233896..fbacac226 100644\n--- a/vllm/model_executor/layers/rotary_embedding.py\n+++ b/vllm/model_executor/layers/rotary_embedding.py\n@@ -26,6 +26,7 @@\n import math\n from typing import Any, Optional, Union\n \n+import numpy as np\n import torch\n import torch.nn as nn\n from transformers import PretrainedConfig\n@@ -1468,6 +1469,17 @@ class MRotaryEmbedding(RotaryEmbedding):\n             mrope_position_delta + seq_len,\n         ).expand(3, -1)\n \n+\n+    @staticmethod\n+    def get_next_input_positions_tensor_out(out: np.ndarray, out_offset: int,\n+                                            mrope_position_delta: int,\n+                                            context_len: int,\n+                                            num_new_tokens: int) -> None:\n+        start = mrope_position_delta + context_len\n+        end = start + num_new_tokens\n+        vals = np.arange(start, end, dtype=out.dtype)\n+        out[:, out_offset:out_offset + num_new_tokens] = vals\n+\n     @classmethod\n     def omni_get_updates_use_audio_in_video(\n         cls,\ndiff --git a/vllm/v1/worker/gpu_model_runner.py b/vllm/v1/worker/gpu_model_runner.py\nindex 520d8fb18..9214965f2 100644\n--- a/vllm/v1/worker/gpu_model_runner.py\n+++ b/vllm/v1/worker/gpu_model_runner.py\n@@ -257,7 +257,7 @@ class GPUModelRunner(LoRAModelRunnerMixin):\n             self.mrope_positions = torch.zeros((3, self.max_num_tokens + 1),\n                                                dtype=torch.int64,\n                                                device=self.device)\n-            self.mrope_positions_cpu = torch.zeros(\n+            self.mrope_positions_cpu = torch.empty(\n                 (3, self.max_num_tokens + 1),\n                 dtype=torch.int64,\n                 device=\"cpu\",\n@@ -280,21 +280,21 @@ class GPUModelRunner(LoRAModelRunnerMixin):\n         # NOTE(woosuk): These tensors are \"stateless\", i.e., they are literally\n         # a faster version of creating a new tensor every time. Thus, we should\n         # not make any assumptions about the values in these tensors.\n-        self.input_ids_cpu = torch.zeros(self.max_num_tokens,\n+        self.input_ids_cpu = torch.empty(self.max_num_tokens,\n                                          dtype=torch.int32,\n                                          device=\"cpu\",\n                                          pin_memory=self.pin_memory)\n-        self.positions_cpu = torch.zeros(self.max_num_tokens,\n+        self.positions_cpu = torch.empty(self.max_num_tokens,\n                                          dtype=torch.int64,\n                                          device=\"cpu\",\n                                          pin_memory=self.pin_memory)\n         self.positions_np = self.positions_cpu.numpy()\n-        self.query_start_loc_cpu = torch.zeros(self.max_num_reqs + 1,\n+        self.query_start_loc_cpu = torch.empty(self.max_num_reqs + 1,\n                                                dtype=torch.int32,\n                                                device=\"cpu\",\n                                                pin_memory=self.pin_memory)\n         self.query_start_loc_np = self.query_start_loc_cpu.numpy()\n-        self.seq_lens_cpu = torch.zeros(self.max_num_reqs,\n+        self.seq_lens_cpu = torch.empty(self.max_num_reqs,\n                                         dtype=torch.int32,\n                                         device=\"cpu\",\n                                         pin_memory=self.pin_memory)\n@@ -889,15 +889,13 @@ class GPUModelRunner(LoRAModelRunnerMixin):\n                 dst_start = mrope_pos_ptr\n                 dst_end = mrope_pos_ptr + completion_part_len\n \n-                self.mrope_positions_cpu[:, dst_start:dst_end] = \\\n-                    MRotaryEmbedding.get_next_input_positions_tensor(\n-                        req.mrope_position_delta,\n-                        context_len=num_computed_tokens +\n-                        prompt_part_len,\n-                        seq_len=num_computed_tokens +\n-                        prompt_part_len +\n-                        completion_part_len,\n-                    )\n+                MRotaryEmbedding.get_next_input_positions_tensor_out(\n+                    self.mrope_positions_cpu.numpy(),\n+                    dst_start,\n+                    req.mrope_position_delta,\n+                    context_len=num_computed_tokens + prompt_part_len,\n+                    num_new_tokens=completion_part_len,\n+                )\n \n                 mrope_pos_ptr += completion_part_len\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
