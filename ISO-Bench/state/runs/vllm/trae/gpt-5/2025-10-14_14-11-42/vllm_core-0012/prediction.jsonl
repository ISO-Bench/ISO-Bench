{"instance_id": "vllm-project__vllm-95baec8", "model_patch": "diff --git a/model_patch.diff b/model_patch.diff\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/vllm/core/block_manager_v1.py b/vllm/core/block_manager_v1.py\nindex b2aaeb33c..5f5396dae 100644\n--- a/vllm/core/block_manager_v1.py\n+++ b/vllm/core/block_manager_v1.py\n@@ -313,7 +313,8 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n \n         # Compute a new hash for the block so that it can be shared by other\n         # Sequences\n-        new_hash = seq.hash_of_block(len(seq.logical_token_blocks) - 1)\n+        last_logical_idx = len(seq.logical_token_blocks) - 1\n+        new_hash = seq.hash_of_block(last_logical_idx)\n \n         # if new_hash is already in the cached table, then free last_block\n         # and return the cached version\n@@ -328,7 +329,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         self,\n         seq: Sequence,\n     ) -> bool:\n-        token_ids_len = len(seq.data.get_token_ids())\n+        token_ids_len = seq.data.get_len()\n         return token_ids_len > 0 and token_ids_len % seq.block_size == 0\n \n     def _maybe_promote_last_block(\n@@ -353,10 +354,10 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         if not self.enable_caching:\n             return self.gpu_allocator.allocate()\n         block_hash: Optional[int] = None\n+        last_logical_idx = len(seq.logical_token_blocks) - 1\n         if (self._is_last_block_full(seq)):\n-            block_hash = seq.hash_of_block(len(seq.logical_token_blocks) - 1)\n-        num_hashed_tokens = seq.num_hashed_tokens_of_block(\n-            len(seq.logical_token_blocks) - 1)\n+            block_hash = seq.hash_of_block(last_logical_idx)\n+        num_hashed_tokens = seq.num_hashed_tokens_of_block(last_logical_idx)\n \n         # num_hashed_tokens is used to compute future hashes\n         # (e.g. in the hashing function, it is used to ask the sequence for\n@@ -377,16 +378,16 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         \"\"\"Allocate a physical slot for a new token.\"\"\"\n         logical_blocks = seq.logical_token_blocks\n         block_table = self.block_tables[seq.seq_id]\n+        lt = len(block_table)\n+        ll = len(logical_blocks)\n         # If we need to allocate a new physical block\n-        if len(block_table) < len(logical_blocks):\n+        if lt < ll:\n             # Currently this code only supports adding one physical block\n-            assert len(block_table) == len(logical_blocks) - 1\n+            assert lt == ll - 1\n \n-            if (self.block_sliding_window\n-                    and len(block_table) >= self.block_sliding_window):\n+            if self.block_sliding_window and lt >= self.block_sliding_window:\n                 # reuse a block\n-                block_table.append(block_table[len(block_table) %\n-                                               self.block_sliding_window])\n+                block_table.append(block_table[lt % self.block_sliding_window])\n             else:\n                 # The sequence has a new logical block.\n                 # Allocate a new physical block.\n@@ -567,11 +568,11 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n     def compute_full_blocks_in_seq(self, seq: Sequence):\n         if seq.seq_id not in self.block_tables:\n             return\n-        max_full_block = seq.get_len() // self.block_size - 1\n+        max_full_block = seq.data.get_len() // self.block_size - 1\n         block_table = self.block_tables[seq.seq_id]\n         if max_full_block == -1:\n             return\n-        for i in reversed(range(max_full_block)):\n+        for i in reversed(range(max_full_block + 1)):\n             if block_table[i].computed:\n                 break\n             block_table[i].computed = True\n@@ -583,10 +584,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n         # NOTE We exclude the last block to avoid the case where the entire\n         # prompt is cached. This would cause erroneous behavior in model\n         # runner.\n-        return [\n-            b.block_number\n-            for b in takewhile(lambda b: b.computed, block_table[:-1])\n-        ]\n+        return [b.block_number for b in takewhile(lambda b: b.computed, block_table[:-1])]\n \n     def get_common_computed_block_ids(self, seqs: List[Sequence]) -> List[int]:\n         \"\"\"Return the block ids that are common for a given sequence group.\n@@ -598,7 +596,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):\n             return []\n \n         ids_list = [self.get_all_computed_blocks(seq) for seq in seqs]\n-        return commonprefix([ids for ids in ids_list if ids != []])\n+        return commonprefix([ids for ids in ids_list if ids])\n \n     def mark_blocks_as_computed(self, seq_group: SequenceGroup):\n         if self.enable_caching:\n", "model_name_or_path": "gpt-5-2025-08-07"}
