{"instance_id": "vllm-project__vllm-6d917d0", "model_patch": "diff --git a/vllm/core/evictor.py b/vllm/core/evictor.py\nindex ed7e06cab..06d986cc3 100644\n--- a/vllm/core/evictor.py\n+++ b/vllm/core/evictor.py\n@@ -1,6 +1,7 @@\n import enum\n+import heapq\n from abc import ABC, abstractmethod\n-from typing import OrderedDict, Tuple\n+from typing import Dict, Tuple\n \n \n class EvictionPolicy(enum.Enum):\n@@ -60,6 +61,8 @@ class BlockMetaData:\n     blocks with the same content hash, but their physical id is unique.\n     \"\"\"\n \n+    __slots__ = (\"content_hash\", \"num_hashed_tokens\", \"last_accessed\")\n+\n     def __init__(self, content_hash: int, num_hashed_tokens: int,\n                  last_accessed: float):\n         self.content_hash = content_hash\n@@ -75,49 +78,75 @@ class LRUEvictor(Evictor):\n     highest num_hashed_tokens value, then one will be chose arbitrarily\n     \"\"\"\n \n+    # Limit how large the priority queue can grow compared to live entries\n+    CLEANUP_THRESHOLD = 50\n+\n     def __init__(self):\n-        self.free_table: OrderedDict[int, BlockMetaData] = OrderedDict()\n+        self.free_table: Dict[int, BlockMetaData] = {}\n+        # heap of tuples: (last_accessed, -num_hashed_tokens, block_id)\n+        self.priority_queue = []\n \n     def __contains__(self, block_id: int) -> bool:\n         return block_id in self.free_table\n \n+    def _maybe_cleanup(self):\n+        # Rebuild the heap if it has grown disproportionately due to lazy updates\n+        live = len(self.free_table)\n+        if live == 0:\n+            self.priority_queue.clear()\n+            return\n+        if len(self.priority_queue) <= max(live * self.CLEANUP_THRESHOLD, live + 16):\n+            return\n+        # Rebuild from scratch using current metadata\n+        self.priority_queue = [\n+            (meta.last_accessed, -meta.num_hashed_tokens, bid)\n+            for bid, meta in self.free_table.items()\n+        ]\n+        heapq.heapify(self.priority_queue)\n+\n     def evict(self) -> Tuple[int, int]:\n         if len(self.free_table) == 0:\n             raise ValueError(\"No usable cache memory left\")\n \n-        evicted_block, evicted_block_id = None, None\n-        # The blocks with the lowest timestamps should be placed consecutively\n-        # at the start of OrderedDict. Loop through all these blocks to\n-        # find the one with maximum number of hashed tokens.\n-        for _id, block in self.free_table.items():\n-            if evicted_block is None:\n-                evicted_block, evicted_block_id = block, _id\n+        # Pop until we find a live, up-to-date entry\n+        while True:\n+            last_accessed, neg_tokens, bid = heapq.heappop(self.priority_queue)\n+            meta = self.free_table.get(bid)\n+            if meta is None:\n+                # stale entry due to removal\n                 continue\n-            if evicted_block.last_accessed < block.last_accessed:\n-                break\n-            if evicted_block.num_hashed_tokens < block.num_hashed_tokens:\n-                evicted_block, evicted_block_id = block, _id\n-\n-        assert evicted_block is not None\n-        assert evicted_block_id is not None\n-        self.free_table.pop(evicted_block_id)\n-\n-        return evicted_block_id, evicted_block.content_hash\n+            if meta.last_accessed != last_accessed or meta.num_hashed_tokens != -neg_tokens:\n+                # stale entry due to update\n+                continue\n+            # Found the correct block to evict\n+            evicted = self.free_table.pop(bid)\n+            # Optional: opportunistically cleanup\n+            self._maybe_cleanup()\n+            return bid, evicted.content_hash\n \n     def add(self, block_id: int, content_hash: int, num_hashed_tokens: int,\n             last_accessed: float):\n-        self.free_table[block_id] = BlockMetaData(content_hash,\n-                                                  num_hashed_tokens,\n-                                                  last_accessed)\n+        meta = BlockMetaData(content_hash, num_hashed_tokens, last_accessed)\n+        self.free_table[block_id] = meta\n+        heapq.heappush(self.priority_queue,\n+                       (last_accessed, -num_hashed_tokens, block_id))\n+        self._maybe_cleanup()\n \n     def update(self, block_id: int, last_accessed: float):\n-        self.free_table[block_id].last_accessed = last_accessed\n+        meta = self.free_table[block_id]\n+        meta.last_accessed = last_accessed\n+        # push a new entry; stale one will be lazily ignored\n+        heapq.heappush(self.priority_queue,\n+                       (last_accessed, -meta.num_hashed_tokens, block_id))\n+        self._maybe_cleanup()\n \n     def remove(self, block_id: int):\n         if block_id not in self.free_table:\n             raise ValueError(\n                 \"Attempting to remove block that's not in the evictor\")\n+        # Lazy removal: delete from map; heap entry becomes stale\n         self.free_table.pop(block_id)\n+        self._maybe_cleanup()\n \n     @property\n     def num_blocks(self) -> int:\n", "model_name_or_path": "gpt-5-2025-08-07"}
