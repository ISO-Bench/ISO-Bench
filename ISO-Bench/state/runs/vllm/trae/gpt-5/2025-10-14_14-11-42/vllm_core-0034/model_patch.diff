diff --git a/model_patch.diff b/model_patch.diff
new file mode 100644
index 000000000..e69de29bb
diff --git a/tests/basic_correctness/test_chunked_prefill.py b/tests/basic_correctness/test_chunked_prefill.py
index fc6f829c3..4c5b579a8 100644
--- a/tests/basic_correctness/test_chunked_prefill.py
+++ b/tests/basic_correctness/test_chunked_prefill.py
@@ -117,6 +117,11 @@ def test_models_with_fp8_kv_cache(
             "#7378: CUDA illegal memory access (undiagnosed) facebook/opt-125m"
         )
 
+    if ((model, kv_cache_dtype, chunked_prefill_token_size) == (
+            "nm-testing/Qwen2-1.5B-Instruct-FP8-K-V", "fp8_e4m3", 4)):
+        pytest.skip("flakey test, see: #7874 #8051")
+
+
     max_num_seqs = chunked_prefill_token_size
     max_num_batched_tokens = chunked_prefill_token_size
 
diff --git a/vllm/core/scheduler.py b/vllm/core/scheduler.py
index 4c2f71582..bf55556ae 100644
--- a/vllm/core/scheduler.py
+++ b/vllm/core/scheduler.py
@@ -138,6 +138,17 @@ class SchedulerOutputs:
         # Swap in and swap out should never happen at the same time.
         assert not (self.blocks_to_swap_in and self.blocks_to_swap_out)
 
+        # Fast path when there are no scheduled groups to avoid set/dict work.
+        try:
+            is_empty = (len(self.scheduled_seq_groups) == 0)  # type: ignore[arg-type]
+        except TypeError:
+            # If scheduled_seq_groups is not sized (e.g., an iterator), skip fast path.
+            is_empty = False
+        if is_empty:
+            self.num_loras = 0
+            self.num_prompt_adapters = 0
+            return
+
         self.num_loras: int = len(self.lora_requests)
         if self.num_loras > 0:
             self._sort_by_lora_ids()
@@ -935,14 +946,15 @@ class Scheduler:
         # Update waiting requests.
         self.waiting.extendleft(running_scheduled.preempted)
         # Update new running requests.
-        if len(prefills.seq_groups) > 0:
-            self.running.extend([s.seq_group for s in prefills.seq_groups])
+        run_ext = self.running.extend
+        if prefills.seq_groups:
+            run_ext(s.seq_group for s in prefills.seq_groups)
 
-        self.running.extend(running_scheduled.decode_seq_groups_list)
+        if running_scheduled.decode_seq_groups_list:
+            run_ext(running_scheduled.decode_seq_groups_list)
 
-        if len(swapped_in.decode_seq_groups) > 0:
-            self.running.extend(
-                [s.seq_group for s in swapped_in.decode_seq_groups])
+        if swapped_in.decode_seq_groups:
+            run_ext(s.seq_group for s in swapped_in.decode_seq_groups)
 
         # Update swapped requests.
         self.swapped.extend(running_scheduled.swapped_out)
@@ -1028,33 +1040,57 @@ class Scheduler:
         # Update waiting requests.
         self.waiting.extendleft(running_scheduled.preempted)
         # Update new running requests.
-        self.running.extend([s.seq_group for s in prefills.seq_groups])
-        self.running.extend(
-            [s.seq_group for s in running_scheduled.decode_seq_groups])
-        self.running.extend(
-            [s.seq_group for s in running_scheduled.prefill_seq_groups])
-        self.running.extend(
-            [s.seq_group for s in swapped_in.decode_seq_groups])
-        self.running.extend(
-            [s.seq_group for s in swapped_in.prefill_seq_groups])
+        run_ext = self.running.extend
+        if prefills.seq_groups:
+            run_ext(s.seq_group for s in prefills.seq_groups)
+        if running_scheduled.decode_seq_groups_list:
+            run_ext(running_scheduled.decode_seq_groups_list)
+        if running_scheduled.prefill_seq_groups_list:
+            run_ext(running_scheduled.prefill_seq_groups_list)
+        if swapped_in.decode_seq_groups:
+            run_ext(s.seq_group for s in swapped_in.decode_seq_groups)
+        if swapped_in.prefill_seq_groups:
+            run_ext(s.seq_group for s in swapped_in.prefill_seq_groups)
         # Update swapped requests.
         self.swapped.extend(running_scheduled.swapped_out)
+        
+        # Build scheduled sequence groups with minimal intermediate allocations.
+        # Prioritize prefills over decodes.
+        scheduled_seq_groups = []
+        if prefills.seq_groups:
+            scheduled_seq_groups.extend(prefills.seq_groups)
+        if running_scheduled.prefill_seq_groups:
+            scheduled_seq_groups.extend(running_scheduled.prefill_seq_groups)
+        if swapped_in.prefill_seq_groups:
+            scheduled_seq_groups.extend(swapped_in.prefill_seq_groups)
+        if running_scheduled.decode_seq_groups:
+            scheduled_seq_groups.extend(running_scheduled.decode_seq_groups)
+        if swapped_in.decode_seq_groups:
+            scheduled_seq_groups.extend(swapped_in.decode_seq_groups)
+
+        num_prefill_groups = (
+            len(prefills.seq_groups)
+            + len(swapped_in.prefill_seq_groups)
+            + len(running_scheduled.prefill_seq_groups)
+        )
+
+        # Avoid '+' which creates a new list; reuse and extend instead.
+        blocks_to_copy = list(running_scheduled.blocks_to_copy)
+        if swapped_in.blocks_to_copy:
+            blocks_to_copy.extend(swapped_in.blocks_to_copy)
+
+        ignored_seq_groups = list(prefills.ignored_seq_groups)
+        if swapped_in.infeasible_seq_groups:
+            ignored_seq_groups.extend(swapped_in.infeasible_seq_groups)
+
         return SchedulerOutputs(
-            scheduled_seq_groups=(prefills.seq_groups +
-                                  running_scheduled.prefill_seq_groups +
-                                  swapped_in.prefill_seq_groups +
-                                  running_scheduled.decode_seq_groups +
-                                  swapped_in.decode_seq_groups),
-            num_prefill_groups=(len(prefills.seq_groups) +
-                                len(swapped_in.prefill_seq_groups) +
-                                len(running_scheduled.prefill_seq_groups)),
+            scheduled_seq_groups=scheduled_seq_groups,
+            num_prefill_groups=num_prefill_groups,
             num_batched_tokens=budget.num_batched_tokens,
             blocks_to_swap_in=swapped_in.blocks_to_swap_in,
             blocks_to_swap_out=running_scheduled.blocks_to_swap_out,
-            blocks_to_copy=running_scheduled.blocks_to_copy +
-            swapped_in.blocks_to_copy,
-            ignored_seq_groups=prefills.ignored_seq_groups +
-            swapped_in.infeasible_seq_groups,
+            blocks_to_copy=blocks_to_copy,
+            ignored_seq_groups=ignored_seq_groups,
             num_lookahead_slots=running_scheduled.num_lookahead_slots,
             running_queue_size=len(self.running),
             preempted=(len(running_scheduled.preempted) +
