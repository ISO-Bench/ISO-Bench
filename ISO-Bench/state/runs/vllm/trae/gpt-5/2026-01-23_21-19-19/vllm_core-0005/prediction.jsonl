{"instance_id": "vllm-project__vllm-cc466a3", "model_patch": "diff --git a/vllm/model_executor/layers/sampler.py b/vllm/model_executor/layers/sampler.py\nindex 5bd37ec..a4c7358 100644\n--- a/vllm/model_executor/layers/sampler.py\n+++ b/vllm/model_executor/layers/sampler.py\n@@ -250,7 +250,7 @@ def _apply_top_k_top_p(\n         k_max = int(k_rows.max().item())\n         # Select the subset of rows and compute topk over columns\n         sub_logits = logits.index_select(0, rows_topk)\n-        topk_vals, topk_idx = torch.topk(sub_logits, k_max, dim=-1, largest=True)\n+        topk_vals, topk_idx = torch.topk(sub_logits, k_max, dim=-1, largest=True, sorted=True)\n \n         # Mask out columns beyond each row's own k\n         col_idx = torch.arange(k_max, device=device).unsqueeze(0).expand_as(topk_vals)\n", "model_name_or_path": "gpt-5-2025-08-07"}
