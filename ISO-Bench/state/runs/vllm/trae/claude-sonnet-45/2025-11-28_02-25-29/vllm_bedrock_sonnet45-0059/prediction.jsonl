{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-e642ec9", "model_patch": "diff --git a/vllm/attention/backends/mla/common.py b/vllm/attention/backends/mla/common.py\nindex 8184b0732..109e8496f 100644\n--- a/vllm/attention/backends/mla/common.py\n+++ b/vllm/attention/backends/mla/common.py\n@@ -1308,7 +1308,7 @@ class MLACommonImpl(MLAAttentionImpl[T], Generic[T]):\n             )\n \n             kv_c_normed = workspace[:toks]\\\n-                [..., :self.kv_lora_rank].unsqueeze(1)\n+                [..., :self.kv_lora_rank]\n             k_pe = workspace[:toks]\\\n                 [..., self.kv_lora_rank:].unsqueeze(1)\n \ndiff --git a/vllm/v1/attention/backends/mla/common.py b/vllm/v1/attention/backends/mla/common.py\nindex c98262eea..0b55854de 100644\n--- a/vllm/v1/attention/backends/mla/common.py\n+++ b/vllm/v1/attention/backends/mla/common.py\n@@ -874,7 +874,7 @@ class MLACommonImpl(MLAAttentionImpl[M], Generic[M]):\n             )\n \n             kv_c_normed = workspace[:toks]\\\n-                [..., :self.kv_lora_rank].unsqueeze(1)\n+                [..., :self.kv_lora_rank]\n             k_pe = workspace[:toks]\\\n                 [..., self.kv_lora_rank:].unsqueeze(1)\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
