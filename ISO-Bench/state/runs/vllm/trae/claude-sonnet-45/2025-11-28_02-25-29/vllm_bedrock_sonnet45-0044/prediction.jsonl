{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-084a01f", "model_patch": "diff --git a/vllm/model_executor/layers/sampler.py b/vllm/model_executor/layers/sampler.py\nindex 5c376797a..121458f81 100644\n--- a/vllm/model_executor/layers/sampler.py\n+++ b/vllm/model_executor/layers/sampler.py\n@@ -220,7 +220,7 @@ def _apply_min_tokens_penalty(\n             seqs_to_penalize: List[int] = []\n             for j, seq_id in enumerate(seq_ids):\n                 seq_data = seq_group.seq_data[seq_id]\n-                if len(seq_data.output_token_ids) < min_tokens:\n+                if len(seq_data.output_token_ids_array) < min_tokens:\n                     seqs_to_penalize.append(j)\n \n             if seqs_to_penalize:\ndiff --git a/vllm/model_executor/sampling_metadata.py b/vllm/model_executor/sampling_metadata.py\nindex 390b5d173..b2683d66a 100644\n--- a/vllm/model_executor/sampling_metadata.py\n+++ b/vllm/model_executor/sampling_metadata.py\n@@ -1,4 +1,5 @@\n import random\n+from array import array\n from dataclasses import dataclass\n from typing import Dict, List, Optional, Tuple\n \n@@ -329,8 +330,8 @@ class SamplingTensors:\n             user-defined seed for each sequence.\n         extra_entropy: extra entropy to use when generating seeds.\n         \"\"\"\n-        prompt_tokens: List[List[int]] = []\n-        output_tokens: List[List[int]] = []\n+        prompt_tokens: List[array] = []\n+        output_tokens: List[array] = []\n         top_ks: List[int] = []\n         temperatures: List[float] = []\n         top_ps: List[float] = []\n@@ -432,13 +433,13 @@ class SamplingTensors:\n                 if (seq_group.is_prompt\n                         and sampling_params.prompt_logprobs is not None):\n                     prefill_len = len(seq_group.prompt_logprob_indices)\n-                    prompt_tokens.extend([] for _ in range(prefill_len))\n-                    output_tokens.extend([] for _ in range(prefill_len))\n+                    prompt_tokens.extend(array('i') for _ in range(prefill_len))\n+                    output_tokens.extend(array('i') for _ in range(prefill_len))\n                 if seq_group.do_sample:\n                     for seq_id in seq_ids:\n                         seq_data = seq_group.seq_data[seq_id]\n-                        prompt_tokens.append(list(seq_data.prompt_token_ids))\n-                        output_tokens.append(list(seq_data.output_token_ids))\n+                        prompt_tokens.append(array('i', seq_data.prompt_token_ids))\n+                        output_tokens.append(seq_data.output_token_ids_array)\n \n         sampling_tensors = SamplingTensors.from_lists(\n             temperatures, top_ps, top_ks, min_ps, presence_penalties,\n@@ -454,8 +455,8 @@ class SamplingTensors:\n                    frequency_penalties: List[float],\n                    repetition_penalties: List[float],\n                    sampling_seeds: List[int], sample_indices: List[int],\n-                   prompt_tokens: List[List[int]],\n-                   output_tokens: List[List[int]], vocab_size: int,\n+                   prompt_tokens: List[array],\n+                   output_tokens: List[array], vocab_size: int,\n                    extra_seeds_to_generate: int, device: torch.device,\n                    dtype: torch.dtype) -> \"SamplingTensors\":\n         # Note that the performance will be very bad without\ndiff --git a/vllm/sequence.py b/vllm/sequence.py\nindex 0cd4c7e71..def0e269b 100644\n--- a/vllm/sequence.py\n+++ b/vllm/sequence.py\n@@ -3,6 +3,7 @@ import copy\n import enum\n import math\n from abc import ABC, abstractmethod\n+from array import array\n from collections import defaultdict\n from dataclasses import dataclass, field\n from typing import (TYPE_CHECKING, Dict, List, Mapping, Optional, Set, Tuple,\n@@ -154,6 +155,11 @@ class SequenceData:\n         self._output_token_ids = list(new_output_token_ids)\n         self._update_cached_all_tokens()\n \n+    @property\n+    def output_token_ids_array(self) -> array:\n+        \"\"\"Return output token IDs as an array for efficient operations.\"\"\"\n+        return array('i', self._output_token_ids)\n+\n     def append_token_id(self, token_id: int, logprob: float) -> None:\n         self._output_token_ids.append(token_id)\n         self._cached_all_token_ids.append(token_id)\n", "model_name_or_path": "gpt-5-2025-08-07"}
