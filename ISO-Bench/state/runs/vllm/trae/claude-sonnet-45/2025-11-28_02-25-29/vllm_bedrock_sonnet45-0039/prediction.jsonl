{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-51e971d", "model_patch": "diff --git a/vllm/sequence.py b/vllm/sequence.py\nindex 13746cef2..22cb26dc0 100644\n--- a/vllm/sequence.py\n+++ b/vllm/sequence.py\n@@ -39,24 +39,21 @@ PromptLogprobs = List[Optional[Dict[int, Logprob]]]\n SampleLogprobs = List[Dict[int, Logprob]]\n \n \n-class SequenceStatus(enum.Enum):\n+class SequenceStatus(enum.IntEnum):\n     \"\"\"Status of a sequence.\"\"\"\n-    WAITING = enum.auto()\n-    RUNNING = enum.auto()\n-    SWAPPED = enum.auto()\n-    FINISHED_STOPPED = enum.auto()\n-    FINISHED_LENGTH_CAPPED = enum.auto()\n-    FINISHED_ABORTED = enum.auto()\n-    FINISHED_IGNORED = enum.auto()\n+    WAITING = 0\n+    RUNNING = 1\n+    SWAPPED = 2\n+    # Note: anything after SWAPPED (2) will be considered\n+    # as a finished status.\n+    FINISHED_STOPPED = 3\n+    FINISHED_LENGTH_CAPPED = 4\n+    FINISHED_ABORTED = 5\n+    FINISHED_IGNORED = 6\n \n     @staticmethod\n     def is_finished(status: \"SequenceStatus\") -> bool:\n-        return status in [\n-            SequenceStatus.FINISHED_STOPPED,\n-            SequenceStatus.FINISHED_LENGTH_CAPPED,\n-            SequenceStatus.FINISHED_ABORTED,\n-            SequenceStatus.FINISHED_IGNORED,\n-        ]\n+        return status > SequenceStatus.SWAPPED\n \n     @staticmethod\n     def get_finished_reason(status: \"SequenceStatus\") -> Union[str, None]:\n", "model_name_or_path": "gpt-5-2025-08-07"}
