diff --git a/vllm/model_executor/layers/rotary_embedding.py b/vllm/model_executor/layers/rotary_embedding.py
index 9de233896..9a42d494c 100644
--- a/vllm/model_executor/layers/rotary_embedding.py
+++ b/vllm/model_executor/layers/rotary_embedding.py
@@ -26,6 +26,7 @@
 import math
 from typing import Any, Optional, Union
 
+import numpy as np
 import torch
 import torch.nn as nn
 from transformers import PretrainedConfig
@@ -1459,14 +1460,30 @@ class MRotaryEmbedding(RotaryEmbedding):
 
     @staticmethod
     def get_next_input_positions_tensor(
+        out: np.ndarray,
+        out_offset: int,
         mrope_position_delta: int,
         context_len: int,
-        seq_len: int,
-    ) -> torch.Tensor:
-        return torch.arange(
+        num_new_tokens: int,
+    ) -> None:
+        """Fill output buffer with MRoPE position IDs.
+        
+        Args:
+            out: Output buffer of shape (3, total_tokens)
+            out_offset: Offset in output buffer to start writing
+            mrope_position_delta: Delta value for MRoPE positions
+            context_len: Context length
+            num_new_tokens: Number of new tokens to generate positions for
+        """
+        values = np.arange(
             mrope_position_delta + context_len,
-            mrope_position_delta + seq_len,
-        ).expand(3, -1)
+            mrope_position_delta + context_len + num_new_tokens,
+            dtype=out.dtype,
+        )
+        # Broadcast to all 3 dimensions
+        out[0, out_offset:out_offset + num_new_tokens] = values
+        out[1, out_offset:out_offset + num_new_tokens] = values
+        out[2, out_offset:out_offset + num_new_tokens] = values
 
     @classmethod
     def omni_get_updates_use_audio_in_video(
