{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-56fe4c2", "model_patch": "diff --git a/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py b/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py\nindex 3ff162170..82c4683ca 100644\n--- a/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py\n+++ b/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py\n@@ -128,7 +128,8 @@ def triton_scaled_mm(input: torch.Tensor,\n                      bias: Optional[torch.Tensor] = None,\n                      block_size_m: int = 32,\n                      block_size_n: int = 32,\n-                     block_size_k: int = 32) -> torch.Tensor:\n+                     block_size_k: int = 32,\n+                     use_heuristic: bool = True) -> torch.Tensor:\n     M, K = input.shape\n     N = weight.shape[1]\n \n@@ -145,6 +146,19 @@ def triton_scaled_mm(input: torch.Tensor,\n     assert is_weak_contiguous(input)\n     assert is_weak_contiguous(weight)\n \n+    # Apply heuristic for block size selection if enabled\n+    if use_heuristic:\n+        is_small_N = N < 8192\n+        next_power_of_2_M = max(32, triton.next_power_of_2(M))\n+        if next_power_of_2_M <= 32:\n+            block_size_m, block_size_n, block_size_k = (64, 64, 256) if is_small_N else (64, 128, 256)\n+        elif next_power_of_2_M <= 64:\n+            block_size_m, block_size_n, block_size_k = (64, 64, 256)\n+        elif next_power_of_2_M <= 128:\n+            block_size_m, block_size_n, block_size_k = (64, 128, 128)\n+        else:\n+            block_size_m, block_size_n, block_size_k = (128, 128, 128)\n+\n     grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(\n         N, META['BLOCK_SIZE_N']), )\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
