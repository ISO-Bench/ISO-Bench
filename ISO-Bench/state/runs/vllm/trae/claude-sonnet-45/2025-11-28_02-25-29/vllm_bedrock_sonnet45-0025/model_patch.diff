diff --git a/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py b/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py
index 3ff162170..82c4683ca 100644
--- a/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py
+++ b/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py
@@ -128,7 +128,8 @@ def triton_scaled_mm(input: torch.Tensor,
                      bias: Optional[torch.Tensor] = None,
                      block_size_m: int = 32,
                      block_size_n: int = 32,
-                     block_size_k: int = 32) -> torch.Tensor:
+                     block_size_k: int = 32,
+                     use_heuristic: bool = True) -> torch.Tensor:
     M, K = input.shape
     N = weight.shape[1]
 
@@ -145,6 +146,19 @@ def triton_scaled_mm(input: torch.Tensor,
     assert is_weak_contiguous(input)
     assert is_weak_contiguous(weight)
 
+    # Apply heuristic for block size selection if enabled
+    if use_heuristic:
+        is_small_N = N < 8192
+        next_power_of_2_M = max(32, triton.next_power_of_2(M))
+        if next_power_of_2_M <= 32:
+            block_size_m, block_size_n, block_size_k = (64, 64, 256) if is_small_N else (64, 128, 256)
+        elif next_power_of_2_M <= 64:
+            block_size_m, block_size_n, block_size_k = (64, 64, 256)
+        elif next_power_of_2_M <= 128:
+            block_size_m, block_size_n, block_size_k = (64, 128, 128)
+        else:
+            block_size_m, block_size_n, block_size_k = (128, 128, 128)
+
     grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(
         N, META['BLOCK_SIZE_N']), )
 
