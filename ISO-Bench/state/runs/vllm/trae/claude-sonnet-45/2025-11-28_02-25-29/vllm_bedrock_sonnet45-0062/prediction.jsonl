{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-3d92516", "model_patch": "diff --git a/tests/core/test_scheduler.py b/tests/core/test_scheduler.py\nindex 9588a1bea..a25112385 100644\n--- a/tests/core/test_scheduler.py\n+++ b/tests/core/test_scheduler.py\n@@ -540,7 +540,7 @@ def test_decode_schedule_preempted():\n     curr_loras = None\n     for i in range(3):\n         _, seq_group = create_dummy_prompt(str(i), prompt_length=60)\n-        scheduler._allocate_and_set_running(seq_group, 60)\n+        scheduler._allocate_and_set_running(seq_group)\n         append_new_token_seq_group(60, seq_group, 1)\n         running.append(seq_group)\n     scheduler.block_manager.can_append_slots = MagicMock()\n@@ -581,7 +581,7 @@ def test_decode_swap_beam_search():\n     budget = create_token_budget()\n     for i in range(3):\n         _, seq_group = create_dummy_prompt(str(i), prompt_length=60, best_of=2)\n-        scheduler._allocate_and_set_running(seq_group, 60)\n+        scheduler._allocate_and_set_running(seq_group)\n         running.append(seq_group)\n         append_new_token_seq_group(60, seq_group, 1)\n         budget.add_num_seqs(seq_group.request_id,\n@@ -629,7 +629,7 @@ def test_schedule_decode_blocks_to_copy_update():\n     running = deque()\n     policy = PolicyFactory.get_policy(policy_name=\"fcfs\")\n     curr_loras = None\n-    scheduler._allocate_and_set_running(seq_group, 60)\n+    scheduler._allocate_and_set_running(seq_group)\n     append_new_token_seq_group(60, seq_group, 1)\n     running.append(seq_group)\n \n@@ -659,7 +659,7 @@ def test_schedule_swapped_simple():\n     curr_loras = None\n     blocks_to_swap_out = {}\n     _, seq_group = create_dummy_prompt(\"1\", prompt_length=60, best_of=2)\n-    scheduler._allocate_and_set_running(seq_group, 60)\n+    scheduler._allocate_and_set_running(seq_group)\n     append_new_token_seq_group(60, seq_group, 1)\n     scheduler._swap_out(seq_group, blocks_to_swap_out)\n     swapped.append(seq_group)\n@@ -687,7 +687,7 @@ def test_schedule_swapped_max_token_budget():\n     blocks_to_swap_out = {}\n     for _ in range(2):\n         _, seq_group = create_dummy_prompt(\"1\", prompt_length=60, best_of=2)\n-        scheduler._allocate_and_set_running(seq_group, 60)\n+        scheduler._allocate_and_set_running(seq_group)\n         append_new_token_seq_group(60, seq_group, 1)\n         scheduler._swap_out(seq_group, blocks_to_swap_out)\n         swapped.append(seq_group)\n@@ -721,7 +721,7 @@ def test_schedule_swapped_max_seqs():\n     blocks_to_swap_out = {}\n     for i in range(4):\n         _, seq_group = create_dummy_prompt(str(i), prompt_length=60)\n-        scheduler._allocate_and_set_running(seq_group, 60)\n+        scheduler._allocate_and_set_running(seq_group)\n         append_new_token_seq_group(60, seq_group, 1)\n         scheduler._swap_out(seq_group, blocks_to_swap_out)\n         swapped.append(seq_group)\n@@ -759,7 +759,7 @@ def test_schedule_swapped_max_loras():\n                                                lora_name=str(i),\n                                                lora_int_id=i + 1,\n                                                lora_local_path=\"abc\"))\n-        scheduler._allocate_and_set_running(seq_group, 60)\n+        scheduler._allocate_and_set_running(seq_group)\n         append_new_token_seq_group(60, seq_group, 1)\n         scheduler._swap_out(seq_group, blocks_to_swap_out)\n         swapped.append(seq_group)\n@@ -783,7 +783,7 @@ def test_schedule_swapped_cannot_swap_in():\n     blocks_to_swap_out = {}\n     for _ in range(2):\n         _, seq_group = create_dummy_prompt(\"1\", prompt_length=60, best_of=2)\n-        scheduler._allocate_and_set_running(seq_group, 60)\n+        scheduler._allocate_and_set_running(seq_group)\n         append_new_token_seq_group(60, seq_group, 1)\n         scheduler._swap_out(seq_group, blocks_to_swap_out)\n         swapped.append(seq_group)\n@@ -808,7 +808,7 @@ def test_schedule_swapped_blocks_to_copy():\n     policy = PolicyFactory.get_policy(policy_name=\"fcfs\")\n     curr_loras = None\n     _, seq_group = create_dummy_prompt(\"1\", prompt_length=60, best_of=2)\n-    scheduler._allocate_and_set_running(seq_group, 60)\n+    scheduler._allocate_and_set_running(seq_group)\n     append_new_token_seq_group(60, seq_group, 1)\n     blocks_to_swap_out = {}\n     scheduler._swap_out(seq_group, blocks_to_swap_out)\ndiff --git a/vllm/core/scheduler.py b/vllm/core/scheduler.py\nindex 419855062..0b0ebcdb3 100644\n--- a/vllm/core/scheduler.py\n+++ b/vllm/core/scheduler.py\n@@ -659,7 +659,7 @@ class Scheduler:\n             if curr_loras is not None and lora_int_id > 0:\n                 curr_loras.add(lora_int_id)\n             waiting_queue.popleft()\n-            self._allocate_and_set_running(seq_group, num_new_tokens)\n+            self._allocate_and_set_running(seq_group)\n             seq_groups.append(\n                 ScheduledSequenceGroup(seq_group=seq_group,\n                                        token_chunk_size=num_new_tokens))\n@@ -952,8 +952,7 @@ class Scheduler:\n         self.running = deque(seq_group for seq_group in self.running\n                              if not seq_group.is_finished())\n \n-    def _allocate_and_set_running(self, seq_group: SequenceGroup,\n-                                  num_new_tokens: int) -> None:\n+    def _allocate_and_set_running(self, seq_group: SequenceGroup) -> None:\n         self.block_manager.allocate(seq_group)\n         for seq in seq_group.get_seqs(status=SequenceStatus.WAITING):\n             seq.status = SequenceStatus.RUNNING\n", "model_name_or_path": "gpt-5-2025-08-07"}
