{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-d666466", "model_patch": "diff --git a/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py b/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py\nindex 7016ff34c..0210488c7 100644\n--- a/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py\n+++ b/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py\n@@ -144,12 +144,13 @@ class DeepEPHTPrepareAndFinalize(mk.FusedMoEPrepareAndFinalize):\n                 \"apply_router_weight_on_input is only implemented for topk=1\")\n             a1 = a1 * topk_weights.to(a1.dtype)\n \n-        if quant_config.per_act_token_quant:\n+        if quant_config.is_block_quantized:\n+            # Quant and Dispatch\n             a1q, a1q_scale = moe_kernel_quantize_input(\n                 a1,\n                 a1_scale,\n                 quant_dtype=quant_config.quant_dtype,\n-                per_act_token_quant=True,\n+                per_act_token_quant=quant_config.per_act_token_quant,\n                 block_shape=quant_config.block_shape,\n             )\n             if a1q_scale is not None and a1q_scale.numel() == 1:\n@@ -162,8 +163,10 @@ class DeepEPHTPrepareAndFinalize(mk.FusedMoEPrepareAndFinalize):\n                  rank_topk_weights=topk_weights,\n                  num_experts=num_experts)\n         else:\n-            # DeepEP kernels only support dispatching per-token-quant\n-            # quantization. dispatch in bfloat16.\n+            # Dispatch and Quant\n+            # DeepEP kernels only support dispatching block-quantized\n+            # activation scales.\n+            # Dispatch in bfloat16\n             (expert_x, _, expert_tokens_meta, expert_topk_ids,\n              expert_topk_weights) = self._do_dispatch(\n                  tokens=a1,\n@@ -178,7 +181,7 @@ class DeepEPHTPrepareAndFinalize(mk.FusedMoEPrepareAndFinalize):\n                     expert_x,\n                     a1_scale,\n                     quant_dtype=quant_config.quant_dtype,\n-                    per_act_token_quant=False,\n+                    per_act_token_quant=quant_config.per_act_token_quant,\n                     block_shape=quant_config.block_shape)\n \n         return (expert_x, expert_x_scale, expert_tokens_meta, expert_topk_ids,\n", "model_name_or_path": "gpt-5-2025-08-07"}
