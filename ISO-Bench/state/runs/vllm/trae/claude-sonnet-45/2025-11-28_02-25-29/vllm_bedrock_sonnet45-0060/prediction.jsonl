{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-bc8a8ce", "model_patch": "diff --git a/vllm/v1/sample/logits_processor.py b/vllm/v1/sample/logits_processor.py\nindex 3a4c25964..108b32f08 100644\n--- a/vllm/v1/sample/logits_processor.py\n+++ b/vllm/v1/sample/logits_processor.py\n@@ -270,10 +270,10 @@ class MinPLogitsProcessor(LogitsProcessor):\n \n         if self.min_p_count:\n             # Process removed requests.\n-            needs_update |= bool(batch_update.removed)\n             for index in batch_update.removed:\n                 if self.min_p_cpu[index]:\n                     self.min_p_count -= 1\n+                    needs_update = True\n \n             # Process moved requests, unidirectional (a->b) and swap (a<->b)\n             for adx, bdx, direct in batch_update.moved:\n@@ -335,14 +335,19 @@ class LogitBiasLogitsProcessor(LogitsProcessor):\n         if not batch_update:\n             return\n \n+        needs_update: bool = False\n         # Process added requests.\n-        needs_update = bool(batch_update.added)\n         for index, params, _ in batch_update.added:\n             if isinstance(params, SamplingParams) and (lb :=\n                                                        params.logit_bias):\n                 self.biases[index] = lb\n+                needs_update = True\n             else:\n-                self.biases.pop(index, None)\n+                # Drop biases metadata at batch index\n+                if self.biases.pop(index, None) is not None:\n+                    # If a new request replaces an old request which\n+                    # specified biases, we should update processor tensors\n+                    needs_update = True\n \n         if self.biases:\n             # Process removed requests.\n@@ -419,7 +424,6 @@ class MinTokensLogitsProcessor(LogitsProcessor):\n \n         if batch_update:\n             # Process added requests.\n-            needs_update |= bool(batch_update.added)\n             for index, params, output_tok_ids in batch_update.added:\n                 if (isinstance(params, SamplingParams)\n                         and (min_tokens := params.min_tokens)\n@@ -427,9 +431,13 @@ class MinTokensLogitsProcessor(LogitsProcessor):\n                     # Replace request metadata at batch index\n                     self.min_toks[index] = (min_tokens, output_tok_ids,\n                                             params.all_stop_token_ids)\n+                    needs_update = True\n                 else:\n                     # Drop request metadata at batch index\n-                    self.min_toks.pop(index, None)\n+                    if self.min_toks.pop(index, None) is not None:\n+                        # If a new request replaces an old request which\n+                        # specified min_tokens, we should update processor tensors\n+                        needs_update = True\n \n             if self.min_toks:\n                 # Process removed requests.\n", "model_name_or_path": "gpt-5-2025-08-07"}
