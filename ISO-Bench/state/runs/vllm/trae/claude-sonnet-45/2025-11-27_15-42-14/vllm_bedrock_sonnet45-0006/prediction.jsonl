{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-b0e96aa", "model_patch": "diff --git a/vllm/utils.py b/vllm/utils.py\nindex 79787303a..3fc22790d 100644\n--- a/vllm/utils.py\n+++ b/vllm/utils.py\n@@ -287,13 +287,17 @@ class LRUCache(Generic[_K, _V]):\n             return\n \n         if not remove_pinned:\n-            # pop the oldest item in the cache that is not pinned\n-            lru_key = next(\n-                (key for key in self.cache if key not in self.pinned_items),\n-                ALL_PINNED_SENTINEL)\n-            if lru_key is ALL_PINNED_SENTINEL:\n-                raise RuntimeError(\"All items are pinned, \"\n-                                   \"cannot remove oldest from the cache.\")\n+            # Fast path: if no items are pinned, just get the first item\n+            if not self.pinned_items:\n+                lru_key = next(iter(self.cache))\n+            else:\n+                # pop the oldest item in the cache that is not pinned\n+                lru_key = next(\n+                    (key for key in self.cache if key not in self.pinned_items),\n+                    ALL_PINNED_SENTINEL)\n+                if lru_key is ALL_PINNED_SENTINEL:\n+                    raise RuntimeError(\"All items are pinned, \"\n+                                       \"cannot remove oldest from the cache.\")\n         else:\n             lru_key = next(iter(self.cache))\n         self.pop(lru_key)  # type: ignore\n@@ -327,15 +331,12 @@ class PyObjectCache:\n         self._obj_builder = obj_builder\n         self._index = 0\n \n-        self._obj_cache = []\n-        for _ in range(128):\n-            self._obj_cache.append(self._obj_builder())\n+        self._obj_cache = [self._obj_builder() for _ in range(128)]\n \n     def _grow_cache(self):\n         # Double the size of the cache\n         num_objs = len(self._obj_cache)\n-        for _ in range(num_objs):\n-            self._obj_cache.append(self._obj_builder())\n+        self._obj_cache.extend(self._obj_builder() for _ in range(num_objs))\n \n     def get_object(self):\n         \"\"\"Returns a pre-allocated cached object. If there is not enough\n@@ -411,6 +412,11 @@ async def merge_async_iterators(\n     When it yields, it yields a tuple (i, item) where i is the index of the\n     iterator that yields the item.\n     \"\"\"\n+    if len(iterators) == 1:\n+        # Fast-path single iterator case.\n+        async for item in iterators[0]:\n+            yield 0, item\n+        return\n \n     loop = asyncio.get_running_loop()\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
