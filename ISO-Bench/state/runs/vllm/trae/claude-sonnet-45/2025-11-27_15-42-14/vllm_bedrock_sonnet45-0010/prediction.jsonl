{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-f728ab8", "model_patch": "diff --git a/vllm/model_executor/layers/utils.py b/vllm/model_executor/layers/utils.py\nindex a9ef97391..5053bb657 100644\n--- a/vllm/model_executor/layers/utils.py\n+++ b/vllm/model_executor/layers/utils.py\n@@ -47,10 +47,15 @@ def apply_penalties(logits: torch.Tensor, prompt_tokens_tensor: torch.Tensor,\n         output_tokens_tensor, vocab_size, num_seqs)\n     repetition_penalties = repetition_penalties.unsqueeze(dim=1).repeat(\n         1, vocab_size)\n-    logits[logits > 0] /= torch.where(prompt_mask | output_mask,\n-                                      repetition_penalties, 1.0)[logits > 0]\n-    logits[logits <= 0] *= torch.where(prompt_mask | output_mask,\n-                                       repetition_penalties, 1.0)[logits <= 0]\n+    \n+    # If token appears in prompt or output, apply penalty, otherwise use 1.0 for no-op.\n+    penalties = torch.where(prompt_mask | output_mask, repetition_penalties,\n+                            1.0)\n+    \n+    # If logits are positive, divide by penalty, otherwise multiply by penalty.\n+    scaling = torch.where(logits > 0, 1.0 / penalties, penalties)\n+    logits *= scaling\n+    \n     # We follow the definition in OpenAI API.\n     # Refer to https://platform.openai.com/docs/api-reference/parameter-details\n     logits -= frequency_penalties.unsqueeze(dim=1) * output_bin_counts\n", "model_name_or_path": "gpt-5-2025-08-07"}
