{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-f728ab8", "model_patch": "diff --git a/vllm/model_executor/layers/utils.py b/vllm/model_executor/layers/utils.py\nindex a9ef973..a56dad3 100644\n--- a/vllm/model_executor/layers/utils.py\n+++ b/vllm/model_executor/layers/utils.py\n@@ -45,14 +45,32 @@ def apply_penalties(logits: torch.Tensor, prompt_tokens_tensor: torch.Tensor,\n                                                    vocab_size, num_seqs)\n     output_bin_counts, output_mask = get_token_bin_counts_and_mask(\n         output_tokens_tensor, vocab_size, num_seqs)\n-    repetition_penalties = repetition_penalties.unsqueeze(dim=1).repeat(\n-        1, vocab_size)\n-    logits[logits > 0] /= torch.where(prompt_mask | output_mask,\n-                                      repetition_penalties, 1.0)[logits > 0]\n-    logits[logits <= 0] *= torch.where(prompt_mask | output_mask,\n-                                       repetition_penalties, 1.0)[logits <= 0]\n+    \n+    # Compute combined mask once to avoid redundant OR operations\n+    combined_mask = prompt_mask | output_mask\n+    \n+    # Use unsqueezed version for broadcasting (avoids .repeat memory allocation)\n+    repetition_penalties_unsq = repetition_penalties.unsqueeze(dim=1)\n+    \n+    # Compute positive mask once\n+    positive_mask = logits > 0\n+    \n+    # Apply penalties only where combined_mask is True\n+    # This avoids creating large intermediate tensors with torch.where\n+    penalty_mask_pos = combined_mask & positive_mask\n+    penalty_mask_neg = combined_mask & ~positive_mask\n+    \n+    # Apply repetition penalties using broadcasting (avoids .repeat memory allocation)\n+    # Use expand instead of expand_as for slightly better performance\n+    rep_pen_expanded = repetition_penalties_unsq.expand(num_seqs, vocab_size)\n+    logits[penalty_mask_pos] /= rep_pen_expanded[penalty_mask_pos]\n+    logits[penalty_mask_neg] *= rep_pen_expanded[penalty_mask_neg]\n+    \n     # We follow the definition in OpenAI API.\n     # Refer to https://platform.openai.com/docs/api-reference/parameter-details\n-    logits -= frequency_penalties.unsqueeze(dim=1) * output_bin_counts\n-    logits -= presence_penalties.unsqueeze(dim=1) * output_mask\n+    # Use in-place operations and cache unsqueeze for better performance\n+    frequency_penalties_unsq = frequency_penalties.unsqueeze(dim=1)\n+    presence_penalties_unsq = presence_penalties.unsqueeze(dim=1)\n+    logits -= frequency_penalties_unsq * output_bin_counts\n+    logits -= presence_penalties_unsq * output_mask\n     return logits\n", "model_name_or_path": "gpt-5-2025-08-07"}
