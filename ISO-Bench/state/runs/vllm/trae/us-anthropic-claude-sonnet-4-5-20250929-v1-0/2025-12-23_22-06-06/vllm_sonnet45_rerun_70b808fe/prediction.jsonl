{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-63d635d", "model_patch": "diff --git a/vllm/model_executor/models/qwen2_5_vl.py b/vllm/model_executor/models/qwen2_5_vl.py\nindex ef3d28c..8901caf 100644\n--- a/vllm/model_executor/models/qwen2_5_vl.py\n+++ b/vllm/model_executor/models/qwen2_5_vl.py\n@@ -540,8 +540,9 @@ class Qwen2_5_VisionTransformer(nn.Module):\n     def rot_pos_emb(self, grid_thw: torch.Tensor) -> torch.Tensor:\n         pos_ids = []\n         for t, h, w in grid_thw:\n-            hpos_ids = torch.arange(h).unsqueeze(1).expand(-1, w)\n-            wpos_ids = torch.arange(w).unsqueeze(0).expand(h, -1)\n+            # Optimize: Specify device to avoid potential device transfers\n+            hpos_ids = torch.arange(h, device=grid_thw.device).unsqueeze(1).expand(-1, w)\n+            wpos_ids = torch.arange(w, device=grid_thw.device).unsqueeze(0).expand(h, -1)\n             hpos_ids = hpos_ids.reshape(\n                 h // self.spatial_merge_size,\n                 self.spatial_merge_size,\n@@ -554,8 +555,11 @@ class Qwen2_5_VisionTransformer(nn.Module):\n                 w // self.spatial_merge_size,\n                 self.spatial_merge_size,\n             ).permute(0, 2, 1, 3).flatten()\n-            pos_ids.append(\n-                torch.stack([hpos_ids, wpos_ids], dim=-1).repeat(t, 1))\n+            # Optimize: Avoid unnecessary repeat when t == 1\n+            stacked = torch.stack([hpos_ids, wpos_ids], dim=-1)\n+            if t > 1:\n+                stacked = stacked.repeat(t, 1)\n+            pos_ids.append(stacked)\n         pos_ids = torch.cat(pos_ids, dim=0)\n         max_grid_size = grid_thw[:, 1:].max()\n         rotary_pos_emb_full = self.rotary_pos_emb(max_grid_size)\n@@ -572,7 +576,9 @@ class Qwen2_5_VisionTransformer(nn.Module):\n         for grid_t, grid_h, grid_w in grid_thw:\n             llm_grid_h = grid_h // self.spatial_merge_size\n             llm_grid_w = grid_w // self.spatial_merge_size\n-            index = torch.arange(grid_t * llm_grid_h * llm_grid_w).reshape(\n+            # Optimize: Create index tensor directly on the correct device\n+            total_size = grid_t * llm_grid_h * llm_grid_w\n+            index = torch.arange(total_size, device=grid_thw.device).reshape(\n                 grid_t, llm_grid_h, llm_grid_w)\n             pad_h = vit_merger_window_size - llm_grid_h % vit_merger_window_size\n             pad_w = vit_merger_window_size - llm_grid_w % vit_merger_window_size\n@@ -586,14 +592,16 @@ class Qwen2_5_VisionTransformer(nn.Module):\n             index_padded = index_padded.permute(0, 1, 3, 2, 4).reshape(\n                 grid_t, num_windows_h * num_windows_w, vit_merger_window_size,\n                 vit_merger_window_size)\n-            seqlens = (index_padded != -100).sum([2, 3]).reshape(-1)\n+            # Optimize: Compute mask once and reuse\n+            mask = index_padded != -100\n+            seqlens = mask.sum([2, 3]).reshape(-1)\n             index_padded = index_padded.reshape(-1)\n-            index_new = index_padded[index_padded != -100]\n+            index_new = index_padded[mask.reshape(-1)]\n             window_index.append(index_new + window_index_id)\n             cu_seqlens_tmp = seqlens.cumsum(\n                 0) * self.spatial_merge_unit + cu_window_seqlens[-1]\n             cu_window_seqlens.extend(cu_seqlens_tmp.tolist())\n-            window_index_id += (grid_t * llm_grid_h * llm_grid_w).item()\n+            window_index_id += total_size\n         window_index = torch.cat(window_index, dim=0)\n         return window_index, cu_window_seqlens\n \n@@ -611,6 +619,7 @@ class Qwen2_5_VisionTransformer(nn.Module):\n \n         # windows attention\n         window_index, cu_window_seqlens = self.get_window_index(grid_thw)\n+        # Optimize: Create tensor directly on the correct device\n         cu_window_seqlens = torch.tensor(\n             cu_window_seqlens,\n             device=hidden_states.device,\ndiff --git a/vllm/model_executor/models/qwen2_vl.py b/vllm/model_executor/models/qwen2_vl.py\nindex ac3d154..5ea7251 100644\n--- a/vllm/model_executor/models/qwen2_vl.py\n+++ b/vllm/model_executor/models/qwen2_vl.py\n@@ -195,9 +195,11 @@ class Qwen2VisionMLP(nn.Module):\n \n def rotate_half(x: torch.Tensor, interleaved: bool = False) -> torch.Tensor:\n     if not interleaved:\n+        # Optimize: Use chunk which is more efficient than manual slicing\n         x1, x2 = x.chunk(2, dim=-1)\n         return torch.cat((-x2, x1), dim=-1)\n     else:\n+        # Optimize: Direct slicing and stacking\n         x1, x2 = x[..., ::2], x[..., 1::2]\n         return rearrange(torch.stack((-x2, x1), dim=-1),\n                          \"... d two -> ... (d two)\",\n@@ -582,8 +584,9 @@ class Qwen2VisionTransformer(nn.Module):\n     def rot_pos_emb(self, grid_thw: torch.Tensor) -> torch.Tensor:\n         pos_ids = []\n         for t, h, w in grid_thw:\n-            hpos_ids = torch.arange(h).unsqueeze(1).expand(-1, w)\n-            wpos_ids = torch.arange(w).unsqueeze(0).expand(h, -1)\n+            # Optimize: Specify device to avoid potential device transfers\n+            hpos_ids = torch.arange(h, device=grid_thw.device).unsqueeze(1).expand(-1, w)\n+            wpos_ids = torch.arange(w, device=grid_thw.device).unsqueeze(0).expand(h, -1)\n             hpos_ids = hpos_ids.reshape(\n                 h // self.spatial_merge_size,\n                 self.spatial_merge_size,\n@@ -596,8 +599,11 @@ class Qwen2VisionTransformer(nn.Module):\n                 w // self.spatial_merge_size,\n                 self.spatial_merge_size,\n             ).permute(0, 2, 1, 3).flatten()\n-            pos_ids.append(\n-                torch.stack([hpos_ids, wpos_ids], dim=-1).repeat(t, 1))\n+            # Optimize: Avoid unnecessary repeat when t == 1\n+            stacked = torch.stack([hpos_ids, wpos_ids], dim=-1)\n+            if t > 1:\n+                stacked = stacked.repeat(t, 1)\n+            pos_ids.append(stacked)\n         pos_ids = torch.cat(pos_ids, dim=0)\n         max_grid_size = grid_thw[:, 1:].max()\n         rotary_pos_emb_full = self.rotary_pos_emb(max_grid_size)\n", "model_name_or_path": "gpt-5-2025-08-07"}
