{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-5c04bb8", "model_patch": "diff --git a/vllm/model_executor/models/qwen2_5_vl.py b/vllm/model_executor/models/qwen2_5_vl.py\nindex 5904ad1..fb61a8f 100644\n--- a/vllm/model_executor/models/qwen2_5_vl.py\n+++ b/vllm/model_executor/models/qwen2_5_vl.py\n@@ -198,7 +198,7 @@ class Qwen2_5_VisionMLP(nn.Module):\n def all_gather_interleave(local_tensor, hidden_size: int, tp_size: int):\n     \"\"\"All-gather the input tensor interleavely across model parallel group.\"\"\"\n     import torch.distributed as dist\n-    gathered_tensors = [torch.zeros_like(local_tensor) for _ in range(tp_size)]\n+    gathered_tensors = [torch.empty_like(local_tensor) for _ in range(tp_size)]\n     dist.all_gather(gathered_tensors,\n                     local_tensor,\n                     group=parallel_state.get_tp_group().device_group)\n@@ -569,9 +569,10 @@ class Qwen2_5_VisionTransformer(nn.Module):\n \n     def rot_pos_emb(self, grid_thw: torch.Tensor) -> torch.Tensor:\n         pos_ids = []\n+        device = grid_thw.device\n         for t, h, w in grid_thw:\n-            hpos_ids = torch.arange(h).unsqueeze(1).expand(-1, w)\n-            wpos_ids = torch.arange(w).unsqueeze(0).expand(h, -1)\n+            hpos_ids = torch.arange(h, dtype=torch.long, device=device).unsqueeze(1).expand(-1, w)\n+            wpos_ids = torch.arange(w, dtype=torch.long, device=device).unsqueeze(0).expand(h, -1)\n             hpos_ids = hpos_ids.reshape(\n                 h // self.spatial_merge_size,\n                 self.spatial_merge_size,\n@@ -598,11 +599,12 @@ class Qwen2_5_VisionTransformer(nn.Module):\n         window_index_id = 0\n         vit_merger_window_size = (self.window_size //\n                                   self.spatial_merge_size // self.patch_size)\n+        device = grid_thw.device\n \n         for grid_t, grid_h, grid_w in grid_thw:\n             llm_grid_h = grid_h // self.spatial_merge_size\n             llm_grid_w = grid_w // self.spatial_merge_size\n-            index = torch.arange(grid_t * llm_grid_h * llm_grid_w).reshape(\n+            index = torch.arange(grid_t * llm_grid_h * llm_grid_w, dtype=torch.long, device=device).reshape(\n                 grid_t, llm_grid_h, llm_grid_w)\n             pad_h = vit_merger_window_size - llm_grid_h % vit_merger_window_size\n             pad_w = vit_merger_window_size - llm_grid_w % vit_merger_window_size\n", "model_name_or_path": "gpt-5-2025-08-07"}
