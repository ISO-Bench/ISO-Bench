diff --git a/vllm/model_executor/models/qwen2_5_vl.py b/vllm/model_executor/models/qwen2_5_vl.py
index 5904ad1..fb61a8f 100644
--- a/vllm/model_executor/models/qwen2_5_vl.py
+++ b/vllm/model_executor/models/qwen2_5_vl.py
@@ -198,7 +198,7 @@ class Qwen2_5_VisionMLP(nn.Module):
 def all_gather_interleave(local_tensor, hidden_size: int, tp_size: int):
     """All-gather the input tensor interleavely across model parallel group."""
     import torch.distributed as dist
-    gathered_tensors = [torch.zeros_like(local_tensor) for _ in range(tp_size)]
+    gathered_tensors = [torch.empty_like(local_tensor) for _ in range(tp_size)]
     dist.all_gather(gathered_tensors,
                     local_tensor,
                     group=parallel_state.get_tp_group().device_group)
@@ -569,9 +569,10 @@ class Qwen2_5_VisionTransformer(nn.Module):
 
     def rot_pos_emb(self, grid_thw: torch.Tensor) -> torch.Tensor:
         pos_ids = []
+        device = grid_thw.device
         for t, h, w in grid_thw:
-            hpos_ids = torch.arange(h).unsqueeze(1).expand(-1, w)
-            wpos_ids = torch.arange(w).unsqueeze(0).expand(h, -1)
+            hpos_ids = torch.arange(h, dtype=torch.long, device=device).unsqueeze(1).expand(-1, w)
+            wpos_ids = torch.arange(w, dtype=torch.long, device=device).unsqueeze(0).expand(h, -1)
             hpos_ids = hpos_ids.reshape(
                 h // self.spatial_merge_size,
                 self.spatial_merge_size,
@@ -598,11 +599,12 @@ class Qwen2_5_VisionTransformer(nn.Module):
         window_index_id = 0
         vit_merger_window_size = (self.window_size //
                                   self.spatial_merge_size // self.patch_size)
+        device = grid_thw.device
 
         for grid_t, grid_h, grid_w in grid_thw:
             llm_grid_h = grid_h // self.spatial_merge_size
             llm_grid_w = grid_w // self.spatial_merge_size
-            index = torch.arange(grid_t * llm_grid_h * llm_grid_w).reshape(
+            index = torch.arange(grid_t * llm_grid_h * llm_grid_w, dtype=torch.long, device=device).reshape(
                 grid_t, llm_grid_h, llm_grid_w)
             pad_h = vit_merger_window_size - llm_grid_h % vit_merger_window_size
             pad_w = vit_merger_window_size - llm_grid_w % vit_merger_window_size
