{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-51e971d", "model_patch": "diff --git a/vllm/sequence.py b/vllm/sequence.py\nindex 13746ce..0cc2783 100644\n--- a/vllm/sequence.py\n+++ b/vllm/sequence.py\n@@ -51,12 +51,13 @@ class SequenceStatus(enum.Enum):\n \n     @staticmethod\n     def is_finished(status: \"SequenceStatus\") -> bool:\n-        return status in [\n+        # Optimize: Use tuple for O(1) lookup instead of creating list each time\n+        return status in (\n             SequenceStatus.FINISHED_STOPPED,\n             SequenceStatus.FINISHED_LENGTH_CAPPED,\n             SequenceStatus.FINISHED_ABORTED,\n             SequenceStatus.FINISHED_IGNORED,\n-        ]\n+        )\n \n     @staticmethod\n     def get_finished_reason(status: \"SequenceStatus\") -> Union[str, None]:\n@@ -525,8 +526,9 @@ class SequenceGroup:\n                 seq.data.update_num_computed_tokens(num_new_computed_tokens)\n \n     def get_num_uncomputed_tokens(self) -> int:\n+        # Optimize: Iterate directly over dict values instead of creating a list\n         num_uncomputed_tokens = 0\n-        for seq in self.get_seqs():\n+        for seq in self.seqs_dict.values():\n             if not seq.is_finished():\n                 num_uncomputed_tokens += seq.data.get_num_uncomputed_tokens()\n         return num_uncomputed_tokens\n@@ -540,10 +542,12 @@ class SequenceGroup:\n         return len(self.get_seqs(status))\n \n     def num_unfinished_seqs(self) -> int:\n-        return len(self.get_unfinished_seqs())\n+        # Optimize: Count directly instead of creating a list\n+        return sum(1 for seq in self.seqs_dict.values() if not seq.is_finished())\n \n     def num_finished_seqs(self) -> int:\n-        return len(self.get_finished_seqs())\n+        # Optimize: Count directly instead of creating a list\n+        return sum(1 for seq in self.seqs_dict.values() if seq.is_finished())\n \n     def find(self, seq_id: int) -> Sequence:\n         if seq_id not in self.seqs_dict:\n@@ -561,11 +565,13 @@ class SequenceGroup:\n         del self.seqs_dict[seq_id]\n \n     def is_finished(self) -> bool:\n-        return all(seq.is_finished() for seq in self.get_seqs())\n+        # Optimize: Iterate directly over dict values instead of creating a list\n+        return all(seq.is_finished() for seq in self.seqs_dict.values())\n \n     def is_prefill(self) -> bool:\n         # Every sequence should be in the same stage.\n-        return self.get_seqs()[0].is_prefill()\n+        # Optimize: Get first value directly without creating a list\n+        return next(iter(self.seqs_dict.values())).is_prefill()\n \n     def __repr__(self) -> str:\n         return (f\"SequenceGroup(request_id={self.request_id}, \"\n@@ -857,7 +863,9 @@ class HiddenStates:\n         seq_ids = get_all_seq_ids(seq_group_metadata_list)\n         if seq_ids != self.seq_ids:\n             # Batch contents changed - prune removed sequences.\n-            index = [self.seq_ids.index(seq_id) for seq_id in seq_ids]\n+            # Optimize: Use dict lookup instead of list.index() for O(n) instead of O(n\u00b2)\n+            seq_id_to_index = {seq_id: idx for idx, seq_id in enumerate(self.seq_ids)}\n+            index = [seq_id_to_index[seq_id] for seq_id in seq_ids]\n             self.hidden_states = self.hidden_states[index]\n             self.seq_ids = seq_ids\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
