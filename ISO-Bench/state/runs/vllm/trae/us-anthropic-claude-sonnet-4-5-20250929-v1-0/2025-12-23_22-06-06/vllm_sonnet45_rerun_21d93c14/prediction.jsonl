{"instance_id": "/home/ubuntu/OmniPerf-Bench/vllm__repo-f1c8520", "model_patch": "diff --git a/vllm/model_executor/models/mixtral.py b/vllm/model_executor/models/mixtral.py\nindex 8e0a094..5b126a8 100644\n--- a/vllm/model_executor/models/mixtral.py\n+++ b/vllm/model_executor/models/mixtral.py\n@@ -243,10 +243,9 @@ class BlockSparseMoE(nn.Module):\n         column_indices_t = row_indices.gather(0, gather_indices.long())\n         block_offsets_t = gather_indices.int()\n \n-        zero = torch.zeros((1, ), dtype=torch.int32, device=row_indices.device)\n         nnz_per_column = ops.histogram(column_indices, block_columns)\n         nnz_per_column = ops.inclusive_cumsum(nnz_per_column, 0)\n-        offsets_t = torch.cat([zero, nnz_per_column])\n+        offsets_t = F.pad(nnz_per_column, (1, 0), value=0)\n         return column_indices_t, offsets_t, block_offsets_t\n \n     def topology(self, x: torch.Tensor,\n", "model_name_or_path": "gpt-5-2025-08-07"}
