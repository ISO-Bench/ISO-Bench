diff --git a/vllm/core/block_manager_v1.py b/vllm/core/block_manager_v1.py
index 622aca6..995841c 100644
--- a/vllm/core/block_manager_v1.py
+++ b/vllm/core/block_manager_v1.py
@@ -671,7 +671,7 @@ class BlockSpaceManagerV1(BlockSpaceManager):
         block_table = self.block_tables[seq.seq_id]
         if max_full_block == -1:
             return
-        for i in reversed(range(max_full_block)):
+        for i in range(max_full_block - 1, -1, -1):
             if block_table[i].computed:
                 break
             block_table[i].computed = True
diff --git a/vllm/sequence.py b/vllm/sequence.py
index ba477ef..f8572a2 100644
--- a/vllm/sequence.py
+++ b/vllm/sequence.py
@@ -129,6 +129,8 @@ class SequenceData:
         # The number of tokens that are computed (that run against the model).
         self._num_computed_tokens = 0
         self._stage: SequenceStage = SequenceStage.PREFILL
+        # Cache the total length to avoid recomputing it
+        self._cached_len = len(self._prompt_token_ids) + len(self._output_token_ids)
 
         self._update_cached_all_tokens()
 
@@ -144,6 +146,7 @@ class SequenceData:
     def prompt_token_ids(self, new_prompt_token_ids) -> None:
         self._prompt_token_ids = array('l', new_prompt_token_ids)
         self._prompt_token_ids_tuple = tuple(new_prompt_token_ids)
+        self._cached_len = len(self._prompt_token_ids) + len(self._output_token_ids)
         self._update_cached_all_tokens()
 
     @property
@@ -157,6 +160,7 @@ class SequenceData:
     @output_token_ids.setter
     def output_token_ids(self, new_output_token_ids) -> None:
         self._output_token_ids = array('l', new_output_token_ids)
+        self._cached_len = len(self._prompt_token_ids) + len(self._output_token_ids)
         self._update_cached_all_tokens()
 
     @property
@@ -167,9 +171,10 @@ class SequenceData:
         self._output_token_ids.append(token_id)
         self._cached_all_token_ids.append(token_id)
         self.cumulative_logprob += logprob
+        self._cached_len += 1
 
     def get_len(self) -> int:
-        return len(self._output_token_ids) + len(self._prompt_token_ids)
+        return self._cached_len
 
     def get_prompt_len(self) -> int:
         return len(self._prompt_token_ids)
