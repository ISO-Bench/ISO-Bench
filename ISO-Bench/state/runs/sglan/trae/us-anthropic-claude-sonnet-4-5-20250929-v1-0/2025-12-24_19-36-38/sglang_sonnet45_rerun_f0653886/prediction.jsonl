{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-b146555", "model_patch": "diff --git a/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py b/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\nindex 4d165db..2336b52 100644\n--- a/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\n+++ b/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\n@@ -260,11 +260,12 @@ class _DeepEPDispatcherImplNormal(_DeepEPDispatcherImplBase):\n                 reorder_topk_ids = torch.empty(\n                     (0,), device=hidden_states.device, dtype=torch.int64\n                 )\n-                seg_indptr = torch.zeros(\n+                seg_indptr = torch.empty(\n                     (self.num_experts + 1,),\n                     device=hidden_states.device,\n                     dtype=torch.int64,\n                 )\n+                seg_indptr.fill_(0)\n \n             masked_m = expected_m = None\n             return (\n@@ -400,7 +401,7 @@ class _DeepEPDispatcherImplNormal(_DeepEPDispatcherImplBase):\n                     BLOCK_SIZE=512,\n                 )\n             else:\n-                output = torch.zeros(\n+                output = torch.empty(\n                     (0, hidden_states.shape[1]),\n                     device=hidden_states.device,\n                     dtype=hidden_states.dtype,\n", "model_name_or_path": "gpt-5-2025-08-07"}
