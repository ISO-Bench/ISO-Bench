{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-4c60523", "model_patch": "diff --git a/python/sglang/srt/mem_cache/allocator.py b/python/sglang/srt/mem_cache/allocator.py\nindex 7dd488e..5d08b23 100644\n--- a/python/sglang/srt/mem_cache/allocator.py\n+++ b/python/sglang/srt/mem_cache/allocator.py\n@@ -175,7 +175,7 @@ class SWATokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n             device,\n             kvcache.swa_kv_pool,\n         )\n-        self.full_to_swa_index_mapping = torch.empty(\n+        self.full_to_swa_index_mapping = torch.zeros(\n             size + size_swa + 1,\n             dtype=torch.int64,\n             device=device,\n@@ -411,6 +411,8 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n         self.num_pages = size // page_size\n         self.debug_mode = get_bool_env_var(\"SGLANG_DEBUG_MEMORY_POOL\")\n         self.ret_values = torch.empty((), dtype=torch.int64, device=self.device)\n+        # Cache page offset tensor to avoid recreating it in alloc()\n+        self._page_offsets = torch.arange(self.page_size, device=self.device)\n         self.clear()\n \n     def alloc(self, need_size: int):\n@@ -429,7 +431,7 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n \n         out_indices = (\n             out_pages[:, None] * self.page_size\n-            + torch.arange(self.page_size, device=self.device)\n+            + self._page_offsets\n         ).reshape(-1)\n \n         return out_indices\n@@ -541,6 +543,7 @@ def alloc_extend_kernel_ascend(\n     out_indices,\n     page_size,\n     device,\n+    pos_in_page=None,\n ):\n     extend_lens = seq_lens - prefix_lens\n     end_pos = torch.cumsum(extend_lens, 0)\n@@ -554,7 +557,8 @@ def alloc_extend_kernel_ascend(\n     need_page = num_new_pages - num_full_new_pages\n     end_new_pages = torch.cumsum(num_new_pages, 0)\n     start_new_pages = end_new_pages - num_new_pages\n-    pos_in_page = torch.arange(page_size, device=device, dtype=torch.int32)\n+    if pos_in_page is None:\n+        pos_in_page = torch.arange(page_size, device=device, dtype=torch.int32)\n     for i in range(len(prefix_lens)):\n         num1 = (\n             min(\n@@ -620,6 +624,8 @@ class AscendPagedTokenToKVPoolAllocator(PagedTokenToKVPoolAllocator):\n     ):\n         super().__init__(size, page_size, dtype, device, kvcache)\n         self.ret_values = torch.empty((), dtype=torch.int32, device=self.device)\n+        # Cache int32 version of page offsets for Ascend\n+        self._page_offsets_int32 = self._page_offsets.to(torch.int32)\n \n     def alloc_extend(\n         self,\n@@ -646,6 +652,7 @@ class AscendPagedTokenToKVPoolAllocator(PagedTokenToKVPoolAllocator):\n             out_indices,\n             self.page_size,\n             self.device,\n+            self._page_offsets_int32,\n         )\n \n         if self.debug_mode:\n", "model_name_or_path": "gpt-5-2025-08-07"}
