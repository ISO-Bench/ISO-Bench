{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-30643fe", "model_patch": "diff --git a/python/sglang/srt/constrained/__init__.py b/python/sglang/srt/constrained/__init__.py\nindex c47c5c8..0a5af23 100644\n--- a/python/sglang/srt/constrained/__init__.py\n+++ b/python/sglang/srt/constrained/__init__.py\n@@ -42,12 +42,14 @@ except ImportError:\n     def build_regex_from_object(\n         object: Union[str, BaseModel, Dict], whitespace_pattern: Optional[str] = None\n     ):\n-        if isinstance(object, type(BaseModel)):\n-            schema = json.dumps(object.model_json_schema())\n-        elif isinstance(object, Dict):\n+        # Optimization: Check for string first (most common case) and use inspect.isclass\n+        if isinstance(object, str):\n+            schema = object\n+        elif isinstance(object, dict):\n             schema = json.dumps(object)\n         else:\n-            schema = object\n+            # Must be a BaseModel class\n+            schema = json.dumps(object.model_json_schema())\n         return build_regex_from_schema(schema, whitespace_pattern)\n \n \ndiff --git a/python/sglang/srt/managers/schedule_batch.py b/python/sglang/srt/managers/schedule_batch.py\nindex fcd06d8..645e909 100644\n--- a/python/sglang/srt/managers/schedule_batch.py\n+++ b/python/sglang/srt/managers/schedule_batch.py\n@@ -30,6 +30,7 @@ ScheduleBatch -> ModelWorkerBatch -> ForwardBatch\n \"\"\"\n \n import dataclasses\n+import itertools\n import logging\n from typing import List, Optional, Tuple, Union\n \n@@ -579,7 +580,8 @@ class ScheduleBatch:\n             pt += req.extend_input_len\n \n         # Reassign\n-        self.input_ids = torch.tensor(sum(input_ids, []), dtype=torch.int32).to(\n+        # Optimization: Use itertools.chain instead of sum(list, []) for better performance\n+        self.input_ids = torch.tensor(list(itertools.chain.from_iterable(input_ids)), dtype=torch.int32).to(\n             self.device, non_blocking=True\n         )\n         self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32).to(\n@@ -650,7 +652,8 @@ class ScheduleBatch:\n             pt += req.extend_input_len\n \n         # Set fields\n-        self.input_ids = torch.tensor(sum(input_ids, []), dtype=torch.int32).to(\n+        # Optimization: Use itertools.chain instead of sum(list, []) for better performance\n+        self.input_ids = torch.tensor(list(itertools.chain.from_iterable(input_ids)), dtype=torch.int32).to(\n             self.device, non_blocking=True\n         )\n         self.req_pool_indices = torch.tensor(req_pool_indices, dtype=torch.int32).to(\ndiff --git a/python/sglang/srt/sampling/sampling_batch_info.py b/python/sglang/srt/sampling/sampling_batch_info.py\nindex 27a2d07..f673dc2 100644\n--- a/python/sglang/srt/sampling/sampling_batch_info.py\n+++ b/python/sglang/srt/sampling/sampling_batch_info.py\n@@ -141,7 +141,8 @@ class SamplingBatchInfo:\n             self.vocab_mask = None\n             return\n \n-        self.vocab_mask = torch.zeros(\n+        # Optimization: Use torch.ones directly instead of torch.zeros + fill_(1)\n+        self.vocab_mask = torch.ones(\n             len(self.temperatures),\n             self.vocab_size,\n             dtype=torch.bool,\n@@ -149,7 +150,6 @@ class SamplingBatchInfo:\n         )\n         for i, regex_fsm in enumerate(self.regex_fsms):\n             if regex_fsm is not None:\n-                self.vocab_mask[i].fill_(1)\n                 self.vocab_mask[i][\n                     regex_fsm.get_next_instruction(self.regex_fsm_states[i]).tokens\n                 ] = 0\n@@ -185,11 +185,11 @@ class SamplingBatchInfo:\n                 shape, dtype = lhs.shape[1:], lhs.dtype\n             else:\n                 shape, dtype = rhs.shape[1:], rhs.dtype\n-            with torch.dtype(dtype):\n-                if lhs is None:\n-                    lhs = torch.empty((bs1, *shape), device=device).fill_(default)\n-                if rhs is None:\n-                    rhs = torch.empty((bs2, *shape), device=device).fill_(default)\n+            # Optimization: Use torch.full for default value initialization\n+            if lhs is None:\n+                lhs = torch.full((bs1, *shape), default, dtype=dtype, device=device)\n+            if rhs is None:\n+                rhs = torch.full((bs2, *shape), default, dtype=dtype, device=device)\n             return torch.cat([lhs, rhs])\n \n         return None\n", "model_name_or_path": "gpt-5-2025-08-07"}
