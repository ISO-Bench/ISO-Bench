{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-6252ade", "model_patch": "diff --git a/python/sglang/srt/layers/attention/triton_ops/extend_attention.py b/python/sglang/srt/layers/attention/triton_ops/extend_attention.py\nindex 608f9ba..4e754f8 100644\n--- a/python/sglang/srt/layers/attention/triton_ops/extend_attention.py\n+++ b/python/sglang/srt/layers/attention/triton_ops/extend_attention.py\n@@ -93,15 +93,19 @@ def _fwd_kernel(\n     offs_d = tl.arange(0, BLOCK_DMODEL)\n     offs_dv = tl.arange(0, BLOCK_DV)\n     offs_m = tl.arange(0, BLOCK_M)\n-    mask_m = (cur_block_m * BLOCK_M + offs_m) < cur_seq_len_extend\n+    # Optimization: Pre-compute block offset\n+    cur_block_m_offs = cur_block_m * BLOCK_M\n+    mask_m = (cur_block_m_offs + offs_m) < cur_seq_len_extend\n \n     mask_d = offs_d < Lq\n     mask_dv = offs_dv < Lv\n \n+    # Optimization: Pre-compute head offset for q\n+    q_head_offset = cur_head * stride_qh\n     offs_q = (\n-        (cur_seq_extend_start_idx + cur_block_m * BLOCK_M + offs_m[:, None])\n+        (cur_seq_extend_start_idx + cur_block_m_offs + offs_m[:, None])\n         * stride_qbs\n-        + cur_head * stride_qh\n+        + q_head_offset\n         + offs_d[None, :]\n     )\n     q = tl.load(\n@@ -111,9 +115,9 @@ def _fwd_kernel(\n     if BLOCK_DPE > 0:\n         offs_dpe = BLOCK_DMODEL + tl.arange(0, BLOCK_DPE)\n         offs_qpe = (\n-            (cur_seq_extend_start_idx + cur_block_m * BLOCK_M + offs_m[:, None])\n+            (cur_seq_extend_start_idx + cur_block_m_offs + offs_m[:, None])\n             * stride_qbs\n-            + cur_head * stride_qh\n+            + q_head_offset\n             + offs_dpe[None, :]\n         )\n         qpe = tl.load(Q_Extend + offs_qpe, mask=mask_m[:, None], other=0.0)\n@@ -121,9 +125,15 @@ def _fwd_kernel(\n     # stage 1: compute scores with prefix\n     offs_n = tl.arange(0, BLOCK_N)\n \n+    # Optimization: Initialize accumulators more efficiently\n     acc = tl.zeros([BLOCK_M, BLOCK_DV], dtype=tl.float32)\n     deno = tl.zeros([BLOCK_M], dtype=tl.float32)\n-    e_max = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\n+    # Directly set e_max to -inf without creating zeros first\n+    e_max = tl.full([BLOCK_M], value=float(\"-inf\"), dtype=tl.float32)\n+\n+    # Optimization: Pre-compute head offsets to avoid redundant computation in loops\n+    kv_head_offset_k = cur_kv_head * stride_buf_kh\n+    kv_head_offset_v = cur_kv_head * stride_buf_vh\n \n     for start_n in range(0, cur_seq_len_prefix, BLOCK_N):\n         start_n = tl.multiple_of(start_n, BLOCK_N)\n@@ -135,7 +145,7 @@ def _fwd_kernel(\n         # load k in transposed way\n         offs_buf_k = (\n             offs_kv_loc[None, :] * stride_buf_kbs\n-            + cur_kv_head * stride_buf_kh\n+            + kv_head_offset_k\n             + offs_d[:, None]\n         )\n         k = tl.load(\n@@ -146,7 +156,7 @@ def _fwd_kernel(\n         if BLOCK_DPE > 0:\n             offs_kpe = (\n                 offs_kv_loc[None, :] * stride_buf_kbs\n-                + cur_kv_head * stride_buf_kh\n+                + kv_head_offset_k\n                 + offs_dpe[:, None]\n             )\n             kpe = tl.load(\n@@ -164,7 +174,7 @@ def _fwd_kernel(\n             custom_mask = tl.load(\n                 mask_ptr\n                 + cur_seq_mask_start_idx\n-                + (cur_block_m * BLOCK_M + offs_m[:, None]) * cur_seq_len\n+                + (cur_block_m_offs + offs_m[:, None]) * cur_seq_len\n                 + start_n\n                 + offs_n[None, :],\n                 mask=(mask_m[:, None] & mask_n[None, :]),\n@@ -182,7 +192,7 @@ def _fwd_kernel(\n \n         offs_buf_v = (\n             offs_kv_loc[:, None] * stride_buf_vbs\n-            + cur_kv_head * stride_buf_vh\n+            + kv_head_offset_v\n             + offs_dv[None, :]\n         )\n         v = tl.load(\n@@ -194,6 +204,9 @@ def _fwd_kernel(\n         e_max = n_e_max\n \n     # stage 2: compute the triangle part\n+    # Optimization: Pre-compute head offsets for extend stage\n+    kv_head_offset_k_extend = cur_kv_head * stride_kh\n+    kv_head_offset_v_extend = cur_kv_head * stride_vh\n \n     cur_block_m_end = tl.minimum(cur_seq_len_extend, (cur_block_m + 1) * BLOCK_M)\n     for start_n in range(0, cur_block_m_end, BLOCK_N):\n@@ -203,7 +216,7 @@ def _fwd_kernel(\n         # load k in transposed way\n         offs_k = (\n             (cur_seq_extend_start_idx + start_n + offs_n[None, :]) * stride_kbs\n-            + cur_kv_head * stride_kh\n+            + kv_head_offset_k_extend\n             + offs_d[:, None]\n         )\n         k = tl.load(\n@@ -214,7 +227,7 @@ def _fwd_kernel(\n         if BLOCK_DPE > 0:\n             offs_kpe = (\n                 (cur_seq_extend_start_idx + start_n + offs_n[None, :]) * stride_kbs\n-                + cur_kv_head * stride_kh\n+                + kv_head_offset_k_extend\n                 + offs_dpe[:, None]\n             )\n             kpe = tl.load(\n@@ -233,7 +246,7 @@ def _fwd_kernel(\n             custom_mask = tl.load(\n                 mask_ptr\n                 + cur_seq_mask_start_idx\n-                + (cur_block_m * BLOCK_M + offs_m[:, None]) * cur_seq_len\n+                + (cur_block_m_offs + offs_m[:, None]) * cur_seq_len\n                 + cur_seq_len_prefix\n                 + start_n\n                 + offs_n[None, :],\n@@ -243,7 +256,7 @@ def _fwd_kernel(\n             custom_mask &= mask_m[:, None] & mask_n[None, :]\n             qk = tl.where(custom_mask, qk, float(\"-inf\"))\n         else:\n-            mask_causual = (cur_block_m * BLOCK_M + offs_m[:, None]) >= (\n+            mask_causual = (cur_block_m_offs + offs_m[:, None]) >= (\n                 start_n + offs_n[None, :]\n             )\n             mask_causual &= mask_m[:, None] & mask_n[None, :]\n@@ -256,7 +269,7 @@ def _fwd_kernel(\n \n         offs_v = (\n             (cur_seq_extend_start_idx + start_n + offs_n[:, None]) * stride_vbs\n-            + cur_kv_head * stride_vh\n+            + kv_head_offset_v_extend\n             + offs_dv[None, :]\n         )\n         v = tl.load(\n@@ -267,10 +280,12 @@ def _fwd_kernel(\n \n         e_max = n_e_max\n \n+    # Optimization: Pre-compute output head offset\n+    o_head_offset = cur_head * stride_oh\n     offs_o = (\n-        (cur_seq_extend_start_idx + cur_block_m * BLOCK_M + offs_m[:, None])\n+        (cur_seq_extend_start_idx + cur_block_m_offs + offs_m[:, None])\n         * stride_obs\n-        + cur_head * stride_oh\n+        + o_head_offset\n         + offs_dv[None, :]\n     )\n     if STORE_TRANSPOSE:\n", "model_name_or_path": "gpt-5-2025-08-07"}
