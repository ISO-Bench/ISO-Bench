{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-10bfce7", "model_patch": "diff --git a/python/sglang/srt/mem_cache/memory_pool.py b/python/sglang/srt/mem_cache/memory_pool.py\nindex e307367..a2b7753 100644\n--- a/python/sglang/srt/mem_cache/memory_pool.py\n+++ b/python/sglang/srt/mem_cache/memory_pool.py\n@@ -59,7 +59,7 @@ class ReqToTokenPool:\n         self.max_context_len = max_context_len\n         self.device = device\n         with memory_saver_adapter.region():\n-            self.req_to_token = torch.zeros(\n+            self.req_to_token = torch.empty(\n                 (size, max_context_len), dtype=torch.int32, device=device\n             )\n         self.free_slots = list(range(size))\n@@ -486,9 +486,10 @@ class MLATokenToKVPoolHost:\n         )\n \n         # Initialize memory states and tracking structures.\n-        self.mem_state = torch.zeros(\n+        self.mem_state = torch.empty(\n             (self.size,), dtype=torch.uint8, device=self.device\n         )\n+        self.mem_state.fill_(0)\n         self.free_slots = torch.arange(self.size, dtype=torch.int32)\n         self.can_use_mem_size = self.size\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
