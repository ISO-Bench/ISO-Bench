{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-42a2d82", "model_patch": "diff --git a/python/sglang/srt/managers/schedule_batch.py b/python/sglang/srt/managers/schedule_batch.py\nindex 2ab0417..26ccb22 100644\n--- a/python/sglang/srt/managers/schedule_batch.py\n+++ b/python/sglang/srt/managers/schedule_batch.py\n@@ -17,6 +17,7 @@ limitations under the License.\n \n \"\"\"Meta data for requests and batches\"\"\"\n \n+import itertools\n import logging\n from dataclasses import dataclass\n from typing import List, Optional, Tuple, Union\n@@ -468,7 +469,7 @@ class ScheduleBatch:\n \n         # Set fields\n         with torch.device(\"cuda\"):\n-            self.input_ids = torch.tensor(sum(input_ids, []), dtype=torch.int32)\n+            self.input_ids = torch.tensor(list(itertools.chain.from_iterable(input_ids)), dtype=torch.int32)\n             self.req_pool_indices = torch.tensor(req_pool_indices_cpu)\n             self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32)\n             self.position_ids_offsets = torch.zeros((bs,), dtype=torch.int64)\ndiff --git a/python/sglang/srt/model_executor/forward_batch_info.py b/python/sglang/srt/model_executor/forward_batch_info.py\nindex 4815fbc..1f2640b 100644\n--- a/python/sglang/srt/model_executor/forward_batch_info.py\n+++ b/python/sglang/srt/model_executor/forward_batch_info.py\n@@ -115,6 +115,7 @@ class InputMetadata:\n                         ],\n                         axis=0,\n                     ),\n+                    dtype=torch.int64,\n                     device=\"cuda\",\n                 )\n             else:\n@@ -131,16 +132,19 @@ class InputMetadata:\n                         ],\n                         axis=0,\n                     ),\n+                    dtype=torch.int64,\n                     device=\"cuda\",\n                 )\n \n-        # Positions should be in long type\n-        self.positions = self.positions.to(torch.int64)\n+        # Positions should be in long type (already set above for non-decode case)\n+        if self.forward_mode.is_decode():\n+            self.positions = self.positions.to(torch.int64)\n \n     def compute_extend_infos(self, batch: ScheduleBatch):\n         self.extend_seq_lens = torch.tensor(batch.extend_lens_cpu, device=\"cuda\")\n         self.extend_prefix_lens = torch.tensor(batch.prefix_lens_cpu, device=\"cuda\")\n-        self.extend_start_loc = torch.zeros_like(self.extend_seq_lens)\n+        self.extend_start_loc = torch.empty_like(self.extend_seq_lens)\n+        self.extend_start_loc[0] = 0\n         self.extend_start_loc[1:] = torch.cumsum(self.extend_seq_lens[:-1], dim=0)\n         self.extend_no_prefix = all(x == 0 for x in batch.prefix_lens_cpu)\n         self.extend_seq_lens_cpu = batch.extend_lens_cpu\ndiff --git a/python/sglang/srt/model_executor/model_runner.py b/python/sglang/srt/model_executor/model_runner.py\nindex 049a438..b6f76f0 100644\n--- a/python/sglang/srt/model_executor/model_runner.py\n+++ b/python/sglang/srt/model_executor/model_runner.py\n@@ -431,8 +431,8 @@ class ModelRunner:\n         \"\"\"We need to run a small matmul to init cublas. Otherwise, it will raise some errors later.\"\"\"\n         dtype = torch.float16\n         device = \"cuda\"\n-        a = torch.ones((16, 16), dtype=dtype, device=device)\n-        b = torch.ones((16, 16), dtype=dtype, device=device)\n+        a = torch.empty((16, 16), dtype=dtype, device=device)\n+        b = torch.empty((16, 16), dtype=dtype, device=device)\n         c = a @ b\n         return c\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
