{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-89a5541", "model_patch": "diff --git a/sgl-kernel/csrc/moe/moe_align_kernel.cu b/sgl-kernel/csrc/moe/moe_align_kernel.cu\nindex 6ffa739..2afce19 100644\n--- a/sgl-kernel/csrc/moe/moe_align_kernel.cu\n+++ b/sgl-kernel/csrc/moe/moe_align_kernel.cu\n@@ -32,9 +32,10 @@ __global__ void count_and_sort_expert_tokens_kernel(\n   const size_t tid = blockIdx.x * blockDim.x + threadIdx.x;\n   const size_t stride = blockDim.x * gridDim.x;\n \n+  // Grid-stride loop for better memory coalescing\n   for (size_t i = tid; i < numel; i += stride) {\n-    int32_t expert_id = topk_ids[i];\n-    int32_t rank_post_pad = atomicAdd(&cumsum_buffer[expert_id], 1);\n+    const int32_t expert_id = topk_ids[i];\n+    const int32_t rank_post_pad = atomicAdd(&cumsum_buffer[expert_id], 1);\n     sorted_token_ids[rank_post_pad] = i;\n   }\n }\n@@ -56,18 +57,21 @@ __global__ void moe_align_block_size_kernel(\n   const int warp_id = threadIdx.x / WARP_SIZE;\n   const int my_expert_start = warp_id * experts_per_warp;\n \n-  for (int i = 0; i < experts_per_warp; ++i) {\n-    if (my_expert_start + i < padded_num_experts) {\n-      shared_counts[warp_id * experts_per_warp + i] = 0;\n-    }\n+  // Optimize shared memory initialization - each thread initializes one element\n+  const int num_warps = blockDim.x / WARP_SIZE;\n+  const int total_shared_elements = num_warps * experts_per_warp;\n+  for (int i = threadIdx.x; i < total_shared_elements; i += blockDim.x) {\n+    shared_counts[i] = 0;\n   }\n \n   __syncthreads();\n \n   const size_t tokens_per_thread = CEILDIV(numel, blockDim.x);\n   const size_t start_idx = threadIdx.x * tokens_per_thread;\n+  const size_t end_idx = min(start_idx + tokens_per_thread, numel);\n \n-  for (int i = start_idx; i < numel && i < start_idx + tokens_per_thread; ++i) {\n+  // Process tokens assigned to this thread\n+  for (size_t i = start_idx; i < end_idx; ++i) {\n     int expert_id = topk_ids[i];\n     int warp_idx = expert_id / experts_per_warp;\n     int expert_offset = expert_id % experts_per_warp;\n@@ -79,20 +83,24 @@ __global__ void moe_align_block_size_kernel(\n   if (threadIdx.x == 0) {\n     cumsum[0] = 0;\n     for (int i = 1; i <= num_experts; ++i) {\n-      int expert_count = 0;\n       int warp_idx = (i - 1) / experts_per_warp;\n       int expert_offset = (i - 1) % experts_per_warp;\n-      expert_count = shared_counts[warp_idx * experts_per_warp + expert_offset];\n+      int expert_count = shared_counts[warp_idx * experts_per_warp + expert_offset];\n \n-      cumsum[i] = cumsum[i - 1] + CEILDIV(expert_count, block_size) * block_size;\n+      // Align to block_size boundary\n+      int padded_count = CEILDIV(expert_count, block_size) * block_size;\n+      cumsum[i] = cumsum[i - 1] + padded_count;\n     }\n     *total_tokens_post_pad = cumsum[num_experts];\n   }\n \n   __syncthreads();\n \n+  // Parallelize expert_ids filling - each thread handles one expert\n   if (threadIdx.x < num_experts) {\n-    for (int i = cumsum[threadIdx.x]; i < cumsum[threadIdx.x + 1]; i += block_size) {\n+    int start = cumsum[threadIdx.x];\n+    int end = cumsum[threadIdx.x + 1];\n+    for (int i = start; i < end; i += block_size) {\n       expert_ids[i / block_size] = threadIdx.x;\n     }\n   }\n@@ -145,16 +153,16 @@ void moe_align_block_size(\n         topk_ids.numel(),\n         cumsum_buffer.data_ptr<int32_t>());\n \n-    const int block_threads = std::min(256, (int)threads);\n-    const int num_blocks = (topk_ids.numel() + block_threads - 1) / block_threads;\n-    const int max_blocks = 65535;\n-    const int actual_blocks = std::min(num_blocks, max_blocks);\n+    // Optimize block configuration for better occupancy\n+    const int block_threads = 256;\n+    const size_t numel = topk_ids.numel();\n+    const int num_blocks = std::min((numel + block_threads - 1) / block_threads, (size_t)65535);\n \n     auto sort_kernel = count_and_sort_expert_tokens_kernel<scalar_t>;\n-    sort_kernel<<<actual_blocks, block_threads, 0, stream>>>(\n+    sort_kernel<<<num_blocks, block_threads, 0, stream>>>(\n         topk_ids.data_ptr<scalar_t>(),\n         sorted_token_ids.data_ptr<int32_t>(),\n         cumsum_buffer.data_ptr<int32_t>(),\n-        topk_ids.numel());\n+        numel);\n   });\n }\n", "model_name_or_path": "gpt-5-2025-08-07"}
