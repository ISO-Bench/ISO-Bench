diff --git a/sgl-kernel/csrc/moe/moe_align_kernel.cu b/sgl-kernel/csrc/moe/moe_align_kernel.cu
index 6ffa739..2afce19 100644
--- a/sgl-kernel/csrc/moe/moe_align_kernel.cu
+++ b/sgl-kernel/csrc/moe/moe_align_kernel.cu
@@ -32,9 +32,10 @@ __global__ void count_and_sort_expert_tokens_kernel(
   const size_t tid = blockIdx.x * blockDim.x + threadIdx.x;
   const size_t stride = blockDim.x * gridDim.x;
 
+  // Grid-stride loop for better memory coalescing
   for (size_t i = tid; i < numel; i += stride) {
-    int32_t expert_id = topk_ids[i];
-    int32_t rank_post_pad = atomicAdd(&cumsum_buffer[expert_id], 1);
+    const int32_t expert_id = topk_ids[i];
+    const int32_t rank_post_pad = atomicAdd(&cumsum_buffer[expert_id], 1);
     sorted_token_ids[rank_post_pad] = i;
   }
 }
@@ -56,18 +57,21 @@ __global__ void moe_align_block_size_kernel(
   const int warp_id = threadIdx.x / WARP_SIZE;
   const int my_expert_start = warp_id * experts_per_warp;
 
-  for (int i = 0; i < experts_per_warp; ++i) {
-    if (my_expert_start + i < padded_num_experts) {
-      shared_counts[warp_id * experts_per_warp + i] = 0;
-    }
+  // Optimize shared memory initialization - each thread initializes one element
+  const int num_warps = blockDim.x / WARP_SIZE;
+  const int total_shared_elements = num_warps * experts_per_warp;
+  for (int i = threadIdx.x; i < total_shared_elements; i += blockDim.x) {
+    shared_counts[i] = 0;
   }
 
   __syncthreads();
 
   const size_t tokens_per_thread = CEILDIV(numel, blockDim.x);
   const size_t start_idx = threadIdx.x * tokens_per_thread;
+  const size_t end_idx = min(start_idx + tokens_per_thread, numel);
 
-  for (int i = start_idx; i < numel && i < start_idx + tokens_per_thread; ++i) {
+  // Process tokens assigned to this thread
+  for (size_t i = start_idx; i < end_idx; ++i) {
     int expert_id = topk_ids[i];
     int warp_idx = expert_id / experts_per_warp;
     int expert_offset = expert_id % experts_per_warp;
@@ -79,20 +83,24 @@ __global__ void moe_align_block_size_kernel(
   if (threadIdx.x == 0) {
     cumsum[0] = 0;
     for (int i = 1; i <= num_experts; ++i) {
-      int expert_count = 0;
       int warp_idx = (i - 1) / experts_per_warp;
       int expert_offset = (i - 1) % experts_per_warp;
-      expert_count = shared_counts[warp_idx * experts_per_warp + expert_offset];
+      int expert_count = shared_counts[warp_idx * experts_per_warp + expert_offset];
 
-      cumsum[i] = cumsum[i - 1] + CEILDIV(expert_count, block_size) * block_size;
+      // Align to block_size boundary
+      int padded_count = CEILDIV(expert_count, block_size) * block_size;
+      cumsum[i] = cumsum[i - 1] + padded_count;
     }
     *total_tokens_post_pad = cumsum[num_experts];
   }
 
   __syncthreads();
 
+  // Parallelize expert_ids filling - each thread handles one expert
   if (threadIdx.x < num_experts) {
-    for (int i = cumsum[threadIdx.x]; i < cumsum[threadIdx.x + 1]; i += block_size) {
+    int start = cumsum[threadIdx.x];
+    int end = cumsum[threadIdx.x + 1];
+    for (int i = start; i < end; i += block_size) {
       expert_ids[i / block_size] = threadIdx.x;
     }
   }
@@ -145,16 +153,16 @@ void moe_align_block_size(
         topk_ids.numel(),
         cumsum_buffer.data_ptr<int32_t>());
 
-    const int block_threads = std::min(256, (int)threads);
-    const int num_blocks = (topk_ids.numel() + block_threads - 1) / block_threads;
-    const int max_blocks = 65535;
-    const int actual_blocks = std::min(num_blocks, max_blocks);
+    // Optimize block configuration for better occupancy
+    const int block_threads = 256;
+    const size_t numel = topk_ids.numel();
+    const int num_blocks = std::min((numel + block_threads - 1) / block_threads, (size_t)65535);
 
     auto sort_kernel = count_and_sort_expert_tokens_kernel<scalar_t>;
-    sort_kernel<<<actual_blocks, block_threads, 0, stream>>>(
+    sort_kernel<<<num_blocks, block_threads, 0, stream>>>(
         topk_ids.data_ptr<scalar_t>(),
         sorted_token_ids.data_ptr<int32_t>(),
         cumsum_buffer.data_ptr<int32_t>(),
-        topk_ids.numel());
+        numel);
   });
 }
