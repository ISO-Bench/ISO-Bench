{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-c4336b2", "model_patch": "diff --git a/python/sglang/srt/managers/scheduler.py b/python/sglang/srt/managers/scheduler.py\nindex 1d1cf3688..c0e0a4a8b 100644\n--- a/python/sglang/srt/managers/scheduler.py\n+++ b/python/sglang/srt/managers/scheduler.py\n@@ -425,8 +425,9 @@ class Scheduler:\n         else:\n             num_tokens = local_batch.extend_num_tokens\n \n-        local_num_tokens = torch.tensor([num_tokens], dtype=torch.int64)\n-        global_num_tokens = torch.empty(self.tp_size, dtype=torch.int64)\n+        local_num_tokens = torch.empty(1, dtype=torch.int64, device=\"cpu\")\n+        local_num_tokens[0] = num_tokens\n+        global_num_tokens = torch.empty(self.tp_size, dtype=torch.int64, device=\"cpu\")\n         torch.distributed.all_gather_into_tensor(\n             global_num_tokens,\n             local_num_tokens,\n@@ -441,14 +442,12 @@ class Scheduler:\n \n             # Check forward mode for cuda graph\n             if not self.server_args.disable_cuda_graph:\n-                forward_mode_state = torch.tensor(\n-                    (\n-                        1\n-                        if local_batch.forward_mode.is_decode()\n-                        or local_batch.forward_mode.is_idle()\n-                        else 0\n-                    ),\n-                    dtype=torch.int32,\n+                forward_mode_state = torch.empty(1, dtype=torch.int32)\n+                forward_mode_state[0] = (\n+                    1\n+                    if local_batch.forward_mode.is_decode()\n+                    or local_batch.forward_mode.is_idle()\n+                    else 0\n                 )\n                 torch.distributed.all_reduce(\n                     forward_mode_state,\n@@ -819,8 +818,9 @@ class Scheduler:\n         can_run_list = adder.can_run_list\n         if len(can_run_list) == 0:\n             return None\n+        can_run_set = set(can_run_list)\n         self.waiting_queue = [\n-            x for x in self.waiting_queue if x not in set(can_run_list)\n+            x for x in self.waiting_queue if x not in can_run_set\n         ]\n \n         if adder.new_inflight_req is not None:\n@@ -924,12 +924,12 @@ class Scheduler:\n                 return\n             else:\n                 logits_output = None\n+                batch_size = batch.batch_size()\n                 if self.skip_tokenizer_init:\n-                    next_token_ids = torch.full(\n-                        (batch.batch_size(),), self.tokenizer.eos_token_id\n-                    )\n+                    next_token_ids = torch.empty(batch_size, dtype=torch.long, device=self.device)\n+                    next_token_ids.fill_(self.tokenizer.eos_token_id)\n                 else:\n-                    next_token_ids = torch.full((batch.batch_size(),), 0)\n+                    next_token_ids = torch.zeros(batch_size, dtype=torch.long, device=self.device)\n             batch.output_ids = next_token_ids\n             ret = logits_output, next_token_ids, model_worker_batch.bid\n         else:  # embedding or reward model\n@@ -1287,7 +1287,8 @@ class Scheduler:\n \n         if self.tp_size > 1:\n             # Sync across TP ranks to make sure they have the same number of ready requests\n-            tensor = torch.tensor(num_ready_reqs, dtype=torch.int32)\n+            tensor = torch.empty(1, dtype=torch.int32)\n+            tensor[0] = num_ready_reqs\n             torch.distributed.all_reduce(\n                 tensor, op=torch.distributed.ReduceOp.MAX, group=self.tp_cpu_group\n             )\ndiff --git a/python/sglang/srt/utils.py b/python/sglang/srt/utils.py\nindex e947d1a92..646892360 100644\n--- a/python/sglang/srt/utils.py\n+++ b/python/sglang/srt/utils.py\n@@ -687,21 +687,23 @@ def broadcast_pyobj(\n \n     if rank == 0:\n         if len(data) == 0:\n-            tensor_size = torch.tensor([0], dtype=torch.long)\n+            tensor_size = torch.empty(1, dtype=torch.long)\n+            tensor_size[0] = 0\n             dist.broadcast(tensor_size, src=0, group=dist_group)\n         else:\n             serialized_data = pickle.dumps(data)\n             size = len(serialized_data)\n-            tensor_data = torch.ByteTensor(\n+            tensor_data = torch.from_numpy(\n                 np.frombuffer(serialized_data, dtype=np.uint8)\n             )\n-            tensor_size = torch.tensor([size], dtype=torch.long)\n+            tensor_size = torch.empty(1, dtype=torch.long)\n+            tensor_size[0] = size\n \n             dist.broadcast(tensor_size, src=0, group=dist_group)\n             dist.broadcast(tensor_data, src=0, group=dist_group)\n         return data\n     else:\n-        tensor_size = torch.tensor([0], dtype=torch.long)\n+        tensor_size = torch.empty(1, dtype=torch.long)\n         dist.broadcast(tensor_size, src=0, group=dist_group)\n         size = tensor_size.item()\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
