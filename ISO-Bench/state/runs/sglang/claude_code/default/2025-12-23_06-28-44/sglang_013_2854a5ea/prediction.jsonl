{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-42a2d82", "model_patch": "diff --git a/python/sglang/srt/managers/schedule_batch.py b/python/sglang/srt/managers/schedule_batch.py\nindex 2ab041726..26ccb2243 100644\n--- a/python/sglang/srt/managers/schedule_batch.py\n+++ b/python/sglang/srt/managers/schedule_batch.py\n@@ -17,6 +17,7 @@ limitations under the License.\n \n \"\"\"Meta data for requests and batches\"\"\"\n \n+import itertools\n import logging\n from dataclasses import dataclass\n from typing import List, Optional, Tuple, Union\n@@ -468,7 +469,7 @@ class ScheduleBatch:\n \n         # Set fields\n         with torch.device(\"cuda\"):\n-            self.input_ids = torch.tensor(sum(input_ids, []), dtype=torch.int32)\n+            self.input_ids = torch.tensor(list(itertools.chain.from_iterable(input_ids)), dtype=torch.int32)\n             self.req_pool_indices = torch.tensor(req_pool_indices_cpu)\n             self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32)\n             self.position_ids_offsets = torch.zeros((bs,), dtype=torch.int64)\ndiff --git a/python/sglang/srt/managers/tp_worker.py b/python/sglang/srt/managers/tp_worker.py\nindex fe9afc9f3..69e86df67 100644\n--- a/python/sglang/srt/managers/tp_worker.py\n+++ b/python/sglang/srt/managers/tp_worker.py\n@@ -1003,7 +1003,7 @@ def broadcast_recv_input(\n         else:\n             serialized_data = pickle.dumps(data)\n             size = len(serialized_data)\n-            tensor_data = torch.ByteTensor(list(serialized_data))\n+            tensor_data = torch.frombuffer(serialized_data, dtype=torch.uint8)\n             tensor_size = torch.tensor([size], dtype=torch.long)\n \n             dist.broadcast(tensor_size, src=0, group=dist_group)\n@@ -1020,6 +1020,6 @@ def broadcast_recv_input(\n         tensor_data = torch.empty(size, dtype=torch.uint8)\n         dist.broadcast(tensor_data, src=0, group=dist_group)\n \n-        serialized_data = bytes(tensor_data.tolist())\n+        serialized_data = tensor_data.cpu().numpy().tobytes()\n         data = pickle.loads(serialized_data)\n         return data\ndiff --git a/python/sglang/srt/model_executor/forward_batch_info.py b/python/sglang/srt/model_executor/forward_batch_info.py\nindex 4815fbc56..70bcd4ca3 100644\n--- a/python/sglang/srt/model_executor/forward_batch_info.py\n+++ b/python/sglang/srt/model_executor/forward_batch_info.py\n@@ -107,32 +107,25 @@ class InputMetadata:\n                 self.positions = (self.seq_lens - 1) + position_ids_offsets\n         else:\n             if True:\n-                self.positions = torch.tensor(\n-                    np.concatenate(\n-                        [\n-                            np.arange(batch.prefix_lens_cpu[i], len(req.fill_ids))\n-                            for i, req in enumerate(batch.reqs)\n-                        ],\n-                        axis=0,\n-                    ),\n-                    device=\"cuda\",\n-                )\n+                # Directly create on device to avoid CPU->GPU transfer\n+                position_list = []\n+                for i, req in enumerate(batch.reqs):\n+                    position_list.extend(range(batch.prefix_lens_cpu[i], len(req.fill_ids)))\n+                self.positions = torch.tensor(position_list, device=\"cuda\", dtype=torch.int64)\n+                return  # Already int64, skip conversion\n             else:\n                 # Deprecated\n                 position_ids_offsets_cpu = position_ids_offsets.cpu().numpy()\n-                self.positions = torch.tensor(\n-                    np.concatenate(\n-                        [\n-                            np.arange(\n-                                batch.prefix_lens_cpu[i] + position_ids_offsets_cpu[i],\n-                                len(req.fill_ids) + position_ids_offsets_cpu[i],\n-                            )\n-                            for i, req in enumerate(batch.reqs)\n-                        ],\n-                        axis=0,\n-                    ),\n-                    device=\"cuda\",\n-                )\n+                position_list = []\n+                for i, req in enumerate(batch.reqs):\n+                    position_list.extend(\n+                        range(\n+                            batch.prefix_lens_cpu[i] + position_ids_offsets_cpu[i],\n+                            len(req.fill_ids) + position_ids_offsets_cpu[i],\n+                        )\n+                    )\n+                self.positions = torch.tensor(position_list, device=\"cuda\", dtype=torch.int64)\n+                return  # Already int64, skip conversion\n \n         # Positions should be in long type\n         self.positions = self.positions.to(torch.int64)\n@@ -140,7 +133,8 @@ class InputMetadata:\n     def compute_extend_infos(self, batch: ScheduleBatch):\n         self.extend_seq_lens = torch.tensor(batch.extend_lens_cpu, device=\"cuda\")\n         self.extend_prefix_lens = torch.tensor(batch.prefix_lens_cpu, device=\"cuda\")\n-        self.extend_start_loc = torch.zeros_like(self.extend_seq_lens)\n+        self.extend_start_loc = torch.empty_like(self.extend_seq_lens)\n+        self.extend_start_loc[0] = 0\n         self.extend_start_loc[1:] = torch.cumsum(self.extend_seq_lens[:-1], dim=0)\n         self.extend_no_prefix = all(x == 0 for x in batch.prefix_lens_cpu)\n         self.extend_seq_lens_cpu = batch.extend_lens_cpu\n", "model_name_or_path": "gpt-5-2025-08-07"}
