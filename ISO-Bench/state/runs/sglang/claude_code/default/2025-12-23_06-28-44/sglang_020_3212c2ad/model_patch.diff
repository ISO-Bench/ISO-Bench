diff --git a/python/sglang/srt/managers/mm_utils.py b/python/sglang/srt/managers/mm_utils.py
index 13ca29c54..a46535bca 100644
--- a/python/sglang/srt/managers/mm_utils.py
+++ b/python/sglang/srt/managers/mm_utils.py
@@ -231,7 +231,7 @@ def _get_precomputed_embedding(
             raise NotImplementedError(
                 "MM inputs where only some items are precomputed."
             )
-        result = torch.concat(precomputed_embeddings)
+        result = torch.cat(precomputed_embeddings)
         # some models embedding is 3-dim, reshape it to 2-dim (similar to get_embedding_chunk)
         result = result.reshape(-1, result.shape[-1])
         return result
@@ -286,7 +286,7 @@ def _get_chunked_prefill_embedding(
         embedding_list.append(embedding_per_req_chunk)
     if len(embedding_list) == 0:
         return None
-    return torch.concat(embedding_list, dim=0)
+    return torch.cat(embedding_list, dim=0)
 
 
 def _get_multimodal_mask(
@@ -433,7 +433,8 @@ def embed_mm_inputs(
                 device=input_ids.device,
             )
             # calculate per request items length offset
-            items_size = torch.zeros(len(mm_inputs_list) + 1, dtype=int)
+            items_size = torch.empty(len(mm_inputs_list) + 1, dtype=int)
+            items_size[0] = 0
             items_offsets = []
             for i, mm_inputs in enumerate(mm_inputs_list):
                 mm_items = [
@@ -591,7 +592,7 @@ def get_multimodal_data_bounds(
     valid_mm_data_nums = min(len(data_start_tokens_cpu), len(data_end_tokens_cpu))
 
     if valid_mm_data_nums == 0:
-        return torch.zeros((0, 2), device=input_ids.device)
+        return torch.empty((0, 2), dtype=torch.int64, device=input_ids.device)
 
     # Filter out pairs where start_token >= end_token
     valid_pairs = []
@@ -602,7 +603,7 @@ def get_multimodal_data_bounds(
             valid_pairs.append((start_token + 1, end_token - 1))
 
     if not valid_pairs:
-        return torch.zeros((0, 2), device=input_ids.device)
+        return torch.empty((0, 2), dtype=torch.int64, device=input_ids.device)
 
     # Convert valid pairs to tensor
     valid_pairs_tensor = torch.as_tensor(valid_pairs, device=input_ids.device)
@@ -624,7 +625,7 @@ def tensor_hash(tensor_list) -> int:
         tensor_list = [
             x.flatten() if isinstance(x, torch.Tensor) else x for x in tensor_list
         ]
-        tensor = torch.concat(tensor_list)
+        tensor = torch.cat(tensor_list)
     if tensor.is_cuda:
         return gpu_tensor_hash(tensor)
     tensor = tensor.detach().contiguous()
diff --git a/python/sglang/srt/managers/schedule_batch.py b/python/sglang/srt/managers/schedule_batch.py
index ad8bcf119..963a8258e 100644
--- a/python/sglang/srt/managers/schedule_batch.py
+++ b/python/sglang/srt/managers/schedule_batch.py
@@ -1096,16 +1096,12 @@ class ScheduleBatch(ScheduleBatchDisaggregationDecodeMixin):
         )
 
         if not decoder_out_cache_loc:
-            self.out_cache_loc = torch.zeros(0, dtype=torch.int64).to(
-                self.device, non_blocking=True
-            )
+            self.out_cache_loc = torch.empty(0, dtype=torch.int64, device=self.device)
         else:
             self.out_cache_loc = torch.cat(decoder_out_cache_loc)
 
         if not encoder_out_cache_loc:
-            self.encoder_out_cache_loc = torch.zeros(0, dtype=torch.int64).to(
-                self.device, non_blocking=True
-            )
+            self.encoder_out_cache_loc = torch.empty(0, dtype=torch.int64, device=self.device)
         else:
             self.encoder_out_cache_loc = torch.cat(encoder_out_cache_loc)
 
