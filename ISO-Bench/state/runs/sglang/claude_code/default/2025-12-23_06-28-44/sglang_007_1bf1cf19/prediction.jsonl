{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-e822e59", "model_patch": "diff --git a/python/sglang/lang/interpreter.py b/python/sglang/lang/interpreter.py\nindex 00691ca50..64e5e7bf5 100644\n--- a/python/sglang/lang/interpreter.py\n+++ b/python/sglang/lang/interpreter.py\n@@ -273,12 +273,12 @@ class StreamExecutor:\n             for _ in range(number)\n         ]\n         for i in range(number):\n-            exes[i].variables = dict(self.variables)\n-            exes[i].text_ = str(self.text_)\n-            exes[i].messages_ = list(self.messages_)\n+            exes[i].variables = self.variables.copy()\n+            exes[i].text_ = self.text_\n+            exes[i].messages_ = self.messages_.copy()\n             exes[i].cur_role = self.cur_role\n             exes[i].fork_start_text_pos = len(self.text_)\n-            exes[i].images_ = list(self.images_)\n+            exes[i].images_ = self.images_.copy()\n \n         return exes\n \n@@ -354,7 +354,8 @@ class StreamExecutor:\n             raise ValueError(f\"Unknown type: {type(other)}\")\n \n     def _execute_fill(self, value: str):\n-        value = str(value)\n+        if not isinstance(value, str):\n+            value = str(value)\n         if self.speculated_text.startswith(value):\n             self.speculated_text = self.speculated_text[len(value) :]\n         else:\n@@ -672,7 +673,7 @@ class ProgramState:\n                 while True:\n                     event.wait()\n                     event.clear()\n-                    out = str(self.stream_executor.text_[prev:])\n+                    out = self.stream_executor.text_[prev:]\n                     prev += len(out)\n                     if out:\n                         yield out\n@@ -683,7 +684,7 @@ class ProgramState:\n                 while True:\n                     event.wait()\n                     event.clear()\n-                    out = str(self.stream_executor.variables[var_name][prev:])\n+                    out = self.stream_executor.variables[var_name][prev:]\n                     prev += len(out)\n                     if out:\n                         yield out\n@@ -707,7 +708,7 @@ class ProgramState:\n                 while True:\n                     await loop.run_in_executor(None, event.wait)\n                     event.clear()\n-                    out = str(self.stream_executor.text_[prev:])\n+                    out = self.stream_executor.text_[prev:]\n                     prev += len(out)\n                     if out:\n                         yield out\n@@ -718,7 +719,7 @@ class ProgramState:\n                 while True:\n                     await loop.run_in_executor(None, event.wait)\n                     event.clear()\n-                    out = str(self.stream_executor.variables[var_name][prev:])\n+                    out = self.stream_executor.variables[var_name][prev:]\n                     prev += len(out)\n                     if out:\n                         if return_meta_data:\ndiff --git a/python/sglang/srt/managers/router/radix_cache.py b/python/sglang/srt/managers/router/radix_cache.py\nindex 7bb8a4b2a..ebc11bfa3 100644\n--- a/python/sglang/srt/managers/router/radix_cache.py\n+++ b/python/sglang/srt/managers/router/radix_cache.py\n@@ -49,9 +49,10 @@ class RadixCache:\n \n         value = []\n         last_node = [self.root_node]\n-        self._match_prefix_helper(self.root_node, key, value, last_node)\n+        current_time = time.time()\n+        self._match_prefix_helper(self.root_node, key, value, last_node, current_time)\n         if value:\n-            value = torch.concat(value)\n+            value = torch.cat(value)\n         return value, last_node[0]\n \n     def insert(self, key, value=None):\n@@ -60,7 +61,8 @@ class RadixCache:\n \n         if value is None:\n             value = [x for x in key]\n-        return self._insert_helper(self.root_node, key, value)\n+        current_time = time.time()\n+        return self._insert_helper(self.root_node, key, value, current_time)\n \n     def pretty_print(self):\n         self._print_helper(self.root_node, 0)\n@@ -115,12 +117,12 @@ class RadixCache:\n         return self.evictable_size_\n \n     ##### Internal Helper Functions #####\n-    def _match_prefix_helper(self, node, key, value, last_node):\n-        node.last_access_time = time.time()\n+    def _match_prefix_helper(self, node, key, value, last_node, current_time):\n+        node.last_access_time = current_time\n         if len(key) == 0:\n             return\n \n-        if key[0] in node.children.keys():\n+        if key[0] in node.children:\n             child = node.children[key[0]]\n             prefix_len = match(child.key, key)\n             if prefix_len < len(child.key):\n@@ -130,7 +132,7 @@ class RadixCache:\n             else:\n                 value.append(child.value)\n                 last_node[0] = child\n-                self._match_prefix_helper(child, key[prefix_len:], value, last_node)\n+                self._match_prefix_helper(child, key[prefix_len:], value, last_node, current_time)\n \n     def _split_node(self, key, child, split_len):\n         # new_node -> child\n@@ -146,12 +148,12 @@ class RadixCache:\n         new_node.parent.children[key[:split_len][0]] = new_node\n         return new_node\n \n-    def _insert_helper(self, node, key, value):\n-        node.last_access_time = time.time()\n+    def _insert_helper(self, node, key, value, current_time):\n+        node.last_access_time = current_time\n         if len(key) == 0:\n             return 0\n \n-        if key[0] in node.children.keys():\n+        if key[0] in node.children:\n             child = node.children[key[0]]\n             prefix_len = match(child.key, key)\n \n@@ -161,11 +163,11 @@ class RadixCache:\n                 else:\n                     key = key[prefix_len:]\n                     value = value[prefix_len:]\n-                    return prefix_len + self._insert_helper(child, key, value)\n+                    return prefix_len + self._insert_helper(child, key, value, current_time)\n \n             new_node = self._split_node(child.key, child, prefix_len)\n             return prefix_len + self._insert_helper(\n-                new_node, key[prefix_len:], value[prefix_len:]\n+                new_node, key[prefix_len:], value[prefix_len:], current_time\n             )\n \n         if len(key):\n", "model_name_or_path": "gpt-5-2025-08-07"}
