diff --git a/python/sglang/srt/layers/attention/triton_ops/extend_attention.py b/python/sglang/srt/layers/attention/triton_ops/extend_attention.py
index 608f9ba..7da696f 100644
--- a/python/sglang/srt/layers/attention/triton_ops/extend_attention.py
+++ b/python/sglang/srt/layers/attention/triton_ops/extend_attention.py
@@ -123,7 +123,7 @@ def _fwd_kernel(
 
     acc = tl.zeros([BLOCK_M, BLOCK_DV], dtype=tl.float32)
     deno = tl.zeros([BLOCK_M], dtype=tl.float32)
-    e_max = tl.zeros([BLOCK_M], dtype=tl.float32) - float("inf")
+    e_max = tl.full([BLOCK_M], float("-inf"), dtype=tl.float32)
 
     for start_n in range(0, cur_seq_len_prefix, BLOCK_N):
         start_n = tl.multiple_of(start_n, BLOCK_N)
@@ -142,7 +142,7 @@ def _fwd_kernel(
             K_Buffer + offs_buf_k, mask=(mask_n[None, :]) & (mask_d[:, None]), other=0.0
         )
 
-        qk = tl.dot(q.to(k.dtype), k)
+        qk = tl.dot(q, k, out_dtype=tl.float32)
         if BLOCK_DPE > 0:
             offs_kpe = (
                 offs_kv_loc[None, :] * stride_buf_kbs
@@ -154,7 +154,7 @@ def _fwd_kernel(
                 mask=mask_n[None, :],
                 other=0.0,
             )
-            qk += tl.dot(qpe.to(kpe.dtype), kpe)
+            qk += tl.dot(qpe, kpe, out_dtype=tl.float32)
         qk *= sm_scale
 
         if logit_cap > 0:
@@ -188,8 +188,7 @@ def _fwd_kernel(
         v = tl.load(
             V_Buffer + offs_buf_v, mask=mask_n[:, None] & mask_dv[None, :], other=0.0
         )
-        p = p.to(v.dtype)
-        acc = acc * re_scale[:, None] + tl.dot(p, v)
+        acc = acc * re_scale[:, None] + tl.dot(p, v, out_dtype=tl.float32)
 
         e_max = n_e_max
 
@@ -222,7 +221,7 @@ def _fwd_kernel(
                 mask=mask_n[None, :],
                 other=0.0,
             )
-            qk += tl.dot(qpe, kpe)
+            qk += tl.dot(qpe, kpe, out_dtype=tl.float32)
 
         qk *= sm_scale
 
@@ -262,8 +261,7 @@ def _fwd_kernel(
         v = tl.load(
             V_Extend + offs_v, mask=mask_n[:, None] & mask_dv[None, :], other=0.0
         )
-        p = p.to(v.dtype)
-        acc = acc * re_scale[:, None] + tl.dot(p, v)
+        acc = acc * re_scale[:, None] + tl.dot(p, v, out_dtype=tl.float32)
 
         e_max = n_e_max
 
