{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-8c7279c", "model_patch": "diff --git a/python/sglang/srt/two_batch_overlap.py b/python/sglang/srt/two_batch_overlap.py\nindex 0fbc3c8..b4a4f09 100644\n--- a/python/sglang/srt/two_batch_overlap.py\n+++ b/python/sglang/srt/two_batch_overlap.py\n@@ -40,13 +40,13 @@ def compute_split_seq_index(\n \n def _split_array_by_half_sum(arr: Sequence[int]) -> int:\n     overall_sum = sum(arr)\n-    accumulator, split_index = 0, 0\n-    for value in arr[:-1]:\n+    half_sum = overall_sum >> 1  # Bit shift is faster than division by 2\n+    accumulator = 0\n+    for split_index, value in enumerate(arr[:-1]):\n         accumulator += value\n-        split_index += 1\n-        if accumulator >= overall_sum // 2:\n-            break\n-    return split_index\n+        if accumulator >= half_sum:\n+            return split_index + 1\n+    return len(arr) - 1\n \n \n def compute_split_token_index(\n@@ -114,18 +114,23 @@ class TboDPAttentionPreparer:\n         return local_can_run_tbo, local_forward_mode\n \n     def compute_output(self, partial_global_info):\n+        # Early exit if two_batch_overlap is disabled\n+        if not self.enable_two_batch_overlap:\n+            return None, None\n+\n         local_can_run_tbo_aggregated = min(partial_global_info[:, 0, 0].tolist())\n+\n+        # Early exit if local can't run tbo\n+        if not local_can_run_tbo_aggregated:\n+            return None, None\n+\n         forward_modes = partial_global_info[:, 0, 1].tolist()\n \n         global_forward_mode, forward_mode_agree = self._compute_global_forward_mode(\n             forward_modes\n         )\n \n-        can_run_tbo = (\n-            self.enable_two_batch_overlap\n-            and local_can_run_tbo_aggregated\n-            and forward_mode_agree\n-        )\n+        can_run_tbo = forward_mode_agree\n \n         tbo_split_seq_index = self.local_tbo_split_seq_index if can_run_tbo else None\n         global_forward_mode = global_forward_mode if can_run_tbo else None\n@@ -139,21 +144,32 @@ class TboDPAttentionPreparer:\n \n     @staticmethod\n     def _compute_global_forward_mode(forward_modes):\n-        converted_forward_modes = [\n-            ForwardMode.DECODE.value if x == ForwardMode.IDLE.value else x\n-            for x in forward_modes\n-        ]\n-        forward_mode_agree = TboDPAttentionPreparer._is_all_same(\n-            converted_forward_modes\n-        )\n+        # Convert IDLE to DECODE in-place check\n+        idle_value = ForwardMode.IDLE.value\n+        decode_value = ForwardMode.DECODE.value\n+\n+        # Convert first element\n+        first_mode = decode_value if forward_modes[0] == idle_value else forward_modes[0]\n+\n+        # Check if all match while converting on the fly\n+        forward_mode_agree = True\n+        for x in forward_modes[1:]:\n+            converted = decode_value if x == idle_value else x\n+            if converted != first_mode:\n+                forward_mode_agree = False\n+                break\n+\n         global_forward_mode = (\n-            ForwardMode(converted_forward_modes[0]) if forward_mode_agree else None\n+            ForwardMode(first_mode) if forward_mode_agree else None\n         )\n         return global_forward_mode, forward_mode_agree\n \n     @staticmethod\n     def _is_all_same(x):\n-        return all(value == x[0] for value in x)\n+        if not x:\n+            return True\n+        first = x[0]\n+        return all(value == first for value in x[1:])\n \n \n class TboForwardBatchPreparer:\n@@ -211,6 +227,8 @@ class TboForwardBatchPreparer:\n \n         output_dict = dict()\n \n+        # Process token-based attributes efficiently\n+        token_slice = slice(start_token_index, end_token_index)\n         for key in [\n             \"input_ids\",\n             \"positions\",\n@@ -220,9 +238,10 @@ class TboForwardBatchPreparer:\n             assert (\n                 old_value.shape[0] == num_tokens\n             ), f\"{key=} {old_value=} {num_tokens=} {batch=}\"\n-            output_dict[key] = old_value[start_token_index:end_token_index]\n+            output_dict[key] = old_value[token_slice]\n \n-        for key in [\n+        # Process sequence-based attributes efficiently\n+        seq_keys = [\n             \"req_pool_indices\",\n             \"seq_lens\",\n             \"seq_lens_cpu\",\n@@ -233,14 +252,15 @@ class TboForwardBatchPreparer:\n             \"extend_seq_lens_cpu\",\n             \"extend_logprob_start_lens_cpu\",\n             \"lora_paths\",\n-        ]:\n+        ]\n+        seq_slice = slice(start_seq_index, end_seq_index)\n+        for key in seq_keys:\n             old_value = getattr(batch, key)\n-            if old_value is None:\n-                continue\n-            assert (\n-                len(old_value) == num_seqs\n-            ), f\"{key=} {old_value=} {num_seqs=} {batch=}\"\n-            output_dict[key] = old_value[start_seq_index:end_seq_index]\n+            if old_value is not None:\n+                assert (\n+                    len(old_value) == num_seqs\n+                ), f\"{key=} {old_value=} {num_seqs=} {batch=}\"\n+                output_dict[key] = old_value[seq_slice]\n \n         for key in [\n             \"forward_mode\",\n@@ -268,7 +288,7 @@ class TboForwardBatchPreparer:\n         # TODO improve, e.g. unify w/ `init_raw`\n         if global_server_args_dict[\"moe_dense_tp_size\"] == 1:\n             sum_len = end_token_index - start_token_index\n-            gathered_buffer = torch.zeros(\n+            gathered_buffer = torch.empty(\n                 (sum_len, batch.gathered_buffer.shape[1]),\n                 dtype=batch.gathered_buffer.dtype,\n                 device=batch.gathered_buffer.device,\n@@ -423,7 +443,7 @@ def _model_forward_tbo_merge_outputs(output_a, output_b):\n         assert (value_a is None) == (value_b is None)\n         if value_a is None:\n             return None\n-        return torch.concat([value_a, value_b], dim=0)\n+        return torch.cat([value_a, value_b], dim=0)\n \n     return _handle_key(\"hidden_states\"), _handle_key(\"residual\")\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
