{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-b146555", "model_patch": "diff --git a/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py b/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\nindex 4d165db..e006254 100644\n--- a/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\n+++ b/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\n@@ -400,7 +400,7 @@ class _DeepEPDispatcherImplNormal(_DeepEPDispatcherImplBase):\n                     BLOCK_SIZE=512,\n                 )\n             else:\n-                output = torch.zeros(\n+                output = torch.empty(\n                     (0, hidden_states.shape[1]),\n                     device=hidden_states.device,\n                     dtype=hidden_states.dtype,\ndiff --git a/python/sglang/srt/layers/moe/topk.py b/python/sglang/srt/layers/moe/topk.py\nindex 4c065e4..64f412e 100644\n--- a/python/sglang/srt/layers/moe/topk.py\n+++ b/python/sglang/srt/layers/moe/topk.py\n@@ -44,10 +44,6 @@ def fused_topk_native(\n         hidden_states.shape[0] == gating_output.shape[0]\n     ), f\"Number of tokens mismatch, {hidden_states.shape=} vs {gating_output.shape=}\"\n     M, _ = hidden_states.shape\n-    topk_weights = torch.empty(\n-        M, topk, dtype=torch.float32, device=hidden_states.device\n-    )\n-    topk_ids = torch.empty(M, topk, dtype=torch.int32, device=hidden_states.device)\n     topk_weights = F.softmax(gating_output.float(), dim=-1)\n     topk_weights, topk_ids = torch.topk(topk_weights, topk, dim=-1)\n     if renormalize:\n@@ -69,17 +65,13 @@ def fused_topk(\n         M, topk, dtype=torch.float32, device=hidden_states.device\n     )\n     topk_ids = torch.empty(M, topk, dtype=torch.int32, device=hidden_states.device)\n-    token_expert_indicies = torch.empty(\n-        M, topk, dtype=torch.int32, device=hidden_states.device\n-    )\n \n     topk_softmax(\n         topk_weights,\n         topk_ids,\n-        token_expert_indicies,\n+        topk_ids,  # Reuse topk_ids buffer to avoid extra allocation\n         gating_output.float(),\n     )\n-    del token_expert_indicies\n \n     if renormalize:\n         topk_weights = topk_weights / topk_weights.sum(dim=-1, keepdim=True)\n", "model_name_or_path": "gpt-5-2025-08-07"}
