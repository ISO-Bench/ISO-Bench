{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-9d5fa68", "model_patch": "diff --git a/python/sglang/srt/lora/layers.py b/python/sglang/srt/lora/layers.py\nindex aa10ef6..e9e4cb0 100644\n--- a/python/sglang/srt/lora/layers.py\n+++ b/python/sglang/srt/lora/layers.py\n@@ -94,19 +94,22 @@ class ColumnParallelLinearWithLoRA(BaseLayerWithLoRA):\n \n     def forward(self, input_: torch.Tensor):\n         # duplicate the logic in ColumnParallelLinear\n-        bias = self.base_layer.bias if not self.base_layer.skip_bias_add else None\n-        output_parallel = self.base_layer.quant_method.apply(\n-            self.base_layer, input_, bias\n-        )\n+        # Cache attribute accesses to reduce overhead\n+        base_layer = self.base_layer\n+        skip_bias_add = base_layer.skip_bias_add\n+        layer_bias = base_layer.bias\n+\n+        bias = layer_bias if not skip_bias_add else None\n+        output_parallel = base_layer.quant_method.apply(base_layer, input_, bias)\n \n         if self.set_lora:\n             output_parallel = self.apply_lora(output_parallel, input_)\n \n-        if self.base_layer.gather_output:\n+        if base_layer.gather_output:\n             output = tensor_model_parallel_all_gather(output_parallel)\n         else:\n             output = output_parallel\n-        output_bias = self.base_layer.bias if self.base_layer.skip_bias_add else None\n+        output_bias = layer_bias if skip_bias_add else None\n         return output, output_bias\n \n     def slice_lora_a_weights(self, A: torch.Tensor, tp_rank: int):\n@@ -137,18 +140,16 @@ class MergedColumnParallelLinearWithLoRA(ColumnParallelLinearWithLoRA):\n         self.A_buffer_gate_up = A_buffer\n         if self.lora_backend.fuse_stacked_lora_b:\n             # B_buffer_gate_up: (num_lora, 2 * output_dim, r)\n+            # Cache shape values to reduce attribute accesses\n+            b0_shape0, b0_shape1, b0_shape2 = B_buffer[0].shape\n             if not hasattr(self, \"B_buffer_gate_up\") or self.B_buffer_gate_up is None:\n                 self.B_buffer_gate_up = torch.empty(\n-                    (\n-                        B_buffer[0].shape[0],\n-                        2 * B_buffer[0].shape[1],\n-                        B_buffer[0].shape[2],\n-                    ),\n+                    (b0_shape0, 2 * b0_shape1, b0_shape2),\n                     dtype=B_buffer[0].dtype,\n                     device=B_buffer[0].device,\n                 )\n-            self.B_buffer_gate_up[:, : B_buffer[0].shape[1], :].copy_(B_buffer[0])\n-            self.B_buffer_gate_up[:, B_buffer[0].shape[1] :, :].copy_(B_buffer[1])\n+            self.B_buffer_gate_up[:, :b0_shape1, :].copy_(B_buffer[0])\n+            self.B_buffer_gate_up[:, b0_shape1:, :].copy_(B_buffer[1])\n         else:\n             self.B_buffer_gate_up = (B_buffer[0], B_buffer[1])\n \n@@ -202,13 +203,11 @@ class QKVParallelLinearWithLoRA(ColumnParallelLinearWithLoRA):\n             output_dim_q, output_dim_kv = B_buffer_q.shape[-2], B_buffer_kv.shape[-2]\n \n             # B_buffer_qkv: (num_lora, output_dim_q + 2 * output_dim_kv, r)\n+            # Cache shape values to reduce attribute accesses\n+            bq0_shape0, bq0_shape2 = B_buffer_q[0].shape[0], B_buffer_q[0].shape[2]\n             if not hasattr(self, \"B_buffer_qkv\") or self.B_buffer_qkv is None:\n                 self.B_buffer_qkv = torch.empty(\n-                    (\n-                        B_buffer_q[0].shape[0],\n-                        output_dim_q + 2 * output_dim_kv,\n-                        B_buffer_q[0].shape[2],\n-                    ),\n+                    (bq0_shape0, output_dim_q + 2 * output_dim_kv, bq0_shape2),\n                     dtype=B_buffer_q[0].dtype,\n                     device=B_buffer_q[0].device,\n                 )\n@@ -225,16 +224,11 @@ class QKVParallelLinearWithLoRA(ColumnParallelLinearWithLoRA):\n                 self.output_offset = torch.empty(\n                     4, dtype=torch.int32, device=B_buffer_q.device\n                 )\n-            self.output_offset[:4] = torch.tensor(\n-                [\n-                    0,\n-                    output_dim_q,\n-                    output_dim_q + output_dim_kv,\n-                    output_dim_q + 2 * output_dim_kv,\n-                ],\n-                dtype=torch.int32,\n-                device=B_buffer_q.device,\n-            )\n+            # Directly assign values to avoid creating temporary tensor\n+            self.output_offset[0] = 0\n+            self.output_offset[1] = output_dim_q\n+            self.output_offset[2] = output_dim_q + output_dim_kv\n+            self.output_offset[3] = output_dim_q + 2 * output_dim_kv\n             # For computing number of launched blocks\n             self.max_qkv_out_dim = max(output_dim_q, output_dim_kv)\n         else:\n@@ -268,6 +262,7 @@ class QKVParallelLinearWithLoRA(ColumnParallelLinearWithLoRA):\n         self, B: List[torch.Tensor], tp_rank: int\n     ) -> Tuple[torch.Tensor, torch.Tensor]:\n         B_q, B_kv = B\n+        # Cache base_layer attributes to reduce attribute access overhead\n         base_layer = self.base_layer\n         q_proj_shard_size = base_layer.q_proj_shard_size\n         kv_proj_shard_size = base_layer.kv_proj_shard_size\n@@ -312,36 +307,35 @@ class RowParallelLinearWithLoRA(BaseLayerWithLoRA):\n \n     def forward(self, input_: torch.Tensor):\n         # duplicate the logic in RowParallelLinear\n-        if self.base_layer.input_is_parallel:\n+        # Cache attribute accesses to reduce overhead\n+        base_layer = self.base_layer\n+\n+        if base_layer.input_is_parallel:\n             input_parallel = input_\n         else:\n             tp_rank = get_tensor_model_parallel_rank()\n             splitted_input = split_tensor_along_last_dim(\n-                input_, num_partitions=self.base_layer.tp_size\n+                input_, num_partitions=base_layer.tp_size\n             )\n             input_parallel = splitted_input[tp_rank].contiguous()\n-        output_parallel = self.base_layer.quant_method.apply(\n-            self.base_layer, input_parallel\n-        )\n+        output_parallel = base_layer.quant_method.apply(base_layer, input_parallel)\n \n         if self.set_lora:\n             output_parallel = self.apply_lora(output_parallel, input_parallel)\n \n-        if self.base_layer.reduce_results and self.base_layer.tp_size > 1:\n+        if base_layer.reduce_results and base_layer.tp_size > 1:\n             output_ = tensor_model_parallel_all_reduce(output_parallel)\n         else:\n             output_ = output_parallel\n \n-        if not self.base_layer.skip_bias_add:\n-            output = (\n-                output_ + self.base_layer.bias\n-                if self.base_layer.bias is not None\n-                else output_\n-            )\n+        skip_bias_add = base_layer.skip_bias_add\n+        layer_bias = base_layer.bias\n+        if not skip_bias_add:\n+            output = output_ + layer_bias if layer_bias is not None else output_\n             output_bias = None\n         else:\n             output = output_\n-            output_bias = self.base_layer.bias\n+            output_bias = layer_bias\n         return output, output_bias\n \n     def slice_lora_a_weights(self, A: torch.Tensor, tp_rank: int):\n", "model_name_or_path": "gpt-5-2025-08-07"}
