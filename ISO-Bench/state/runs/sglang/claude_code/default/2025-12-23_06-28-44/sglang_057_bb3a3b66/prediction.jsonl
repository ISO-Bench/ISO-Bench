{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-45d6592", "model_patch": "diff --git a/python/sglang/srt/managers/router/infer_batch.py b/python/sglang/srt/managers/router/infer_batch.py\nindex 88f6031..df8d757 100644\n--- a/python/sglang/srt/managers/router/infer_batch.py\n+++ b/python/sglang/srt/managers/router/infer_batch.py\n@@ -238,7 +238,7 @@ class Batch:\n                 logit_bias[i] = int_token_logit_bias\n \n         # Set fields\n-        self.input_ids = torch.tensor(\n+        self.input_ids = torch.as_tensor(\n             flatten_input_ids, dtype=torch.int32, device=device\n         )\n         self.pixel_values = [r.pixel_values for r in reqs]\n@@ -247,29 +247,29 @@ class Batch:\n             r.image_offset - p_len for r, p_len in zip(reqs, prefix_lens)\n         ]\n         self.req_pool_indices = req_pool_indices\n-        self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32, device=device)\n-        self.prefix_lens = torch.tensor(prefix_lens, dtype=torch.int32, device=device)\n+        self.seq_lens = torch.from_numpy(seq_lens).to(dtype=torch.int32, device=device)\n+        self.prefix_lens = torch.from_numpy(prefix_lens).to(dtype=torch.int32, device=device)\n         self.position_ids_offsets = position_ids_offsets\n         self.extend_num_tokens = extend_num_tokens\n         self.out_cache_loc = out_cache_loc\n \n-        self.temperatures = torch.tensor(\n+        self.temperatures = torch.as_tensor(\n             [r.sampling_params.temperature for r in reqs],\n             dtype=torch.float,\n             device=device,\n         ).view(-1, 1)\n-        self.top_ps = torch.tensor(\n+        self.top_ps = torch.as_tensor(\n             [r.sampling_params.top_p for r in reqs], dtype=torch.float, device=device\n         ).view(-1, 1)\n-        self.top_ks = torch.tensor(\n+        self.top_ks = torch.as_tensor(\n             [r.sampling_params.top_k for r in reqs], dtype=torch.int, device=device\n         ).view(-1, 1)\n-        self.frequency_penalties = torch.tensor(\n+        self.frequency_penalties = torch.as_tensor(\n             [r.sampling_params.frequency_penalty for r in reqs],\n             dtype=torch.float,\n             device=device,\n         )\n-        self.presence_penalties = torch.tensor(\n+        self.presence_penalties = torch.as_tensor(\n             [r.sampling_params.presence_penalty for r in reqs],\n             dtype=torch.float,\n             device=device,\n@@ -366,7 +366,7 @@ class Batch:\n             input_ids = [\n                 r.output_ids[-1] if r.output_ids else r.input_ids[-1] for r in self.reqs\n             ]\n-        self.input_ids = torch.tensor(input_ids, dtype=torch.int32, device=\"cuda\")\n+        self.input_ids = torch.as_tensor(input_ids, dtype=torch.int32, device=\"cuda\")\n         self.seq_lens.add_(1)\n         self.prefix_lens = None\n \n@@ -394,7 +394,7 @@ class Batch:\n \n     def filter_batch(self, unfinished_indices: List[int]):\n         self.reqs = [self.reqs[i] for i in unfinished_indices]\n-        new_indices = torch.tensor(unfinished_indices, dtype=torch.int32, device=\"cuda\")\n+        new_indices = torch.as_tensor(unfinished_indices, dtype=torch.int32, device=\"cuda\")\n         self.seq_lens = self.seq_lens[new_indices]\n         self.input_ids = None\n         self.req_pool_indices = self.req_pool_indices[new_indices]\n@@ -447,10 +447,9 @@ class Batch:\n \n         has_regex = any(req.regex_fsm is not None for req in self.reqs)\n         if has_regex:\n-            allowed_mask = torch.empty_like(logits[0], dtype=torch.bool)\n+            allowed_mask = torch.zeros_like(logits[0], dtype=torch.bool)\n             for i, req in enumerate(self.reqs):\n                 if req.regex_fsm is not None:\n-                    allowed_mask.zero_()\n                     allowed_mask[\n                         req.regex_fsm.allowed_token_ids(req.regex_fsm_state)\n                     ] = 1\ndiff --git a/python/sglang/srt/managers/router/model_rpc.py b/python/sglang/srt/managers/router/model_rpc.py\nindex 8b7adf9..55e7364 100644\n--- a/python/sglang/srt/managers/router/model_rpc.py\n+++ b/python/sglang/srt/managers/router/model_rpc.py\n@@ -85,7 +85,7 @@ class ModelRpcServer(rpyc.Service):\n             self.model_config.context_len,\n             self.max_total_num_token // 6 if server_args.max_prefill_num_token is None else server_args.max_prefill_num_token,\n         )\n-        self.int_token_logit_bias = torch.tensor(\n+        self.int_token_logit_bias = torch.as_tensor(\n             get_int_token_logit_bias(self.tokenizer, self.model_config.vocab_size)\n         )\n         set_random_seed(server_args.random_seed)\n", "model_name_or_path": "gpt-5-2025-08-07"}
