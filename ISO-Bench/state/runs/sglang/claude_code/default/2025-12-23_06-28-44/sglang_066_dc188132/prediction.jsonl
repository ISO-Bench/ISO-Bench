{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-10bfce7", "model_patch": "diff --git a/python/sglang/srt/mem_cache/memory_pool.py b/python/sglang/srt/mem_cache/memory_pool.py\nindex e307367..df50fb4 100644\n--- a/python/sglang/srt/mem_cache/memory_pool.py\n+++ b/python/sglang/srt/mem_cache/memory_pool.py\n@@ -59,7 +59,7 @@ class ReqToTokenPool:\n         self.max_context_len = max_context_len\n         self.device = device\n         with memory_saver_adapter.region():\n-            self.req_to_token = torch.zeros(\n+            self.req_to_token = torch.empty(\n                 (size, max_context_len), dtype=torch.int32, device=device\n             )\n         self.free_slots = list(range(size))\n@@ -245,7 +245,7 @@ class MHATokenToKVPool(BaseTokenToKVPool):\n     @debug_timing\n     def transfer(self, indices, flat_data):\n         # transfer prepared data from host to device\n-        flat_data = flat_data.to(device=self.device, non_blocking=False)\n+        flat_data = flat_data.to(device=self.device, non_blocking=True)\n         k_data, v_data = flat_data[0], flat_data[1]\n         for i in range(self.layer_num):\n             self.k_buffer[i][indices] = k_data[i]\n@@ -486,9 +486,10 @@ class MLATokenToKVPoolHost:\n         )\n \n         # Initialize memory states and tracking structures.\n-        self.mem_state = torch.zeros(\n+        self.mem_state = torch.empty(\n             (self.size,), dtype=torch.uint8, device=self.device\n         )\n+        self.mem_state.fill_(0)\n         self.free_slots = torch.arange(self.size, dtype=torch.int32)\n         self.can_use_mem_size = self.size\n \n@@ -502,7 +503,7 @@ class MLATokenToKVPoolHost:\n     def transfer(self, indices, flat_data):\n         # backup prepared data from device to host\n         self.kv_buffer[:, :, indices] = flat_data.to(\n-            device=self.device, non_blocking=False\n+            device=self.device, non_blocking=True\n         )\n \n     @synchronized\n", "model_name_or_path": "gpt-5-2025-08-07"}
