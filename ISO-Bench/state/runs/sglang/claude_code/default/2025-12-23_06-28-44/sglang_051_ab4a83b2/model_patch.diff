diff --git a/python/sglang/srt/managers/policy_scheduler.py b/python/sglang/srt/managers/policy_scheduler.py
index 04169e8..845bc22 100644
--- a/python/sglang/srt/managers/policy_scheduler.py
+++ b/python/sglang/srt/managers/policy_scheduler.py
@@ -68,9 +68,8 @@ class PolicyScheduler:
             for req in waiting_queue:
                 last_node_to_reqs[req.last_node].append(req)
 
-            node_to_weight = defaultdict(int)
-            for node in last_node_to_reqs:
-                node_to_weight[node] = len(last_node_to_reqs[node])
+            # Optimize: use dict comprehension instead of loop
+            node_to_weight = defaultdict(int, {node: len(reqs) for node, reqs in last_node_to_reqs.items()})
             self.calc_weight(self.tree_cache.root_node, node_to_weight)
 
             waiting_queue.clear()
@@ -97,8 +96,8 @@ class PolicyScheduler:
         last_node_to_reqs: Dict,
         q: List,
     ):
-        childs = [child for child in cur_node.children.values()]
-        childs.sort(key=lambda x: -node_to_priority[x])
+        # Optimize: use sorted() directly instead of list comprehension + sort
+        childs = sorted(cur_node.children.values(), key=lambda x: -node_to_priority[x])
         for child in childs:
             self.get_dfs_priority(child, node_to_priority, last_node_to_reqs, q)
         q.extend(last_node_to_reqs[cur_node])
diff --git a/python/sglang/srt/managers/tp_worker.py b/python/sglang/srt/managers/tp_worker.py
index 8fc03b8..6d1a29f 100644
--- a/python/sglang/srt/managers/tp_worker.py
+++ b/python/sglang/srt/managers/tp_worker.py
@@ -487,7 +487,9 @@ class ModelTpServer:
             self.token_to_kv_pool,
             self.tree_cache,
         )
-        self.waiting_queue = [x for x in self.waiting_queue if x not in can_run_list]
+        # Optimize: use set for O(1) lookup instead of O(n) list lookup
+        can_run_set = set(can_run_list)
+        self.waiting_queue = [x for x in self.waiting_queue if x not in can_run_set]
         return new_batch
 
     def forward_prefill_batch(self, batch: ScheduleBatch):
@@ -931,7 +933,8 @@ def broadcast_recv_input(
         else:
             serialized_data = pickle.dumps(data)
             size = len(serialized_data)
-            tensor_data = torch.ByteTensor(list(serialized_data))
+            # Optimize: use frombuffer instead of list conversion
+            tensor_data = torch.frombuffer(serialized_data, dtype=torch.uint8).clone()
             tensor_size = torch.tensor([size], dtype=torch.long)
 
             dist.broadcast(tensor_size, src=0, group=dist_group)
@@ -948,6 +951,7 @@ def broadcast_recv_input(
         tensor_data = torch.empty(size, dtype=torch.uint8)
         dist.broadcast(tensor_data, src=0, group=dist_group)
 
-        serialized_data = bytes(tensor_data.tolist())
+        # Optimize: use numpy tobytes instead of list conversion
+        serialized_data = tensor_data.cpu().numpy().tobytes()
         data = pickle.loads(serialized_data)
         return data
