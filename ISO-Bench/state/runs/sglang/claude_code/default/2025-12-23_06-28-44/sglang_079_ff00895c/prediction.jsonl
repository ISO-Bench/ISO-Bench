{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-ff91474", "model_patch": "diff --git a/sgl-kernel/csrc/cpu/norm.cpp b/sgl-kernel/csrc/cpu/norm.cpp\nindex 391a0d4..7dce52e 100644\n--- a/sgl-kernel/csrc/cpu/norm.cpp\n+++ b/sgl-kernel/csrc/cpu/norm.cpp\n@@ -25,9 +25,9 @@ void rmsnorm_kernel_impl(\n       fVec sum_fvec = fVec(float(0));\n       float sum_val = float(0);\n \n-      int64_t d;\n-#pragma GCC unroll 4\n-      for (d = 0; d <= hidden_size - kVecSize; d += kVecSize) {\n+      int64_t d = 0;\n+#pragma GCC unroll 8\n+      for (; d <= hidden_size - kVecSize; d += kVecSize) {\n         bVec x_bvec = bVec::loadu(input_ptr + d);\n         fVec x_fvec0, x_fvec1;\n         std::tie(x_fvec0, x_fvec1) = at::vec::convert_to_float(x_bvec);\n@@ -35,7 +35,7 @@ void rmsnorm_kernel_impl(\n         sum_fvec += x_fvec0 * x_fvec0;\n         sum_fvec += x_fvec1 * x_fvec1;\n       }\n-#pragma GCC unroll 4\n+#pragma GCC unroll 8\n       for (; d < hidden_size; ++d) {\n         float x_val = static_cast<float>(input_ptr[d]);\n         sum_val += x_val * x_val;\n@@ -45,8 +45,9 @@ void rmsnorm_kernel_impl(\n       float rsqrt_var = float(1) / std::sqrt(sum_val / hidden_size + eps);\n       const fVec scale_fvec = fVec(rsqrt_var);\n \n-#pragma GCC unroll 4\n-      for (d = 0; d <= hidden_size - kVecSize; d += kVecSize) {\n+      d = 0;\n+#pragma GCC unroll 8\n+      for (; d <= hidden_size - kVecSize; d += kVecSize) {\n         bVec x_bvec = bVec::loadu(input_ptr + d);\n         fVec x_fvec0, x_fvec1;\n         std::tie(x_fvec0, x_fvec1) = at::vec::convert_to_float(x_bvec);\n@@ -61,7 +62,7 @@ void rmsnorm_kernel_impl(\n         bVec out_bvec = convert_from_float_ext<scalar_t>(x_fvec0, x_fvec1);\n         out_bvec.store(out_ptr + d);\n       }\n-#pragma GCC unroll 4\n+#pragma GCC unroll 8\n       for (; d < hidden_size; ++d) {\n         float x_val = static_cast<float>(input_ptr[d]);\n         float w_val = static_cast<float>(weight[d]);\n@@ -96,9 +97,9 @@ void fused_add_rmsnorm_kernel_impl(\n       fVec sum_fvec = fVec(float(0));\n       float sum_val = float(0);\n \n-      int64_t d;\n-#pragma GCC unroll 4\n-      for (d = 0; d <= hidden_size - kVecSize; d += kVecSize) {\n+      int64_t d = 0;\n+#pragma GCC unroll 8\n+      for (; d <= hidden_size - kVecSize; d += kVecSize) {\n         bVec x_bvec = bVec::loadu(input_ptr + d);\n         fVec x_fvec0, x_fvec1;\n         std::tie(x_fvec0, x_fvec1) = at::vec::convert_to_float(x_bvec);\n@@ -119,7 +120,7 @@ void fused_add_rmsnorm_kernel_impl(\n         x_fvec0.store(buffer_ptr + d);\n         x_fvec1.store(buffer_ptr + d + fVec::size());\n       }\n-#pragma GCC unroll 4\n+#pragma GCC unroll 8\n       for (; d < hidden_size; ++d) {\n         float x_val = static_cast<float>(input_ptr[d]);\n         float r_val = static_cast<float>(residual_ptr[d]);\n@@ -135,8 +136,9 @@ void fused_add_rmsnorm_kernel_impl(\n       float rsqrt_var = float(1) / std::sqrt(sum_val / hidden_size + eps);\n       const fVec scale_fvec = fVec(rsqrt_var);\n \n-#pragma GCC unroll 4\n-      for (d = 0; d <= hidden_size - kVecSize; d += kVecSize) {\n+      d = 0;\n+#pragma GCC unroll 8\n+      for (; d <= hidden_size - kVecSize; d += kVecSize) {\n         fVec x_fvec0 = fVec::loadu(buffer_ptr + d);\n         fVec x_fvec1 = fVec::loadu(buffer_ptr + d + fVec::size());\n \n@@ -149,7 +151,7 @@ void fused_add_rmsnorm_kernel_impl(\n         bVec x_bvec = convert_from_float_ext<scalar_t>(x_fvec0, x_fvec1);\n         x_bvec.store(input_ptr + d);\n       }\n-#pragma GCC unroll 4\n+#pragma GCC unroll 8\n       for (; d < hidden_size; ++d) {\n         float x_val = buffer_ptr[d] * rsqrt_var * static_cast<float>(weight[d]);\n         input_ptr[d] = x_val;\ndiff --git a/sgl-kernel/csrc/cpu/rope.cpp b/sgl-kernel/csrc/cpu/rope.cpp\nindex 64bc297..7e03023 100644\n--- a/sgl-kernel/csrc/cpu/rope.cpp\n+++ b/sgl-kernel/csrc/cpu/rope.cpp\n@@ -39,6 +39,7 @@ void rope_kernel_impl(\n       cos_start = t_emb_pos + p * HR;\n       // step 1) apply_rotary_pos_emb for the rotary_dim elements in every\n       // head of query/key\n+#pragma GCC unroll 4\n       for (int64_t h = 0; h < rotary_dim; h += 2) {\n         scalar_t cos = cos_start[h >> 1];\n         scalar_t sin = sin_start[h >> 1];\n@@ -49,10 +50,11 @@ void rope_kernel_impl(\n         q_pe_out[out_offset_q + h] = out1;\n         q_pe_out[out_offset_q + h + 1] = out2;\n       }\n+      int64_t k_pe_offset = seq * k_pe_stride_s;\n+#pragma GCC unroll 4\n       for (int64_t h = 0; h < HK; h += 2) {\n         scalar_t cos = cos_start[h >> 1];\n         scalar_t sin = sin_start[h >> 1];\n-        int64_t k_pe_offset = seq * k_pe_stride_s;\n         scalar_t in1_k = k_pe[k_pe_offset + h];\n         scalar_t in2_k = k_pe[k_pe_offset + h + 1];\n         scalar_t out1_k = in1_k * cos - in2_k * sin;\ndiff --git a/sgl-kernel/csrc/cpu/topk.cpp b/sgl-kernel/csrc/cpu/topk.cpp\nindex 6a6b64d..6b672ef 100644\n--- a/sgl-kernel/csrc/cpu/topk.cpp\n+++ b/sgl-kernel/csrc/cpu/topk.cpp\n@@ -81,20 +81,23 @@ void grouped_topk_kernel_impl(\n     alignas(64) float scores[NUM_EXPERTS];\n \n     using elem_t = std::pair<float, int32_t>;\n-    std::vector<elem_t> queue(num_groups);\n-    std::vector<elem_t> queue2(topk_group * num_experts_per_group);\n+    std::vector<elem_t> queue;\n+    queue.reserve(num_groups);\n+    std::vector<elem_t> queue2;\n+    queue2.reserve(topk_group * num_experts_per_group);\n \n     for (int64_t i = begin; i < end; ++i) {\n       // do softmax to get scores\n       softmax<scalar_t, NUM_EXPERTS>(scores, gating_output + i * NUM_EXPERTS);\n \n       // find max score per group\n+      queue.clear();\n       for (int64_t g = 0; g < num_groups; ++g) {\n         float gmax = -std::numeric_limits<float>::infinity();\n         for (int64_t e = 0; e < num_experts_per_group; ++e) {\n           gmax = std::max(gmax, scores[g * num_experts_per_group + e]);\n         }\n-        queue[g] = {gmax, g};\n+        queue.push_back({gmax, g});\n       }\n \n       // find group topk\n@@ -103,11 +106,12 @@ void grouped_topk_kernel_impl(\n             return x.first > y.first;\n           });\n \n+      queue2.clear();\n       for (int64_t g = 0; g < topk_group; ++g) {\n         int32_t group_idx = queue[g].second;\n         for (int64_t e = 0; e < num_experts_per_group; ++e) {\n           int32_t expert_idx = group_idx * num_experts_per_group + e;\n-          queue2[g * num_experts_per_group + e] = {scores[expert_idx], expert_idx};\n+          queue2.push_back({scores[expert_idx], expert_idx});\n         }\n       }\n \n@@ -194,14 +198,17 @@ void biased_grouped_topk_kernel_impl(\n     alignas(64) float scores2[NUM_EXPERTS];\n \n     using elem_t = std::pair<float, int32_t>;\n-    std::vector<elem_t> queue(num_groups);\n-    std::vector<elem_t> queue2(topk_group * num_experts_per_group);\n+    std::vector<elem_t> queue;\n+    queue.reserve(num_groups);\n+    std::vector<elem_t> queue2;\n+    queue2.reserve(topk_group * num_experts_per_group);\n \n     for (int64_t i = begin; i < end; ++i) {\n       // do sigmoid to get scores\n       sigmoid<scalar_t, NUM_EXPERTS>(scores, gating_output + i * NUM_EXPERTS);\n       apply_bias<scalar_t, NUM_EXPERTS>(scores2, scores, bias);\n \n+      queue.clear();\n       for (int64_t g = 0; g < num_groups; ++g) {\n         // find the max\n         float gmax = at::vec::reduce_all<float>(\n@@ -228,7 +235,7 @@ void biased_grouped_topk_kernel_impl(\n         // restore scores for choice\n         scores2[first_max_idx] = gmax;\n \n-        queue[g] = {gmax + gmax2, g};\n+        queue.push_back({gmax + gmax2, g});\n       }\n \n       // find group topk\n@@ -237,11 +244,12 @@ void biased_grouped_topk_kernel_impl(\n             return x.first > y.first;\n           });\n \n+      queue2.clear();\n       for (int64_t g = 0; g < topk_group; ++g) {\n         int32_t group_idx = queue[g].second;\n         for (int64_t e = 0; e < num_experts_per_group; ++e) {\n           int32_t expert_idx = group_idx * num_experts_per_group + e;\n-          queue2[g * num_experts_per_group + e] = {scores2[expert_idx], expert_idx};\n+          queue2.push_back({scores2[expert_idx], expert_idx});\n         }\n       }\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
