{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-36fc926", "model_patch": "diff --git a/python/sglang/srt/layers/moe/ep_moe/layer.py b/python/sglang/srt/layers/moe/ep_moe/layer.py\nindex 66fbb36..3624b4f 100644\n--- a/python/sglang/srt/layers/moe/ep_moe/layer.py\n+++ b/python/sglang/srt/layers/moe/ep_moe/layer.py\n@@ -351,13 +351,14 @@ class DeepEPMoE(EPMoE):\n             # for instance, if we have 4 experts on this rank, we would have a expert_mask like:\n             #     self.expert_mask = [1, 1, 1, 1, 0]\n             # idx from 0-3 is valid and will be processed, while idx == 4 will be masked out\n-            self.expert_mask = torch.zeros(\n+            self.expert_mask = torch.empty(\n                 (self.num_local_experts + 1),\n                 device=torch.cuda.current_device(),\n                 dtype=torch.int,\n             )\n             # the last one is invalid rank_id\n             self.expert_mask[:-1] = 1\n+            self.expert_mask[-1] = 0\n         else:\n             self.w13_weight_fp8 = (\n                 self.w13_weight,\n@@ -502,8 +503,7 @@ class DeepEPMoE(EPMoE):\n                 dtype=hidden_states_fp8.dtype,\n             ),\n             (\n-                # TODO check whether need `zeros`\n-                torch.zeros(\n+                torch.empty(\n                     (ceil_div(K // 128, 4), all_tokens),\n                     device=hidden_states_fp8.device,\n                     dtype=torch.int,\ndiff --git a/python/sglang/srt/layers/moe/fused_moe_triton/layer.py b/python/sglang/srt/layers/moe/fused_moe_triton/layer.py\nindex d0a9ed1..efe99e6 100644\n--- a/python/sglang/srt/layers/moe/fused_moe_triton/layer.py\n+++ b/python/sglang/srt/layers/moe/fused_moe_triton/layer.py\n@@ -127,9 +127,6 @@ class FusedMoE(torch.nn.Module):\n             self.expert_map_cpu = torch.full(\n                 (self.num_experts,), -1, dtype=torch.int32, device=\"cpu\"\n             )\n-            self.expert_map_cpu = torch.full(\n-                (self.num_experts,), -1, dtype=torch.int32, device=\"cpu\"\n-            )\n             # Create a expert map for the local experts\n             self.expert_map_cpu[\n                 self.moe_ep_rank\n", "model_name_or_path": "gpt-5-2025-08-07"}
