{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-9282306", "model_patch": "diff --git a/python/sglang/srt/speculative/eagle_utils.py b/python/sglang/srt/speculative/eagle_utils.py\nindex 19fa180..348e955 100644\n--- a/python/sglang/srt/speculative/eagle_utils.py\n+++ b/python/sglang/srt/speculative/eagle_utils.py\n@@ -117,10 +117,12 @@ class EagleDraftInput:\n     ):\n         bs = self.accept_length.numel()\n \n-        qo_indptr = torch.zeros((bs + 1,), dtype=torch.int32, device=\"cuda\")\n+        qo_indptr = torch.empty((bs + 1,), dtype=torch.int32, device=\"cuda\")\n+        qo_indptr[0] = 0\n         qo_indptr[1:] = torch.cumsum(self.accept_length, dim=0)\n \n-        cum_kv_seq_len = torch.zeros((bs + 1,), dtype=torch.int32, device=\"cuda\")\n+        cum_kv_seq_len = torch.empty((bs + 1,), dtype=torch.int32, device=\"cuda\")\n+        cum_kv_seq_len[0] = 0\n         cum_kv_seq_len[1:] = torch.cumsum(paged_kernel_lens, dim=0)\n \n         # TODO: replace cum_kv_seq_len[-1] with paged_kernel_lens_sum to avoid the device sync.\n@@ -278,9 +280,10 @@ class EagleVerifyInput:\n             dtype=torch.int32,\n             device=\"cuda\",\n         )\n-        cum_kv_seq_len = torch.zeros(\n+        cum_kv_seq_len = torch.empty(\n             (batch_size + 1,), dtype=torch.int32, device=\"cuda\"\n         )\n+        cum_kv_seq_len[0] = 0\n \n         paged_kernel_lens = paged_kernel_lens + self.draft_token_num\n         cum_kv_seq_len[1:] = torch.cumsum(paged_kernel_lens, dim=0)\n@@ -738,12 +741,13 @@ def select_top_k_tokens(\n         hidden_states = hidden_states.repeat_interleave(topk, dim=0)\n         scores = topk_p  # shape: (b, topk)\n \n+        # Optimize: use expand instead of repeat for memory efficiency\n         tree_info = (\n             topk_p.unsqueeze(1),  # shape: (b, 1, topk)\n             topk_index,  # shape: (b, topk)\n             torch.arange(-1, topk, dtype=torch.long, device=\"cuda\")\n             .unsqueeze(0)\n-            .repeat(topk_p.shape[0], 1),  # shape: (b, topk + 1)\n+            .expand(topk_p.shape[0], -1),  # shape: (b, topk + 1)\n         )\n     else:\n         # The later decode steps\n", "model_name_or_path": "gpt-5-2025-08-07"}
