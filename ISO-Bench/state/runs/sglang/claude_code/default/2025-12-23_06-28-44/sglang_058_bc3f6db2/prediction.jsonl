{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-aac531c", "model_patch": "diff --git a/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py b/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\nindex 100fa57..7e7eec7 100644\n--- a/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\n+++ b/python/sglang/srt/layers/moe/ep_moe/token_dispatcher.py\n@@ -180,7 +180,7 @@ class _DeepEPDispatcherImplNormal(_DeepEPDispatcherImplBase):\n             reorder_topk_ids = torch.empty(\n                 (0,), device=hidden_states.device, dtype=torch.int64\n             )\n-            seg_indptr = torch.zeros(\n+            seg_indptr = torch.empty(\n                 (num_experts + 1,), device=hidden_states.device, dtype=torch.int64\n             )\n \n@@ -311,7 +311,7 @@ class _DeepEPDispatcherImplNormal(_DeepEPDispatcherImplBase):\n                 BLOCK_SIZE=512,\n             )\n         else:\n-            output = torch.zeros(\n+            output = torch.empty(\n                 (0, hidden_states.shape[1]),\n                 device=hidden_states.device,\n                 dtype=hidden_states.dtype,\ndiff --git a/python/sglang/srt/model_executor/forward_batch_info.py b/python/sglang/srt/model_executor/forward_batch_info.py\nindex 96a13a9..47c67d4 100644\n--- a/python/sglang/srt/model_executor/forward_batch_info.py\n+++ b/python/sglang/srt/model_executor/forward_batch_info.py\n@@ -280,7 +280,7 @@ class ForwardBatch:\n             ).to(device, non_blocking=True)\n \n             sum_len = sum(batch.global_num_tokens)\n-            ret.gathered_buffer = torch.zeros(\n+            ret.gathered_buffer = torch.empty(\n                 (sum_len, model_runner.model_config.hidden_size),\n                 dtype=model_runner.dtype,\n                 device=device,\n@@ -515,7 +515,8 @@ def compute_position_torch(\n         ],\n         axis=0,\n     )\n-    extend_start_loc = torch.zeros_like(extend_seq_lens)\n+    extend_start_loc = torch.empty_like(extend_seq_lens)\n+    extend_start_loc[0] = 0\n     extend_start_loc[1:] = torch.cumsum(extend_seq_lens[:-1], dim=0)\n     return positions.to(torch.int64), extend_start_loc\n \ndiff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py\nindex d973f1b..451a9f3 100644\n--- a/python/sglang/srt/models/deepseek_v2.py\n+++ b/python/sglang/srt/models/deepseek_v2.py\n@@ -298,8 +298,8 @@ class DeepseekV2MoE(nn.Module):\n         self, hidden_states: torch.Tensor, forward_mode: ForwardMode\n     ) -> torch.Tensor:\n         shared_output = None\n-        topk_idx = torch.full(\n-            (0, self.top_k), -1, dtype=torch.int, device=hidden_states.device\n+        topk_idx = torch.empty(\n+            (0, self.top_k), dtype=torch.int, device=hidden_states.device\n         )\n         topk_weights = torch.empty(\n             (0, self.top_k), dtype=torch.float32, device=hidden_states.device\n", "model_name_or_path": "gpt-5-2025-08-07"}
