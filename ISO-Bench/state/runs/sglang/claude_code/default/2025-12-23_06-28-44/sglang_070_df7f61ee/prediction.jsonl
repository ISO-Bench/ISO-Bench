{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-ef21729", "model_patch": "diff --git a/python/sglang/srt/managers/expert_location.py b/python/sglang/srt/managers/expert_location.py\nindex 615e0a4..23462b5 100644\n--- a/python/sglang/srt/managers/expert_location.py\n+++ b/python/sglang/srt/managers/expert_location.py\n@@ -266,6 +266,7 @@ def _compute_logical_to_all_physical_map(\n     # This is rarely called, so we use for loops for maximum clarity\n \n     num_layers, num_physical_experts = physical_to_logical_map.shape\n+    device = physical_to_logical_map.device\n \n     logical_to_all_physical_map = [\n         [[] for _ in range(num_logical_experts)] for _ in range(num_layers)\n@@ -284,7 +285,7 @@ def _compute_logical_to_all_physical_map(\n     )\n \n     return torch.tensor(\n-        logical_to_all_physical_map, device=physical_to_logical_map.device\n+        logical_to_all_physical_map, dtype=torch.int64, device=device\n     )\n \n \n@@ -311,11 +312,11 @@ def compute_logical_to_rank_dispatch_physical_map(\n     num_layers, num_logical_experts, _ = logical_to_all_physical_map.shape\n     dtype = logical_to_all_physical_map.dtype\n \n-    logical_to_rank_dispatch_physical_map = torch.full(\n+    logical_to_rank_dispatch_physical_map = torch.empty(\n         size=(num_gpus, num_layers, num_logical_experts),\n-        fill_value=-1,\n         dtype=dtype,\n     )\n+    logical_to_rank_dispatch_physical_map.fill_(-1)\n \n     for layer_id in range(num_layers):\n         for logical_expert_id in range(num_logical_experts):\n@@ -339,10 +340,12 @@ def compute_logical_to_rank_dispatch_physical_map(\n                     output_partial[gpu_id] = same_gpu_physical_expert_ids[0]\n \n             num_remain = torch.sum(output_partial == -1).item()\n-            output_partial[output_partial == -1] = torch.tensor(\n-                _fair_choices(candidate_physical_expert_ids, k=num_remain, r=r),\n-                dtype=dtype,\n-            )\n+            if num_remain > 0:\n+                fair_choices_result = _fair_choices(candidate_physical_expert_ids, k=num_remain, r=r)\n+                output_partial[output_partial == -1] = torch.tensor(\n+                    fair_choices_result,\n+                    dtype=dtype,\n+                )\n \n     assert torch.all(logical_to_rank_dispatch_physical_map != -1)\n \ndiff --git a/python/sglang/srt/managers/expert_location_dispatch.py b/python/sglang/srt/managers/expert_location_dispatch.py\nindex 6880b01..a45af0b 100644\n--- a/python/sglang/srt/managers/expert_location_dispatch.py\n+++ b/python/sglang/srt/managers/expert_location_dispatch.py\n@@ -63,7 +63,8 @@ def transform_select_experts_inputs(\n     if (info is not None) and (info.ep_dispatch_algorithm == \"fake\"):\n         router_logits = torch.randn_like(router_logits)\n         if correction_bias is not None:\n-            correction_bias = torch.zeros_like(correction_bias)\n+            correction_bias = torch.empty_like(correction_bias)\n+            correction_bias.fill_(0)\n     return router_logits, correction_bias\n \n \n@@ -91,13 +92,13 @@ def _topk_ids_logical_to_physical_dynamic(\n ) -> torch.Tensor:\n     topk_ids_original_shape = topk_ids.shape\n     device = topk_ids.device\n-    topk_ids = topk_ids.flatten()\n+    topk_ids_flat = topk_ids.flatten()\n \n+    num_valid = info.partial_logical_to_all_physical_map_num_valid[topk_ids_flat]\n     chosen_dispatch_index = (\n-        torch.randint(0, 65536, topk_ids.shape, dtype=torch.int32, device=device)\n-        % info.partial_logical_to_all_physical_map_num_valid[topk_ids]\n+        torch.randint(0, 65536, topk_ids_flat.shape, dtype=torch.int32, device=device)\n+        % num_valid\n     )\n-    topk_ids = info.partial_logical_to_all_physical_map[topk_ids, chosen_dispatch_index]\n+    result = info.partial_logical_to_all_physical_map[topk_ids_flat, chosen_dispatch_index]\n \n-    topk_ids = topk_ids.view(topk_ids_original_shape)\n-    return topk_ids\n+    return result.view(topk_ids_original_shape)\n", "model_name_or_path": "gpt-5-2025-08-07"}
