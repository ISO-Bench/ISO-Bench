{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-b170930", "model_patch": "diff --git a/python/sglang/srt/server.py b/python/sglang/srt/server.py\nindex dea4a7d04..626fadc49 100644\n--- a/python/sglang/srt/server.py\n+++ b/python/sglang/srt/server.py\n@@ -28,7 +28,8 @@ import os\n import threading\n import time\n from http import HTTPStatus\n-from typing import Dict, List, Optional, Union\n+from typing import Dict, List, Optional, Union, AsyncIterator\n+import orjson\n \n # Fix a bug of Python threading\n setattr(threading, \"_register_atexit\", lambda *args, **kwargs: None)\n@@ -192,14 +193,16 @@ async def generate_request(obj: GenerateReqInput, request: Request):\n     \"\"\"Handle a generate request.\"\"\"\n     if obj.stream:\n \n-        async def stream_results():\n+        async def stream_results() -> AsyncIterator[bytes]:\n             try:\n                 async for out in tokenizer_manager.generate_request(obj, request):\n-                    yield f\"data: {json.dumps(out, ensure_ascii=False)}\\n\\n\"\n+                    yield b\"data: \" + orjson.dumps(\n+                        out, option=orjson.OPT_NON_STR_KEYS\n+                    ) + b\"\\n\\n\"\n             except ValueError as e:\n                 out = {\"error\": {\"message\": str(e)}}\n-                yield f\"data: {json.dumps(out, ensure_ascii=False)}\\n\\n\"\n-            yield \"data: [DONE]\\n\\n\"\n+                yield b\"data: \" + orjson.dumps(out) + b\"\\n\\n\"\n+            yield b\"data: [DONE]\\n\\n\"\n \n         return StreamingResponse(\n             stream_results(),\n@@ -639,7 +642,7 @@ class Runtime:\n                     if chunk and chunk.startswith(\"data:\"):\n                         if chunk == \"data: [DONE]\\n\\n\":\n                             break\n-                        data = json.loads(chunk[5:].strip(\"\\n\"))\n+                        data = orjson.loads(chunk[5:].strip(\"\\n\"))\n                         if \"text\" in data:\n                             cur = data[\"text\"][pos:]\n                             if cur:\n@@ -672,7 +675,7 @@ class Runtime:\n             self.url + \"/generate\",\n             json=json_data,\n         )\n-        return json.dumps(response.json())\n+        return response.text\n \n     def encode(\n         self,\n@@ -696,7 +699,7 @@ class Runtime:\n                 self.url + \"/judge\",\n                 json=json_data,\n             )\n-        return json.dumps(response.json())\n+        return response.text\n \n     def __del__(self):\n         self.shutdown()\n@@ -755,12 +758,18 @@ class Engine:\n                 while True:\n                     chunk = loop.run_until_complete(generator.__anext__())\n \n+                    if isinstance(chunk, (bytes, bytearray)):\n+                        chunk = chunk.decode(\"utf-8\")\n+\n                     if chunk.startswith(STREAM_END_SYMBOL):\n                         break\n                     else:\n-                        data = json.loads(chunk[len(STREAM_CHUNK_START_SYMBOL) :])\n-                        data[\"text\"] = data[\"text\"][offset:]\n-                        offset += len(data[\"text\"])\n+                        payload = chunk[len(STREAM_CHUNK_START_SYMBOL) :].strip()\n+                        data = orjson.loads(payload)\n+                        text = data.get(\"text\")\n+                        if text is not None:\n+                            data[\"text\"] = text[offset:]\n+                            offset += len(data[\"text\"])\n                         yield data\n \n             # we cannot yield in the scope of generate() because python does not allow yield + return in the same function\n@@ -804,12 +813,18 @@ class Engine:\n                 while True:\n                     chunk = await generator.__anext__()\n \n+                    if isinstance(chunk, (bytes, bytearray)):\n+                        chunk = chunk.decode(\"utf-8\")\n+\n                     if chunk.startswith(STREAM_END_SYMBOL):\n                         break\n                     else:\n-                        data = json.loads(chunk[len(STREAM_CHUNK_START_SYMBOL) :])\n-                        data[\"text\"] = data[\"text\"][offset:]\n-                        offset += len(data[\"text\"])\n+                        payload = chunk[len(STREAM_CHUNK_START_SYMBOL) :].strip()\n+                        data = orjson.loads(payload)\n+                        text = data.get(\"text\")\n+                        if text is not None:\n+                            data[\"text\"] = text[offset:]\n+                            offset += len(data[\"text\"])\n                         yield data\n \n             return generator_wrapper()\n", "model_name_or_path": "gpt-5-2025-08-07"}
