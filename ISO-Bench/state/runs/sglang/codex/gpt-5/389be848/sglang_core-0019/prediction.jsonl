{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-d818966", "model_patch": "diff --git a/python/sglang/srt/layers/moe/topk.py b/python/sglang/srt/layers/moe/topk.py\nindex 8895e6be6..21e23c215 100644\n--- a/python/sglang/srt/layers/moe/topk.py\n+++ b/python/sglang/srt/layers/moe/topk.py\n@@ -49,10 +49,7 @@ def fused_topk_native(\n         hidden_states.shape[0] == gating_output.shape[0]\n     ), f\"Number of tokens mismatch, {hidden_states.shape=} vs {gating_output.shape=}\"\n     M, _ = hidden_states.shape\n-    topk_weights = torch.empty(\n-        M, topk, dtype=torch.float32, device=hidden_states.device\n-    )\n-    topk_ids = torch.empty(M, topk, dtype=torch.int32, device=hidden_states.device)\n+    # Avoid unnecessary pre-allocation; topk returns new tensors\n     topk_weights = F.softmax(gating_output.float(), dim=-1)\n     topk_weights, topk_ids = torch.topk(topk_weights, topk, dim=-1)\n     if renormalize:\n@@ -117,14 +114,15 @@ def grouped_topk(\n     group_idx = torch.topk(group_scores, k=topk_group, dim=-1, sorted=False)[\n         1\n     ]  # [n, top_k_group]\n-    group_mask = torch.zeros_like(group_scores)  # [n, n_group]\n-    group_mask.scatter_(1, group_idx, 1)  # [n, n_group]\n+    # Use boolean mask to reduce memory bandwidth and avoid casts\n+    group_mask = torch.zeros_like(group_scores, dtype=torch.bool)  # [n, n_group]\n+    group_mask.scatter_(1, group_idx, True)  # [n, n_group]\n     score_mask = (\n         group_mask.unsqueeze(-1)\n         .expand(num_token, num_expert_group, scores.shape[-1] // num_expert_group)\n         .reshape(num_token, -1)\n     )  # [n, e]\n-    tmp_scores = scores.masked_fill(~score_mask.bool(), 0.0)  # [n, e]\n+    tmp_scores = scores.masked_fill(~score_mask, 0.0)  # [n, e]\n     topk_weights, topk_ids = torch.topk(tmp_scores, k=topk, dim=-1, sorted=False)\n     if n_share_experts_fusion:\n         topk_ids[:, -1] = torch.randint(\n@@ -146,7 +144,8 @@ def grouped_topk(\n \n     topk_weights, topk_ids = topk_weights.to(torch.float32), topk_ids.to(torch.int32)\n     topk_ids = topk_ids_logical_to_physical(topk_ids, expert_location_dispatch_info)\n-    _mask_topk_ids_padded_region(topk_ids, num_token_non_padded)\n+    if num_token_non_padded is not None:\n+        _mask_topk_ids_padded_region(topk_ids, num_token_non_padded)\n     return topk_weights, topk_ids\n \n \n@@ -177,16 +176,15 @@ def biased_grouped_topk_impl(\n     group_idx = torch.topk(group_scores, k=topk_group, dim=-1, sorted=False)[\n         1\n     ]  # [n, top_k_group]\n-    group_mask = torch.zeros_like(group_scores)  # [n, n_group]\n-    group_mask.scatter_(1, group_idx, 1)  # [n, n_group]\n+    # Use boolean mask to reduce memory bandwidth and avoid casts\n+    group_mask = torch.zeros_like(group_scores, dtype=torch.bool)  # [n, n_group]\n+    group_mask.scatter_(1, group_idx, True)  # [n, n_group]\n     score_mask = (\n         group_mask.unsqueeze(-1)\n         .expand(num_token, num_expert_group, scores.shape[-1] // num_expert_group)\n         .reshape(num_token, -1)\n     )  # [n, e]\n-    tmp_scores = scores_for_choice.masked_fill(\n-        ~score_mask.bool(), float(\"-inf\")\n-    )  # [n, e]\n+    tmp_scores = scores_for_choice.masked_fill(~score_mask, float(\"-inf\"))  # [n, e]\n     _, topk_ids = torch.topk(tmp_scores, k=topk, dim=-1, sorted=False)\n     topk_weights = scores.gather(1, topk_ids)\n \n@@ -263,6 +261,9 @@ def biased_grouped_topk(\n         )\n         # TODO merge into kernel for this branch\n         topk_ids = topk_ids_logical_to_physical(topk_ids, expert_location_dispatch_info)\n+        # Avoid compiling and invoking the masking kernel when not needed\n+        if num_token_non_padded is None:\n+            return topk_weights, topk_ids\n         # TODO will fuse this into kernel, thus use slow manual operation now\n         torch.compile(\n             _mask_topk_ids_padded_region, dynamic=True, backend=get_compiler_backend()\n", "model_name_or_path": "gpt-5-2025-08-07"}
