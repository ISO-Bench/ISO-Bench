{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-cd68723", "model_patch": "diff --git a/python/sglang/srt/managers/router/infer_batch.py b/python/sglang/srt/managers/router/infer_batch.py\nindex 00ada2955..0b8d4fcb0 100644\n--- a/python/sglang/srt/managers/router/infer_batch.py\n+++ b/python/sglang/srt/managers/router/infer_batch.py\n@@ -21,10 +21,10 @@ class FinishReason(Enum):\n \n \n class Req:\n-    def __init__(self, rid):\n+    def __init__(self, rid, input_text=None, input_ids=None):\n         self.rid = rid\n-        self.input_text = None\n-        self.input_ids = []\n+        self.input_text = input_text\n+        self.input_ids = list(input_ids) if input_ids is not None else []\n         self.output_ids = []\n         self.pixel_values = None\n         self.image_size = None\n@@ -221,11 +221,19 @@ class Batch:\n             ] = out_cache_loc[pt : pt + extend_lens[i]]\n             pt += extend_lens[i]\n \n-        # Handle logit bias\n-        logit_bias = torch.zeros((bs, vocab_size), dtype=torch.float32, device=device)\n-        for i in range(bs):\n-            if reqs[i].sampling_params.dtype == \"int\":\n-                logit_bias[i] = int_token_logit_bias\n+        # Handle logit bias (vectorized assignment to reduce per-row overhead)\n+        logit_bias = torch.empty((bs, vocab_size), dtype=torch.float32, device=device)\n+        logit_bias.zero_()\n+        mask = torch.tensor(\n+            [getattr(r.sampling_params, \"dtype\", None) == \"int\" for r in reqs],\n+            dtype=torch.bool,\n+            device=device,\n+        )\n+        if mask.any():\n+            int_token_logit_bias = int_token_logit_bias.to(\n+                device=device, dtype=torch.float32, non_blocking=True\n+            )\n+            logit_bias[mask] = int_token_logit_bias\n \n         # Set fields\n         self.input_ids = torch.tensor(\ndiff --git a/python/sglang/srt/managers/router/manager.py b/python/sglang/srt/managers/router/manager.py\nindex 0732d0fa8..15ce48481 100644\n--- a/python/sglang/srt/managers/router/manager.py\n+++ b/python/sglang/srt/managers/router/manager.py\n@@ -46,7 +46,8 @@ class RouterManager:\n                 if has_finished:\n                     await asyncio.sleep(self.extend_dependency_time)\n \n-            await asyncio.sleep(0.0006)\n+            # Shorter sleep improves streaming latency while yielding the loop\n+            await asyncio.sleep(0.0003)\n \n     async def loop_for_recv_requests(self):\n         while True:\ndiff --git a/python/sglang/srt/managers/router/model_rpc.py b/python/sglang/srt/managers/router/model_rpc.py\nindex 199a8974b..2f1546fd1 100644\n--- a/python/sglang/srt/managers/router/model_rpc.py\n+++ b/python/sglang/srt/managers/router/model_rpc.py\n@@ -225,9 +225,7 @@ class ModelRpcServer(rpyc.Service):\n         self,\n         recv_req: TokenizedGenerateReqInput,\n     ):\n-        req = Req(recv_req.rid)\n-        req.input_text = recv_req.input_text\n-        req.input_ids = recv_req.input_ids\n+        req = Req(recv_req.rid, recv_req.input_text, recv_req.input_ids)\n         req.pixel_values = recv_req.pixel_values\n         req.image_size = recv_req.image_size\n         if req.pixel_values is not None:\ndiff --git a/python/sglang/srt/managers/router/model_runner.py b/python/sglang/srt/managers/router/model_runner.py\nindex c85ec534d..9375a9357 100644\n--- a/python/sglang/srt/managers/router/model_runner.py\n+++ b/python/sglang/srt/managers/router/model_runner.py\n@@ -86,9 +86,10 @@ class InputMetadata:\n     decode_wrapper = None\n \n     def init_flashinfer_args(self, tp_size):\n-        self.kv_indptr = torch.zeros(\n+        self.kv_indptr = torch.empty(\n             (self.batch_size + 1,), dtype=torch.int32, device=\"cuda\"\n         )\n+        self.kv_indptr[0] = 0\n         self.kv_indptr[1:] = torch.cumsum(self.seq_lens, dim=0)\n         self.kv_indices = torch.cat(\n             [\n@@ -112,9 +113,10 @@ class InputMetadata:\n             self.forward_mode == ForwardMode.PREFILL\n             or self.forward_mode == ForwardMode.EXTEND\n         ):\n-            self.qo_indptr = torch.zeros(\n+            self.qo_indptr = torch.empty(\n                 (self.batch_size + 1,), dtype=torch.int32, device=\"cuda\"\n             )\n+            self.qo_indptr[0] = 0\n             self.qo_indptr[1:] = torch.cumsum(self.extend_seq_lens, dim=0)\n             self.prefill_wrapper = BatchPrefillWithPagedKVCacheWrapper()\n             self.prefill_wrapper.begin_forward(\n@@ -139,7 +141,8 @@ class InputMetadata:\n \n     def init_extend_args(self):\n         self.extend_seq_lens = self.seq_lens - self.prefix_lens\n-        self.extend_start_loc = torch.zeros_like(self.seq_lens)\n+        self.extend_start_loc = torch.empty_like(self.seq_lens)\n+        self.extend_start_loc[0] = 0\n         self.extend_start_loc[1:] = torch.cumsum(self.extend_seq_lens[:-1], dim=0)\n         self.max_extend_len = int(torch.max(self.extend_seq_lens))\n \n@@ -159,7 +162,8 @@ class InputMetadata:\n         return_logprob=False,\n     ):\n         batch_size = len(req_pool_indices)\n-        start_loc = torch.zeros((batch_size,), dtype=torch.int32, device=\"cuda\")\n+        start_loc = torch.empty((batch_size,), dtype=torch.int32, device=\"cuda\")\n+        start_loc[0] = 0\n         start_loc[1:] = torch.cumsum(seq_lens[:-1], dim=0)\n         total_num_tokens = int(torch.sum(seq_lens))\n         max_seq_len = int(torch.max(seq_lens))\n@@ -253,7 +257,8 @@ class ModelRunner:\n \n         # A small all_reduce for warmup.\n         if self.tp_size > 1:\n-            torch.distributed.all_reduce(torch.zeros(1).cuda())\n+            _tmp = torch.empty(1, device=\"cuda\")\n+            torch.distributed.all_reduce(_tmp)\n         initialize_model_parallel(tensor_model_parallel_size=self.tp_size)\n \n         total_gpu_memory = get_available_gpu_memory(\n", "model_name_or_path": "gpt-5-2025-08-07"}
