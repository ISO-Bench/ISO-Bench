{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-05b3bf5", "model_patch": "diff --git a/python/sglang/srt/hf_transformers_utils.py b/python/sglang/srt/hf_transformers_utils.py\nindex 56d7c8a1f..6a2582e42 100644\n--- a/python/sglang/srt/hf_transformers_utils.py\n+++ b/python/sglang/srt/hf_transformers_utils.py\n@@ -164,7 +164,7 @@ def get_tokenizer(\n             \"slowdown. Consider using a fast tokenizer instead.\"\n         )\n \n-    handle_additional_stop_token_ids(tokenizer)\n+    attach_additional_stop_token_ids(tokenizer)\n     return tokenizer\n \n \n@@ -184,11 +184,11 @@ def get_processor(\n         **kwargs,\n     )\n \n-    handle_additional_stop_token_ids(processor.tokenizer)\n+    attach_additional_stop_token_ids(processor.tokenizer)\n     return processor\n \n \n-def handle_additional_stop_token_ids(tokenizer):\n+def attach_additional_stop_token_ids(tokenizer):\n     # Special handling for stop token <|eom_id|> generated by llama 3 tool use.\n     if \"<|eom_id|>\" in tokenizer.get_added_vocab():\n         tokenizer.additional_stop_token_ids = set(\ndiff --git a/python/sglang/srt/layers/sampler.py b/python/sglang/srt/layers/sampler.py\nindex 9ae5801cc..f43bb20f7 100644\n--- a/python/sglang/srt/layers/sampler.py\n+++ b/python/sglang/srt/layers/sampler.py\n@@ -60,9 +60,10 @@ class Sampler(nn.Module):\n \n             if global_server_args_dict[\"sampling_backend\"] == \"flashinfer\":\n                 max_top_k_round, batch_size = 32, probs.shape[0]\n-                uniform_samples = torch.rand(\n+                # Use empty + in-place uniform_ to avoid unnecessary zero-initialization\n+                uniform_samples = torch.empty(\n                     (max_top_k_round, batch_size), device=probs.device\n-                )\n+                ).uniform_()\n                 if sampling_info.need_min_p_sampling:\n                     probs = top_k_renorm_prob(probs, sampling_info.top_ks)\n                     probs = top_p_renorm_prob(probs, sampling_info.top_ps)\ndiff --git a/python/sglang/srt/managers/schedule_batch.py b/python/sglang/srt/managers/schedule_batch.py\nindex fac008d3f..aa6701cf1 100644\n--- a/python/sglang/srt/managers/schedule_batch.py\n+++ b/python/sglang/srt/managers/schedule_batch.py\n@@ -543,8 +543,8 @@ class ScheduleBatch:\n                     or len(req.prefix_indices) >= im.num_image_tokens\n                 )\n \n-        self.encoder_lens = torch.tensor(self.encoder_lens_cpu, dtype=torch.int32).to(\n-            self.device, non_blocking=True\n+        self.encoder_lens = torch.tensor(\n+            self.encoder_lens_cpu, dtype=torch.int32, device=self.device\n         )\n \n         # Strip encoder infos\n@@ -574,12 +574,10 @@ class ScheduleBatch:\n             pt += req.extend_input_len\n \n         # Reassign\n-        self.input_ids = torch.tensor(sum(input_ids, []), dtype=torch.int32).to(\n-            self.device, non_blocking=True\n-        )\n-        self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32).to(\n-            self.device, non_blocking=True\n+        self.input_ids = torch.tensor(\n+            sum(input_ids, []), dtype=torch.int32, device=self.device\n         )\n+        self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32, device=self.device)\n \n         if not decoder_out_cache_loc:\n             self.out_cache_loc = torch.empty(0, dtype=torch.int32).to(\n@@ -589,8 +587,8 @@ class ScheduleBatch:\n             self.out_cache_loc = torch.cat(decoder_out_cache_loc)\n \n         if not encoder_out_cache_loc:\n-            self.encoder_out_cache_loc = torch.empty(0, dtype=torch.int32).to(\n-                self.device, non_blocking=True\n+            self.encoder_out_cache_loc = torch.empty(\n+                0, dtype=torch.int32, device=self.device\n             )\n         else:\n             self.encoder_out_cache_loc = torch.cat(encoder_out_cache_loc)\n@@ -645,15 +643,13 @@ class ScheduleBatch:\n             pt += req.extend_input_len\n \n         # Set fields\n-        self.input_ids = torch.tensor(sum(input_ids, []), dtype=torch.int32).to(\n-            self.device, non_blocking=True\n-        )\n-        self.req_pool_indices = torch.tensor(req_pool_indices, dtype=torch.int32).to(\n-            self.device, non_blocking=True\n+        self.input_ids = torch.tensor(\n+            sum(input_ids, []), dtype=torch.int32, device=self.device\n         )\n-        self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32).to(\n-            self.device, non_blocking=True\n+        self.req_pool_indices = torch.tensor(\n+            req_pool_indices, dtype=torch.int32, device=self.device\n         )\n+        self.seq_lens = torch.tensor(seq_lens, dtype=torch.int32, device=self.device)\n \n         self.out_cache_loc = out_cache_loc\n \ndiff --git a/python/sglang/srt/sampling/penaltylib/penalizers/min_new_tokens.py b/python/sglang/srt/sampling/penaltylib/penalizers/min_new_tokens.py\nindex c9e0f078e..dcda1320d 100644\n--- a/python/sglang/srt/sampling/penaltylib/penalizers/min_new_tokens.py\n+++ b/python/sglang/srt/sampling/penaltylib/penalizers/min_new_tokens.py\n@@ -11,7 +11,9 @@ class BatchedMinNewTokensPenalizer(_BatchedPenalizer):\n     \"\"\"\n \n     min_new_tokens: torch.Tensor = None\n-    stop_token_penalties: torch.Tensor = None\n+    # Precomputed padded stop token ids per request to avoid dense allocations\n+    stop_token_ids_padded: torch.Tensor = None\n+    stop_token_valid_mask: torch.Tensor = None\n     len_output_tokens: torch.Tensor = None\n \n     def _is_required(self) -> bool:\n@@ -43,22 +45,9 @@ class BatchedMinNewTokensPenalizer(_BatchedPenalizer):\n             batch_first=True,\n             padding_value=self.orchestrator.vocab_size,\n         )\n-        self.stop_token_penalties = torch.zeros(\n-            size=(self.orchestrator.batch_size(), self.orchestrator.vocab_size + 1),\n-            dtype=torch.float32,\n-            device=self.orchestrator.device,\n-        ).scatter_add_(\n-            dim=1,\n-            index=padded_stop_token_ids,\n-            src=torch.full_like(\n-                input=padded_stop_token_ids,\n-                dtype=torch.float32,\n-                fill_value=float(\"-inf\"),\n-                device=self.orchestrator.device,\n-            ),\n-        )[\n-            :, : self.orchestrator.vocab_size\n-        ]\n+        # Cache padded stop ids and mask for use during apply without allocating\n+        self.stop_token_ids_padded = padded_stop_token_ids\n+        self.stop_token_valid_mask = padded_stop_token_ids != self.orchestrator.vocab_size\n \n         self.len_output_tokens = torch.zeros(\n             size=(self.orchestrator.batch_size(), 1),\n@@ -68,11 +57,13 @@ class BatchedMinNewTokensPenalizer(_BatchedPenalizer):\n \n     def _teardown(self):\n         del self.min_new_tokens\n-        del self.stop_token_penalties\n+        del self.stop_token_ids_padded\n+        del self.stop_token_valid_mask\n         del self.len_output_tokens\n \n         self.min_new_tokens = None\n-        self.stop_token_penalties = None\n+        self.stop_token_ids_padded = None\n+        self.stop_token_valid_mask = None\n         self.len_output_tokens = None\n \n     def _cumulate_input_tokens(self, input_ids: _TokenIDs):\n@@ -82,23 +73,36 @@ class BatchedMinNewTokensPenalizer(_BatchedPenalizer):\n         self.len_output_tokens += 1\n \n     def _apply(self, logits: torch.Tensor) -> torch.Tensor:\n-        mask = (self.len_output_tokens < self.min_new_tokens).expand_as(logits)\n-        logits[mask] += self.stop_token_penalties[mask]\n+        rows_to_penalize = (self.len_output_tokens < self.min_new_tokens).squeeze(1)\n+        if not torch.any(rows_to_penalize):\n+            return logits\n+\n+        rows_idx = torch.nonzero(rows_to_penalize, as_tuple=False).squeeze(1)\n+        # For each selected row, set logits at stop-token indices to -inf\n+        for i in rows_idx.tolist():\n+            valid = self.stop_token_valid_mask[i]\n+            idx = self.stop_token_ids_padded[i][valid]\n+            # In-place assignment avoids allocating a dense penalty matrix\n+            logits[i, idx] = float(\"-inf\")\n         return logits\n \n     def _filter(\n         self, indices_to_keep: typing.List[int], indices_tensor_to_keep: torch.Tensor\n     ):\n         self.min_new_tokens = self.min_new_tokens[indices_tensor_to_keep]\n-        self.stop_token_penalties = self.stop_token_penalties[indices_tensor_to_keep]\n+        self.stop_token_ids_padded = self.stop_token_ids_padded[indices_tensor_to_keep]\n+        self.stop_token_valid_mask = self.stop_token_valid_mask[indices_tensor_to_keep]\n         self.len_output_tokens = self.len_output_tokens[indices_tensor_to_keep]\n \n     def _merge(self, their: \"BatchedMinNewTokensPenalizer\"):\n         self.min_new_tokens = torch.cat(\n             [self.min_new_tokens, their.min_new_tokens], dim=0\n         )\n-        self.stop_token_penalties = torch.cat(\n-            [self.stop_token_penalties, their.stop_token_penalties], dim=0\n+        self.stop_token_ids_padded = torch.cat(\n+            [self.stop_token_ids_padded, their.stop_token_ids_padded], dim=0\n+        )\n+        self.stop_token_valid_mask = torch.cat(\n+            [self.stop_token_valid_mask, their.stop_token_valid_mask], dim=0\n         )\n         self.len_output_tokens = torch.cat(\n             [self.len_output_tokens, their.len_output_tokens], dim=0\ndiff --git a/python/sglang/srt/sampling/sampling_params.py b/python/sglang/srt/sampling/sampling_params.py\nindex b0863b557..36240dec1 100644\n--- a/python/sglang/srt/sampling/sampling_params.py\n+++ b/python/sglang/srt/sampling/sampling_params.py\n@@ -63,6 +63,8 @@ class SamplingParams:\n         self.n = n\n         self.json_schema = json_schema\n         self.no_stop_trim = no_stop_trim\n+        # Internal memoization to avoid repeated updates across normalizations\n+        self._added_additional_stop_token_ids = False\n \n         # Process some special cases\n         if self.temperature < _SAMPLING_EPS:\n@@ -135,8 +137,14 @@ class SamplingParams:\n             self.stop_str_max_len = stop_str_max_len\n \n         # Process stop token ids\n-        if tokenizer and tokenizer.additional_stop_token_ids:\n+        if (\n+            tokenizer\n+            and hasattr(tokenizer, \"additional_stop_token_ids\")\n+            and tokenizer.additional_stop_token_ids\n+            and not self._added_additional_stop_token_ids\n+        ):\n             self.stop_token_ids.update(tokenizer.additional_stop_token_ids)\n+            self._added_additional_stop_token_ids = True\n \n     def to_srt_kwargs(self):\n         return {\n", "model_name_or_path": "gpt-5-2025-08-07"}
