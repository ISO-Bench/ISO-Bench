{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-ae6a5b2", "model_patch": "diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py\nindex 29f18f0ef..b4fc4d7a7 100644\n--- a/python/sglang/srt/models/deepseek_v2.py\n+++ b/python/sglang/srt/models/deepseek_v2.py\n@@ -454,6 +454,7 @@ class DeepseekV2MoE(nn.Module):\n                 num_expert_group=self.num_expert_group,\n                 correction_bias=self.correction_bias,\n                 routed_scaling_factor=self.routed_scaling_factor,\n+                num_token_non_padded=state.forward_batch.num_token_non_padded,\n                 expert_location_dispatch_info=ExpertLocationDispatchInfo.init_new(\n                     layer_id=self.layer_id,\n                 ),\ndiff --git a/python/sglang/srt/two_batch_overlap.py b/python/sglang/srt/two_batch_overlap.py\nindex 6b0241f40..0b897fbe0 100644\n--- a/python/sglang/srt/two_batch_overlap.py\n+++ b/python/sglang/srt/two_batch_overlap.py\n@@ -110,7 +110,12 @@ def compute_split_indices_for_cuda_graph_replay(\n \n class TboCudaGraphRunnerPlugin:\n     def __init__(self):\n-        pass  # TODO add logic here\n+        # Persist a small device buffer used by CUDA graphs to feed\n+        # per-child non-padded token counts at replay time.\n+        # Using empty to avoid redundant zero-initialization overhead.\n+        self._tbo_children_num_token_non_padded = torch.empty(\n+            (2,), dtype=torch.int32\n+        )\n \n     def capture_one_batch_size(self, batch: ForwardBatch, num_tokens: int):\n         if not global_server_args_dict[\"enable_two_batch_overlap\"]:\n@@ -126,13 +131,38 @@ class TboCudaGraphRunnerPlugin:\n \n         TboForwardBatchPreparer.prepare(batch)\n \n+        # Wire children to read num_token_non_padded from our persistent buffer\n+        # and initialize values for capture.\n+        assert batch.tbo_children is not None and len(batch.tbo_children) == 2\n+        for i, child in enumerate(batch.tbo_children):\n+            # Make each child reference a view into our buffer\n+            child.num_token_non_padded = self._tbo_children_num_token_non_padded[\n+                i : i + 1\n+            ]\n+        # Initialize capture-time values based on actual child token counts\n+        self._tbo_children_num_token_non_padded[0] = (\n+            batch.tbo_children[0].input_ids.shape[0]\n+        )\n+        self._tbo_children_num_token_non_padded[1] = (\n+            batch.tbo_children[1].input_ids.shape[0]\n+        )\n+\n     def replay_prepare(\n         self, forward_mode: ForwardMode, bs: int, num_token_non_padded: int\n     ):\n         if not global_server_args_dict[\"enable_two_batch_overlap\"]:\n             return\n \n-        pass  # TODO add logic here\n+        # Compute token split for the current CUDA graph replay configuration\n+        # and update the shared buffer so captured children read correct values.\n+        _, tbo_split_token_index = compute_split_indices_for_cuda_graph_replay(\n+            forward_mode=forward_mode, cuda_graph_num_tokens=bs\n+        )\n+        # Respect padding: distribute only non-padded tokens across children\n+        left = min(num_token_non_padded, tbo_split_token_index)\n+        right = max(num_token_non_padded - tbo_split_token_index, 0)\n+        self._tbo_children_num_token_non_padded[0] = left\n+        self._tbo_children_num_token_non_padded[1] = right\n \n \n class TboDPAttentionPreparer:\n@@ -324,7 +354,9 @@ class TboForwardBatchPreparer:\n         # TODO improve, e.g. unify w/ `init_raw`\n         if global_server_args_dict[\"moe_dense_tp_size\"] == 1:\n             sum_len = end_token_index - start_token_index\n-            gathered_buffer = torch.zeros(\n+            # Allocate without zero-initialization; the buffer will be fully written\n+            # by gather/scatter ops downstream.\n+            gathered_buffer = torch.empty(\n                 (sum_len, batch.gathered_buffer.shape[1]),\n                 dtype=batch.gathered_buffer.dtype,\n                 device=batch.gathered_buffer.device,\n", "model_name_or_path": "gpt-5-2025-08-07"}
