{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-73fa2d4", "model_patch": "diff --git a/python/sglang/srt/managers/policy_scheduler.py b/python/sglang/srt/managers/policy_scheduler.py\nindex 30a009c2e..9253b1672 100644\n--- a/python/sglang/srt/managers/policy_scheduler.py\n+++ b/python/sglang/srt/managers/policy_scheduler.py\n@@ -18,27 +18,18 @@ limitations under the License.\n import random\n from collections import defaultdict\n from contextlib import contextmanager\n+from typing import List\n \n from sglang.srt.managers.schedule_batch import Req, ScheduleBatch\n \n \n class PolicyScheduler:\n-    def __init__(\n-        self,\n-        policy,\n-        max_running_seqs,\n-        max_prefill_num_tokens,\n-        max_total_num_tokens,\n-        tree_cache,\n-    ):\n-        if tree_cache.disable and policy == \"lpm\":\n-            # LMP is meaningless when the tree cache is disabled.\n+    def __init__(self, policy, tree_cache):\n+        if tree_cache.disable and policy in [\"lpm\", \"dfs-weight\"]:\n+            # LPM and DFS-weight are meaningless when the tree cache is disabled.\n             policy = \"fcfs\"\n \n         self.policy = policy\n-        self.max_running_seqs = max_running_seqs\n-        self.max_prefill_num_tokens = max_prefill_num_tokens\n-        self.max_total_num_tokens = max_total_num_tokens\n         self.tree_cache = tree_cache\n \n     def get_priority_queue(self, waiting_queue):\ndiff --git a/python/sglang/srt/managers/tp_worker.py b/python/sglang/srt/managers/tp_worker.py\nindex 0228073c7..ceeca3cd8 100644\n--- a/python/sglang/srt/managers/tp_worker.py\n+++ b/python/sglang/srt/managers/tp_worker.py\n@@ -165,13 +165,7 @@ class ModelTpServer:\n                 disable=server_args.disable_radix_cache,\n             )\n         self.tree_cache_metrics = {\"total\": 0, \"hit\": 0}\n-        self.scheduler = PolicyScheduler(\n-            self.schedule_policy,\n-            self.max_running_requests,\n-            self.max_prefill_tokens,\n-            self.max_total_num_tokens,\n-            self.tree_cache,\n-        )\n+        self.scheduler = PolicyScheduler(self.schedule_policy, self.tree_cache)\n         self.req_to_token_pool = self.model_runner.req_to_token_pool\n         self.token_to_kv_pool = self.model_runner.token_to_kv_pool\n \n@@ -377,9 +371,14 @@ class ModelTpServer:\n         for req in self.waiting_queue:\n             req.input_ids = req.origin_input_ids + req.output_ids\n             # NOTE: the prefix_indices must always be aligned with last_node\n-            req.prefix_indices, req.last_node = self.tree_cache.match_prefix(\n-                rid=req.rid, key=req.adjust_max_prefix_ids()\n-            )\n+            if self.tree_cache.disable:\n+                # Fast path: avoid unnecessary work when cache is disabled\n+                req.prefix_indices = []\n+                req.last_node = self.tree_cache.root_node\n+            else:\n+                req.prefix_indices, req.last_node = self.tree_cache.match_prefix(\n+                    rid=req.rid, key=req.adjust_max_prefix_ids()\n+                )\n             req.extend_input_len = len(req.input_ids) - len(req.prefix_indices)\n \n         # Get priority queue\ndiff --git a/python/sglang/srt/mem_cache/radix_cache.py b/python/sglang/srt/mem_cache/radix_cache.py\nindex c23812049..1b7edefb8 100644\n--- a/python/sglang/srt/mem_cache/radix_cache.py\n+++ b/python/sglang/srt/mem_cache/radix_cache.py\n@@ -169,6 +169,8 @@ class RadixCache(BasePrefixCache):\n                 heapq.heappush(leaves, x.parent)\n \n     def inc_lock_ref(self, node: TreeNode):\n+        if self.disable:\n+            return 0\n         delta = 0\n         while node != self.root_node:\n             if node.lock_ref == 0:\n@@ -179,6 +181,8 @@ class RadixCache(BasePrefixCache):\n         return delta\n \n     def dec_lock_ref(self, node: TreeNode):\n+        if self.disable:\n+            return 0\n         delta = 0\n         while node != self.root_node:\n             if node.lock_ref == 1:\n", "model_name_or_path": "gpt-5-2025-08-07"}
