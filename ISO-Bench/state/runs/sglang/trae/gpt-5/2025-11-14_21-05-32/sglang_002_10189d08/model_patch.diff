diff --git a/python/sglang/srt/managers/scheduler.py b/python/sglang/srt/managers/scheduler.py
index 1d1cf3688..58e77f286 100644
--- a/python/sglang/srt/managers/scheduler.py
+++ b/python/sglang/srt/managers/scheduler.py
@@ -72,6 +72,7 @@ from sglang.srt.utils import (
     configure_logger,
     crash_on_warnings,
     get_zmq_socket,
+    gpu_proc_affinity,
     kill_parent_process,
     set_random_seed,
     suppress_other_loggers,
@@ -1393,6 +1394,8 @@ def run_scheduler_process(
     dp_rank: Optional[int],
     pipe_writer,
 ):
+    # set cpu affinity to this gpu process
+    gpu_proc_affinity(server_args.tp_size, server_args.nnodes, gpu_id)
     # [For Router] if env var "DP_RANK" exist, set dp_rank to the value of the env var
     if dp_rank is None and "DP_RANK" in os.environ:
         dp_rank = int(os.environ["DP_RANK"])
diff --git a/python/sglang/srt/utils.py b/python/sglang/srt/utils.py
index e947d1a92..1ccab7cf6 100644
--- a/python/sglang/srt/utils.py
+++ b/python/sglang/srt/utils.py
@@ -53,10 +53,112 @@ from triton.runtime.cache import (
     default_dump_dir,
     default_override_dir,
 )
+from functools import lru_cache
 
 logger = logging.getLogger(__name__)
 
 
+@lru_cache(maxsize=None)
+def _parse_numa_cpu_map() -> List[List[int]]:
+    """Parse NUMA node CPU lists from sysfs.
+
+    Returns a list where each element is the sorted list of CPU ids for a node.
+    If parsing fails or the system has no NUMA info, returns an empty list.
+    """
+    nodes_dir = "/sys/devices/system/node"
+    if not os.path.isdir(nodes_dir):
+        return []
+    cpu_map: List[List[int]] = []
+    try:
+        for name in sorted(os.listdir(nodes_dir)):
+            if not name.startswith("node"):
+                continue
+            path = os.path.join(nodes_dir, name, "cpulist")
+            if not os.path.exists(path):
+                continue
+            with open(path, "r") as f:
+                cpulist = f.read().strip()
+            if not cpulist:
+                cpu_map.append([])
+                continue
+            # Parse format like: "0-7,16-23"
+            cpus: List[int] = []
+            for part in cpulist.split(","):
+                if "-" in part:
+                    a, b = part.split("-")
+                    cpus.extend(range(int(a), int(b) + 1))
+                else:
+                    cpus.append(int(part))
+            cpu_map.append(sorted(cpus))
+        return cpu_map
+    except Exception:
+        return []
+
+
+def _available_cpus() -> List[int]:
+    try:
+        allowed = os.sched_getaffinity(0)
+        cpus = sorted(list(allowed))
+        if cpus:
+            return cpus
+    except Exception:
+        pass
+    count = psutil.cpu_count(logical=True) or os.cpu_count() or 1
+    return list(range(count))
+
+
+def _chunk_list(lst: List[int], num_chunks: int) -> List[List[int]]:
+    num_chunks = max(1, min(num_chunks, len(lst)))
+    base, rem = divmod(len(lst), num_chunks)
+    out: List[List[int]] = []
+    start = 0
+    for i in range(num_chunks):
+        size = base + (1 if i < rem else 0)
+        out.append(lst[start : start + size])
+        start += size
+    return out
+
+
+def gpu_proc_affinity(tp_size: int, nnodes: int, gpu_id: int) -> None:
+    """
+    Pin the current process to a subset of CPU cores to reduce context switching
+    and improve cache/NUMA locality. Heuristic mapping with multi-socket support.
+
+    - Prefer binding to the CPUs of a NUMA node when available
+    - Otherwise, partition the allowed CPUs across local GPUs
+    """
+    try:
+        cpus_allowed = _available_cpus()
+        if not cpus_allowed:
+            return
+
+        # Try NUMA-aware assignment first
+        numa_map = _parse_numa_cpu_map()
+        selected: List[int] = []
+        if numa_map:
+            node_idx = gpu_id % len(numa_map)
+            node_cpus = [c for c in numa_map[node_idx] if c in cpus_allowed]
+            if node_cpus:
+                selected = node_cpus
+
+        # Fallback: split CPUs evenly across GPUs/TP ranks on this host
+        if not selected:
+            try:
+                local_gpus = torch.cuda.device_count() if torch.cuda.is_available() else tp_size
+            except Exception:
+                local_gpus = tp_size or 1
+            groups = max(1, local_gpus)
+            chunks = _chunk_list(cpus_allowed, groups)
+            selected = chunks[gpu_id % len(chunks)] if chunks else cpus_allowed
+
+        if selected:
+            os.sched_setaffinity(0, set(selected))
+            logger.info("Set CPU affinity (pid=%d) to %s", os.getpid(), selected)
+    except Exception as e:
+        # Best-effort only
+        logger.debug("Failed to set CPU affinity: %s", e)
+
+
 show_time_cost = False
 time_infos = {}
 
@@ -192,6 +294,7 @@ def get_available_gpu_memory(device, gpu_id, distributed=False):
     return free_gpu_memory / (1 << 30)
 
 
+@lru_cache(maxsize=None)
 def is_pin_memory_available() -> bool:
     return torch.cuda.is_available()
 
@@ -711,7 +814,7 @@ def broadcast_pyobj(
         tensor_data = torch.empty(size, dtype=torch.uint8)
         dist.broadcast(tensor_data, src=0, group=dist_group)
 
-        serialized_data = bytes(tensor_data.cpu().numpy())
+        serialized_data = tensor_data.cpu().numpy().tobytes()
         data = pickle.loads(serialized_data)
         return data
 
@@ -764,6 +867,11 @@ def get_zmq_socket(context: zmq.Context, socket_type: zmq.SocketType, endpoint:
         buf_size = -1
 
     socket = context.socket(socket_type)
+    # Avoid blocking on close; best-effort fire-and-forget behavior for IPC
+    try:
+        socket.setsockopt(zmq.LINGER, 0)
+    except Exception:
+        pass
     if socket_type == zmq.PUSH:
         socket.setsockopt(zmq.SNDHWM, 0)
         socket.setsockopt(zmq.SNDBUF, buf_size)
@@ -793,6 +901,7 @@ def dump_to_file(dirpath, name, value):
     np.save(output_filename, value)
 
 
+@lru_cache(maxsize=None)
 def is_triton_3():
     return triton.__version__.startswith("3.")
 
