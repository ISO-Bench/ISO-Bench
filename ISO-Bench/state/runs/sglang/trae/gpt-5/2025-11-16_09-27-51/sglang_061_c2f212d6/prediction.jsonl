{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-e2cdc8a", "model_patch": "diff --git a/benchmark/kernels/minmax-text-01-lighting_attention/benchmark_lighting_attention_decode.py b/benchmark/kernels/minmax-text-01-lighting_attention/benchmark_lighting_attention_decode.py\nindex 1a2036dc0..387248f5b 100644\n--- a/benchmark/kernels/minmax-text-01-lighting_attention/benchmark_lighting_attention_decode.py\n+++ b/benchmark/kernels/minmax-text-01-lighting_attention/benchmark_lighting_attention_decode.py\n@@ -22,16 +22,19 @@ def _decode_kernel(\n     b: tl.constexpr,\n     h: tl.constexpr,\n     n: tl.constexpr,\n-    d: tl.constexpr,\n-    e: tl.constexpr,\n+    d: tl.constexpr,  # padded d\n+    e: tl.constexpr,  # padded e\n+    d_original: tl.constexpr,\n+    e_original: tl.constexpr,\n+    BLOCK_SIZE: tl.constexpr = 32,\n ):\n     off_bh = tl.program_id(0)\n     off_h = off_bh % h\n \n-    qk_offset = off_bh * n * d\n-    v_offset = off_bh * n * e\n-    o_offset = off_bh * n * e\n-    kv_offset = off_bh * d * e\n+    qk_offset = off_bh * n * d_original\n+    v_offset = off_bh * n * e_original\n+    o_offset = off_bh * n * e_original\n+    kv_offset = off_bh * d_original * e_original\n \n     s = tl.load(S + off_h)\n     ratio = tl.exp(-s)\n@@ -39,21 +42,30 @@ def _decode_kernel(\n     d_idx = tl.arange(0, d)\n     e_idx = tl.arange(0, e)\n \n-    q = tl.load(Q + qk_offset + d_idx)\n-    k = tl.load(K + qk_offset + d_idx)\n-    v = tl.load(V + v_offset + e_idx)\n+    d_mask = d_idx < d_original\n+    e_mask = e_idx < e_original\n \n-    kv = tl.load(KV + kv_offset + d_idx[:, None] * e + e_idx[None, :])\n+    q = tl.load(Q + qk_offset + d_idx, mask=d_mask, other=0.0).to(tl.float32)\n+    k = tl.load(K + qk_offset + d_idx, mask=d_mask, other=0.0).to(tl.float32)\n+    v = tl.load(V + v_offset + e_idx, mask=e_mask, other=0.0).to(tl.float32)\n+\n+    kv = tl.load(\n+        KV + kv_offset + d_idx[:, None] * e_original + e_idx[None, :],\n+        mask=d_mask[:, None] & e_mask[None, :],\n+        other=0.0,\n+    ).to(tl.float32)\n \n     k_v_prod = k[:, None] * v[None, :]\n     kv = ratio * kv + k_v_prod\n \n     tl.store(\n-        KV + kv_offset + d_idx[:, None] * e + e_idx[None, :], kv.to(KV.dtype.element_ty)\n+        KV + kv_offset + d_idx[:, None] * e_original + e_idx[None, :],\n+        kv.to(KV.dtype.element_ty),\n+        mask=d_mask[:, None] & e_mask[None, :],\n     )\n \n     o = tl.sum(q[:, None] * kv, axis=0)\n-    tl.store(Out + o_offset + e_idx, o.to(Out.dtype.element_ty))\n+    tl.store(Out + o_offset + e_idx, o.to(Out.dtype.element_ty), mask=e_mask)\n \n \n def lightning_attn_decode(q, k, v, kv, s):\n@@ -66,47 +78,41 @@ def lightning_attn_decode(q, k, v, kv, s):\n     d_padded = next_power_of_2(d)\n     e_padded = next_power_of_2(e)\n \n-    # Pad inputs\n-    q_padded = F.pad(q, (0, d_padded - d))\n-    k_padded = F.pad(k, (0, d_padded - d))\n-    v_padded = F.pad(v, (0, e_padded - e))\n-    kv_padded = F.pad(kv, (0, e_padded - e, 0, d_padded - d))\n-\n     # Ensure inputs are contiguous\n-    q_padded = q_padded.contiguous()\n-    k_padded = k_padded.contiguous()\n-    v_padded = v_padded.contiguous()\n-    kv_padded = kv_padded.contiguous().to(torch.float32)\n+    q = q.contiguous()\n+    k = k.contiguous()\n+    v = v.contiguous()\n+    kv = kv.contiguous()\n     s = s.contiguous()\n \n-    # Create output tensor (padded)\n-    o_padded = torch.empty(b, h, n, e_padded, dtype=v.dtype, device=v.device)\n+    # Create output tensor\n+    o = torch.empty(b, h, n, e, dtype=v.dtype, device=v.device)\n \n     # Launch kernel\n     grid = (b * h, 1)\n     _decode_kernel[grid](\n-        q_padded,\n-        k_padded,\n-        v_padded,\n-        kv_padded,\n-        o_padded,\n+        q,\n+        k,\n+        v,\n+        kv,\n+        o,\n         s,\n         b=b,\n         h=h,\n         n=n,\n         d=d_padded,\n         e=e_padded,\n+        d_original=d,\n+        e_original=e,\n     )\n \n-    # Remove padding\n-    o = o_padded[..., :e]\n-    kv_out = kv_padded[..., :d, :e]\n-\n-    return o, kv_out\n+    return o, kv\n \n \n def next_power_of_2(n):\n-    return 2 ** (int(math.ceil(math.log(n, 2))))\n+    if n <= 1:\n+        return 1\n+    return 1 << ((n - 1).bit_length())\n \n \n class MiniMaxText01LightningAttention(nn.Module):\n", "model_name_or_path": "gpt-5-2025-08-07"}
