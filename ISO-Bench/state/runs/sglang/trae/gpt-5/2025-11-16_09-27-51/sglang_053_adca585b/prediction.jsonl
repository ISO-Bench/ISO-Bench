{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-39d9044", "model_patch": "diff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py\nindex 42ae9d293..772f047e6 100644\n--- a/python/sglang/srt/models/deepseek_v2.py\n+++ b/python/sglang/srt/models/deepseek_v2.py\n@@ -180,7 +180,6 @@ class DeepseekV2MoE(nn.Module):\n             else 0\n         )\n \n-        self.routed_scaling_factor = config.routed_scaling_factor\n         if self.tp_size > config.n_routed_experts:\n             raise ValueError(\n                 f\"Tensor parallel size {self.tp_size} is greater than \"\n@@ -283,10 +282,8 @@ class DeepseekV2MoE(nn.Module):\n         shared_output = self._forward_shared_experts(hidden_states)\n         # router_logits: (num_tokens, n_experts)\n         router_logits = self.gate(hidden_states)\n-        final_hidden_states = (\n-            self.experts(hidden_states=hidden_states, router_logits=router_logits)\n-            * self.routed_scaling_factor\n-        )\n+        final_hidden_states = self.experts(hidden_states=hidden_states, router_logits=router_logits)\n+        final_hidden_states.mul_(self.routed_scaling_factor)\n         if shared_output is not None:\n             final_hidden_states = final_hidden_states + shared_output\n         if self.tp_size > 1:\n@@ -337,16 +334,13 @@ class DeepseekV2MoE(nn.Module):\n                 topk_weights,\n                 forward_mode=forward_mode,\n             )\n-        final_hidden_states = (\n-            self.experts(\n-                hidden_states=hidden_states,\n-                reorder_topk_ids=reorder_topk_ids,\n-                seg_indptr=seg_indptr,\n-                masked_m=masked_m,\n-                expected_m=expected_m,\n-                forward_mode=forward_mode,\n-            )\n-            * self.routed_scaling_factor\n+        final_hidden_states = self.experts(\n+            hidden_states=hidden_states,\n+            reorder_topk_ids=reorder_topk_ids,\n+            seg_indptr=seg_indptr,\n+            masked_m=masked_m,\n+            expected_m=expected_m,\n+            forward_mode=forward_mode,\n         )\n         if self.ep_size > 1:\n             final_hidden_states = self.deepep_dispatcher.combine(\n@@ -355,6 +349,7 @@ class DeepseekV2MoE(nn.Module):\n                 topk_weights,\n                 forward_mode,\n             )\n+        final_hidden_states.mul_(self.routed_scaling_factor)\n         if shared_output is not None:\n             final_hidden_states = final_hidden_states + shared_output\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
