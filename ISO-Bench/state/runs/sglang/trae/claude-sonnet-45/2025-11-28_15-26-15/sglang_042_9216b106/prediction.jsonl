{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-da19434", "model_patch": "diff --git a/python/sglang/srt/managers/router/model_rpc.py b/python/sglang/srt/managers/router/model_rpc.py\nindex 883bb12f9..8aab19155 100644\n--- a/python/sglang/srt/managers/router/model_rpc.py\n+++ b/python/sglang/srt/managers/router/model_rpc.py\n@@ -310,10 +310,8 @@ class ModelRpcServer:\n         )\n         if self.running_batch:\n             available_size -= sum(\n-                [\n-                    (r.max_new_tokens() - len(r.output_ids)) * self.new_token_ratio\n-                    for r in self.running_batch.reqs\n-                ]\n+                (r.max_new_tokens() - len(r.output_ids)) * self.new_token_ratio\n+                for r in self.running_batch.reqs\n             )\n \n         for req in self.forward_queue:\n@@ -348,6 +346,7 @@ class ModelRpcServer:\n                     # Undo the insertion\n                     delta = self.tree_cache.dec_ref_counter(req.last_node)\n                     available_size += delta\n+                    break\n                 else:\n                     # Add this request to the running batch\n                     self.token_to_kv_pool.add_refs(req.prefix_indices)\n@@ -356,7 +355,8 @@ class ModelRpcServer:\n                         req.extend_input_len + req.max_new_tokens()\n                     )\n                     new_batch_input_tokens += req.extend_input_len\n-\n+            else:\n+                break\n         if len(can_run_list) == 0:\n             return None\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
