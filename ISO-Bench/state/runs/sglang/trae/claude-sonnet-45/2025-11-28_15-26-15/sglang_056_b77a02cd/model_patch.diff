diff --git a/python/sglang/srt/constrained/__init__.py b/python/sglang/srt/constrained/__init__.py
index c47c5c8dd..41563adf6 100644
--- a/python/sglang/srt/constrained/__init__.py
+++ b/python/sglang/srt/constrained/__init__.py
@@ -26,30 +26,75 @@ try:
     from outlines.fsm.guide import RegexGuide
     from outlines.fsm.regex import FSMInfo, make_byte_level_fsm, make_deterministic_fsm
     from outlines.models.transformers import TransformerTokenizer
+    _OUTLINES_AVAILABLE = True
 except ImportError as e:
-    print(
-        f'\nError: {e}. Please install a new version of outlines by `pip install "outlines>=0.0.44"`\n'
-    )
-    raise
+    # Make constrained decoding optional: provide lightweight fallbacks when outlines is unavailable
+    _OUTLINES_AVAILABLE = False
+
+    class _Dummy:
+        pass
+
+    # Placeholders to avoid hard import failures in modules that only use these for typing
+    RegexGuide = _Dummy  # type: ignore
+    FSMInfo = _Dummy  # type: ignore
+    TransformerTokenizer = _Dummy  # type: ignore
+
+    # Disk cache fallbacks
+    def disable_cache(*args, **kwargs):  # type: ignore
+        return None
+
+    def disk_cache(*args, **kwargs):  # type: ignore
+        return None
+
+    def make_byte_level_fsm(*args, **kwargs):  # type: ignore
+        raise ImportError(
+            f"{e}. Please install a new version of outlines by `pip install \"outlines>=0.0.44\"`"
+        )
+
+    def make_deterministic_fsm(*args, **kwargs):  # type: ignore
+        raise ImportError(
+            f"{e}. Please install a new version of outlines by `pip install \"outlines>=0.0.44\"`"
+        )
+
+# Handle json schema utility imports conditionally to avoid hard failures
+if _OUTLINES_AVAILABLE:
+    try:
+        from outlines.fsm.json_schema import build_regex_from_object
+    except ImportError:
+        # Since outlines 0.0.32, build_regex_from_object is replaced by build_regex_from_schema,
+        # which only accepts string schema as input.
+        from outlines.fsm.json_schema import build_regex_from_schema
+
+        def build_regex_from_object(
+            object: Union[str, BaseModel, Dict], whitespace_pattern: Optional[str] = None
+        ):
+            if isinstance(object, type(BaseModel)):
+                schema = json.dumps(object.model_json_schema())
+            elif isinstance(object, Dict):
+                schema = json.dumps(object)
+            else:
+                schema = object
+            return build_regex_from_schema(schema, whitespace_pattern)
+else:
+    def build_regex_from_object(*args, **kwargs):  # type: ignore
+        raise ImportError(
+            "Outlines is not available. Please install `outlines>=0.0.44` to use JSON-constrained decoding."
+        )
 
 try:
-    from outlines.fsm.json_schema import build_regex_from_object
+    from xgrammar import (
+        GrammarMatcher,
+        GrammarMatcherInitContext,
+        GrammarMatcherInitContextCache,
+    )
 except ImportError:
-    # Since outlines 0.0.32, build_regex_from_object is replaced by build_regex_from_schema,
-    # which only accepts string schema as input.
-    from outlines.fsm.json_schema import build_regex_from_schema
-
-    def build_regex_from_object(
-        object: Union[str, BaseModel, Dict], whitespace_pattern: Optional[str] = None
-    ):
-        if isinstance(object, type(BaseModel)):
-            schema = json.dumps(object.model_json_schema())
-        elif isinstance(object, Dict):
-            schema = json.dumps(object)
-        else:
-            schema = object
-        return build_regex_from_schema(schema, whitespace_pattern)
 
+    class Dummy:
+        pass
+
+    GrammarMatcher = Dummy  # type: ignore
+    GrammarMatcherInitContext = Dummy  # type: ignore
+    GrammarMatcherInitContextCache = Dummy  # type: ignore
 
 __all__ = [
     "RegexGuide",
@@ -60,4 +105,7 @@ __all__ = [
     "disk_cache",
     "disable_cache",
     "make_byte_level_fsm",
+    "GrammarMatcher",
+    "GrammarMatcherInitContext",
+    "GrammarMatcherInitContextCache",
 ]
diff --git a/python/sglang/srt/sampling/sampling_batch_info.py b/python/sglang/srt/sampling/sampling_batch_info.py
index 27a2d07fb..932b570f0 100644
--- a/python/sglang/srt/sampling/sampling_batch_info.py
+++ b/python/sglang/srt/sampling/sampling_batch_info.py
@@ -52,23 +52,20 @@ class SamplingBatchInfo:
     ):
         reqs = batch.reqs
         device = batch.device
-        temperatures = (
-            torch.tensor(
-                [r.sampling_params.temperature for r in reqs],
-                dtype=torch.float,
-            )
-            .view(-1, 1)
-            .to(device, non_blocking=True)
-        )
+        temperatures = torch.tensor(
+            [r.sampling_params.temperature for r in reqs],
+            dtype=torch.float,
+            device=device,
+        ).view(-1, 1)
         top_ps = torch.tensor(
-            [r.sampling_params.top_p for r in reqs], dtype=torch.float
-        ).to(device, non_blocking=True)
+            [r.sampling_params.top_p for r in reqs], dtype=torch.float, device=device
+        )
         top_ks = torch.tensor(
-            [r.sampling_params.top_k for r in reqs], dtype=torch.int32
-        ).to(device, non_blocking=True)
+            [r.sampling_params.top_k for r in reqs], dtype=torch.int32, device=device
+        )
         min_ps = torch.tensor(
-            [r.sampling_params.min_p for r in reqs], dtype=torch.float
-        ).to(device, non_blocking=True)
+            [r.sampling_params.min_p for r in reqs], dtype=torch.float, device=device
+        )
 
         ret = cls(
             temperatures=temperatures,
@@ -128,6 +125,7 @@ class SamplingBatchInfo:
             else:
                 if self.linear_penalties is None:
                     bs = self.penalizer_orchestrator.batch.batch_size()
+                    # Allocate once with zeros
                     self.linear_penalties = torch.zeros(
                         (bs, self.vocab_size),
                         dtype=torch.float32,
@@ -141,7 +139,8 @@ class SamplingBatchInfo:
             self.vocab_mask = None
             return
 
-        self.vocab_mask = torch.zeros(
+        # Start with all tokens masked (True), then unmask allowed tokens (set False)
+        self.vocab_mask = torch.ones(
             len(self.temperatures),
             self.vocab_size,
             dtype=torch.bool,
@@ -149,7 +148,6 @@ class SamplingBatchInfo:
         )
         for i, regex_fsm in enumerate(self.regex_fsms):
             if regex_fsm is not None:
-                self.vocab_mask[i].fill_(1)
                 self.vocab_mask[i][
                     regex_fsm.get_next_instruction(self.regex_fsm_states[i]).tokens
                 ] = 0
@@ -185,11 +183,10 @@ class SamplingBatchInfo:
                 shape, dtype = lhs.shape[1:], lhs.dtype
             else:
                 shape, dtype = rhs.shape[1:], rhs.dtype
-            with torch.dtype(dtype):
-                if lhs is None:
-                    lhs = torch.empty((bs1, *shape), device=device).fill_(default)
-                if rhs is None:
-                    rhs = torch.empty((bs2, *shape), device=device).fill_(default)
+            if lhs is None:
+                lhs = torch.full((bs1, *shape), default, device=device, dtype=dtype)
+            if rhs is None:
+                rhs = torch.full((bs2, *shape), default, device=device, dtype=dtype)
             return torch.cat([lhs, rhs])
 
         return None
