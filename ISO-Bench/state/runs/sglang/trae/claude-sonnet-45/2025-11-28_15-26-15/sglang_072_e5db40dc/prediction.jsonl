{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-b170930", "model_patch": "diff --git a/python/sglang/srt/server.py b/python/sglang/srt/server.py\nindex dea4a7d04..045e90083 100644\n--- a/python/sglang/srt/server.py\n+++ b/python/sglang/srt/server.py\n@@ -21,19 +21,19 @@ SRT = SGLang Runtime.\n import asyncio\n import atexit\n import dataclasses\n-import json\n import logging\n import multiprocessing as mp\n import os\n import threading\n import time\n from http import HTTPStatus\n-from typing import Dict, List, Optional, Union\n+from typing import AsyncIterator, Dict, List, Optional, Union\n \n # Fix a bug of Python threading\n setattr(threading, \"_register_atexit\", lambda *args, **kwargs: None)\n \n import aiohttp\n+import orjson\n import requests\n import uvicorn\n import uvloop\n@@ -192,14 +192,14 @@ async def generate_request(obj: GenerateReqInput, request: Request):\n     \"\"\"Handle a generate request.\"\"\"\n     if obj.stream:\n \n-        async def stream_results():\n+        async def stream_results() -> AsyncIterator[bytes]:\n             try:\n                 async for out in tokenizer_manager.generate_request(obj, request):\n-                    yield f\"data: {json.dumps(out, ensure_ascii=False)}\\n\\n\"\n+                    yield b\"data: \" + orjson.dumps(out, option=orjson.OPT_NON_STR_KEYS) + b\"\\n\\n\"\n             except ValueError as e:\n                 out = {\"error\": {\"message\": str(e)}}\n-                yield f\"data: {json.dumps(out, ensure_ascii=False)}\\n\\n\"\n-            yield \"data: [DONE]\\n\\n\"\n+                yield b\"data: \" + orjson.dumps(out, option=orjson.OPT_NON_STR_KEYS) + b\"\\n\\n\"\n+            yield b\"data: [DONE]\\n\\n\"\n \n         return StreamingResponse(\n             stream_results(),\n@@ -635,11 +635,10 @@ class Runtime:\n         async with aiohttp.ClientSession(timeout=timeout, trust_env=True) as session:\n             async with session.post(self.generate_url, json=json_data) as response:\n                 async for chunk, _ in response.content.iter_chunks():\n-                    chunk = chunk.decode(\"utf-8\")\n-                    if chunk and chunk.startswith(\"data:\"):\n-                        if chunk == \"data: [DONE]\\n\\n\":\n+                    if chunk and chunk.startswith(b\"data:\"):\n+                        if chunk == b\"data: [DONE]\\n\\n\":\n                             break\n-                        data = json.loads(chunk[5:].strip(\"\\n\"))\n+                        data = orjson.loads(chunk[5:].strip())\n                         if \"text\" in data:\n                             cur = data[\"text\"][pos:]\n                             if cur:\n@@ -672,7 +671,7 @@ class Runtime:\n             self.url + \"/generate\",\n             json=json_data,\n         )\n-        return json.dumps(response.json())\n+        return orjson.dumps(response.json()).decode(\"utf-8\")\n \n     def encode(\n         self,\n@@ -696,7 +695,7 @@ class Runtime:\n                 self.url + \"/judge\",\n                 json=json_data,\n             )\n-        return json.dumps(response.json())\n+        return orjson.dumps(response.json()).decode(\"utf-8\")\n \n     def __del__(self):\n         self.shutdown()\n@@ -745,8 +744,8 @@ class Engine:\n         ret = loop.run_until_complete(generate_request(obj, None))\n \n         if stream is True:\n-            STREAM_END_SYMBOL = \"data: [DONE]\"\n-            STREAM_CHUNK_START_SYMBOL = \"data:\"\n+            STREAM_END_SYMBOL = b\"data: [DONE]\"\n+            STREAM_CHUNK_START_SYMBOL = b\"data:\"\n \n             def generator_wrapper():\n                 offset = 0\n@@ -758,7 +757,7 @@ class Engine:\n                     if chunk.startswith(STREAM_END_SYMBOL):\n                         break\n                     else:\n-                        data = json.loads(chunk[len(STREAM_CHUNK_START_SYMBOL) :])\n+                        data = orjson.loads(chunk[len(STREAM_CHUNK_START_SYMBOL) :].strip())\n                         data[\"text\"] = data[\"text\"][offset:]\n                         offset += len(data[\"text\"])\n                         yield data\n@@ -792,8 +791,8 @@ class Engine:\n         ret = await generate_request(obj, None)\n \n         if stream is True:\n-            STREAM_END_SYMBOL = \"data: [DONE]\"\n-            STREAM_CHUNK_START_SYMBOL = \"data:\"\n+            STREAM_END_SYMBOL = b\"data: [DONE]\"\n+            STREAM_CHUNK_START_SYMBOL = b\"data:\"\n \n             generator = ret.body_iterator\n \n@@ -807,7 +806,7 @@ class Engine:\n                     if chunk.startswith(STREAM_END_SYMBOL):\n                         break\n                     else:\n-                        data = json.loads(chunk[len(STREAM_CHUNK_START_SYMBOL) :])\n+                        data = orjson.loads(chunk[len(STREAM_CHUNK_START_SYMBOL) :].strip())\n                         data[\"text\"] = data[\"text\"][offset:]\n                         offset += len(data[\"text\"])\n                         yield data\n", "model_name_or_path": "gpt-5-2025-08-07"}
