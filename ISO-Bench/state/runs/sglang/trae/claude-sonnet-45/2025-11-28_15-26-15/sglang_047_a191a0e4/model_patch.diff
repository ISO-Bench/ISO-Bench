diff --git a/model_patch.diff b/model_patch.diff
new file mode 100644
index 000000000..e69de29bb
diff --git a/python/sglang/srt/two_batch_overlap.py b/python/sglang/srt/two_batch_overlap.py
index 0fbc3c8e7..2560de245 100644
--- a/python/sglang/srt/two_batch_overlap.py
+++ b/python/sglang/srt/two_batch_overlap.py
@@ -40,13 +40,21 @@ def compute_split_seq_index(
 
 def _split_array_by_half_sum(arr: Sequence[int]) -> int:
     overall_sum = sum(arr)
-    accumulator, split_index = 0, 0
-    for value in arr[:-1]:
-        accumulator += value
-        split_index += 1
-        if accumulator >= overall_sum // 2:
+    left_sum = 0
+    min_diff = float("inf")
+    best_index = 0
+
+    for i in range(1, len(arr)):
+        left_sum += arr[i - 1]
+        right_sum = overall_sum - left_sum
+        diff = abs(left_sum - right_sum)
+        if diff <= min_diff:
+            min_diff = diff
+            best_index = i
+        else:
             break
-    return split_index
+
+    return best_index
 
 
 def compute_split_token_index(
@@ -139,17 +147,15 @@ class TboDPAttentionPreparer:
 
     @staticmethod
     def _compute_global_forward_mode(forward_modes):
-        converted_forward_modes = [
-            ForwardMode.DECODE.value if x == ForwardMode.IDLE.value else x
-            for x in forward_modes
-        ]
-        forward_mode_agree = TboDPAttentionPreparer._is_all_same(
-            converted_forward_modes
-        )
-        global_forward_mode = (
-            ForwardMode(converted_forward_modes[0]) if forward_mode_agree else None
-        )
-        return global_forward_mode, forward_mode_agree
+        def _convert(x):
+            return ForwardMode.DECODE.value if x == ForwardMode.IDLE.value else x
+
+        it = iter(forward_modes)
+        first = _convert(next(it))
+        for x in it:
+            if _convert(x) != first:
+                return None, False
+        return ForwardMode(first), True
 
     @staticmethod
     def _is_all_same(x):
@@ -268,7 +274,7 @@ class TboForwardBatchPreparer:
         # TODO improve, e.g. unify w/ `init_raw`
         if global_server_args_dict["moe_dense_tp_size"] == 1:
             sum_len = end_token_index - start_token_index
-            gathered_buffer = torch.zeros(
+            gathered_buffer = torch.empty(
                 (sum_len, batch.gathered_buffer.shape[1]),
                 dtype=batch.gathered_buffer.dtype,
                 device=batch.gathered_buffer.device,
