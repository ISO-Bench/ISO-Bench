{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-e3bed74", "model_patch": "diff --git a/model_patch.diff b/model_patch.diff\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/python/sglang/srt/layers/moe/fused_moe_triton/layer.py b/python/sglang/srt/layers/moe/fused_moe_triton/layer.py\nindex 74c6216ac..5c9d12e0c 100644\n--- a/python/sglang/srt/layers/moe/fused_moe_triton/layer.py\n+++ b/python/sglang/srt/layers/moe/fused_moe_triton/layer.py\n@@ -170,6 +170,7 @@ class UnquantizedFusedMoEMethod(FusedMoEMethodBase, CustomOp):\n         inplace: bool = True,\n         no_combine: bool = False,\n         routed_scaling_factor: Optional[float] = None,\n+        num_token_non_padded: Optional[torch.Tensor] = None,\n     ) -> torch.Tensor:\n         topk_weights, topk_ids = select_experts(\n             hidden_states=x,\n@@ -182,6 +183,7 @@ class UnquantizedFusedMoEMethod(FusedMoEMethodBase, CustomOp):\n             custom_routing_function=custom_routing_function,\n             correction_bias=correction_bias,\n             routed_scaling_factor=routed_scaling_factor,\n+            num_token_non_padded=num_token_non_padded,\n         )\n \n         if _is_hip and get_bool_env_var(\"SGLANG_AITER_MOE\"):\n@@ -637,7 +639,7 @@ class FusedMoE(torch.nn.Module):\n             )\n             return\n \n-    def forward(self, hidden_states: torch.Tensor, router_logits: torch.Tensor):\n+    def forward(self, hidden_states: torch.Tensor, router_logits: torch.Tensor, num_token_non_padded: Optional[torch.Tensor] = None):\n         assert self.quant_method is not None\n \n         # Matrix multiply.\n@@ -655,6 +657,7 @@ class FusedMoE(torch.nn.Module):\n             activation=self.activation,\n             apply_router_weight_on_input=self.apply_router_weight_on_input,\n             routed_scaling_factor=self.routed_scaling_factor,\n+            num_token_non_padded=num_token_non_padded,\n         )\n \n         if self.reduce_results and self.tp_size > 1:\ndiff --git a/python/sglang/srt/layers/moe/topk.py b/python/sglang/srt/layers/moe/topk.py\nindex a7af87144..c5d547ce3 100644\n--- a/python/sglang/srt/layers/moe/topk.py\n+++ b/python/sglang/srt/layers/moe/topk.py\n@@ -35,6 +35,19 @@ if _is_cuda or _is_hip:\n expert_distribution_recorder = ExpertDistributionRecorder()\n \n \n+\n+def _mask_topk_ids_padded_region(topk_ids: torch.Tensor, num_token_non_padded: Optional[torch.Tensor]):\n+    if num_token_non_padded is None:\n+        return\n+    # Accept int or 0-dim/1-dim tensor\n+    if isinstance(num_token_non_padded, torch.Tensor):\n+        n = int(num_token_non_padded.item()) if num_token_non_padded.dim() == 0 else int(num_token_non_padded)\n+    else:\n+        n = int(num_token_non_padded)\n+    if n < topk_ids.shape[0]:\n+        topk_ids[n:, :].fill_(0)\n+\n+\n def fused_topk_native(\n     hidden_states: torch.Tensor,\n     gating_output: torch.Tensor,\n@@ -45,10 +58,6 @@ def fused_topk_native(\n         hidden_states.shape[0] == gating_output.shape[0]\n     ), f\"Number of tokens mismatch, {hidden_states.shape=} vs {gating_output.shape=}\"\n     M, _ = hidden_states.shape\n-    topk_weights = torch.empty(\n-        M, topk, dtype=torch.float32, device=hidden_states.device\n-    )\n-    topk_ids = torch.empty(M, topk, dtype=torch.int32, device=hidden_states.device)\n     topk_weights = F.softmax(gating_output.float(), dim=-1)\n     topk_weights, topk_ids = torch.topk(topk_weights, topk, dim=-1)\n     if renormalize:\n@@ -99,6 +108,7 @@ def grouped_topk(\n     topk_group: int = 0,\n     n_share_experts_fusion: int = 0,\n     routed_scaling_factor: Optional[float] = None,\n+    num_token_non_padded: Optional[torch.Tensor] = None,\n ):\n     assert hidden_states.shape[0] == gating_output.shape[0], \"Number of tokens mismatch\"\n \n@@ -111,7 +121,8 @@ def grouped_topk(\n     group_idx = torch.topk(group_scores, k=topk_group, dim=-1, sorted=False)[\n         1\n     ]  # [n, top_k_group]\n-    group_mask = torch.zeros_like(group_scores)  # [n, n_group]\n+    group_mask = torch.empty_like(group_scores)  # [n, n_group]\n+    group_mask.fill_(0)\n     group_mask.scatter_(1, group_idx, 1)  # [n, n_group]\n     score_mask = (\n         group_mask.unsqueeze(-1)\n@@ -138,7 +149,10 @@ def grouped_topk(\n         )\n         topk_weights = topk_weights / topk_weights_sum\n \n-    return topk_weights.to(torch.float32), topk_ids.to(torch.int32)\n+    topk_weights, topk_ids = topk_weights.to(torch.float32), topk_ids.to(torch.int32)\n+    _mask_topk_ids_padded_region(topk_ids, num_token_non_padded)\n+    return topk_weights, topk_ids\n+\n \n \n def biased_grouped_topk_impl(\n@@ -151,6 +165,7 @@ def biased_grouped_topk_impl(\n     topk_group: int = 0,\n     n_share_experts_fusion: int = 0,\n     routed_scaling_factor: Optional[float] = None,\n+    num_token_non_padded: Optional[torch.Tensor] = None,\n ):\n     assert hidden_states.shape[0] == gating_output.shape[0], \"Number of tokens mismatch\"\n \n@@ -166,7 +181,8 @@ def biased_grouped_topk_impl(\n     group_idx = torch.topk(group_scores, k=topk_group, dim=-1, sorted=False)[\n         1\n     ]  # [n, top_k_group]\n-    group_mask = torch.zeros_like(group_scores)  # [n, n_group]\n+    group_mask = torch.empty_like(group_scores)  # [n, n_group]\n+    group_mask.fill_(0)\n     group_mask.scatter_(1, group_idx, 1)  # [n, n_group]\n     score_mask = (\n         group_mask.unsqueeze(-1)\n@@ -197,7 +213,10 @@ def biased_grouped_topk_impl(\n         )\n         topk_weights = topk_weights / topk_weights_sum\n \n-    return topk_weights.to(torch.float32), topk_ids.to(torch.int32)\n+    topk_weights, topk_ids = topk_weights.to(torch.float32), topk_ids.to(torch.int32)\n+    _mask_topk_ids_padded_region(topk_ids, num_token_non_padded)\n+    return topk_weights, topk_ids\n+\n \n \n def is_power_of_two(n):\n@@ -215,6 +234,7 @@ def biased_grouped_topk(\n     compiled: bool = True,\n     n_share_experts_fusion: int = 0,\n     routed_scaling_factor: Optional[float] = None,\n+    num_token_non_padded: Optional[torch.Tensor] = None,\n ):\n     assert (\n         routed_scaling_factor is not None\n@@ -253,6 +273,7 @@ def biased_grouped_topk(\n             topk_group,\n             n_share_experts_fusion=n_share_experts_fusion,\n             routed_scaling_factor=routed_scaling_factor,\n+            num_token_non_padded=num_token_non_padded,\n         )\n \n \n@@ -268,6 +289,7 @@ def select_experts(\n     correction_bias: Optional[torch.Tensor] = None,\n     torch_native: bool = False,\n     routed_scaling_factor: Optional[float] = None,\n+    num_token_non_padded: Optional[torch.Tensor] = None,\n ):\n     n_share_experts_fusion = global_server_args_dict[\"n_share_experts_fusion\"]\n     # DeepSeek V2/V3/R1 series models use grouped_top_k\n@@ -284,6 +306,7 @@ def select_experts(\n                 topk_group=topk_group,\n                 n_share_experts_fusion=n_share_experts_fusion,\n                 routed_scaling_factor=routed_scaling_factor,\n+                num_token_non_padded=num_token_non_padded,\n             )\n         else:\n             topk_weights, topk_ids = biased_grouped_topk(\n@@ -296,6 +319,7 @@ def select_experts(\n                 topk_group=topk_group,\n                 n_share_experts_fusion=n_share_experts_fusion,\n                 routed_scaling_factor=routed_scaling_factor,\n+                num_token_non_padded=num_token_non_padded,\n             )\n     elif torch_native and custom_routing_function is None:\n         topk_weights, topk_ids = fused_topk_native(\ndiff --git a/python/sglang/srt/model_executor/cuda_graph_runner.py b/python/sglang/srt/model_executor/cuda_graph_runner.py\nindex e88022beb..0c33e91cc 100644\n--- a/python/sglang/srt/model_executor/cuda_graph_runner.py\n+++ b/python/sglang/srt/model_executor/cuda_graph_runner.py\n@@ -232,23 +232,24 @@ class CudaGraphRunner:\n \n         # Graph inputs\n         with torch.device(\"cuda\"):\n-            self.input_ids = torch.zeros((self.max_num_token,), dtype=torch.int64)\n-            self.req_pool_indices = torch.zeros((self.max_bs,), dtype=torch.int32)\n+            self.input_ids = torch.empty((self.max_num_token,), dtype=torch.int64)\n+            self.req_pool_indices = torch.empty((self.max_bs,), dtype=torch.int32)\n             self.seq_lens = torch.full(\n                 (self.max_bs,), self.seq_len_fill_value, dtype=torch.int32\n             )\n-            self.out_cache_loc = torch.zeros((self.max_num_token,), dtype=torch.int64)\n-            self.positions = torch.zeros((self.max_num_token,), dtype=torch.int64)\n-            self.mrope_positions = torch.zeros((3, self.max_bs), dtype=torch.int64)\n+            self.out_cache_loc = torch.empty((self.max_num_token,), dtype=torch.int64)\n+            self.positions = torch.empty((self.max_num_token,), dtype=torch.int64)\n+            self.mrope_positions = torch.empty((3, self.max_bs), dtype=torch.int64)\n+            self.num_token_non_padded = torch.empty((1,), dtype=torch.int32)\n \n             # pipeline parallelism\n             if self.pp_size > 1:\n                 self.pp_proxy_tensors = {\n-                    \"hidden_states\": torch.zeros(\n+                    \"hidden_states\": torch.empty(\n                         (self.max_bs, self.model_runner.model_config.hidden_size),\n                         dtype=torch.bfloat16,\n                     ),\n-                    \"residual\": torch.zeros(\n+                    \"residual\": torch.empty(\n                         (self.max_bs, self.model_runner.model_config.hidden_size),\n                         dtype=torch.bfloat16,\n                     ),\n@@ -259,7 +260,7 @@ class CudaGraphRunner:\n                 model_runner.spec_algorithm.is_eagle3()\n                 and not model_runner.is_draft_worker\n             ):\n-                self.hidden_states = torch.zeros(\n+                self.hidden_states = torch.empty(\n                     (\n                         self.max_num_token,\n                         3 * self.model_runner.model_config.hidden_size,\n@@ -268,7 +269,7 @@ class CudaGraphRunner:\n                 )\n                 self.model_runner.model.set_eagle3_layers_to_capture()\n             elif model_runner.spec_algorithm.is_eagle():\n-                self.hidden_states = torch.zeros(\n+                self.hidden_states = torch.empty(\n                     (self.max_num_token, self.model_runner.model_config.hidden_size),\n                     dtype=self.model_runner.dtype,\n                 )\n@@ -282,14 +283,14 @@ class CudaGraphRunner:\n                 self.encoder_lens = None\n             if self.enable_dp_attention or self.enable_sp_layernorm:\n                 # TODO(ch-wan): SP layernorm should use a different logic to manage gathered_buffer\n-                self.gathered_buffer = torch.zeros(\n+                self.gathered_buffer = torch.empty(\n                     (\n                         self.max_bs * self.dp_size * self.num_tokens_per_bs,\n                         self.model_runner.model_config.hidden_size,\n                     ),\n                     dtype=self.model_runner.dtype,\n                 )\n-                self.global_num_tokens_gpu = torch.zeros(\n+                self.global_num_tokens_gpu = torch.empty(\n                     (self.dp_size,), dtype=torch.int32\n                 )\n \n@@ -461,6 +462,7 @@ class CudaGraphRunner:\n             spec_info=spec_info,\n             capture_hidden_mode=self.capture_hidden_mode,\n             lora_paths=lora_paths,\n+            num_token_non_padded=self.num_token_non_padded,\n         )\n \n         if lora_paths is not None:\n@@ -572,6 +574,9 @@ class CudaGraphRunner:\n             self.mrope_positions[:, :raw_bs].copy_(forward_batch.mrope_positions)\n         if self.enable_dp_attention or self.enable_sp_layernorm:\n             self.global_num_tokens_gpu.copy_(forward_batch.global_num_tokens_gpu)\n+        \n+        # Set num_token_non_padded for MoE optimization\n+        self.num_token_non_padded[0] = raw_bs\n \n         if hasattr(forward_batch.spec_info, \"hidden_states\"):\n             self.hidden_states[:raw_num_token] = forward_batch.spec_info.hidden_states\ndiff --git a/python/sglang/srt/model_executor/forward_batch_info.py b/python/sglang/srt/model_executor/forward_batch_info.py\nindex 5018f92d5..d79a8c2ba 100644\n--- a/python/sglang/srt/model_executor/forward_batch_info.py\n+++ b/python/sglang/srt/model_executor/forward_batch_info.py\n@@ -247,6 +247,7 @@ class ForwardBatch:\n \n     # For padding\n     padded_static_len: int = -1  # -1 if not padded\n+    num_token_non_padded: Optional[torch.Tensor] = None\n \n     # For Qwen2-VL\n     mrope_positions: torch.Tensor = None\n@@ -305,7 +306,7 @@ class ForwardBatch:\n             ).to(device, non_blocking=True)\n \n             sum_len = sum(batch.global_num_tokens)\n-            ret.gathered_buffer = torch.zeros(\n+            ret.gathered_buffer = torch.empty(\n                 (sum_len, model_runner.model_config.hidden_size),\n                 dtype=model_runner.dtype,\n                 device=device,\n@@ -565,12 +566,13 @@ class ForwardBatch:\n         self.prefix_chunk_seq_lens = prefix_chunk_seq_lens_cuda\n \n         # Metadata for attention backend\n-        self.prefix_chunk_cu_seq_lens = torch.zeros(\n+        self.prefix_chunk_cu_seq_lens = torch.empty(\n             self.num_prefix_chunks,\n             self.batch_size + 1,\n             device=device,\n             dtype=torch.int32,\n         )\n+        self.prefix_chunk_cu_seq_lens[:, 0].zero_()\n         self.prefix_chunk_cu_seq_lens[:, 1:] = prefix_chunk_seq_lens_cuda.cumsum(\n             dim=1\n         ).to(torch.int32)\n@@ -683,7 +685,8 @@ def compute_position_torch(\n         ],\n         axis=0,\n     )\n-    extend_start_loc = torch.zeros_like(extend_seq_lens)\n+    extend_start_loc = torch.empty_like(extend_seq_lens)\n+    extend_start_loc[0] = 0\n     extend_start_loc[1:] = torch.cumsum(extend_seq_lens[:-1], dim=0)\n     return positions.to(torch.int64), extend_start_loc\n \ndiff --git a/python/sglang/srt/models/deepseek_v2.py b/python/sglang/srt/models/deepseek_v2.py\nindex 436e966db..16e2da730 100644\n--- a/python/sglang/srt/models/deepseek_v2.py\n+++ b/python/sglang/srt/models/deepseek_v2.py\n@@ -287,19 +287,19 @@ class DeepseekV2MoE(nn.Module):\n             )\n \n     def forward(\n-        self, hidden_states: torch.Tensor, forward_mode: Optional[ForwardMode] = None\n+        self, hidden_states: torch.Tensor, forward_mode: Optional[ForwardMode] = None, num_token_non_padded: Optional[torch.Tensor] = None\n     ) -> torch.Tensor:\n         if not global_server_args_dict[\"enable_deepep_moe\"]:\n-            return self.forward_normal(hidden_states)\n+            return self.forward_normal(hidden_states, num_token_non_padded)\n         else:\n-            return self.forward_deepep(hidden_states, forward_mode)\n+            return self.forward_deepep(hidden_states, forward_mode, num_token_non_padded)\n \n-    def forward_normal(self, hidden_states: torch.Tensor) -> torch.Tensor:\n+    def forward_normal(self, hidden_states: torch.Tensor, num_token_non_padded: Optional[torch.Tensor] = None) -> torch.Tensor:\n         shared_output = self._forward_shared_experts(hidden_states)\n         # router_logits: (num_tokens, n_experts)\n         router_logits = self.gate(hidden_states)\n         final_hidden_states = self.experts(\n-            hidden_states=hidden_states, router_logits=router_logits\n+            hidden_states=hidden_states, router_logits=router_logits, num_token_non_padded=num_token_non_padded\n         )\n         final_hidden_states *= self.routed_scaling_factor\n         if shared_output is not None:\n@@ -309,7 +309,7 @@ class DeepseekV2MoE(nn.Module):\n         return final_hidden_states\n \n     def forward_deepep(\n-        self, hidden_states: torch.Tensor, forward_mode: ForwardMode\n+        self, hidden_states: torch.Tensor, forward_mode: ForwardMode, num_token_non_padded: Optional[torch.Tensor] = None\n     ) -> torch.Tensor:\n         shared_output = None\n         if (\n@@ -330,10 +330,11 @@ class DeepseekV2MoE(nn.Module):\n                 num_expert_group=self.num_expert_group,\n                 correction_bias=self.correction_bias,\n                 routed_scaling_factor=self.routed_scaling_factor,\n+                num_token_non_padded=num_token_non_padded,\n             )\n         else:\n-            topk_idx = torch.full(\n-                (0, self.top_k), -1, dtype=torch.int, device=hidden_states.device\n+            topk_idx = torch.empty(\n+                (0, self.top_k), dtype=torch.int, device=hidden_states.device\n             )\n             topk_weights = torch.empty(\n                 (0, self.top_k), dtype=torch.float32, device=hidden_states.device\n@@ -1272,7 +1273,7 @@ class DeepseekV2DecoderLayer(nn.Module):\n             )\n \n         # Fully Connected\n-        hidden_states = self.mlp(hidden_states)\n+        hidden_states = self.mlp(hidden_states, num_token_non_padded=forward_batch.num_token_non_padded)\n \n         # TODO(ch-wan): use reduce-scatter in MLP to avoid this scatter\n         # Scatter\n@@ -1339,7 +1340,7 @@ class DeepseekV2DecoderLayer(nn.Module):\n             and (not self.info.is_sparse)\n             and hidden_states.shape[0] == 0\n         ):\n-            hidden_states = self.mlp(hidden_states, forward_batch.forward_mode)\n+            hidden_states = self.mlp(hidden_states, forward_batch.forward_mode, num_token_non_padded=forward_batch.num_token_non_padded)\n \n         if self.is_last_layer and self.attn_tp_size != 1:\n             hidden_states += residual\n", "model_name_or_path": "gpt-5-2025-08-07"}
