diff --git a/docker/Dockerfile.rocm b/docker/Dockerfile.rocm
index 84ea69cc0..0c0b7e019 100644
--- a/docker/Dockerfile.rocm
+++ b/docker/Dockerfile.rocm
@@ -2,7 +2,7 @@
 #   docker build --build-arg SGL_BRANCH=v0.4.1.post3 -t v0.4.1.post3-rocm620 -f Dockerfile.rocm .
 
 # default base image
-ARG BASE_IMAGE="rocm/vllm-dev:20241031-tuned"
+ARG BASE_IMAGE="rocmshared/vllm-rocm:20241031-tuned"
 
 FROM $BASE_IMAGE AS base
 USER root
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py b/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py
index cbacd90c0..fde1174f4 100644
--- a/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py
+++ b/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py
@@ -263,15 +263,14 @@ def moe_align_block_size(
         by block_size for proper block matrix operations.
     """
     max_num_tokens_padded = topk_ids.numel() + num_experts * (block_size - 1)
-    sorted_ids = torch.empty(
-        (max_num_tokens_padded,), dtype=torch.int32, device=topk_ids.device
+    sorted_ids = torch.full(
+        (max_num_tokens_padded,), topk_ids.numel(), dtype=torch.int32, device=topk_ids.device
     )
-    sorted_ids.fill_(topk_ids.numel())
     max_num_m_blocks = triton.cdiv(max_num_tokens_padded, block_size)
     expert_ids = torch.empty(
         (max_num_m_blocks,), dtype=torch.int32, device=topk_ids.device
     )
-    num_tokens_post_pad = torch.empty((1), dtype=torch.int32, device=topk_ids.device)
+    num_tokens_post_pad = torch.empty(1, dtype=torch.int32, device=topk_ids.device)
     if not_hip and num_experts >= 224:
         token_cnts_buffer = torch.empty(
             (num_experts + 1) * num_experts, dtype=torch.int32, device=topk_ids.device
@@ -854,11 +853,22 @@ def fused_experts_impl(
             block_shape=block_shape,
         )
 
-        torch.sum(
-            intermediate_cache3.view(*intermediate_cache3.shape),
-            dim=1,
-            out=out_hidden_states[begin_chunk_idx:end_chunk_idx],
-        )
+        if not_hip:
+            torch.sum(
+                intermediate_cache3,
+                dim=1,
+                out=out_hidden_states[begin_chunk_idx:end_chunk_idx],
+            )
+        else:
+            out_slice = out_hidden_states[begin_chunk_idx:end_chunk_idx]
+            vals = intermediate_cache3
+            tk = vals.shape[1]
+            if tk == 1:
+                out_slice.copy_(vals[:, 0, :])
+            else:
+                out_slice.copy_(vals[:, 0, :])
+                for i in range(1, tk):
+                    out_slice.add_(vals[:, i, :])
     return out_hidden_states
 
 
