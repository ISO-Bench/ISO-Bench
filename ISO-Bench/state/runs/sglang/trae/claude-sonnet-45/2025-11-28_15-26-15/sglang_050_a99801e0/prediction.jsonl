{"instance_id": "/home/ubuntu/OmniPerf-Bench/sglan__repo-4c60523", "model_patch": "diff --git a/python/sglang/srt/mem_cache/allocator.py b/python/sglang/srt/mem_cache/allocator.py\nindex 7dd488e9c..bb33a565d 100644\n--- a/python/sglang/srt/mem_cache/allocator.py\n+++ b/python/sglang/srt/mem_cache/allocator.py\n@@ -51,6 +51,7 @@ class BaseTokenToKVPoolAllocator(abc.ABC):\n         self._kvcache = kvcache\n \n         self.free_pages = None\n+        self.release_pages = None\n         self.is_not_in_free_group = True\n         self.free_group = []\n \n@@ -58,16 +59,25 @@ class BaseTokenToKVPoolAllocator(abc.ABC):\n         return \"\"\n \n     def available_size(self):\n-        return len(self.free_pages) * self.page_size\n+        release_cnt = 0\n+        if isinstance(self.release_pages, list) and self.release_pages:\n+            release_cnt = sum(x.numel() for x in self.release_pages)\n+        elif isinstance(self.release_pages, torch.Tensor):\n+            release_cnt = len(self.release_pages)\n+        return (len(self.free_pages) + release_cnt) * self.page_size\n \n     def get_kvcache(self):\n         return self._kvcache\n \n-    def restore_state(self, free_pages):\n-        self.free_pages = free_pages\n+    def restore_state(self, state):\n+        if isinstance(state, tuple) and len(state) == 2:\n+            self.free_pages, self.release_pages = state\n+        else:\n+            self.free_pages = state\n+            self.release_pages = []\n \n     def backup_state(self):\n-        return self.free_pages\n+        return (self.free_pages, self.release_pages)\n \n     def free_group_begin(self):\n         self.is_not_in_free_group = False\n@@ -110,6 +120,7 @@ class TokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n \n     def __init__(self, size: int, dtype: torch.dtype, device: str, kvcache: KVCache):\n         super().__init__(size, 1, dtype, device, kvcache)\n+        self._release_count = 0\n         self.clear()\n \n     def clear(self):\n@@ -117,16 +128,21 @@ class TokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n         self.free_pages = torch.arange(\n             1, self.size + 1, dtype=torch.int64, device=self.device\n         )\n+        self.release_pages = []\n+        self._release_count = 0\n         self.is_not_in_free_group = True\n         self.free_group = []\n \n     def available_size(self):\n-        # To avoid minor \"len(free_pages) * 1\" overhead\n-        return len(self.free_pages)\n+        # Use cached release count for better performance\n+        return len(self.free_pages) + self._release_count\n \n     def alloc(self, need_size: int):\n         if need_size > len(self.free_pages):\n-            return None\n+            if self.release_pages:\n+                self._flush_release_pages()\n+            if need_size > len(self.free_pages):\n+                return None\n \n         select_index = self.free_pages[:need_size]\n         self.free_pages = self.free_pages[need_size:]\n@@ -137,13 +153,25 @@ class TokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n             return\n \n         if self.is_not_in_free_group:\n-            self.free_pages = torch.cat((self.free_pages, free_index))\n+            self.release_pages.append(free_index)\n+            self._release_count += free_index.numel()\n         else:\n             self.free_group.append(free_index)\n \n     def get_cpu_copy(self, indices):\n         return self._kvcache.get_cpu_copy(indices)\n \n+    def _flush_release_pages(self):\n+        if not self.release_pages:\n+            return\n+        # Concatenate all tensors at once for better performance\n+        all_pages = [self.free_pages] + self.release_pages\n+        merged = torch.cat(all_pages)\n+        self.free_pages = torch.sort(merged)[0]\n+        self.release_pages = []\n+        self._release_count = 0\n+\n+\n     def load_cpu_copy(self, kv_cache_cpu, indices):\n         return self._kvcache.load_cpu_copy(kv_cache_cpu, indices)\n \n@@ -411,6 +439,7 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n         self.num_pages = size // page_size\n         self.debug_mode = get_bool_env_var(\"SGLANG_DEBUG_MEMORY_POOL\")\n         self.ret_values = torch.empty((), dtype=torch.int64, device=self.device)\n+        self._page_offsets = torch.arange(self.page_size, device=self.device)\n         self.clear()\n \n     def alloc(self, need_size: int):\n@@ -422,14 +451,17 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n \n         num_pages = need_size // self.page_size\n         if num_pages > len(self.free_pages):\n-            return None\n+            if self.release_pages:\n+                self._flush_release_pages()\n+            if num_pages > len(self.free_pages):\n+                return None\n \n         out_pages = self.free_pages[:num_pages]\n         self.free_pages = self.free_pages[num_pages:]\n \n         out_indices = (\n             out_pages[:, None] * self.page_size\n-            + torch.arange(self.page_size, device=self.device)\n+            + self._page_offsets\n         ).reshape(-1)\n \n         return out_indices\n@@ -446,6 +478,10 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n                 (last_loc + 1) % self.page_size == prefix_lens % self.page_size\n             )\n \n+\n+        if self.release_pages:\n+            self._flush_release_pages()\n+\n         bs = len(prefix_lens)\n         out_indices = torch.empty(\n             (extend_num_tokens,), dtype=torch.int64, device=self.device\n@@ -483,6 +519,10 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n                 (last_loc + 2) % self.page_size == seq_lens % self.page_size\n             )\n \n+\n+        if self.release_pages:\n+            self._flush_release_pages()\n+\n         bs = len(seq_lens)\n         out_indices = torch.empty((bs,), dtype=torch.int64, device=self.device)\n         alloc_decode_kernel[(bs,)](\n@@ -511,7 +551,7 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n \n         if self.is_not_in_free_group:\n             free_page_indices = torch.unique(free_index // self.page_size)\n-            self.free_pages = torch.cat((free_page_indices, self.free_pages))\n+            self.release_pages.append(free_page_indices)\n         else:\n             self.free_group.append(free_index)\n \n@@ -523,9 +563,20 @@ class PagedTokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):\n         self.free_pages = torch.arange(\n             1, self.num_pages + 1, dtype=torch.int64, device=self.device\n         )\n+        self.release_pages = []\n         self.is_not_in_free_group = True\n         self.free_group = []\n \n+\n+    def _flush_release_pages(self):\n+        if not self.release_pages:\n+            return\n+        # Concatenate all tensors at once for better performance\n+        all_pages = [self.free_pages] + self.release_pages\n+        merged = torch.cat(all_pages)\n+        self.free_pages = torch.sort(merged)[0]\n+        self.release_pages = []\n+\n     def get_cpu_copy(self, indices):\n         return self._kvcache.get_cpu_copy(indices)\n \n@@ -633,6 +684,10 @@ class AscendPagedTokenToKVPoolAllocator(PagedTokenToKVPoolAllocator):\n                 (last_loc + 1) % self.page_size == prefix_lens % self.page_size\n             )\n \n+\n+        if self.release_pages:\n+            self._flush_release_pages()\n+\n         bs = len(prefix_lens)\n         out_indices = torch.empty(\n             (extend_num_tokens,), dtype=torch.int32, device=self.device\n@@ -668,6 +723,9 @@ class AscendPagedTokenToKVPoolAllocator(PagedTokenToKVPoolAllocator):\n                 (last_loc + 2) % self.page_size == seq_lens % self.page_size\n             )\n \n+        if self.release_pages:\n+            self._flush_release_pages()\n+\n         bs = len(seq_lens)\n         out_indices = torch.empty((bs,), dtype=torch.int32, device=self.device)\n \n", "model_name_or_path": "gpt-5-2025-08-07"}
